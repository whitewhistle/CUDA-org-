{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3989074,"sourceType":"datasetVersion","datasetId":2367101}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-26T03:58:42.001021Z","iopub.execute_input":"2024-01-26T03:58:42.001916Z","iopub.status.idle":"2024-01-26T03:58:42.410792Z","shell.execute_reply.started":"2024-01-26T03:58:42.001882Z","shell.execute_reply":"2024-01-26T03:58:42.409793Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/smoker-status-prediction-using-biosignals/train_dataset.csv\n/kaggle/input/smoker-status-prediction-using-biosignals/test_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\n\nimport argparse, os, shutil, time, random, math\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.utils.data as data\nimport torch.nn.functional as F\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:42.412572Z","iopub.execute_input":"2024-01-26T03:58:42.413056Z","iopub.status.idle":"2024-01-26T03:58:43.992435Z","shell.execute_reply.started":"2024-01-26T03:58:42.413018Z","shell.execute_reply":"2024-01-26T03:58:43.991572Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"bcl.py","metadata":{}},{"cell_type":"code","source":"\"\"\"\nAuthor: Yonglong Tian (yonglong@mit.edu)\nDate: May 07, 2020\n\"\"\"\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport math\nimport torch.nn.functional as F\nimport numpy as np\n\n\n\nclass BalSCL(nn.Module):\n    def __init__(self, cls_num_list=None, temperature=0.1):\n        super(BalSCL, self).__init__()\n        self.temperature = temperature\n        self.cls_num_list = cls_num_list\n\n    def forward(self, centers1, features, targets, ):\n\n        device = (torch.device('cuda')\n                  if features.is_cuda\n                  else torch.device('cpu'))\n        batch_size = features.shape[0]\n        targets = targets.contiguous().view(-1, 1)\n        targets_centers = torch.arange(len(self.cls_num_list), device=device).view(-1, 1)\n        targets = torch.cat([targets.repeat(2, 1), targets_centers], dim=0)\n        batch_cls_count = torch.eye(len(self.cls_num_list))[targets].sum(dim=0).squeeze()\n\n        mask = torch.eq(targets[:2 * batch_size], targets.T).float().to(device)\n        logits_mask = torch.scatter(\n            torch.ones_like(mask),\n            1,\n            torch.arange(batch_size * 2).view(-1, 1).to(device),\n            0\n        )\n        mask = mask * logits_mask\n        \n        # class-complement\n        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n        features = torch.cat([features, centers1], dim=0)\n        logits = features[:2 * batch_size].mm(features.T)\n        logits = torch.div(logits, self.temperature)\n\n        # For numerical stability\n        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n        logits = logits - logits_max.detach()\n\n        # class-averaging\n        exp_logits = torch.exp(logits) * logits_mask\n        per_ins_weight = torch.tensor([batch_cls_count[i] for i in targets], device=device).view(1, -1).expand(\n            2 * batch_size, 2 * batch_size + len(self.cls_num_list)) - mask\n        exp_logits_sum = exp_logits.div(per_ins_weight).sum(dim=1, keepdim=True)\n        \n        log_prob = logits - torch.log(exp_logits_sum)\n        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n\n        loss = - mean_log_prob_pos\n        loss = loss.view(2, batch_size).mean()\n        return loss\n\n\n\n\nclass LogitAdjust(nn.Module):\n\n    def __init__(self, cls_num_list, tau=1, weight=None):\n        super(LogitAdjust, self).__init__()\n        cls_num_list = torch.cuda.FloatTensor(cls_num_list)\n        cls_p_list = cls_num_list / cls_num_list.sum()\n        m_list = tau * torch.log(cls_p_list)\n        self.m_list = m_list.view(1, -1)\n        self.weight = weight\n\n    def forward(self, x, target):\n        x_m = x + self.m_list\n        return F.cross_entropy(x_m, target, weight=self.weight)\n\n\nclass BCLLoss(nn.Module):\n    def __init__(self, cls_num_list, tau=1, weight=None, temperature = 0.1, alpha=2.0, beta=0.6 ):\n        super(BCLLoss, self).__init__()\n        self.criterion_ce = LogitAdjust(cls_num_list).cuda()\n        self.criterion_scl = BalSCL(cls_num_list, temperature).cuda()\n        self.alpha = alpha\n        self.beta = beta\n        \n    def forward(self, centers,  logits, features, targets):\n        scl_loss = self.criterion_scl(centers, features, targets)\n        ce_loss = self.criterion_ce(logits, targets)\n\n        return self.alpha * ce_loss + self.beta * scl_loss\n\n\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:43.993790Z","iopub.execute_input":"2024-01-26T03:58:43.994229Z","iopub.status.idle":"2024-01-26T03:58:44.013931Z","shell.execute_reply.started":"2024-01-26T03:58:43.994201Z","shell.execute_reply":"2024-01-26T03:58:44.013046Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"bs.py","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BS(nn.Module):\n    def __init__(self, dist):\n        super().__init__()\n        dist = torch.from_numpy(np.array(dist)).float().cuda()\n        self.prob = dist / sum(dist)\n        self.log_prior = torch.log(self.prob).unsqueeze(0)\n        \n    def forward(self, logits, targets, epoch=None, reduction='mean'):\n        adjusted_logits = logits + self.log_prior\n        return F.cross_entropy(adjusted_logits, targets, reduction = reduction)\n        \n        \n        # targets = F.one_hot(targets, num_classes=logits.size(1))\n        # logits = logits + torch.log(self.prob.view(1, -1).expand(logits.shape[0], -1)).cuda()\n        \n        # if reduction == 'none':\n        #     return -(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n        # else:\n        #     return -torch.mean(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:44.016547Z","iopub.execute_input":"2024-01-26T03:58:44.017272Z","iopub.status.idle":"2024-01-26T03:58:44.030225Z","shell.execute_reply.started":"2024-01-26T03:58:44.017238Z","shell.execute_reply":"2024-01-26T03:58:44.029388Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"ce drw","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass CE_DRW(nn.Module):\n    \n    def __init__(self, cls_num_list, reweight_epoch=160):\n        super(CE_DRW, self).__init__()\n        self.cls_num_list = cls_num_list\n        self.reweight_epoch= reweight_epoch\n        \n    def drw(self, epoch):\n        idx = epoch // self.reweight_epoch\n        betas = [0, 0.9999]\n        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n        self.weight = per_cls_weights\n\n    def forward(self, x, target, epoch, reduction='mean'):\n        self.drw(epoch)\n        return F.cross_entropy(x, target, weight=self.weight, reduction=reduction)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:44.031361Z","iopub.execute_input":"2024-01-26T03:58:44.031642Z","iopub.status.idle":"2024-01-26T03:58:44.044068Z","shell.execute_reply.started":"2024-01-26T03:58:44.031616Z","shell.execute_reply":"2024-01-26T03:58:44.043039Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"ce","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CE(nn.Module):\n    def __init__(self, weight=None):\n        super().__init__()\n        self.weight = weight\n    def forward(self, logits, targets, epoch=None, reduction='mean'):\n        # targets = F.one_hot(targets, num_classes=logits.size(1))\n        # if reduction == 'mean':\n        #     return -torch.mean(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n        # else:\n        #     return -(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n\n        return F.cross_entropy(logits, targets, weight = self.weight, reduction = reduction)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:44.045239Z","iopub.execute_input":"2024-01-26T03:58:44.045592Z","iopub.status.idle":"2024-01-26T03:58:44.055352Z","shell.execute_reply.started":"2024-01-26T03:58:44.045557Z","shell.execute_reply":"2024-01-26T03:58:44.054176Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"ldam drw","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass LDAM_DRW(nn.Module):\n    def __init__(self, cls_num_list, reweight_epoch, max_m=0.5, s=30):\n        super(LDAM_DRW, self).__init__()\n        self.cls_num_list = cls_num_list\n        self.reweight_epoch = reweight_epoch\n        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n        m_list = m_list * (max_m / np.max(m_list))\n        m_list = torch.cuda.FloatTensor(m_list)\n        self.m_list = m_list\n        assert s > 0\n        self.s = s\n      \n    def drw(self, epoch):\n        idx = epoch // self.reweight_epoch\n        betas = [0, 0.9999]\n        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n        self.weight = per_cls_weights\n\n\n    def forward(self, x, target, epoch=None, reduction='mean'):\n        self.drw(epoch)\n        index = torch.zeros_like(x, dtype=torch.uint8)\n        index.scatter_(1, target.data.view(-1, 1), 1)\n        \n        index_float = index.type(torch.cuda.FloatTensor)\n        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n        batch_m = batch_m.view((-1, 1))\n        x_m = x - batch_m\n    \n        output = torch.where(index, x_m, x)\n        return F.cross_entropy(self.s*output, target, weight=self.weight, reduction=reduction)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:44.056441Z","iopub.execute_input":"2024-01-26T03:58:44.056747Z","iopub.status.idle":"2024-01-26T03:58:44.070321Z","shell.execute_reply.started":"2024-01-26T03:58:44.056723Z","shell.execute_reply":"2024-01-26T03:58:44.069470Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"ncl","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\ndef NBOD(inputs, factor):\n\n    classifier_num = len(inputs)\n    if classifier_num == 1:\n        return 0\n    logits_softmax = []\n    logits_logsoftmax = []\n    for i in range(classifier_num):\n        logits_softmax.append(F.softmax(inputs[i], dim=1))\n        logits_logsoftmax.append(torch.log(logits_softmax[i] + 1e-9))\n\n    loss_mutual = 0\n    for i in range(classifier_num):\n        for j in range(classifier_num):\n            if i == j:\n                continue\n            loss_mutual += factor * F.kl_div(logits_logsoftmax[i], logits_softmax[j],reduction='batchmean')\n    loss_mutual /= (classifier_num - 1)\n    return  loss_mutual\n\nclass NIL_NBOD(nn.Module):\n    def __init__(self, args, num_class_list):\n        super(NIL_NBOD, self).__init__()\n        self.args = args\n        self.num_class_list = num_class_list\n        self.bsce_weight = torch.FloatTensor(self.num_class_list).cuda()\n\n\n        self.multi_classifier_diversity_factor = 0.6\n        self.multi_classifier_diversity_factor_hcm = 0.6\n        self.ce_ratio = 1.0\n        self.hcm_ratio = 1.0\n        if self.args.dataset == 'cifar100':\n            self.hcm_N = 30\n        elif self.args.dataset == 'imgnet':\n            self.hcm_N = 300\n        elif self.args.dataset == 'places':\n            self.hcm_N = 122\n        elif self.args.dataset == 'inat':\n            self.hcm_N = 2442\n\n\n\n    def forward(self, inputs, targets, **kwargs):\n        \"\"\"\n        Args:\n            inputs: prediction matrix (before softmax) with shape (classifier_num, batch_size, num_classes)\n            targets: ground truth labels with shape (classifier_num, batch_size)\n        \"\"\"\n        classifier_num = len(inputs)\n        loss_HCM = 0\n        loss = 0\n        los_ce = 0\n\n        inputs_HCM_balance = []\n        inputs_balance = []\n        class_select = inputs[0].scatter(1, targets[0].unsqueeze(1), 999999)\n        class_select_include_target = class_select.sort(descending=True, dim=1)[1][:, :self.hcm_N]\n        mask = torch.zeros_like(inputs[0]).scatter(1, class_select_include_target, 1)\n        for i in range(classifier_num):\n\n            logits = inputs[i] + self.bsce_weight.unsqueeze(0).expand(inputs[i].shape[0], -1).log()\n            inputs_balance.append(logits)\n            inputs_HCM_balance.append(logits * mask)\n\n            los_ce += F.cross_entropy(logits, targets[0])\n            loss_HCM += F.cross_entropy(inputs_HCM_balance[i], targets[0])\n\n        loss += NBOD(inputs_balance, factor=self.multi_classifier_diversity_factor)\n        loss += NBOD(inputs_HCM_balance, factor=self.multi_classifier_diversity_factor_hcm)\n        loss += los_ce * self.ce_ratio + loss_HCM * self.hcm_ratio\n        return loss\n\n    def update(self, epoch):\n        \"\"\"\n        Args:\n           code can be added for progressive loss.\n        \"\"\"\n        pass\n\n\nif __name__ == '__main__':\n    pass","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:44.071634Z","iopub.execute_input":"2024-01-26T03:58:44.072412Z","iopub.status.idle":"2024-01-26T03:58:44.087920Z","shell.execute_reply.started":"2024-01-26T03:58:44.072376Z","shell.execute_reply":"2024-01-26T03:58:44.087106Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"ride","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nimport random\n\nclass RIDE(nn.Module):\n    def __init__(self, cls_num_list=None, base_diversity_temperature=1.0, max_m=0.5, s=30, reweight=True, reweight_epoch=-1, \n        base_loss_factor=1.0, additional_diversity_factor=-0.2, reweight_factor=0.05):\n        super().__init__()\n        self.base_loss = F.cross_entropy\n        self.base_loss_factor = base_loss_factor\n        if not reweight:\n            self.reweight_epoch = -1\n        else:\n            self.reweight_epoch = reweight_epoch\n\n        # LDAM is a variant of cross entropy and we handle it with self.m_list.\n        if cls_num_list is None:\n            # No cls_num_list is provided, then we cannot adjust cross entropy with LDAM.\n\n            self.m_list = None\n            self.per_cls_weights_enabled = None\n            self.per_cls_weights_enabled_diversity = None\n        else:\n            # We will use LDAM loss if we provide cls_num_list.\n\n            m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n            m_list = m_list * (max_m / np.max(m_list))\n            m_list = torch.tensor(m_list, dtype=torch.float, requires_grad=False)\n            self.m_list = m_list\n            self.s = s\n            assert s > 0\n            \n            if reweight_epoch != -1:\n                idx = 1 # condition could be put in order to set idx\n                betas = [0, 0.9999]\n                effective_num = 1.0 - np.power(betas[idx], cls_num_list)\n                per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n                per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(cls_num_list)\n                self.per_cls_weights_enabled = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False)\n            else:\n                self.per_cls_weights_enabled = None\n\n            cls_num_list = np.array(cls_num_list) / np.sum(cls_num_list)\n            C = len(cls_num_list)\n            per_cls_weights = C * cls_num_list * reweight_factor + 1 - reweight_factor\n\n            # Experimental normalization: This is for easier hyperparam tuning, the effect can be described in the learning rate so the math formulation keeps the same.\n            # At the same time, the 1 - max trick that was previously used is not required since weights are already adjusted.\n            per_cls_weights = per_cls_weights / np.max(per_cls_weights)\n\n            assert np.all(per_cls_weights > 0), \"reweight factor is too large: out of bounds\"\n            # save diversity per_cls_weights\n            self.per_cls_weights_enabled_diversity = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False).cuda()\n\n        self.base_diversity_temperature = base_diversity_temperature\n        self.additional_diversity_factor = additional_diversity_factor\n\n    def to(self, device):\n        super().to(device)\n        if self.m_list is not None:\n            self.m_list = self.m_list.to(device)\n        \n        if self.per_cls_weights_enabled is not None:\n            self.per_cls_weights_enabled = self.per_cls_weights_enabled.to(device)\n\n        if self.per_cls_weights_enabled_diversity is not None:\n            self.per_cls_weights_enabled_diversity = self.per_cls_weights_enabled_diversity.to(device)\n\n        return self\n\n    def _hook_before_epoch(self, epoch):\n        if self.reweight_epoch != -1:\n            self.epoch = epoch\n\n            if epoch > self.reweight_epoch:\n                self.per_cls_weights_base = self.per_cls_weights_enabled\n                self.per_cls_weights_diversity = self.per_cls_weights_enabled_diversity\n            else:\n                self.per_cls_weights_base = None\n                self.per_cls_weights_diversity = None\n\n    def get_final_output(self, output_logits, target):\n        x = output_logits\n\n        index = torch.zeros_like(x, dtype=torch.uint8, device=x.device)\n        index.scatter_(1, target.data.view(-1, 1), 1)\n        \n        index_float = index.float()\n        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n        \n        batch_m = batch_m.view((-1, 1))\n        x_m = x - batch_m * self.s\n\n        final_output = torch.where(index, x_m, x)\n        return final_output\n\n    def forward(self, output_logits, target, extra_info=None, reduction='mean'):\n        if extra_info is None:\n            return self.base_loss(output_logits, target)\n\n        if reduction == 'none':\n            loss = torch.zeros_like(target).float()\n        else:\n            loss = 0\n\n\n        # Adding RIDE Individual Loss for each expert\n        for logits_item in extra_info['logits']:\n            ride_loss_logits = output_logits if self.additional_diversity_factor == 0 else logits_item\n            if self.m_list is None:\n                loss += self.base_loss_factor * self.base_loss(ride_loss_logits, target, reduction=reduction)\n            else:\n                final_output = self.get_final_output(ride_loss_logits, target)\n                loss += self.base_loss_factor * self.base_loss(final_output, target, weight=self.per_cls_weights_base, reduction=reduction)\n            \n            base_diversity_temperature = self.base_diversity_temperature\n\n            if self.per_cls_weights_diversity is not None:\n                diversity_temperature = base_diversity_temperature * self.per_cls_weights_diversity.view((1, -1))\n                temperature_mean = diversity_temperature.mean().item()\n            else:\n                diversity_temperature = base_diversity_temperature\n                temperature_mean = base_diversity_temperature\n            \n            output_dist = F.log_softmax(logits_item / diversity_temperature, dim=1)\n            with torch.no_grad():\n                # Using the mean takes only linear instead of quadratic time in computing and has only a slight difference so using the mean is preferred here\n                mean_output_dist = F.softmax(output_logits / diversity_temperature, dim=1)\n            \n            loss += self.additional_diversity_factor * temperature_mean * temperature_mean * F.kl_div(output_dist, mean_output_dist, reduction='batchmean')\n        \n        return loss\n\nclass RIDEWithDistill(nn.Module):\n    def __init__(self, cls_num_list=None, additional_distill_loss_factor=1.0, distill_temperature=1.5, ride_loss_factor=1.0, **kwargs):\n        super().__init__()\n        self.ride_loss = RIDE(cls_num_list=cls_num_list, **kwargs)\n        self.distill_temperature = distill_temperature\n\n        self.ride_loss_factor = ride_loss_factor\n        self.additional_distill_loss_factor = additional_distill_loss_factor\n\n    def to(self, device):\n        super().to(device)\n        self.ride_loss = self.ride_loss.to(device)\n        return self\n\n    def _hook_before_epoch(self, epoch):\n        self.ride_loss._hook_before_epoch(epoch)\n\n    def forward(self, student, target=None, teacher=None, extra_info=None):\n        output_logits = student\n        if extra_info is None:\n            return self.ride_loss(output_logits, target)\n\n        loss = 0\n        num_experts = len(extra_info['logits'])\n        for logits_item in extra_info['logits']:\n            loss += self.ride_loss_factor * self.ride_loss(output_logits, target, extra_info)\n            distill_temperature = self.distill_temperature\n\n            student_dist = F.log_softmax(student / distill_temperature, dim=1)\n            with torch.no_grad():\n                teacher_dist = F.softmax(teacher / distill_temperature, dim=1)\n            \n            distill_loss = F.kl_div(student_dist, teacher_dist, reduction='batchmean')\n            distill_loss = distill_temperature * distill_temperature * distill_loss\n            loss += self.additional_distill_loss_factor * distill_loss\n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:44.089521Z","iopub.execute_input":"2024-01-26T03:58:44.089855Z","iopub.status.idle":"2024-01-26T03:58:44.121812Z","shell.execute_reply.started":"2024-01-26T03:58:44.089824Z","shell.execute_reply":"2024-01-26T03:58:44.120888Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"common.py\n","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\n\nimport argparse, os, shutil, random, math\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\n!pip install progress\n# added on my own\nimport progress \n#end\n\nfrom progress.bar import Bar as Bar\n\ndef make_imb_data(max_num, class_num, gamma):\n    mu = np.power(1/gamma, 1/(class_num - 1))\n    class_num_list = []\n    for i in range(class_num):\n        if i == (class_num - 1):\n            class_num_list.append(int(max_num / gamma))\n        else:\n            class_num_list.append(int(max_num * np.power(mu, i)))\n    print(class_num_list)\n    return list(class_num_list)\n\ndef hms_string(sec_elapsed):\n    h = int(sec_elapsed / (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) / 60)\n    s = sec_elapsed % 60.\n    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n\ndef save_checkpoint(state, epoch, checkpoint='none', filename='checkpoint.pth.tar'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n    \n    if epoch % 100 == 0:\n        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_' + str(epoch) + '.pth.tar'))\n        \ndef linear_rampup(current, rampup_length=0):\n    if rampup_length == 0:\n        return 1.0\n    else:\n        current = np.clip(current / rampup_length, 0.0, 1.0)\n        return float(current)\n    \ndef adjust_learning_rate(optimizer, epoch, scheduler, args):\n    if scheduler == None:\n        if args.epochs == 200:\n            epoch = epoch + 1\n            if epoch <= args.warmup:\n                lr = args.lr * epoch / args.warmup\n            elif epoch > 180:\n                lr = args.lr * args.lr_decay ** 2\n            elif epoch > 160:\n                lr = args.lr * args.lr_decay\n            else:\n                lr = args.lr\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = lr\n            return lr\n\n        elif args.epochs == 400:\n            if args.loss_fn == 'bcl':\n                epoch = epoch + 1\n                if epoch <= args.warmup:\n                    lr = args.lr * epoch / args.warmup\n                elif epoch > 380:\n                    lr = args.lr * args.lr_decay ** 2\n                elif epoch > 360:\n                    lr = args.lr * args.lr_decay\n                else:\n                    lr = args.lr\n\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = lr\n                return lr\n            else:\n                epoch = epoch + 1\n                if epoch <= args.warmup:\n                    lr = args.lr * epoch / args.warmup\n                elif epoch > 360:\n                    lr = args.lr * args.lr_decay ** 2\n                elif epoch > 320:\n                    lr = args.lr * args.lr_decay\n                else:\n                    lr = args.lr\n\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = lr\n                return lr\n        else:\n            return args.lr\n    else:\n        scheduler.step()\n        return optimizer.param_groups[0]['lr']\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:44.125318Z","iopub.execute_input":"2024-01-26T03:58:44.125868Z","iopub.status.idle":"2024-01-26T03:58:56.394949Z","shell.execute_reply.started":"2024-01-26T03:58:44.125839Z","shell.execute_reply":"2024-01-26T03:58:56.393602Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Requirement already satisfied: progress in /opt/conda/lib/python3.10/site-packages (1.6)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"loss.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom bisect import bisect_right\n\n\n\n#from utils.common import adjust_learning_rate\n\nfrom torch.optim import lr_scheduler\n\ndef get_optimizer(args, model):\n    _model = model['model'] if args.loss_fn == 'ncl' else model\n    return optim.SGD(_model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd,\n                     nesterov=args.nesterov)\n\ndef get_scheduler(args, optimizer):\n    if args.scheduler == 'cosine':\n        return lr_scheduler.CosineAnnealingLR(optimizer, args.epochs, eta_min = 0)\n    elif args.scheduler == 'warmup':\n        return None\n\ndef get_loss(args, N_SAMPLES_PER_CLASS):\n    if args.loss_fn == 'ce':\n        train_criterion = CE()\n    elif args.loss_fn == 'ce_drw':\n        train_criterion = CE_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160)\n    elif args.loss_fn == 'bs':\n        train_criterion = BS(N_SAMPLES_PER_CLASS)\n    elif args.loss_fn == 'ldam_drw':\n        train_criterion = LDAM_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160, max_m=0.5, s=30).cuda()\n    elif args.loss_fn == 'ride':\n        if args.num_experts == 3 and args.ride_distill:\n            train_criterion = RIDEWithDistill(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n        else:\n            train_criterion = RIDE(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n        train_criterion = train_criterion.to(torch.device('cuda'))\n    elif args.loss_fn == 'ncl':\n        train_criterion = NIL_NBOD(args, N_SAMPLES_PER_CLASS)\n\n    elif args.loss_fn == 'bcl':\n        train_criterion = BCLLoss(N_SAMPLES_PER_CLASS)\n\n    else:\n        raise NotImplementedError\n        \n\n    return train_criterion\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.396638Z","iopub.execute_input":"2024-01-26T03:58:56.396967Z","iopub.status.idle":"2024-01-26T03:58:56.416053Z","shell.execute_reply.started":"2024-01-26T03:58:56.396937Z","shell.execute_reply":"2024-01-26T03:58:56.408339Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"cuda.py","metadata":{}},{"cell_type":"code","source":"import torch as t\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom torch.utils.data.dataset import Dataset\n\nimport random\nimport PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\nimport numpy as np\nimport torch\nfrom PIL import Image\n\ndef CUDA(img,m,n, rand=True, max_d=30):\n    _augment_list = augment_list()\n    ops = random.choices(_augment_list, k=n)\n    m = float(m) / max_d\n    for op, minval, maxval in ops:\n        val = (float(m)) * float(maxval - minval) + minval\n        img = op(img, val)\n    return img\n\ndef Flip(img, _):\n    return PIL.ImageOps.flip(img)\n\ndef Mirror(img, _):\n    return PIL.ImageOps.mirror(img)\n\ndef EdgeEnhance(img, _):\n    return img.filter(PIL.ImageFilter.EDGE_ENHANCE)\n\ndef Detail(img, _):\n    return img.filter(PIL.ImageFilter.DETAIL)\n\ndef Smooth(img, _):\n    return img.filter(PIL.ImageFilter.SMOOTH)\n    \ndef AutoContrast(img, _):\n    return PIL.ImageOps.autocontrast(img)\n\ndef Equalize(img, _):\n    return PIL.ImageOps.equalize(img)\n\ndef Invert(img, _):\n    return PIL.ImageOps.invert(img)\n\ndef GaussianBlur(img, v):\n    # assert 0 <= v <= 5\n    filter = PIL.ImageFilter.GaussianBlur(v)\n    return img.filter(filter)\n\ndef ResizeCrop(img, v):\n    # assert 1 <= v <= 2\n    width, height = img.size\n    enlarge = img.resize((int(width*v), int(height*v)), Image.ANTIALIAS)\n    left = int(width*v)//2 - width//2\n    right = int(width*v)//2 + width//2\n    top = int(height*v)//2 - height//2\n    bottom = int(height*v)//2 + height//2\n    return enlarge.crop((left, top, right, bottom))\n\ndef Rotate(img, v):  # [-30, 30]\n    # assert -30 <= v <= 30\n    if random.random() > 0.5:\n        v = -v\n    return img.rotate(v)\n\ndef Posterize(img, v):  # [4, 8]\n    v = int(v)\n    v = max(1, v)\n    return PIL.ImageOps.posterize(img, v)\n\ndef Solarize(img, v):  # [0, 256]\n    # assert 0 <= v <= 256\n    return PIL.ImageOps.solarize(img, v)\n\ndef SolarizeAdd(img, addition=0, threshold=128):\n    img_np = np.array(img).astype(int)\n    img_np = img_np + addition\n    img_np = np.clip(img_np, 0, 255)\n    img_np = img_np.astype(np.uint8)\n    img = Image.fromarray(img_np)\n    return PIL.ImageOps.solarize(img, threshold)\n\ndef Color(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Color(img).enhance(v)\n\ndef Contrast(img, v):  # [0.1,1.9]ƒ\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Contrast(img).enhance(v)\n\ndef Brightness(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Brightness(img).enhance(v)\n\ndef Sharpness(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n\ndef ShearX(img, v):  # [-0.3, 0.3]\n    # assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n\ndef ShearY(img, v):  # [-0.3, 0.3]\n    # assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n\ndef TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    # assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\ndef TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    # assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\ndef augment_list():  \n    l = [\n        (Flip, 0, 1),\n        (Mirror, 0, 1),\n        (EdgeEnhance, 0, 1),\n        (Detail, 0, 1),\n        (Smooth, 0, 1),\n        (AutoContrast, 0, 1),\n        (Equalize, 0, 1),\n        (Invert, 0, 1),\n        (GaussianBlur, 0, 2),\n        (ResizeCrop,1, 1.5),\n        (Rotate, 0, 30),\n        (Posterize, 0, 4),\n        (Solarize, 0, 256),\n        (SolarizeAdd, 0, 110),\n        (Color, 0.1, 1.9),\n        (Contrast, 0.1, 1.9),\n        (Brightness, 0.1, 1.9),\n        (Sharpness, 0.1, 1.9),\n        (ShearX, 0., 0.3),\n        (ShearY, 0., 0.3),\n        (TranslateXabs, 0., 100),\n        (TranslateYabs, 0., 100),\n    ]\n\n    \n\n    return l\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.417954Z","iopub.execute_input":"2024-01-26T03:58:56.418399Z","iopub.status.idle":"2024-01-26T03:58:56.448615Z","shell.execute_reply.started":"2024-01-26T03:58:56.418361Z","shell.execute_reply":"2024-01-26T03:58:56.447464Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"autoaug.py\n","metadata":{}},{"cell_type":"code","source":"from PIL import Image, ImageEnhance, ImageOps\nimport numpy as np\nimport random\nimport torch\n\n\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n\nclass ImageNetPolicy(object):\n    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n        Example:\n        >>> policy = ImageNetPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     ImageNetPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment ImageNet Policy\"\n\n\nclass CIFAR10Policy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n        Example:\n        >>> policy = CIFAR10Policy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     CIFAR10Policy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n\n            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n\n            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n\n            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n\n            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment CIFAR10 Policy\"\n\n\nclass SVHNPolicy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on SVHN.\n        Example:\n        >>> policy = SVHNPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     SVHNPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.9, \"shearX\", 4, 0.2, \"invert\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.7, \"invert\", 5, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.6, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 3, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"equalize\", 1, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.8, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.4, \"invert\", 5, fillcolor),\n            SubPolicy(0.9, \"shearY\", 5, 0.2, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 6, 0.8, \"autocontrast\", 1, fillcolor),\n            SubPolicy(0.6, \"equalize\", 3, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.3, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 8, 0.7, \"invert\", 4, fillcolor),\n            SubPolicy(0.9, \"equalize\", 5, 0.6, \"translateY\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 4, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.3, \"contrast\", 3, 0.8, \"rotate\", 4, fillcolor),\n\n            SubPolicy(0.8, \"invert\", 5, 0.0, \"translateY\", 2, fillcolor),\n            SubPolicy(0.7, \"shearY\", 6, 0.4, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 0.8, \"rotate\", 4, fillcolor),\n            SubPolicy(0.3, \"shearY\", 7, 0.9, \"translateX\", 3, fillcolor),\n            SubPolicy(0.1, \"shearX\", 6, 0.6, \"invert\", 5, fillcolor),\n\n            SubPolicy(0.7, \"solarize\", 2, 0.6, \"translateY\", 7, fillcolor),\n            SubPolicy(0.8, \"shearY\", 4, 0.8, \"invert\", 8, fillcolor),\n            SubPolicy(0.7, \"shearX\", 9, 0.8, \"translateY\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 5, 0.7, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.7, \"shearX\", 2, 0.1, \"invert\", 5, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment SVHN Policy\"\n\n\nclass SubPolicy(object):\n    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n        ranges = {\n            \"shearX\": np.linspace(0, 0.3, 10),\n            \"shearY\": np.linspace(0, 0.3, 10),\n            \"translateX\": np.linspace(0, 150 / 331, 10),\n            \"translateY\": np.linspace(0, 150 / 331, 10),\n            \"rotate\": np.linspace(0, 30, 10),\n            \"color\": np.linspace(0.0, 0.9, 10),\n            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n            \"solarize\": np.linspace(256, 0, 10),\n            \"contrast\": np.linspace(0.0, 0.9, 10),\n            \"sharpness\": np.linspace(0.0, 0.9, 10),\n            \"brightness\": np.linspace(0.0, 0.9, 10),\n            \"autocontrast\": [0] * 10,\n            \"equalize\": [0] * 10,\n            \"invert\": [0] * 10\n        }\n\n        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n        def rotate_with_fill(img, magnitude):\n            rot = img.convert(\"RGBA\").rotate(magnitude)\n            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n\n        func = {\n            \"shearX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"shearY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"translateX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n                fillcolor=fillcolor),\n            \"translateY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n                fillcolor=fillcolor),\n            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n        }\n\n        self.p1 = p1\n        self.operation1 = func[operation1]\n        self.magnitude1 = ranges[operation1][magnitude_idx1]\n        self.p2 = p2\n        self.operation2 = func[operation2]\n        self.magnitude2 = ranges[operation2][magnitude_idx2]\n\n\n    def __call__(self, img):\n        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n        return img","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.450764Z","iopub.execute_input":"2024-01-26T03:58:56.451168Z","iopub.status.idle":"2024-01-26T03:58:56.509193Z","shell.execute_reply.started":"2024-01-26T03:58:56.451140Z","shell.execute_reply":"2024-01-26T03:58:56.508067Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"randaug.py\n","metadata":{}},{"cell_type":"code","source":"# code in this file is adpated from rpmcruz/autoaugment\n# https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\nimport random\n\nimport PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\nimport numpy as np\nimport torch\nfrom PIL import Image\n\n\ndef ShearX(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n\n\ndef ShearY(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n\n\ndef TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random.random() > 0.5:\n        v = -v\n    v = v * img.size[0]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random.random() > 0.5:\n        v = -v\n    v = v * img.size[1]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef Rotate(img, v):  # [-30, 30]\n    assert -30 <= v <= 30\n    if random.random() > 0.5:\n        v = -v\n    return img.rotate(v)\n\n\ndef AutoContrast(img, _):\n    return PIL.ImageOps.autocontrast(img)\n\n\ndef Invert(img, _):\n    return PIL.ImageOps.invert(img)\n\n\ndef Equalize(img, _):\n    return PIL.ImageOps.equalize(img)\n\n\ndef Flip(img, _):  # not from the paper\n    return PIL.ImageOps.mirror(img)\n\n\ndef Solarize(img, v):  # [0, 256]\n    assert 0 <= v <= 256\n    return PIL.ImageOps.solarize(img, v)\n\n\ndef SolarizeAdd(img, addition=0, threshold=128):\n    img_np = np.array(img).astype(int)\n    img_np = img_np + addition\n    img_np = np.clip(img_np, 0, 255)\n    img_np = img_np.astype(np.uint8)\n    img = Image.fromarray(img_np)\n    return PIL.ImageOps.solarize(img, threshold)\n\n\ndef Posterize(img, v):  # [4, 8]\n    v = int(v)\n    v = max(1, v)\n    return PIL.ImageOps.posterize(img, v)\n\n\ndef Contrast(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Contrast(img).enhance(v)\n\n\ndef Color(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Color(img).enhance(v)\n\n\ndef Brightness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Brightness(img).enhance(v)\n\n\ndef Sharpness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n\n\n\n\ndef CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n    # assert 0 <= v <= 20\n    if v < 0:\n        return img\n    w, h = img.size\n    x0 = np.random.uniform(w)\n    y0 = np.random.uniform(h)\n\n    x0 = int(max(0, x0 - v / 2.))\n    y0 = int(max(0, y0 - v / 2.))\n    x1 = min(w, x0 + v)\n    y1 = min(h, y0 + v)\n\n    xy = (x0, y0, x1, y1)\n    color = (125, 123, 114)\n    # color = (0, 0, 0)\n    img = img.copy()\n    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n    return img\n\n\ndef SamplePairing(imgs):  # [0, 0.4]\n    def f(img1, v):\n        i = np.random.choice(len(imgs))\n        img2 = PIL.Image.fromarray(imgs[i])\n        return PIL.Image.blend(img1, img2, v)\n\n    return f\n\n\ndef Identity(img, v):\n    return img\n\n\ndef augment_list():  # 16 oeprations and their ranges\n    # https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57\n    # l = [\n    #     (Identity, 0., 1.0),\n    #     (ShearX, 0., 0.3),  # 0\n    #     (ShearY, 0., 0.3),  # 1\n    #     (TranslateX, 0., 0.33),  # 2\n    #     (TranslateY, 0., 0.33),  # 3\n    #     (Rotate, 0, 30),  # 4\n    #     (AutoContrast, 0, 1),  # 5\n    #     (Invert, 0, 1),  # 6\n    #     (Equalize, 0, 1),  # 7\n    #     (Solarize, 0, 110),  # 8\n    #     (Posterize, 4, 8),  # 9\n    #     # (Contrast, 0.1, 1.9),  # 10\n    #     (Color, 0.1, 1.9),  # 11\n    #     (Brightness, 0.1, 1.9),  # 12\n    #     (Sharpness, 0.1, 1.9),  # 13\n    #     # (Cutout, 0, 0.2),  # 14\n    #     # (SamplePairing(imgs), 0, 0.4),  # 15\n    # ]\n\n    # https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505\n    l = [\n        (AutoContrast, 0, 1),\n        (Equalize, 0, 1),\n        (Invert, 0, 1),\n        (Rotate, 0, 30),\n        (Posterize, 0, 4),\n        (Solarize, 0, 256),\n        (SolarizeAdd, 0, 110),\n        (Color, 0.1, 1.9),\n        (Contrast, 0.1, 1.9),\n        (Brightness, 0.1, 1.9),\n        (Sharpness, 0.1, 1.9),\n        (ShearX, 0., 0.3),\n        (ShearY, 0., 0.3),\n        (CutoutAbs, 0, 40),\n        (TranslateXabs, 0., 100),\n        (TranslateYabs, 0., 100),\n    ]\n\n    return l\n\n\nclass Lighting(object):\n    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n\n    def __init__(self, alphastd, eigval, eigvec):\n        self.alphastd = alphastd\n        self.eigval = torch.Tensor(eigval)\n        self.eigvec = torch.Tensor(eigvec)\n\n    def __call__(self, img):\n        if self.alphastd == 0:\n            return img\n\n        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n        rgb = self.eigvec.type_as(img).clone() \\\n            .mul(alpha.view(1, 3).expand(3, 3)) \\\n            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n            .sum(1).squeeze()\n\n        return img.add(rgb.view(3, 1, 1).expand_as(img))\n\n\nclass CutoutDefault(object):\n    \"\"\"\n    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py\n    \"\"\"\n    def __init__(self, length):\n        self.length = length\n\n    def __call__(self, img):\n        h, w = img.size(1), img.size(2)\n        mask = np.ones((h, w), np.float32)\n        y = np.random.randint(h)\n        x = np.random.randint(w)\n\n        y1 = np.clip(y - self.length // 2, 0, h)\n        y2 = np.clip(y + self.length // 2, 0, h)\n        x1 = np.clip(x - self.length // 2, 0, w)\n        x2 = np.clip(x + self.length // 2, 0, w)\n\n        mask[y1: y2, x1: x2] = 0.\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img *= mask\n        return img\n\n\nclass RandAugment:\n    def __init__(self, n, m):\n        self.n = n\n        self.m = m      # [0, 30]\n        self.augment_list = augment_list()\n\n    def __call__(self, img):\n        ops = random.choices(self.augment_list, k=self.n)\n        for op, minval, maxval in ops:\n            val = (float(self.m) / 30) * float(maxval - minval) + minval\n            img = op(img, val)\n\n        return img\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.511180Z","iopub.execute_input":"2024-01-26T03:58:56.511551Z","iopub.status.idle":"2024-01-26T03:58:56.551627Z","shell.execute_reply.started":"2024-01-26T03:58:56.511503Z","shell.execute_reply":"2024-01-26T03:58:56.550515Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"cutout.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.553139Z","iopub.execute_input":"2024-01-26T03:58:56.553945Z","iopub.status.idle":"2024-01-26T03:58:56.567251Z","shell.execute_reply.started":"2024-01-26T03:58:56.553916Z","shell.execute_reply":"2024-01-26T03:58:56.566014Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"transformer.py","metadata":{}},{"cell_type":"code","source":"from torchvision.transforms import transforms\nfrom PIL import ImageFilter\nimport random\n#from aug.cutout import *\n\ncifar10_mean = (0.4914, 0.4822, 0.4465)\ncifar10_std = (0.2023, 0.1994, 0.2010)\n\n\n\nclass GaussianBlur(object):\n    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n\n    def __init__(self, sigma=[.1, 2.]):\n        self.sigma = sigma\n\n    def __call__(self, x):\n        sigma = random.uniform(self.sigma[0], self.sigma[1])\n        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n        return x\n\n\n\ndef get_transform(loss_fn, cutout = False):\n    # Augmentations.\n    if loss_fn in ['ce', 'ldam_drw', 'bs', 'ce_drw', 'ride']:\n        train_before = [\n                transforms.RandomCrop(32, padding=4),\n                transforms.RandomHorizontalFlip(),\n            ]\n        \n        if cutout:\n            train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n\n        transform_train = [[transforms.Compose(train_before), transforms.Compose(train_after)]]\n\n    elif loss_fn in ['ncl']:\n        regular_train_before = [\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),\n            ]\n\n        if cutout:\n            regular_train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            regular_train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n\n\n        sim_cifar_before = [\n            transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n            ]\n        sim_cifar_after = [\n            transforms.ToTensor(),\n            transforms.Normalize(cifar10_mean, cifar10_std),\n            ]\n        transform_train = [\n            [transforms.Compose(regular_train_before), \n            transforms.Compose(regular_train_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)],\n            ]\n\n\n    \n    elif loss_fn in ['bcl']:\n        regular_train_before = [\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),\n            ]\n\n        if cutout:\n            regular_train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            regular_train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        \n        sim_cifar_before = [\n            transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n            ]\n        sim_cifar_after = [\n            transforms.ToTensor(),\n            transforms.Normalize(cifar10_mean, cifar10_std),\n            ]\n\n        transform_train = [\n            [transforms.Compose(regular_train_before), \n            transforms.Compose(regular_train_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)],\n            ]\n\n    transform_val = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(cifar10_mean, cifar10_std)\n    ])\n    \n    return transform_train, transform_val\n    \n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.568838Z","iopub.execute_input":"2024-01-26T03:58:56.569172Z","iopub.status.idle":"2024-01-26T03:58:56.595886Z","shell.execute_reply.started":"2024-01-26T03:58:56.569145Z","shell.execute_reply":"2024-01-26T03:58:56.594858Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"cifar100.py\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport random\n\nimport torchvision\nimport torch\n\nfrom torch.utils.data import Dataset\n\nfrom torchvision.transforms import transforms\n\n\n\n    \ndef get_cifar100(root, args):\n    transform_train, transform_val = get_transform(args.loss_fn, cutout = args.cutout)\n\n    train_dataset = CIFAR100_train(root, args, imb_ratio = args.imb_ratio, train=True, transform = transform_train, aug_prob=args.aug_prob)\n    test_dataset = CIFAR100_val(root, transform=transform_val)\n    print (f\"#Train: {len(train_dataset)}, #Test: {len(test_dataset)}\")\n    return train_dataset, test_dataset\n    \nclass test_CIFAR100(Dataset):\n    def __init__(self, indices, state, cifar_dataset):\n        self.indices = indices\n        self.state = state\n        self.dataset = cifar_dataset\n\n    def __getitem__(self,idx):\n        data, label, _ = self.dataset.get_item(self.indices[idx], self.state[idx], train=False)\n        return data, label, self.indices[idx], self.state[idx]\n    \n    def __len__(self):\n        return len(self.indices)\n\nclass CIFAR100_train(torchvision.datasets.CIFAR100):\n    def __init__(self, root , args, aug_prob, imb_type='exp', imb_ratio=100, train=True, transform=None, target_transform=None, download=True):\n        super(CIFAR100_train,self).__init__(root, train=train, transform=transform, target_transform = target_transform, download= download)\n\n        np.random.seed(0)\n        self.args = args\n        self.cls_num = 100\n        self.img_num_list = self.get_img_num_per_cls(self.cls_num, imb_type, 1./imb_ratio)\n        self.transform_train = transform\n        self.gen_imbalanced_data(self.img_num_list)\n        \n\n        if 'autoaug_cifar' in args.aug_type:\n            print('autoaug_cifar')\n            self.aug_transform = transforms.Compose([CIFAR10Policy()])\n        elif 'autoaug_svhn' in args.aug_type:\n            print('autoaug_svhn')\n            self.aug_transform = transforms.Compose([SVHNPolicy()])\n        elif 'autoaug_imagenet' in args.aug_type:\n            print('autoaug_imagenet')\n            self.aug_transform = transforms.Compose([ImageNetPolicy()])\n        #elif 'dada_cifar' in args.aug_type:\n            print('dada_cifar')\n            self.aug_transform = transforms.Compose([dada_cifar()])\n        #elif 'dada_imagenet' in args.aug_type:\n            print('dada_imagenet')\n            self.aug_transform = transforms.Compose([dada_imagenet()])\n        #elif 'faa_cifar' in args.aug_type:\n            print('faa_cifar')\n            self.aug_transform = transforms.Compose([faa_cifar()])\n        #elif 'faa_imagenet' in args.aug_type:\n            print('faa_imagenet')\n            self.aug_transform = transforms.Compose([faa_imagenet()])\n        elif 'randaug' in args.aug_type:\n            print('randaug')\n            self.aug_transform = transforms.Compose([RandAugment(2, 14)])\n        elif 'none' in args.aug_type:\n            self.aug_transform = transforms.Compose([])\n        else:\n            raise NotImplementedError\n        \n\n\n\n        # max_mag = 10\n        # max_ops = 10\n        max_mag = 10\n        max_ops = 10\n        self.min_state = 0\n        self.max_state = max(max_mag, max_ops) + 1\n        \n        states = torch.arange(self.min_state, self.max_state)\n        if self.max_state == 1:\n            self.ops = torch.tensor([0])\n            self.mag = torch.tensor([0])\n            \n        elif max_mag > max_ops:\n            self.ops = (states * max_ops / max_mag).ceil().int()\n            self.mag = states.int()\n        else:\n            self.mag = (states * max_mag / max_ops).ceil().int()\n            self.ops = states.int()\n        \n        print(f\"Magnitude set = {self.mag}\")\n        print(f\"Operation set = {self.ops}\")\n\n        self.curr_state = torch.zeros(len(self.data))\n        self.score_tmp = torch.zeros((len(self.targets), self.max_state))\n        self.num_test = torch.zeros((len(self.targets), self.max_state))\n        self.aug_prob = aug_prob\n\n\n\n    def get_img_num_per_cls(self, cls_num, imb_type, imb_factor):\n        img_max = len(self.data) / cls_num\n        img_num_per_cls = []\n        if imb_type == 'exp':\n            for cls_idx in range(cls_num):\n                num = img_max * (imb_factor ** (cls_idx / (cls_num - 1.0)))\n                img_num_per_cls.append(int(num))\n        else:\n            img_num_per_cls.extend([int(img_max)] * cls_num)\n        return img_num_per_cls\n\n\n    def gen_imbalanced_data(self, img_num_per_cls):\n        new_data = []\n        new_targets = []\n        #changed from np.int64\n        targets_np = np.array(self.targets, dtype=int)\n        classes = np.unique(targets_np)\n        # np.random.shuffle(classes)\n\n        self.num_per_cls_dict = dict()\n        for the_class, the_img_num in zip(classes, img_num_per_cls):\n            self.num_per_cls_dict[the_class] = the_img_num\n            idx = np.where(targets_np == the_class)[0]\n            np.random.shuffle(idx)\n            selec_idx = idx[:the_img_num]\n            # print(selec_idx)\n            new_data.append(self.data[selec_idx, ...])\n            new_targets.extend([the_class, ] * the_img_num)\n        new_data = np.vstack(new_data)\n        self.data = new_data\n        self.targets = new_targets\n\n    def get_cls_num_list(self):\n        cls_num_list = []\n        for i in range(self.cls_num):\n            cls_num_list.append(self.num_per_cls_dict[i])\n        return cls_num_list\n\n    def sim_aug(self, img, state, type):\n        if type == 'cuda':\n            return  CUDA(img, self.mag[state], self.ops[state], max_d = self.args.max_d)\n        else:\n            return img\n        \n\n    \n    def get_item(self, index, state, train=True):\n        img, target = self.data[index], self.targets[index]\n        img = Image.fromarray(img)\n        \n        if train:\n            if len(self.transform_train) == 1:\n                img = self.transform_train[0][0](img)\n                img = self.aug_transform(img)\n                img = CUDA(img, self.mag[state], self.ops[state])\n                img = self.transform_train[0][1](img)\n                return img, target, index\n\n            elif len(self.transform_train) == 2:\n                img1 = self.transform_train[0][0](img)\n                img1 = self.aug_transform(img1)\n                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n                img1 = self.transform_train[0][1](img1)\n\n                img2 = self.transform_train[1][0](img)\n                img2 = self.sim_aug(img2, state, self.args.sim_type)\n                img2 = self.transform_train[1][1](img2)\n                \n                return (img1, img2), target, index\n                \n            elif len(self.transform_train) == 3:\n                img1 = self.transform_train[0][0](img)\n                img1 = self.aug_transform(img1)\n                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n                img1 = self.transform_train[0][1](img1)\n\n                img2 = self.transform_train[1][0](img)\n                img2 = self.sim_aug(img2, state, self.args.sim_type)\n                img2 = self.transform_train[1][1](img2)\n                \n                img3 = self.transform_train[2][0](img)\n                img3 = self.sim_aug(img3, state, self.args.sim_type)\n                img3 = self.transform_train[2][1](img3)\n                return (img1, img2, img3), target, index\n\n        else:\n            img = self.transform_train[0][0](img)\n            img = self.aug_transform(img)\n            img = CUDA(img, self.mag[state], self.ops[state], rand=False , max_d = self.args.max_d)\n            img = self.transform_train[0][1](img)\n            return img, target, index\n        \n    def __getitem__(self, index):\n        state = self.curr_state[index].int() if torch.rand(1) < self.aug_prob else 0\n        \n        img, target, index = self.get_item(index, state, train=True)\n        return img, target, index\n    \n    def update_scores(self, correct, index, state):\n        for s in np.unique(state):\n            pos = np.where(state == s)\n            score_result = np.bincount(index[pos], correct[pos], len(self.score_tmp))\n            num_test_result = np.bincount(index[pos], np.ones(len(index))[pos], len(self.score_tmp))\n            self.score_tmp[:,s] += score_result\n            self.num_test[:,s] += num_test_result\n            \n\n    def update(self):\n        # Increase\n        pos = torch.where((self.score_tmp == self.num_test) & (self.num_test != 0))\n        self.curr_state[pos] += 1\n        \n        # Decrease\n        pos = torch.where(self.score_tmp != self.num_test)\n        self.curr_state[pos] -= 1\n        \n        \n        self.curr_state = torch.clamp(self.curr_state, self.min_state, self.max_state-1)\n        self.score_tmp *= 0\n        self.num_test *= 0\n        \n    \nclass CIFAR100_val(torchvision.datasets.CIFAR100):\n    def __init__(self, root, transform=None, indexs=None,\n                 target_transform=None, download=True):\n        super(CIFAR100_val, self).__init__(root, train=False, transform=transform, target_transform=target_transform,download=download)\n        \n        if indexs is not None:\n            self.data = self.data[indexs]\n            self.targets = np.array(self.targets)[indexs]\n        self.data = [Image.fromarray(img) for img in self.data]\n        \n    def __getitem__(self, index):\n        img, target = self.data[index], self.targets[index]\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n        return img, target, index","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.598251Z","iopub.execute_input":"2024-01-26T03:58:56.598661Z","iopub.status.idle":"2024-01-26T03:58:56.655914Z","shell.execute_reply.started":"2024-01-26T03:58:56.598626Z","shell.execute_reply":"2024-01-26T03:58:56.654918Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"accuracy.py","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function, absolute_import\n\nimport errno\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\nfrom torch.autograd import Variable\n\n\n__all__ = ['accuracy', 'AverageMeter']\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].reshape(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\n       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.657224Z","iopub.execute_input":"2024-01-26T03:58:56.657669Z","iopub.status.idle":"2024-01-26T03:58:56.671227Z","shell.execute_reply.started":"2024-01-26T03:58:56.657644Z","shell.execute_reply":"2024-01-26T03:58:56.670065Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"cutmix.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ndef rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix(data_f, data_b):\n    lam = np.random.beta(1., 1.)\n    bbx1, bby1, bbx2, bby2 = rand_bbox(data_f.size(), lam)\n    data_b[:, :, bbx1:bbx2, bby1:bby2] = data_f[:, :, bbx1:bbx2, bby1:bby2]\n    lam = 1-((bbx2 - bbx1) * (bby2 - bby1) / (data_f.size()[2] * data_f.size()[3]))\n    \n    return data_b, torch.tensor(lam)\n\n# def cutmix(data_aug, data, label, param, percent=1.0):\n    # data = data_aug\n    # sample_num = int(len(param)*percent)\n    # argsort = torch.argsort(param,descending=True)\n    # param /= torch.max(param)\n    \n    # candidate = argsort[:sample_num]\n    \n    # data_f = data[candidate]\n    # label_f = label[candidate]\n    # param_f = param[candidate]\n    \n    # back_perm = candidate[torch.randperm(len(candidate))]\n    # data_b = data[back_perm]\n    # label_b = label[back_perm]\n    # param_b = param[back_perm]\n    \n    # # lam = torch.exp(param_f) / (torch.exp(param_f)+torch.exp(param_b))\n    # lam = torch.tensor(np.random.beta(1.,1.,(sample_num,)))\n    \n    # size = data.size()\n    # W = size[2]\n    # H = size[3]\n    # cut_rat = torch.sqrt(1. - lam)\n    # cut_w = (cut_rat * W).int()\n    # cut_h = (cut_rat * H).int()\n\n    # # uniform\n    # cx = torch.randint(0,W,(len(candidate),))\n    # cy = torch.randint(0,H,(len(candidate),))\n\n    # bbx1 = torch.clip(cx - cut_w // 2, 0, W)\n    # bby1 = torch.clip(cy - cut_h // 2, 0, H)\n    # bbx2 = torch.clip(cx + cut_w // 2, 0, W)\n    # bby2 = torch.clip(cy + cut_h // 2, 0, H)\n    \n    # for idx in range(len(data_b)):\n    #     data_b[idx, :, bbx1[idx]:bbx2[idx], bby1[idx]:bby2[idx]] = data_f[idx, :, bbx1[idx]:bbx2[idx], bby1[idx]:bby2[idx]]\n    # data_aug[candidate] = data_b\n    \n    # label[candidate] = label_b\n    # label_aug = torch.zeros(len(label),dtype=int)\n    # label_aug[candidate] = label_f.cpu()\n\n    # ret_lbd = torch.ones(len(label))\n    # ret_lbd[candidate] -= ((bbx2 - bbx1) * (bby2 - bby1) / (W*H))\n\n    # return data_aug, label, label_aug, ret_lbd","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.672933Z","iopub.execute_input":"2024-01-26T03:58:56.673335Z","iopub.status.idle":"2024-01-26T03:58:56.685752Z","shell.execute_reply.started":"2024-01-26T03:58:56.673292Z","shell.execute_reply":"2024-01-26T03:58:56.684741Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"basetrain","metadata":{}},{"cell_type":"code","source":"\nfrom __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar\n\nimport copy, time\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\n\n\ndef update_score_base(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    curr_state = loader.dataset.curr_state\n    max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        n = num_test\n        pos, state = [], []\n        ''' \n        for s in range(max_state):\n            entire_pos = torch.arange(len(loader.dataset.targets))\n            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n            pos +=  _pos\n            state += [s] * len(_pos)\n        tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n                                                 shuffle=False, num_workers = 8)\n        \n        '''\n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            logit = model(data, output_type = None).cpu()\n\n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n\n    \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    \n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    '''\n    \n\n    all_indices = torch.arange(len(loader.dataset.targets))\n    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n\n    ratio = correct_sum_all_classes / trial_sum_all_classes\n    idx = loader.dataset.curr_state[0].int() + 1\n    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n\n    if condition:\n            loader.dataset.curr_state[all_indices] += 1\n    else:\n            loader.dataset.curr_state[all_indices] -= 1\n    '''\n        \n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n\n    # print(f'Max correct: {int(torch.max(correct_sum_per_class))} Max trial: {int(torch.max(trial_sum_per_class))}')\n    \n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    \n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n# def update_score_base(loader, model, n_samples_per_class, posthoc_la):\n#     model.eval()\n    \n#     if posthoc_la:\n#         dist = torch.tensor(n_samples_per_class)\n#         prob = dist / dist.sum()\n    \n#     # curr_state= loader.dataset.curr_state\n#     # max_state = torch.max(curr_state).int() + 1\n    \n#     with torch.no_grad():\n#         # pos, state = [], []\n            \n#         # for s in range(max_state):\n#         #     _pos = torch.where(curr_state >= s)[0]\n#         #     pos_list = _pos.tolist() * (s+1) \n#         #     pos +=  pos_list\n#         #     state += [s] * len(pos_list)\n#         # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n#         # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n#         #                                         shuffle=False, num_workers = 8)\n        \n#         n = 10\n#         pos, state = [], []\n#         for cidx in range(len(n_samples_per_class)):\n#             class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n#             max_state = loader.dataset.curr_state[class_pos[0]].int() \n#             for s in range(max_state+1):\n#                 _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n#                 pos += _pos \n#                 state += [s] * len(_pos)\n \n#         tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n#         tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n#         for batch_idx, data_tuple in enumerate(tmp_loader):\n#             data = data_tuple[0].cuda()\n#             label = data_tuple[1]\n#             idx = data_tuple[2]\n\n#             logit = model(data, output_type = None).cpu()\n\n#             if posthoc_la:\n#                 logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n#             correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n#             loader.dataset.update_scores(correct,idx)\n#     print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    \n#     # loader.dataset.update()\n#     for cidx in range(len(n_samples_per_class)):\n#         class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n#         correct_sum = torch.sum(loader.dataset.score_tmp[class_pos])\n#         trial_sum = torch.sum(loader.dataset.num_test[class_pos])\n\n#         # if correct_sum == trial_sum:\n#         if float(correct_sum) >= float(trial_sum * 0.8):\n#             loader.dataset.curr_state[class_pos] += 1\n#         else:\n#             loader.dataset.curr_state[class_pos] -= 1\n\n#     loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n#     loader.dataset.score_tmp *= 0\n#     loader.dataset.num_test *= 0\n\n\n\n\n#     model.train()\n    \n#     # Debug\n#     curr_state = loader.dataset.curr_state\n#     label = loader.dataset.targets\n#     print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n#     return curr_state, label\n\n\n\n\n\ndef train_base(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    bar = Bar('Training', max=len(trainloader))\n\n    if args.cmo and 3 < epoch < (args.epochs - 3):\n        inverse_iter = iter(weighted_trainloader)\n\n        \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo and 3 < epoch < (args.epochs - 3):\n            try:\n                data_tuple_f = next(inverse_iter)\n            except:\n                inverse_iter = iter(weighted_trainloader)\n                data_tuple_f = next(inverse_iter)\n\n            inputs_f = data_tuple_f[0]\n            targets_f = data_tuple_f[1]\n            inputs_f = inputs_f[:len(inputs_b)]\n            targets_f = targets_f[:len(targets_b)]\n            inputs_f = inputs_f.cuda(non_blocking=True)\n            targets_f = targets_f.cuda(non_blocking=True)\n\n        inputs_b = inputs_b.cuda(non_blocking=True)\n        targets_b = targets_b.cuda(non_blocking=True)\n\n\n        r = np.random.rand(1)\n        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n            inputs_b, lam = cutmix(inputs_f, inputs_b)\n            outputs = model(inputs_b, None)\n            loss = criterion(outputs, targets_b, epoch) * lam + criterion(outputs, targets_f, epoch) * (1.-lam)\n        else:\n            outputs = model(inputs_b, None)\n            loss = criterion(outputs, targets_b, epoch)\n        \n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.687283Z","iopub.execute_input":"2024-01-26T03:58:56.687654Z","iopub.status.idle":"2024-01-26T03:58:56.721621Z","shell.execute_reply.started":"2024-01-26T03:58:56.687621Z","shell.execute_reply":"2024-01-26T03:58:56.720371Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"bcltrain","metadata":{}},{"cell_type":"code","source":"\n\nfrom __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar\n\nimport copy, time\nimport random\n\n#from datasets.cifar100 import test_CIFAR100\n\n\n\ndef update_score_bcl(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    # curr_state = loader.dataset.curr_state\n    # max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        # pos, state = [], []\n            \n        # for s in range(max_state):\n        #     _pos = torch.where(curr_state >= s)[0]\n        #     pos_list = _pos.tolist() * (s+1) \n        #     pos +=  pos_list\n        #     state += [s] * len(pos_list)\n        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n        #                                         shuffle=False, num_workers = 8)\n        \n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            _, logit, _ = model(data)\n            \n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n            correct = (logit.cpu().max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n\n\n            \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    # print(f'Max correct: {int(torch.max(correct_sum_per_class))} Max trial: {int(torch.max(trial_sum_per_class))}')\n    \n    \n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n\n\n\ndef train_bcl(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    bar = Bar('Training', max=len(trainloader))\n        \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo:\n            raise \"BCL not implemented for CMO...\"\n        else:\n            inputs_b = torch.cat([inputs_b[0], inputs_b[1], inputs_b[2]], dim=0).cuda()\n            batch_size = targets_b.shape[0]\n            targets_b = targets_b.cuda()\n            feat_mlp, logits, centers = model(inputs_b)\n            centers = centers[:args.num_class]\n            _, f2, f3 = torch.split(feat_mlp, [batch_size, batch_size, batch_size], dim=0)\n            features = torch.cat([f2.unsqueeze(1), f3.unsqueeze(1)], dim=1)\n            logits, _, __ = torch.split(logits, [batch_size, batch_size, batch_size], dim=0)\n            loss = criterion(centers, logits, features, targets_b)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.723475Z","iopub.execute_input":"2024-01-26T03:58:56.723850Z","iopub.status.idle":"2024-01-26T03:58:56.752538Z","shell.execute_reply.started":"2024-01-26T03:58:56.723817Z","shell.execute_reply":"2024-01-26T03:58:56.751463Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"ncltrain","metadata":{}},{"cell_type":"code","source":"\n#from utils.accuracy import AverageMeter\nimport torch\nimport time\n#from utils.common import Bar, adjust_learning_rate\n\nimport copy\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\ndef update_score_ncl(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model = model['model']\n    model.eval()\n     \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    \n    # curr_state = loader.dataset.curr_state\n    # max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        # pos, state = [], []\n            \n        # for s in range(max_state):\n        #     _pos = torch.where(curr_state >= s)[0]\n        #     pos_list = _pos.tolist() * (s+1) \n        #     pos +=  pos_list\n        #     state += [s] * len(pos_list)\n        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,   shuffle=False, num_workers = 8, drop_last=True)\n        \n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            data_list = [data for i in range(model.network_num)]\n\n            feature = model((data_list,data_list), label=label, feature_flag=True)\n            output_ce, output, output_MA = model(feature, classifier_flag=True)\n            logit = torch.mean(torch.stack(output_ce), dim=0).cpu()\n\n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1)).cuda()\n\n            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n    \n    \n \n    \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n    \n    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    \n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\ndef train_ncl(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher=None):\n    combiner = model['comb']\n    model = model['model']\n    network_num = 3\n\n    model.train()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n\n    bar = Bar('Training', max=len(trainloader))\n    \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs = data_tuple[0]\n        targets = data_tuple[1]\n        indexs = data_tuple[2]\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets.size(0)\n\n        if args.cmo:\n            raise \"NCL not implemented for CMO...\"\n        else:\n            image_list = [inputs] * network_num\n            label_list = [targets] * network_num\n            indexs_list = [indexs] * network_num\n\n            loss = combiner.forward(model, criterion, image_list, label_list)\n\n            if args.dataset in ['cifar100', 'places']:\n                alpha = 0.999\n                for net_id in range(network_num):\n                    net = ['backbone', 'module']\n                    for name in net:\n                        for ema_param, param in zip(eval('model.' + name + '_MA').parameters(),\n                                                    eval('model.' + name).parameters()):\n                            ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n\n        # record\n        losses.update(loss.data.item(), targets.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.754470Z","iopub.execute_input":"2024-01-26T03:58:56.754776Z","iopub.status.idle":"2024-01-26T03:58:56.783240Z","shell.execute_reply.started":"2024-01-26T03:58:56.754751Z","shell.execute_reply":"2024-01-26T03:58:56.782205Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"ridetrain","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar, adjust_learning_rate\n\nimport copy\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\ndef update_score_ride(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    curr_state = loader.dataset.curr_state\n    max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        n = num_test\n        pos, state = [], []\n            \n\n    \n    with torch.no_grad():\n        pos, state = [], []\n            \n        # for s in range(max_state):\n        #     _pos = torch.where(curr_state >= s)[0]\n        #     pos_list = _pos.tolist() * (s+1) \n        #     pos +=  pos_list\n        #     state += [s] * len(pos_list)\n        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n        #                                         shuffle=False, num_workers = 8)\n        \n        n = num_test\n        pos, state = [], []\n        \n        \n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n        '''\n        \n        for s in range(max_state):\n            entire_pos = torch.arange(len(loader.dataset.targets))\n            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n            pos +=  _pos\n            state += [s] * len(_pos)\n        '''\n\n        \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            # logit = model(data, output_type = None).cpu()\n            # if posthoc_la:\n            #     logit = logit - tau * torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n            # correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n\n            outputs = model(data, output_type='dict')\n            logit = outputs['logits'].cpu()\n\n            for cor_idx in range(logit.size(1)):\n                if cor_idx == 0:\n                    correct = (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n                else:\n                    correct += (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n            \n            correct = torch.floor(correct/logit.size(1))\n            loader.dataset.update_scores(correct,idx, state)\n    '''\n    all_indices = torch.arange(len(loader.dataset.targets))\n    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n\n    ratio = correct_sum_all_classes / trial_sum_all_classes\n    idx = loader.dataset.curr_state[0].int() + 1\n    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n\n    if condition:\n            loader.dataset.curr_state[all_indices] += 1\n    else:\n            loader.dataset.curr_state[all_indices] -= 1 \n    \n    '''\n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    \n\n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n\ndef ride_loss_wrap(criterion, student, teacher, target, extra_info):\n    if teacher == None:\n        return criterion(output_logits = student['output'], target = target, extra_info = extra_info)\n    else:\n        return criterion(student = student['output'], target = target, teacher = teacher, extra_info = extra_info)\n\ndef train_ride(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher):\n    \"\"\"\n    Training logic for an epoch\n    \n    :param epoch: Integer, current training epoch.\n    :return: A log that contains average loss and metric in this epoch.\n    \"\"\"\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    if hasattr(criterion, \"_hook_before_epoch\"):\n        criterion._hook_before_epoch(epoch)\n        \n    bar = Bar('Training', max=len(trainloader))\n\n\n    if args.cmo and 3 < epoch < (args.epochs-3):\n        inverse_iter = iter(weighted_trainloader)\n\n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n        \n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo and 3 < epoch < (args.epochs-3):\n            try:\n                data_tuple_f = next(inverse_iter)\n            except:\n                inverse_iter = iter(weighted_trainloader)\n                data_tuple_f = next(inverse_iter)\n                \n            inputs_f = data_tuple_f[0]\n            targets_f = data_tuple_f[1]\n            inputs_f = inputs_f[:len(inputs_b)]\n            targets_f = targets_f[:len(targets_b)]\n            inputs_f = inputs_f.cuda(non_blocking=True)\n            targets_f = targets_f.cuda(non_blocking=True)\n\n\n        inputs_b = inputs_b.cuda(non_blocking=True)\n        targets_b = targets_b.cuda(non_blocking=True)\n\n        r = np.random.rand(1)\n        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n            inputs_b, lam = cutmix(inputs_f, inputs_b)\n            outputs =  model(inputs_b)\n            extra_info = {}\n            # logits = outputs[\"logits\"]\n            # extra_info.update({\"logits\" : logits.transpose(0,1)})\n            # loss = criterion(output_logits = outputs['output'], target = targets_b, extra_info = extra_info) * lam + criterion(output_logits = outputs['output'], target = targets_f, extra_info = extra_info) * (1.-lam)\n            if teacher == None:\n                teacher_outputs = None\n            else:\n                teacher_outputs = teacher(inputs_b)['output']\n            \n            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n                \n            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info) * lam + ride_loss_wrap(criterion, outputs, teacher_outputs, targets_f, extra_info) * (1.-lam)\n            \n            \n        else:\n            extra_info = {}\n            outputs = model(inputs_b)\n            # logits = outputs[\"logits\"]\n            # extra_info.update({\"logits\": logits.transpose(0, 1)})\n            # loss = criterion(output_logits=outputs['output'], target=targets_b, extra_info=extra_info)\n            \n            if teacher == None:\n                teacher_outputs = None\n            else:\n                teacher_outputs = teacher(inputs_b)['output']\n            \n            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        \n        bar.next()\n    bar.finish()\n    return losses.avg\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.784864Z","iopub.execute_input":"2024-01-26T03:58:56.785276Z","iopub.status.idle":"2024-01-26T03:58:56.825054Z","shell.execute_reply.started":"2024-01-26T03:58:56.785239Z","shell.execute_reply":"2024-01-26T03:58:56.823922Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"train.py","metadata":{}},{"cell_type":"code","source":"#from train.train_fn.base import train_base, update_score_base\n#from train.train_fn.ride import train_ride, update_score_ride\n#from train.train_fn.ncl import train_ncl, update_score_ncl\n#from train.train_fn.bcl import train_bcl, update_score_bcl\n\ndef get_train_fn(args):\n    if args.loss_fn == 'ride':\n        return train_ride\n    elif args.loss_fn == 'ncl':\n        return train_ncl\n    elif args.loss_fn == 'bcl':\n        return train_bcl\n    else:\n        return train_base\n\n        \n        \ndef get_update_score_fn(args):\n    if args.loss_fn == 'ride':\n        return update_score_ride\n    elif args.loss_fn == 'ncl':\n        return update_score_ncl\n    elif args.loss_fn == 'bcl':\n        return update_score_bcl\n    else:\n        return update_score_base\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.826588Z","iopub.execute_input":"2024-01-26T03:58:56.827008Z","iopub.status.idle":"2024-01-26T03:58:56.837785Z","shell.execute_reply.started":"2024-01-26T03:58:56.826963Z","shell.execute_reply":"2024-01-26T03:58:56.836829Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"validate.py","metadata":{}},{"cell_type":"code","source":"#from utils.accuracy import AverageMeter, accuracy\nfrom scipy import optimize\n#from utils.common import Bar\nimport torch\nimport numpy as np\nimport time\n\ndef get_valid_fn(args):\n    if args.loss_fn == 'ncl':\n        return valid_ncl\n    elif args.loss_fn == 'bcl':\n        return valid_bcl\n    else:\n        return valid_normal\n\n\ndef valid_ncl(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats'):\n    combiner = model['comb']\n    model = model['model']\n    network_num = 3\n    model.eval()\n    network_num = 3\n    cnt_all = 0\n    every_network_result = [0 for _ in range(network_num)]\n\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    \n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            image = data_tuple[0]\n            label = data_tuple[1]\n            indexs = data_tuple[2]\n\n            image, label = image.cuda(), label.cuda()\n            image_list = [image for i in range(network_num)]\n\n            if args.dataset in ['cifar100', 'places']:\n                feature = model((image_list,image_list), label=label, feature_flag=True)\n                output_ce, output, output_MA = model(feature, classifier_flag=True)\n            else:\n                feature = model(image_list, label=label, feature_flag=True)\n                output_ce = model(feature, classifier_flag=True)\n\n\n            \n            for j, logit in enumerate(output_ce):\n                every_network_result[j] += torch.sum(torch.argmax(logit, dim=1).cpu() == label.cpu())\n\n            average_result = torch.mean(torch.stack(output_ce), dim=0)\n            loss = criterion(average_result, label)\n\n            prec1, prec5 = accuracy(average_result.cpu(), label.cpu(), topk=(1,5))\n            losses.update(loss.data.item(), image.size(0))\n            top1.update(prec1.item(), image.size(0))\n            top5.update(prec5.item(), image.size(0))\n\n            # classwise prediction\n            pred_label = average_result.max(1)[1]\n            pred_mask = (label == pred_label).float()\n            for i in range(num_class):\n                class_mask = (label == i).float()\n                classwise_correct[i] += (class_mask * pred_mask).sum().detach().cpu()\n                classwise_num[i] += class_mask.sum().detach().cpu()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        \n    # Major, Neutral, Minor\n    classwise_acc = (classwise_correct / classwise_num)\n    \n    per_class_num = torch.tensor(per_class_num)\n    many_pos = torch.where(per_class_num > 100)\n    med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n    few_pos = torch.where(per_class_num < 20)\n    section_acc[0] = classwise_acc[many_pos].mean()\n    section_acc[1] = classwise_acc[med_pos].mean()\n    section_acc[2] = classwise_acc[few_pos].mean()\n    \n    return (losses.avg, top1.avg,  section_acc)\n\ndef valid_normal(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    \n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    all_preds = np.zeros(len(valloader.dataset))\n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            inputs = data_tuple[0].cuda(non_blocking=True)\n            targets = data_tuple[1].cuda(non_blocking=True)\n            indexs = data_tuple[2]\n            \n            # measure data loading time\n            data_time.update(time.time() - end)\n            \n            # compute output\n            outputs = model(inputs, None)\n            loss = criterion(outputs, targets)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n            losses.update(loss.item(), inputs.size(0))\n            top1.update(prec1.item(), inputs.size(0))\n            top5.update(prec5.item(), inputs.size(0))\n            \n            # classwise prediction\n            pred_label = outputs.max(1)[1]\n            all_preds[indexs] = pred_label.cpu().numpy()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        # Major, Neutral, Minor\n        \n        all_targets = np.array(valloader.dataset.targets)\n        pred_mask = (all_targets == all_preds).astype(float)\n        for i in range(num_class):\n            class_mask = np.where(all_targets == i)[0].reshape(-1)\n            classwise_correct[i] += pred_mask[class_mask].sum()\n            classwise_num[i] += len(class_mask)\n            \n        classwise_acc = (classwise_correct / classwise_num)\n        \n        per_class_num = torch.tensor(per_class_num)\n        many_pos = torch.where(per_class_num > 100)\n        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n        few_pos = torch.where(per_class_num < 20)\n        section_acc[0] = classwise_acc[many_pos].mean()\n        section_acc[1] = classwise_acc[med_pos].mean()\n        section_acc[2] = classwise_acc[few_pos].mean()\n\n    return (losses.avg, top1.avg,  section_acc)\n\n\ndef valid_bcl(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    \n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    all_preds = np.zeros(len(valloader.dataset))\n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            inputs = data_tuple[0].cuda(non_blocking=True)\n            targets = data_tuple[1].cuda(non_blocking=True)\n            indexs = data_tuple[2]\n            \n            # measure data loading time\n            data_time.update(time.time() - end)\n            \n            # compute output\n            _, outputs, _ = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n            losses.update(loss.item(), inputs.size(0))\n            top1.update(prec1.item(), inputs.size(0))\n            top5.update(prec5.item(), inputs.size(0))\n            \n            # classwise prediction\n            pred_label = outputs.max(1)[1]\n            all_preds[indexs] = pred_label.cpu().numpy()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        # Major, Neutral, Minor\n        \n        all_targets = np.array(valloader.dataset.targets)\n        pred_mask = (all_targets == all_preds).astype(float)\n        for i in range(num_class):\n            class_mask = np.where(all_targets == i)[0].reshape(-1)\n            classwise_correct[i] += pred_mask[class_mask].sum()\n            classwise_num[i] += len(class_mask)\n            \n        classwise_acc = (classwise_correct / classwise_num)\n        \n        per_class_num = torch.tensor(per_class_num)\n        many_pos = torch.where(per_class_num > 100)\n        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n        few_pos = torch.where(per_class_num < 20)\n        section_acc[0] = classwise_acc[many_pos].mean()\n        section_acc[1] = classwise_acc[med_pos].mean()\n        section_acc[2] = classwise_acc[few_pos].mean()\n\n    return (losses.avg, top1.avg,  section_acc)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:56.839582Z","iopub.execute_input":"2024-01-26T03:58:56.839981Z","iopub.status.idle":"2024-01-26T03:58:57.066804Z","shell.execute_reply.started":"2024-01-26T03:58:56.839949Z","shell.execute_reply":"2024-01-26T03:58:57.065540Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"resnetbcl","metadata":{}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n        self.apply(_weights_init)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass LambdaLayer(nn.Module):\n\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='A'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_s(nn.Module):\n\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet_s, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        return out\n\nclass bcl_model(nn.Module):\n    def __init__(self, num_classes=100, use_norm=False):\n        super(bcl_model, self).__init__()\n        self.encoder = ResNet_s(BasicBlock, [5,5,5], num_classes)\n        dim_in = 64 #2048\n        mid_dim = 512 #2048\n        feat_dim = 128 #1024\n        self.use_norm = use_norm\n        self.head = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n        \n        if self.use_norm:\n            self.fc = NormedLinear(dim_in, num_classes)\n        else:\n            self.fc = nn.Linear(dim_in, num_classes)\n        self.head_fc = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n\n        self.apply(_weights_init)\n\n\n    def forward(self, x):\n        feat = self.encoder(x)\n        feat_mlp = F.normalize(self.head(feat), dim=1)\n        logits = self.fc(feat)\n        if self.use_norm:\n            centers_logits = F.normalize(self.head_fc(self.fc.weight.T), dim=1)\n        else:\n            centers_logits = F.normalize(self.head_fc(self.fc.weight), dim=1)\n        return feat_mlp, logits, centers_logits\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.068243Z","iopub.execute_input":"2024-01-26T03:58:57.068561Z","iopub.status.idle":"2024-01-26T03:58:57.249812Z","shell.execute_reply.started":"2024-01-26T03:58:57.068534Z","shell.execute_reply":"2024-01-26T03:58:57.248685Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"resnetncl","metadata":{}},{"cell_type":"code","source":"\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\n\nimport numpy as np\nimport cv2\nimport os\nimport copy\nimport math\nfrom torch.nn.parameter import Parameter\n\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            inplanes, planes, kernel_size=3, padding=1, bias=False, stride=stride\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, padding=1, bias=False, stride=1\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n        # self.downsample = downsample\n        if stride != 1 or self.expansion * planes != inplanes:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(\n                    inplanes,\n                    self.expansion * planes,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n        else:\n            self.downsample = None\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass BottleNeck(nn.Module):\n\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1):\n        super(BottleNeck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu1 = nn.ReLU(True)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.relu2 = nn.ReLU(True)\n        self.conv3 = nn.Conv2d(\n            planes, planes * self.expansion, kernel_size=1, bias=False\n        )\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n        if stride != 1 or self.expansion * planes != inplanes:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(\n                    inplanes,\n                    self.expansion * planes,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n        else:\n            self.downsample = None\n        self.relu = nn.ReLU(True)\n\n    def forward(self, x):\n        out = self.relu1(self.bn1(self.conv1(x)))\n\n        out = self.relu2(self.bn2(self.conv2(out)))\n\n        out = self.bn3(self.conv3(out))\n\n        if self.downsample != None:\n            residual = self.downsample(x)\n        else:\n            residual = x\n        out = out + residual\n        out = self.relu(out)\n        return out\n\n##kaiming init missing!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nclass ResNet(nn.Module):\n    def __init__(\n        self,\n        args,\n        block_type,\n        num_blocks,\n        last_layer_stride=2,\n    ):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.block = block_type\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(True)\n        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(num_blocks[0], 64)\n        self.layer2 = self._make_layer(\n            num_blocks[1], 128, stride=2\n        )\n        self.layer3 = self._make_layer(\n            num_blocks[2], 256, stride=2\n        )\n        self.layer4 = self._make_layer(\n            num_blocks[3],\n            512,\n            stride=last_layer_stride,\n        )\n\n    def load_model(self, pretrain):\n        print(\"Loading Backbone pretrain model from {}......\".format(pretrain))\n        model_dict = self.state_dict()\n        pretrain_dict = torch.load(pretrain)\n        pretrain_dict = pretrain_dict[\"state_dict\"] if \"state_dict\" in pretrain_dict else pretrain_dict\n        from collections import OrderedDict\n\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if k.startswith(\"module\"):\n                k = k[7:]\n            if \"fc\" not in k and \"classifier\" not in k:\n                k = k.replace(\"backbone.\", \"\")\n                new_dict[k] = v\n\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"Backbone model has been loaded......\")\n\n    def _make_layer(self, num_block, planes, stride=1):\n        strides = [stride] + [1] * (num_block - 1)\n        layers = []\n        for now_stride in strides:\n            layers.append(\n                self.block(\n                    self.inplanes, planes, stride=now_stride\n                )\n            )\n            self.inplanes = planes * self.block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x, **kwargs):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.pool(out)\n\n        out = self.layer1(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer1':\n            out = kwargs['coef']*out + (1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer2(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer2':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer3(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer3':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer4(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer4':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        return out\n\ndef res50(args,last_layer_stride=2):\n    return ResNet(args,BottleNeck,[3, 4, 6, 3],last_layer_stride=last_layer_stride)\n    \n\ndef res152(args,last_layer_stride=2):\n    return ResNet(args,BottleNeck,[3, 8, 36, 3],last_layer_stride=last_layer_stride)\n    \n\n\n\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\n\nclass LambdaLayer(nn.Module):\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option=\"A\"):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == \"A\":\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(\n                    lambda x: F.pad(\n                        x[:, :, ::2, ::2],\n                        (0, 0, 0, 0, planes // 4, planes // 4),\n                        \"constant\",\n                        0,\n                    )\n                )\n            elif option == \"B\":\n                self.shortcut = nn.Sequential(\n                    nn.Conv2d(\n                        in_planes,\n                        self.expansion * planes,\n                        kernel_size=1,\n                        stride=stride,\n                        bias=False,\n                    ),\n                    nn.BatchNorm2d(self.expansion * planes),\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_Cifar(nn.Module):\n    def __init__(self, block, num_blocks):\n        super(ResNet_Cifar, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def load_model(self, pretrain):\n        print(\"Loading Backbone pretrain model from {}......\".format(pretrain))\n        model_dict = self.state_dict()\n        pretrain_dict = torch.load(pretrain)\n        pretrain_dict = pretrain_dict[\"state_dict\"] if \"state_dict\" in pretrain_dict else pretrain_dict\n        from collections import OrderedDict\n\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if k.startswith(\"module\"):\n                k = k[7:]\n            if \"last_linear\" not in k and \"classifier\" not in k and \"linear\" not in k and \"fd\" not in k:\n                k = k.replace(\"backbone.\", \"\")\n                k = k.replace(\"fr\", \"layer3.4\")\n                new_dict[k] = v\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"Backbone model has been loaded......\")\n\n    def forward(self, x, **kwargs):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer1':\n            out = kwargs['coef']*out + (1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer2(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer2':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer3(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer3':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        return out\n\ndef res32_cifar(args,last_layer_stride):\n    return ResNet_Cifar(BasicBlock, [5, 5, 5])\n    \n\n\n\ndef ncl_model(args, num_class_list):\n    if args.dataset in ['cifar100', 'places']:\n        model = multi_Network_MOCO(args, mode=\"train\", num_classes=args.num_class).cuda()\n        comb = Combiner(args, num_class_list)\n    else:\n        model = multi_Network(args, mode=\"train\", num_classes=args.num_class).cuda()\n        comb = Combiner(args, num_class_list)\n    return {'comb': comb, 'model': model}\n\nclass Combiner:\n    def __init__(self, args, num_class_list=None):\n        self.args = args\n\n        if self.args.dataset in ['cifar100', 'places']:\n            self.type = 'multi_network_default_CON'\n        else:\n            self.type = 'multi_network_default'\n        \n        self.num_class_list = torch.FloatTensor(num_class_list)\n        self.epoch_number = self.args.epochs\n        self.initilize_all_parameters()\n\n    def initilize_all_parameters(self):\n\n        if self.args.dataset == 'cifar100':\n            self.show_step = 100\n            self.CON_ratio = 1.0    \n            self.distributed = False\n        elif self.args.dataset == 'places':\n            self.show_step = 200\n            self.CON_ratio = 1.0    \n            self.distributed = True\n        elif self.args.dataset == 'imgnet':\n            self.show_step = 200\n            self.CON_ratio = 0.0\n            self.distributed = True\n        elif self.args.dataset == 'inat':\n            self.show_step = 500\n            self.CON_ratio = 0.0\n            self.distributed = True\n\n    def update(self, epoch):\n        self.epoch = epoch\n\n\n    def forward(self, model, criterion, image, label):\n        return eval(\"self.{}\".format(self.type))(model, criterion, image, label)\n\n\n    def multi_network_default(self, model, criterion, image, label):\n\n        for i in range(len(image)):\n            image[i], label[i] = image[i].cuda(), label[i].cuda()\n\n\n        feature = model(image, feature_flag=True, label=label)\n        output = model(feature, classifier_flag=True)\n\n        loss = criterion(output, label)\n\n        average_result = torch.mean(torch.stack(output), dim=0)\n        \n        return loss\n\n    def multi_network_default_CON(self, model, criterion, image, label):\n\n        image_p = []\n        image_k = []\n        for i in range(len(image)):\n            image_p.append(image[i][0].cuda())\n            image_k.append(image[i][1].cuda())\n            label[i] = label[i].cuda()\n\n        # shuffle BN\n        if self.distributed:\n            image_k, idx_unshuffle = shuffle_BN_DDP(image_k)\n            pass\n        else:\n            image_k, idx_unshuffle = shuffle_BN(image_k)\n\n\n        feature = model((image_p, image_k), feature_flag=True, label=label)\n        output_ce, output_p, output_k = model(feature, classifier_flag=True)\n\n        # unshuffle\n        if self.distributed:\n            output_k = unshuffle_BN_DDP(output_k, idx_unshuffle)\n        else:\n            output_k = unshuffle_BN(output_k, idx_unshuffle)\n\n        loss_ce = criterion(output_ce, label, feature=feature, classifier=model.classifier)\n\n        average_result = torch.mean(torch.stack(output_ce), dim=0)\n        \n        # contrastive_loss\n        loss_CON = 0\n        for i, (q, k) in enumerate(zip(output_p, output_k)):\n            q = F.normalize(q, dim=1)\n            k = F.normalize(k, dim=1)\n            # compute logits\n            # Einstein sum is more intuitive\n            # positive logits: Nx1\n            l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n            # negative logits: NxK\n            l_neg = torch.einsum('nc,ck->nk', [q, model.MOCO[i].queue.clone().detach()])\n\n            # logits: Nx(1+K)\n            logits = torch.cat([l_pos, l_neg], dim=1)\n\n            # apply temperature\n            logits /= model.MOCO[i].T\n\n            # labels: positive key indicators\n            labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n\n            # dequeue and enqueue\n            if self.distributed:\n                model.MOCO[i]._dequeue_and_enqueue_DDP(k)\n            else:\n                model.MOCO[i]._dequeue_and_enqueue(k)\n\n\n            loss_CON += F.cross_entropy(logits, labels)\n\n        loss = loss_ce + loss_CON * self.CON_ratio\n\n        return loss\n\n\n\nclass FCNorm(nn.Module):\n    def __init__(self, num_features, num_classes):\n        super(FCNorm, self).__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.linear(F.normalize(x), F.normalize(self.weight))\n        return out\n\n\nclass GAP(nn.Module):\n    \"\"\"Global Average pooling\n        Widely used in ResNet, Inception, DenseNet, etc.\n     \"\"\"\n\n    def __init__(self):\n        super(GAP, self).__init__()\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n    def forward(self, x):\n        x = self.avgpool(x)\n        #         x = x.view(x.shape[0], -1)\n        return x\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n\n    def forward(self, x):\n        return x\n\n\n@torch.no_grad()\ndef concat_all_gather(tensor):\n    \"\"\"\n    Performs all_gather operation on the provided tensors.\n    *** Warning ***: torch.distributed.all_gather has no gradient.\n    \"\"\"\n    #with torch.no_grad():\n    tensors_gather = [torch.ones_like(tensor)\n        for _ in range(torch.distributed.get_world_size())]\n    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n\n    output = torch.cat(tensors_gather, dim=0)\n    return output\n\n@torch.no_grad()\ndef shuffle_BN(image):\n    #with torch.no_grad():\n    batch_size = image[0].shape[0]\n    idx_shuffle = torch.randperm(batch_size).cuda()\n    for i in range(len(image)):\n        image[i] = image[i][idx_shuffle]\n    idx_unshuffle = torch.argsort(idx_shuffle)\n    return image, idx_unshuffle\n\n@torch.no_grad()\ndef shuffle_BN_DDP(x):\n    \"\"\"\n    Batch shuffle, for making use of BatchNorm.\n    *** Only support DistributedDataParallel (DDP) model. ***\n    \"\"\"\n    # gather from all gpus\n\n    #with torch.no_grad():\n    shuffle_list = []\n    idx_shuffle = 0\n    for i in range(len(x)):\n        batch_size_this = x[i].shape[0]\n        x_gather = concat_all_gather(x[i])\n        batch_size_all = x_gather.shape[0]\n\n        num_gpus = batch_size_all // batch_size_this\n\n        # random shuffle index\n        if i == 0:\n            idx_shuffle = torch.randperm(batch_size_all).cuda()\n            # index for restoring\n            idx_unshuffle = torch.argsort(idx_shuffle)\n\n        # broadcast to all gpus\n        torch.distributed.broadcast(idx_shuffle, src=0)\n\n\n\n        # shuffled index for this gpu\n        gpu_idx = torch.distributed.get_rank()\n        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n        shuffle_list.append(x_gather[idx_this])\n\n    return shuffle_list, idx_unshuffle\n\n@torch.no_grad()\ndef unshuffle_BN(x, idx_unshuffle):\n    #with torch.no_grad():\n    for i in range(len(x)):\n        x[i] = x[i][idx_unshuffle]\n    return x\n\n@torch.no_grad()\ndef unshuffle_BN_DDP(x, idx_unshuffle):\n    \"\"\"\n    Undo batch shuffle.\n    *** Only support DistributedDataParallel (DDP) model. ***\n    \"\"\"\n    # gather from all gpus\n   # with torch.no_grad():\n    unshuffle_list = []\n    for i in range(len(x)):\n        batch_size_this = x[i].shape[0]\n        x_gather = concat_all_gather(x[i])\n        batch_size_all = x_gather.shape[0]\n\n        num_gpus = batch_size_all // batch_size_this\n\n        # restored index for this gpu\n        gpu_idx = torch.distributed.get_rank()\n        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n        unshuffle_list.append(x_gather[idx_this])\n\n    return unshuffle_list\n\nclass MoCo(nn.Module):\n    \"\"\"\n    Build a MoCo model with: a query encoder, a key encoder, and a queue\n    https://arxiv.org/abs/1911.05722\n    \"\"\"\n    def __init__(self, dim=128, K=65536, m=0.999, T=0.07):\n        \"\"\"\n        dim: feature dimension (default: 128)\n        K: queue size; number of negative keys (default: 65536)\n        m: moco momentum of updating key encoder (default: 0.999)\n        T: softmax temperature (default: 0.07)\n        \"\"\"\n        super(MoCo, self).__init__()\n\n        self.K = K\n        self.m = m\n        self.T = T\n\n        # create the queue\n        self.register_buffer(\"queue\", torch.randn(dim, K))\n        self.queue = nn.functional.normalize(self.queue, dim=0)\n\n        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n\n\n\n    @torch.no_grad()\n    def _dequeue_and_enqueue_DDP(self, keys):\n        # gather keys before updating queue\n        keys = concat_all_gather(keys)\n\n        batch_size = keys.shape[0]\n\n        ptr = int(self.queue_ptr)\n\n        assert self.K % batch_size == 0  # for simplicity\n\n        # replace the keys at ptr (dequeue and enqueue)\n        self.queue[:, ptr:ptr + batch_size] = keys.T\n        ptr = (ptr + batch_size) % self.K  # move pointer\n\n        self.queue_ptr[0] = ptr\n\n    @torch.no_grad()\n    def _dequeue_and_enqueue(self, keys, **kwargs):\n\n        batch_size = keys.shape[0]\n\n        ptr = int(self.queue_ptr)\n\n        assert self.K % batch_size == 0  # for simplicity\n\n        # replace the keys at ptr (dequeue and enqueue)\n        self.queue[:, ptr:ptr + batch_size] = keys.T\n\n        ptr = (ptr + batch_size) % self.K  # move pointer\n\n        self.queue_ptr[0] = ptr\n\nclass Cos_Classifier(nn.Module):\n    \"\"\" plain cosine classifier \"\"\"\n\n    def __init__(self, num_classes=10, in_dim=640, scale=16, bias=False):\n        super(Cos_Classifier, self).__init__()\n        self.scale = scale\n        self.weight = Parameter(torch.Tensor(num_classes, in_dim).cuda())\n        self.bias = Parameter(torch.Tensor(num_classes).cuda(), requires_grad=bias)\n        self.init_weights()\n\n    def init_weights(self):\n        self.bias.data.fill_(0.)\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n\n    def forward(self, x, **kwargs):\n        ex = x / torch.norm(x.clone(), 2, 1, keepdim=True)\n        ew = self.weight / torch.norm(self.weight, 2, 1, keepdim=True)\n        out = torch.mm(ex, self.scale * ew.t()) + self.bias\n        return out\n\nclass multi_Network(nn.Module):\n    def __init__(self, args, mode=\"train\", num_classes=1000):\n        super(multi_Network, self).__init__()\n        \n        self.num_classes = num_classes\n        self.args = args\n        self.network_num = 3\n        \n        \n        if self.args.dataset == 'cifar100':\n            self.args.net_type = 'res32_cifar'\n            self.args.cf = 'FC'\n            self.args.cos_scale = 16\n        elif self.args.dataset == 'imgnet':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 16\n        elif self.args.dataset == 'inat':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 32\n            \n\n        self.backbone = nn.ModuleList(\n            eval(self.args.net_type)(\n                self.args,\n                last_layer_stride=2,\n            ) for i in range(self.network_num))\n\n        self.module = nn.ModuleList(\n            self._get_module()\n            for i in range(self.network_num))\n\n        \n        self.classifier = nn.ModuleList(\n            self._get_multi_classifer(True, self.cf)\n            for i in range(self.network_num))\n\n    def forward(self, input, **kwargs):\n\n        if \"feature_flag\" in kwargs:\n            return self.extract_feature(input, **kwargs)\n        elif \"classifier_flag\" in kwargs:\n            return self.get_logits(input, **kwargs)\n\n        logits = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i], **kwargs)\n            x = (self.module[i])(x)\n            x = x.view(x.shape[0], -1)\n            self.feat.append(copy.deepcopy(x))\n            x = (self.classifier[i])(x)\n            logits.append(x)\n\n        return logits\n\n    def extract_feature(self, input, **kwargs):\n\n        feature = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i])\n            x = (self.module[i])(x)\n            x = x.view(x.shape[0], -1)\n            feature.append(x)\n\n        return feature\n\n    def get_logits(self, input, **kwargs):\n\n        logits = []\n        for i in range(self.network_num):\n            x = input[i]\n            x = (self.classifier[i])(x)\n            logits.append(x)\n\n        return logits\n\n    def extract_feature_maps(self, x):\n        x = self.backbone(x)\n        return x\n\n    def freeze_multi_backbone(self):\n        print(\"Freezing backbone .......\")\n        for p in self.backbone.parameters():\n            p.requires_grad = False\n\n    def load_backbone_model(self, backbone_path=\"\"):\n        self.backbone.load_model(backbone_path)\n        print(\"Backbone model has been loaded...\")\n\n    def load_model(self, model_path, **kwargs):\n        pretrain_dict = torch.load(\n            model_path, map_location=\"cuda\"\n        )\n        pretrain_dict = pretrain_dict['state_dict'] if 'state_dict' in pretrain_dict else pretrain_dict\n        model_dict = self.state_dict()\n        from collections import OrderedDict\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if 'backbone_only' in kwargs.keys() and 'classifier' in k:\n                continue;\n            if k.startswith(\"module\"):\n                if k[7:] not in model_dict.keys():\n                    print('not load:{}'.format(k))\n                new_dict[k[7:]] = v\n            else:\n                new_dict[k] = v\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"All model has been loaded...\")\n\n    def get_feature_length(self):\n        if \"cifar\" in self.args.net_type:\n            num_features = 64\n        else:\n            num_features = 2048\n        return num_features\n\n    def _get_module(self):\n        module = GAP()\n        return module\n\n    def _get_multi_classifer(self, bias_flag, type):\n\n        num_features = self.get_feature_length()\n        if type == \"FCNorm\":\n            classifier = FCNorm(num_features, self.num_classes)\n        elif type == \"FC\":\n            classifier = nn.Linear(num_features, self.num_classes, bias=bias_flag)\n        elif type == 'cos':\n            classifier = Cos_Classifier(self.num_classes, num_features, scale=self.args.cos_scale, bias=bias_flag)\n        else:\n            raise NotImplementedError\n\n        return classifier\n\nclass multi_Network_MOCO(nn.Module):\n    def __init__(self, args, mode=\"train\", num_classes=1000):\n        super(multi_Network_MOCO, self).__init__()\n        \n        self.args = args\n        self.num_classes = num_classes\n        self.network_num = 3\n        \n        if self.args.dataset == 'cifar100':\n            self.args.net_type = 'res32_cifar'\n            self.args.cf = 'FC'\n            self.args.scf = 'mlp'\n            self.args.cos_scale = 16\n            self.args.moco_dim = 64\n            self.args.mlp_dim = self.args.moco_dim\n            self.args.moco_k = 1024\n            self.args.moco_t = 0.2\n        \n        elif self.args.dataset == 'imgnet':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 16\n\n        elif self.args.dataset == 'inat':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 32\n\n        self.MOCO = nn.ModuleList(\n            MoCo(dim=self.args.moco_dim, K=self.args.moco_k, T=self.args.moco_t)\n            for i in range(self.network_num))\n\n\n        self.backbone = nn.ModuleList(\n            eval(self.args.net_type)(\n                self.args,\n                last_layer_stride=2,\n            ) for i in range(self.network_num))\n\n\n        self.module = nn.ModuleList(\n            self._get_module()\n            for i in range(self.network_num))\n\n        \n        self.classifier = nn.ModuleList(\n            self._get_multi_classifer(True, self.args.scf)\n            for i in range(self.network_num))\n        self.feat = []\n\n        self.backbone_MA = nn.ModuleList(\n            eval(self.args.net_type)(\n                self.args,\n                last_layer_stride=2,\n            ) for i in range(self.network_num))\n\n        for i in range(self.network_num):\n            for param in self.backbone_MA[i].parameters():\n                param.detach_()\n\n        self.module_MA = nn.ModuleList(\n            self._get_module()\n            for i in range(self.network_num))\n        for i in range(self.network_num):\n            for param in self.module_MA[i].parameters():\n                param.detach_()\n\n        \n        self.classifier_MA = nn.ModuleList(\n            self._get_multi_classifer(True, self.args.scf)\n            for i in range(self.network_num))\n        for i in range(self.network_num):\n            for param in self.classifier_MA[i].parameters():\n                param.detach_()\n        self.feat_MA = []\n\n        if self.args.cf == 'FC':\n            self.classifier_ce = nn.ModuleList(\n                nn.Linear(self.get_feature_length(), self.num_classes, True)\n                for i in range(self.network_num))\n        elif self.args.cf == 'cos':\n            self.classifier_ce = nn.ModuleList(\n                Cos_Classifier(self.num_classes, in_dim=self.get_feature_length(), scale=self.args.cos_scale, bias=True)\n                for i in range(self.network_num))\n\n    def forward(self, input, **kwargs):\n\n\n        if \"feature_flag\" in kwargs:\n            return self.extract_feature(input, **kwargs)\n        elif \"classifier_flag\" in kwargs:\n            return self.get_logits(input, **kwargs)\n\n        logits = []\n        logits_ce = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i], **kwargs)\n            x = (self.module[i])(x)\n            feature = x.view(x.shape[0], -1)\n            self.feat.append(copy.deepcopy(feature))\n            \n            output = (self.classifier[i])(feature)\n            logits.append(output)\n\n            output_ce = (self.classifier_ce[i])(feature)\n            logits_ce.append(output_ce)\n\n        logits_MA = []\n        for i in range(self.network_num):\n            x = (self.backbone_MA[i])(input[i], **kwargs)\n            x = (self.module_MA[i])(x)\n            x = x.view(x.shape[0], -1)\n            self.feat_MA.append(copy.deepcopy(x))\n            x = (self.classifier_MA[i])(x)\n            logits_MA.append(x)\n\n        return logits_ce, logits, logits_MA\n\n    def extract_feature(self, input_all, **kwargs):\n\n        input, input_MA = input_all\n\n        feature = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i], label=kwargs['label'][i])\n            x = (self.module[i])(x)\n            x = x.view(x.shape[0], -1)\n            feature.append(x)\n\n        feature_MA = []\n        for i in range(self.network_num):\n            x = (self.backbone_MA[i])(input_MA[i], label=kwargs['label'][i])\n            x = (self.module_MA[i])(x)\n            x = x.view(x.shape[0], -1)\n            feature_MA.append(x)\n        return feature, feature_MA\n\n    def get_logits(self, input_all, **kwargs):\n\n        input, input_MA = input_all\n        logits = []\n        logits_ce = []\n        for i in range(self.network_num):\n            feature = input[i]\n            \n            output = (self.classifier[i])(feature)\n            logits.append(output)\n\n            output_ce = (self.classifier_ce[i])(feature)\n            logits_ce.append(output_ce)\n\n        logits_MA = []\n        for i in range(self.network_num):\n            x = input_MA[i]\n            x = (self.classifier_MA[i])(x)\n            logits_MA.append(x)\n\n        return logits_ce, logits, logits_MA\n\n    def extract_feature_maps(self, x):\n        x = self.backbone(x)\n        return x\n\n    def freeze_multi_backbone(self):\n        print(\"Freezing backbone .......\")\n        for p in self.backbone.parameters():\n            p.requires_grad = False\n\n    def load_backbone_model(self, backbone_path=\"\"):\n        self.backbone.load_model(backbone_path)\n        print(\"Backbone model has been loaded...\")\n\n    def load_model(self, model_path, **kwargs):\n        pretrain_dict = torch.load(\n            model_path, map_location=\"cuda\"\n        )\n        pretrain_dict = pretrain_dict['state_dict'] if 'state_dict' in pretrain_dict else pretrain_dict\n        model_dict = self.state_dict()\n        from collections import OrderedDict\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if 'backbone_only' in kwargs.keys() and 'classifier' in k:\n                continue;\n            if k.startswith(\"module\"):\n                if k[7:] not in model_dict.keys():\n                    print('not load:{}'.format(k))\n                    continue\n                new_dict[k[7:]] = v\n            else:\n                new_dict[k] = v\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"All model has been loaded...\")\n\n    def get_feature_length(self):\n        if \"cifar\" in self.args.net_type:\n            num_features = 64\n        else:\n            num_features = 2048\n        return num_features\n\n    def _get_module(self):\n        module = GAP()\n        return module\n\n    def _get_multi_classifer(self, bias_flag, type):\n\n        num_features = self.get_feature_length()\n        if type == \"FCNorm\":\n            classifier = FCNorm(num_features, self.args.mlp_dim)\n        elif type == \"FC\":\n            classifier = nn.Linear(num_features, self.args.mlp_dim, bias=bias_flag)\n        elif type == \"mlp\":\n            classifier = nn.Sequential(nn.Linear(num_features, num_features, bias=bias_flag), \\\n                                       nn.ReLU(), \\\n                                       nn.Linear(num_features, self.args.mlp_dim, bias=bias_flag))\n        elif type == 'cos':\n            classifier = Cos_Classifier(self.args.mlp_dim, num_features, scale=self.args.cos_scale, bias=bias_flag)\n        else:\n            raise NotImplementedError\n\n        return classifier\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.252363Z","iopub.execute_input":"2024-01-26T03:58:57.252814Z","iopub.status.idle":"2024-01-26T03:58:57.445671Z","shell.execute_reply.started":"2024-01-26T03:58:57.252774Z","shell.execute_reply":"2024-01-26T03:58:57.444801Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"resnetride","metadata":{}},{"cell_type":"code","source":"import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\nimport random\n\n__all__ = ['resnet32_ride']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_planes, planes, stride=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        \n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n            \n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n    \nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n    \nclass ResNet_s(nn.Module):\n    def __init__(self, block, num_blocks, num_experts, num_classes=10, \n                 reduce_dimension=False, layer2_output_dim=None, \n                 layer3_output_dim=None, use_norm=False, use_experts=None, s=30):\n        super(ResNet_s, self).__init__()\n        \n        self.in_planes = 16\n        self.num_experts = num_experts\n        \n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.in_planes = self.next_in_planes\n        \n        if layer2_output_dim is None:\n            if reduce_dimension:\n                layer2_output_dim = 24\n            else:\n                layer2_output_dim = 32\n                \n        if layer3_output_dim is None:\n            if reduce_dimension:\n                layer3_output_dim = 48\n            else:\n                layer3_output_dim = 64\n                \n        self.layer2s = nn.ModuleList([self._make_layer(block, layer2_output_dim, num_blocks[1], stride=2) for _ in range(num_experts)])\n        self.in_planes = self.next_in_planes\n        self.layer3s = nn.ModuleList([self._make_layer(block, layer3_output_dim, num_blocks[2], stride=2) for _ in range(num_experts)])\n        self.in_planes = self.next_in_planes\n        \n        if use_norm:\n            self.linears = nn.ModuleList([NormedLinear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n        else:\n            self.linears = nn.ModuleList([nn.Linear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n            s = 1\n            \n        if use_experts is None:\n            self.use_experts = list(range(num_experts))\n        elif use_experts == \"rand\":\n            self.use_experts = None\n        else:\n            self.use_experts = [int(item) for item in use_experts.split(\",\")]\n            \n        self.s = s\n        self.apply(_weights_init)\n        \n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        self.next_in_planes = self.in_planes\n        for stride in strides:\n            layers.append(block(self.next_in_planes, planes, stride))\n            self.next_in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n    \n    def _hook_before_iter(self):\n        assert self.training, \"_hook_before_iter should be called at training time only, after train() is called\"\n        count = 0\n        for module in self.modules():\n            if isinstance(module, nn.BatchNorm2d):\n                if module.weight.requires_grad == False:\n                    module.eval()\n                    count += 1\n                    \n        if count > 0:\n            print(\"Warning: detected at least one frozen BN, set them to eval state. Count:\", count)\n            \n    def _separate_part(self, x, ind):\n        out = x\n        out = (self.layer2s[ind])(out)\n        out = (self.layer3s[ind])(out)\n        self.feat_before_GAP.append(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        self.feat.append(out)\n        out = (self.linears[ind])(out)\n        out = out * self.s\n        return out\n    \n    def forward(self, x, output_type = 'dict'):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        \n        outs = []\n        self.feat = []\n        self.logits = outs\n        self.feat_before_GAP = []\n        \n        if self.use_experts is None:\n            use_experts = random.sample(range(self.num_experts), self.num_experts - 1)\n        else:\n            use_experts = self.use_experts\n            \n        for ind in use_experts:\n            outs.append(self._separate_part(out, ind))\n        final_out = torch.stack(outs, dim=1).mean(dim=1)\n\n        if output_type == 'dict':\n            return {\"output\": final_out, \"logits\": torch.stack(outs, dim=1)}\n        else:\n            return final_out\n        \ndef resnet32_ride(num_class, use_norm=True, num_experts=3):\n    return ResNet_s(BasicBlock, [5,5,5], num_experts, num_classes=num_class, use_norm=use_norm, reduce_dimension=True)\n\ndef test(net):\n    import numpy as np\n    total_params = 0\n\n    for x in filter(lambda p: p.requires_grad, net.parameters()):\n        total_params += np.prod(x.data.numpy().shape)\n    print(\"Total number of params\", total_params)\n    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n    \nif __name__ == \"__main__\":\n    for net_name in __all__:\n        if net_name.startswith(\"resnet\"):\n            print(net_name)\n            test(globals()[net_name](2))\n            print()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.451951Z","iopub.execute_input":"2024-01-26T03:58:57.452397Z","iopub.status.idle":"2024-01-26T03:58:57.558092Z","shell.execute_reply.started":"2024-01-26T03:58:57.452368Z","shell.execute_reply":"2024-01-26T03:58:57.557080Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"resnet32_ride\nTotal number of params 774784\nTotal layers 80\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"resnet","metadata":{}},{"cell_type":"code","source":"'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\n__all__ = ['resnet32', 'NormedLinear']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass LambdaLayer(nn.Module):\n\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='A'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_s(nn.Module):\n\n    def __init__(self, block, num_blocks, num_classes=10, use_norm=False):\n        super(ResNet_s, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        if use_norm:\n            self.linear = NormedLinear(64, num_classes)\n        else:\n            self.linear = nn.Linear(64, num_classes)\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x, output_type='feat'):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out1 = out.view(out.size(0), -1)\n        out = self.linear(out1)\n        if output_type == 'feat':\n            return out, out1\n        else:\n            return out\n\ndef resnet32(num_class, use_norm):\n    return ResNet_s(BasicBlock, [5,5,5], num_class, use_norm=use_norm)\n'''","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.559945Z","iopub.execute_input":"2024-01-26T03:58:57.560634Z","iopub.status.idle":"2024-01-26T03:58:57.575348Z","shell.execute_reply.started":"2024-01-26T03:58:57.560597Z","shell.execute_reply":"2024-01-26T03:58:57.574349Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torch.nn.init as init\\nfrom torch.nn import Parameter\\n\\n__all__ = [\\'resnet32\\', \\'NormedLinear\\']\\n\\ndef _weights_init(m):\\n    classname = m.__class__.__name__\\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\\n        init.kaiming_normal_(m.weight)\\n\\nclass NormedLinear(nn.Module):\\n\\n    def __init__(self, in_features, out_features):\\n        super(NormedLinear, self).__init__()\\n        self.weight = Parameter(torch.Tensor(in_features, out_features))\\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\\n\\n    def forward(self, x):\\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\\n        return out\\n\\nclass LambdaLayer(nn.Module):\\n\\n    def __init__(self, lambd):\\n        super(LambdaLayer, self).__init__()\\n        self.lambd = lambd\\n\\n    def forward(self, x):\\n        return self.lambd(x)\\n\\n\\nclass BasicBlock(nn.Module):\\n    expansion = 1\\n\\n    def __init__(self, in_planes, planes, stride=1, option=\\'A\\'):\\n        super(BasicBlock, self).__init__()\\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\\n        self.bn1 = nn.BatchNorm2d(planes)\\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\\n        self.bn2 = nn.BatchNorm2d(planes)\\n\\n        self.shortcut = nn.Sequential()\\n        if stride != 1 or in_planes != planes:\\n            if option == \\'A\\':\\n                \"\"\"\\n                For CIFAR10 ResNet paper uses option A.\\n                \"\"\"\\n                self.shortcut = LambdaLayer(lambda x:\\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\\n            elif option == \\'B\\':\\n                self.shortcut = nn.Sequential(\\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\\n                     nn.BatchNorm2d(self.expansion * planes)\\n                )\\n\\n    def forward(self, x):\\n        out = F.relu(self.bn1(self.conv1(x)))\\n        out = self.bn2(self.conv2(out))\\n        out += self.shortcut(x)\\n        out = F.relu(out)\\n        return out\\n\\n\\nclass ResNet_s(nn.Module):\\n\\n    def __init__(self, block, num_blocks, num_classes=10, use_norm=False):\\n        super(ResNet_s, self).__init__()\\n        self.in_planes = 16\\n\\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\\n        self.bn1 = nn.BatchNorm2d(16)\\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\\n        if use_norm:\\n            self.linear = NormedLinear(64, num_classes)\\n        else:\\n            self.linear = nn.Linear(64, num_classes)\\n        self.apply(_weights_init)\\n\\n    def _make_layer(self, block, planes, num_blocks, stride):\\n        strides = [stride] + [1]*(num_blocks-1)\\n        layers = []\\n        for stride in strides:\\n            layers.append(block(self.in_planes, planes, stride))\\n            self.in_planes = planes * block.expansion\\n\\n        return nn.Sequential(*layers)\\n\\n    def forward(self, x, output_type=\\'feat\\'):\\n        out = F.relu(self.bn1(self.conv1(x)))\\n        out = self.layer1(out)\\n        out = self.layer2(out)\\n        out = self.layer3(out)\\n        out = F.avg_pool2d(out, out.size()[3])\\n        out1 = out.view(out.size(0), -1)\\n        out = self.linear(out1)\\n        if output_type == \\'feat\\':\\n            return out, out1\\n        else:\\n            return out\\n\\ndef resnet32(num_class, use_norm):\\n    return ResNet_s(BasicBlock, [5,5,5], num_class, use_norm=use_norm)\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"net.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport shutil\n#from models.resnet import *\n#from models.resnet_ride import *\n#from models.resnet_bcl import *\n#from models.resnet_ncl import *\n\nimport torch.nn as nn\nimport torchvision.models as models\n\ndef get_model(args, num_class_list):\n    \n    if args.loss_fn in ['ride']:\n        model = resnet32_ride(args.num_class, num_experts=args.num_experts).cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    \n    if args.loss_fn in ['ncl']:\n        model = ncl_model(args, num_class_list)\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model['model'].parameters())/1000000.0))\n\n    elif args.loss_fn in ['bcl']:\n        model = bcl_model(args.num_class, use_norm=args.use_norm).cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    '''\n    else:\n        model = resnet32(args.num_class, use_norm= args.loss_fn == 'ldam_drw').cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    '''\n    \n    torch.backends.cudnn.benchmark = True\n    return model   \n    \n\n\ndef load_model(args):\n    if args.loss_fn == 'ride' and args.num_experts == 3 and args.ride_distill:\n        print(\"---- ride teacher load ----\")\n        filepath = os.path.join(args.out, 'checkpoint_teacher.pth.tar')\n        if os.path.isfile(filepath):\n            pass    \n        else:\n            shutil.copy2(os.path.join(args.out, 'checkpoint.pth.tar'), os.path.join(args.out, 'checkpoint_teacher.pth.tar'))\n        checkpoint = torch.load(filepath)\n        teacher = resnet32_ride(args.num_class, num_experts = 6).cuda()\n        teacher.load_state_dict(checkpoint['state_dict'])\n    else:\n        teacher = None\n    return teacher\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.576550Z","iopub.execute_input":"2024-01-26T03:58:57.576880Z","iopub.status.idle":"2024-01-26T03:58:57.590599Z","shell.execute_reply.started":"2024-01-26T03:58:57.576845Z","shell.execute_reply":"2024-01-26T03:58:57.589590Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"config","metadata":{}},{"cell_type":"code","source":"import argparse, torch, os, random\nimport numpy as np\n\ndef parse_args(run_type = 'terminal'):\n    parser = argparse.ArgumentParser(description='Python Training')\n    \n    # Optimization options\n    parser.add_argument('--network', default='resnet32', help='Network: resnet32')\n    parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs to run')\n    parser.add_argument('--batch-size', default=128, type=int, metavar='N', help='train batchsize')\n    parser.add_argument('--update-epoch', default=1, type=int, metavar='N', help='Update epoch')\n    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float, metavar='LR', help='initial learning rate')\n    parser.add_argument('--lr_decay', default=0.01, type=float, help='learnign rate decay')\n    parser.add_argument('--momentum', default=0.9, type=float, help='SGD momentum')\n    parser.add_argument('--wd', default=2e-4, type=float, help='weight decay factor for optimizer')\n    parser.add_argument('--nesterov', action='store_true', help=\"Utilizing Nesterov\")\n    parser.add_argument('--scheduler', default='warmup', type=str, help='LR scheduler')\n    parser.add_argument('--warmup', default=5, type=int, help='Warmup epochs')\n        \n    parser.add_argument('--aug_prob', default=0.5, type=float, help='Augmentation Coin-tossing Probability')\n    parser.add_argument('--cutout', action='store_true', help='Utilizing Cutout')\n    parser.add_argument('--cmo', action='store_true', help='Utilizing CMO')\n    parser.add_argument('--posthoc_la', action='store_true', help='Posthoc LA for state update')\n    parser.add_argument('--cuda', action='store_true', help='Use CUDA')\n    parser.add_argument('--aug_type', default='none')\n    parser.add_argument('--sim_type', default='none')\n    parser.add_argument('--max_d', type=int, default=30, help='max_d')\n\n    parser.add_argument('--num_test', default=10, type=int, help='Curriculum Test')\n    parser.add_argument('--accept_rate', type=float, default=0.6, help='Increasing accept ratio')\n    parser.add_argument('--verbose', action='store_true', help='Debug on/off')\n    parser.add_argument('--use_norm', action='store_true', help='Utilize Normed Linear')\n    \n    # Checkpoints\n    parser.add_argument('--out', default='./results/', help='Directory to output the result')\n    parser.add_argument('--data_dir', default='~/dataset/')\n    \n    # Miscs\n    parser.add_argument('--workers', type=int, default=4, help='# workers')\n    parser.add_argument('--seed', type=str, default='None', help='manual seed')\n    parser.add_argument('--gpu', default=None, type=str, help='id(s) for CUDA_VISIBLE_DEVICES')\n    \n    # Dataset options\n    parser.add_argument('--dataset', default='cifar100', help='Dataset: cifar100')\n    parser.add_argument('--num_max', type=int, default=500, help='Number of samples in the maximal class')\n    parser.add_argument('--imb_ratio', type=int, default=100, help='Imbalance ratio for data')\n    \n    # Method options\n    parser.add_argument('--loss_fn', type=str, default='ce', help='Loss function for training')\n    parser.add_argument('--num_experts', type=int, default=3, help='Number of experts for RIDE')\n    parser.add_argument('--ride_distill', action='store_true', help='Use RIDEWithDistill Loss')\n    \n    if run_type == 'terminal':\n        args = parser.parse_args()\n    elif run_type =='jupyter':\n        args = parser.parse_args(args=[])\n        \n    args.out = f'{args.out}{args.dataset}/{args.loss_fn}@N_{args.num_max}_ir_{args.imb_ratio}/'\n    \n    if args.gpu:\n        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n    return args\n\n\ndef reproducibility(seed):\n    if seed == 'None':\n        return\n    else:\n        seed = int(seed)\n        torch.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        np.random.seed(seed)\n        random.seed(seed)\n\ndef dataset_argument(args):\n    if args.dataset == 'cifar100':\n        args.num_class = 100\n    else:\n        args.num_class = 10\n\n    return args\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.592302Z","iopub.execute_input":"2024-01-26T03:58:57.592711Z","iopub.status.idle":"2024-01-26T03:58:57.615354Z","shell.execute_reply.started":"2024-01-26T03:58:57.592673Z","shell.execute_reply":"2024-01-26T03:58:57.614304Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"logger","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\nfrom datetime import datetime\nimport os\nimport torch as t\n\nimport pandas as pd\n\nclass logger:\n    def __init__(self, args):\n            \n        self.logger = logging.getLogger('Evaluation')\n        self.logger.setLevel(logging.INFO)\n        self.args = args\n        \n        formatter = logging.Formatter('%(message)s')\n        \n        strm_handler = logging.StreamHandler()\n        strm_handler.setFormatter(formatter)\n        \n        now = datetime.now()\n        time = f'{now.hour}:{now.minute}:{now.second}-{now.year}-{now.month}-{now.day}'\n        os.makedirs(f'{args.out}',exist_ok=True)\n        file_handler = logging.FileHandler(f'{args.out}/{time.replace(\":\", \"-\")}.txt')\n\n\n        file_handler.setFormatter(formatter)\n                        \n        self.logger.addHandler(strm_handler)\n        self.logger.addHandler(file_handler)\n\n        message = f'---{args.dataset}---'\n        self(message, level=1)\n        self.arg_logging(args)\n\n    def __call__(self,message, level):\n        if level == 1:\n            prefix = '--->' \n        else:\n            prefix = '  '*level + '>'\n        \n        self.logger.info(f'{prefix} {message}')\n\n\n    def arg_logging(self, argument):\n        self('Argument', level=1)\n        arg_dict = vars(argument)\n        for key in arg_dict.keys():\n            if key == 'logger':\n                pass\n            else:\n                self(f'{key:12s}: {arg_dict[key]}', level=2)\n\n    def map_save(self, map):\n        map_df = pd.DataFrame(map)\n        map_df.to_csv(f'{self.args.out}/curriculum.csv',encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.616735Z","iopub.execute_input":"2024-01-26T03:58:57.617119Z","iopub.status.idle":"2024-01-26T03:58:57.631593Z","shell.execute_reply.started":"2024-01-26T03:58:57.617092Z","shell.execute_reply":"2024-01-26T03:58:57.630726Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"plot","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch as t\nimport numpy as np\nimport os\nimport pandas as pd\n\nsns.set_palette(\"bright\")\nsns.set_style(\"darkgrid\")\n\ndef plot_score_epoch(curr_state, label, epoch, maps, out, name='heat'):\n    label = t.tensor(label)\n    \n    num_samples_per_class = t.sum(t.nn.functional.one_hot(label, num_classes=len(t.unique(label))), dim=0)\n    num_samples_sort = t.argsort(num_samples_per_class)\n    \n    for cidx in t.unique(label):\n        pos = t.where(cidx == label)\n        maps[epoch, cidx] = t.mean(curr_state[pos]).numpy()\n\n    # Transpose the matrix before plotting\n    transposed_maps = np.transpose(maps)\n\n    sns.heatmap(transposed_maps, cmap='YlGnBu', vmin=0, vmax=10)\n    plt.xlabel('Epoch')\n    plt.ylabel('Class index')\n\n    # Flip the graph vertically before saving\n    plt.gca().invert_yaxis()\n\n    os.makedirs(f'{out}/score_epoch_plot/', exist_ok=True)\n    plt.savefig(f'{out}/score_epoch_plot/{name}.png')\n\n    plt.close()\n\n    return maps\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.632879Z","iopub.execute_input":"2024-01-26T03:58:57.633471Z","iopub.status.idle":"2024-01-26T03:58:57.915672Z","shell.execute_reply.started":"2024-01-26T03:58:57.633443Z","shell.execute_reply":"2024-01-26T03:58:57.914803Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.__version__)\nprint(f\"CUDA version: {torch.version.cuda}\")\ntorch.has_mps","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.916913Z","iopub.execute_input":"2024-01-26T03:58:57.917253Z","iopub.status.idle":"2024-01-26T03:58:57.924386Z","shell.execute_reply.started":"2024-01-26T03:58:57.917225Z","shell.execute_reply":"2024-01-26T03:58:57.923447Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"2.0.0\nCUDA version: 11.8\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import losses\n\n#from datasets.cifar100 import *\n\n#from train.train import *\n#from train.validate import *\n\n#from models.net import *\n\n#from losses.loss import *\n\n#from utils.config import *\n#from utils.plot import *\n#from utils.common import make_imb_data, save_checkpoint, hms_string\n\n#from utils.logger import logger\n\n#args = parse_args()\n\nfrom argparse import Namespace\n\n# Replace the command below with your actual values\nargs=Namespace(network='resnet32', epochs=200, batch_size=128, update_epoch=1,\n               lr=0.1, lr_decay=0.01, momentum=0.9, wd=0.0002, nesterov=False,\n               scheduler='warmup', warmup=5, aug_prob=0.5, cutout=False, cmo=False,\n               posthoc_la=False, cuda=False, aug_type='none', sim_type='none', max_d=30,\n               num_test=10, accept_rate=0.6, verbose=False, use_norm=False,\n               out='/kaggle/working/log3',\n               data_dir='~/dataset/', workers=4, seed='None',\n               gpu='0', dataset='cifar100', num_max=500, imb_ratio=100,\n               loss_fn='ride', num_experts=3, ride_distill=False)\n\nreproducibility(args.seed)\nargs = dataset_argument(args)\nargs.logger = logger(args)\n\nbest_acc = 0 # best test accuracy\ncurr_state_ac=[]\nlabel_ac=[]\nvariance_list1=[]\n\ndef main():\n    global best_acc,curr_state_ac,label_ac,variance_list\n\n    try:\n        assert args.num_max <= 50000. / args.num_class\n    except AssertionError:\n        args.num_max = int(50000 / args.num_class)\n    \n    print(f'==> Preparing imbalanced CIFAR-100')\n    # N_SAMPLES_PER_CLASS = make_imb_data(args.num_max, args.num_class, args.imb_ratio)\n    trainset, testset = get_cifar100(os.path.join(args.data_dir, 'cifar100/'), args)\n    N_SAMPLES_PER_CLASS = trainset.img_num_list\n        \n    trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, drop_last= args.loss_fn == 'ncl', pin_memory=True, sampler=None)\n    testloader = data.DataLoader(testset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True) \n    \n    if args.cmo:\n        cls_num_list = N_SAMPLES_PER_CLASS\n        cls_weight = 1.0 / (np.array(cls_num_list))\n        cls_weight = cls_weight / np.sum(cls_weight) * len(cls_num_list)\n        labels = trainloader.dataset.targets\n        samples_weight = np.array([cls_weight[t] for t in labels])\n        samples_weight = torch.from_numpy(samples_weight)\n        samples_weight = samples_weight.double()\n        print(\"samples_weight\", samples_weight)\n        sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(labels), replacement=True)\n        weighted_trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, sampler=sampler)\n    else:\n        weighted_trainloader = None\n    \n\n    # Model\n    print (\"==> creating {}\".format(args.network))\n    model = get_model(args, N_SAMPLES_PER_CLASS)\n    train_criterion = get_loss(args, N_SAMPLES_PER_CLASS)\n    criterion = nn.CrossEntropyLoss() # For test, validation \n    optimizer = get_optimizer(args, model)\n    scheduler = get_scheduler(args,optimizer)\n\n    teacher = load_model(args)\n\n\n    train = get_train_fn(args)\n    validate = get_valid_fn(args)\n    update_score = get_update_score_fn(args)\n    \n    start_time = time.time()\n    \n    test_accs = []\n    for epoch in range(args.epochs):\n        \n        lr = adjust_learning_rate(optimizer, epoch, scheduler, args)\n        if args.cuda:\n            if epoch % args.update_epoch == 0:\n                curr_state_ac, label_ac = update_score(trainloader, model, N_SAMPLES_PER_CLASS, posthoc_la = args.posthoc_la, num_test = args.num_test, accept_rate = args.accept_rate)\n                print(curr_state_ac)\n                \n            if args.verbose:\n                if epoch == 0:\n                    maps = np.zeros((args.epochs,args.num_class))\n                maps = plot_score_epoch(curr_state_ac,label_ac, epoch, maps, args.out)\n        train_loss = train(args, trainloader, model, optimizer,train_criterion, epoch, weighted_trainloader, teacher) \n\n\n        test_loss, test_acc, test_cls = validate(args, testloader, model, criterion, N_SAMPLES_PER_CLASS,  num_class=args.num_class, mode='test Valid')\n\n        if best_acc <= test_acc:\n            best_acc = test_acc\n            many_best = test_cls[0]\n            med_best = test_cls[1]\n            few_best = test_cls[2]\n            # Save models\n            save_checkpoint({\n                'epoch': epoch + 1,\n                'state_dict': model['model'].state_dict() if args.loss_fn == 'ncl' else model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, epoch + 1, args.out)\n        test_accs.append(test_acc)\n        \n        \n        #code for weight L1 norm\n        \n        model_weights = model.state_dict()\n        classwise_l1_norms = {}\n        for class_label in range(args.num_class):\n            if args.loss_fn=='ride':\n                trans_weight1=model_weights['linears.0.weight'].transpose(0, 1)\n                trans_weight2=model_weights['linears.1.weight'].transpose(0, 1)\n                trans_weight3=model_weights['linears.2.weight'].transpose(0, 1)\n                \n                class_l1_norm1 = torch.abs(trans_weight1[class_label]).sum()\n                class_l1_norm2 = torch.abs(trans_weight2[class_label]).sum()\n                class_l1_norm3 = torch.abs(trans_weight3[class_label]).sum()\n\n                class_l1_norm = class_l1_norm1 + class_l1_norm2 + class_l1_norm3\n                \n            elif args.loss_fn=='ldam_drw':\n                trans_weight = model_weights['linear.weight'].transpose(0, 1)\n                linear_weight = trans_weight[class_label]\n                class_l1_norm = torch.abs(linear_weight).sum()\n            else:\n                trans_weight = model_weights['linear.weight']\n                linear_weight = trans_weight[class_label]\n                class_l1_norm = torch.abs(linear_weight).sum()\n            classwise_l1_norms[f'Class_{class_label}'] = class_l1_norm\n        l1_norm_values = [tensor.item() for tensor in classwise_l1_norms.values()]\n        variance_l1_norm = np.var(l1_norm_values)\n        variance_list1.append(np.sqrt(variance_l1_norm))\n        print(np.sqrt(variance_l1_norm))\n        \n        #endu\n        \n        args.logger(f'Epoch: [{epoch+1} | {args.epochs}]', level=1)\n        if args.cuda:\n            args.logger(f'Max_state: {int(torch.max(curr_state_ac))}, min_state: {int(torch.min(curr_state_ac))}', level=2)\n        args.logger(f'[Train]\\tLoss:\\t{train_loss:.4f}', level=2)\n        args.logger(f'[Test ]\\tLoss:\\t{test_loss:.4f}\\tAcc:\\t{test_acc:.4f}', level=2)\n        args.logger(f'[Stats]\\tMany:\\t{test_cls[0]:.4f}\\tMedium:\\t{test_cls[1]:.4f}\\tFew:\\t{test_cls[2]:.4f}', level=2)\n        args.logger(f'[Best ]\\tAcc:\\t{np.max(test_accs):.4f}\\tMany:\\t{100*many_best:.4f}\\tMedium:\\t{100*med_best:.4f}\\tFew:\\t{100*few_best:.4f}', level=2)\n        args.logger(f'[Param]\\tLR:\\t{lr:.8f}', level=2)\n    \n    end_time = time.time()\n\n    # Print the final results\n    args.logger(f'Final performance...', level=1)\n    args.logger(f'best bAcc (test):\\t{np.max(test_accs)}', level=2)\n    args.logger(f'best statistics:\\tMany:\\t{many_best}\\tMed:\\t{med_best}\\tFew:\\t{few_best}', level=2)\n    args.logger(f'Training Time: {hms_string(end_time - start_time)}', level=1)\n\n    \n    if args.verbose:\n        args.logger.map_save(maps)\n\nif __name__ == '__main__':\n    main()\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T03:58:57.925606Z","iopub.execute_input":"2024-01-26T03:58:57.925910Z","iopub.status.idle":"2024-01-26T04:22:37.854063Z","shell.execute_reply.started":"2024-01-26T03:58:57.925884Z","shell.execute_reply":"2024-01-26T04:22:37.852869Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"---> ---cifar100---\n---> Argument\n    > network     : resnet32\n    > epochs      : 200\n    > batch_size  : 128\n    > update_epoch: 1\n    > lr          : 0.1\n    > lr_decay    : 0.01\n    > momentum    : 0.9\n    > wd          : 0.0002\n    > nesterov    : False\n    > scheduler   : warmup\n    > warmup      : 5\n    > aug_prob    : 0.5\n    > cutout      : False\n    > cmo         : False\n    > posthoc_la  : False\n    > cuda        : False\n    > aug_type    : none\n    > sim_type    : none\n    > max_d       : 30\n    > num_test    : 10\n    > accept_rate : 0.6\n    > verbose     : False\n    > use_norm    : False\n    > out         : /kaggle/working/log3\n    > data_dir    : ~/dataset/\n    > workers     : 4\n    > seed        : None\n    > gpu         : 0\n    > dataset     : cifar100\n    > num_max     : 500\n    > imb_ratio   : 100\n    > loss_fn     : ride\n    > num_experts : 3\n    > ride_distill: False\n    > num_class   : 100\n","output_type":"stream"},{"name":"stdout","text":"==> Preparing imbalanced CIFAR-100\nFiles already downloaded and verified\nMagnitude set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nOperation set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nFiles already downloaded and verified\n#Train: 10847, #Test: 10000\n==> creating resnet32\n    Total params: 0.79M\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_1840/2298205333.py:97: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorCompare.cpp:493.)\n  final_output = torch.where(index, x_m, x)\n---> Epoch: [1 | 200]\n    > [Train]\tLoss:\t31.8801\n    > [Test ]\tLoss:\t5.5722\tAcc:\t5.5400\n    > [Stats]\tMany:\t0.1446\tMedium:\t0.0137\tFew:\t0.0000\n    > [Best ]\tAcc:\t5.5400\tMany:\t14.4571\tMedium:\t1.3714\tFew:\t0.0000\n    > [Param]\tLR:\t0.02000000\n","output_type":"stream"},{"name":"stdout","text":"2.9233015779622535\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [2 | 200]\n    > [Train]\tLoss:\t29.7277\n    > [Test ]\tLoss:\t5.6810\tAcc:\t6.8600\n    > [Stats]\tMany:\t0.1917\tMedium:\t0.0043\tFew:\t0.0000\n    > [Best ]\tAcc:\t6.8600\tMany:\t19.1714\tMedium:\t0.4286\tFew:\t0.0000\n    > [Param]\tLR:\t0.04000000\n","output_type":"stream"},{"name":"stdout","text":"5.031301948596366\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [3 | 200]\n    > [Train]\tLoss:\t29.0659\n    > [Test ]\tLoss:\t5.5151\tAcc:\t8.6400\n    > [Stats]\tMany:\t0.2317\tMedium:\t0.0151\tFew:\t0.0000\n    > [Best ]\tAcc:\t8.6400\tMany:\t23.1714\tMedium:\t1.5143\tFew:\t0.0000\n    > [Param]\tLR:\t0.06000000\n","output_type":"stream"},{"name":"stdout","text":"7.5654318566466285\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [4 | 200]\n    > [Train]\tLoss:\t28.2297\n    > [Test ]\tLoss:\t5.2919\tAcc:\t10.4400\n    > [Stats]\tMany:\t0.2840\tMedium:\t0.0143\tFew:\t0.0000\n    > [Best ]\tAcc:\t10.4400\tMany:\t28.4000\tMedium:\t1.4286\tFew:\t0.0000\n    > [Param]\tLR:\t0.08000000\n","output_type":"stream"},{"name":"stdout","text":"9.704695166064162\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [5 | 200]\n    > [Train]\tLoss:\t27.3601\n    > [Test ]\tLoss:\t5.3933\tAcc:\t10.4600\n    > [Stats]\tMany:\t0.2669\tMedium:\t0.0300\tFew:\t0.0023\n    > [Best ]\tAcc:\t10.4600\tMany:\t26.6857\tMedium:\t3.0000\tFew:\t0.2333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.340183952383676\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [6 | 200]\n    > [Train]\tLoss:\t26.4079\n    > [Test ]\tLoss:\t5.3399\tAcc:\t10.3400\n    > [Stats]\tMany:\t0.2480\tMedium:\t0.0469\tFew:\t0.0007\n    > [Best ]\tAcc:\t10.4600\tMany:\t26.6857\tMedium:\t3.0000\tFew:\t0.2333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.395697847689462\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [7 | 200]\n    > [Train]\tLoss:\t25.5027\n    > [Test ]\tLoss:\t4.9420\tAcc:\t12.2600\n    > [Stats]\tMany:\t0.3057\tMedium:\t0.0446\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.2600\tMany:\t30.5714\tMedium:\t4.4571\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.053884649426136\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [8 | 200]\n    > [Train]\tLoss:\t24.7427\n    > [Test ]\tLoss:\t4.9069\tAcc:\t14.1300\n    > [Stats]\tMany:\t0.3700\tMedium:\t0.0291\tFew:\t0.0053\n    > [Best ]\tAcc:\t14.1300\tMany:\t37.0000\tMedium:\t2.9143\tFew:\t0.5333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.566071986446048\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [9 | 200]\n    > [Train]\tLoss:\t24.1061\n    > [Test ]\tLoss:\t4.8085\tAcc:\t15.2000\n    > [Stats]\tMany:\t0.3469\tMedium:\t0.0826\tFew:\t0.0057\n    > [Best ]\tAcc:\t15.2000\tMany:\t34.6857\tMedium:\t8.2571\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.137371400169636\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [10 | 200]\n    > [Train]\tLoss:\t23.5557\n    > [Test ]\tLoss:\t4.5999\tAcc:\t18.0800\n    > [Stats]\tMany:\t0.4280\tMedium:\t0.0869\tFew:\t0.0020\n    > [Best ]\tAcc:\t18.0800\tMany:\t42.8000\tMedium:\t8.6857\tFew:\t0.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.403944744224878\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [11 | 200]\n    > [Train]\tLoss:\t22.8348\n    > [Test ]\tLoss:\t4.7491\tAcc:\t17.6900\n    > [Stats]\tMany:\t0.4191\tMedium:\t0.0820\tFew:\t0.0050\n    > [Best ]\tAcc:\t18.0800\tMany:\t42.8000\tMedium:\t8.6857\tFew:\t0.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.588420739947418\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [12 | 200]\n    > [Train]\tLoss:\t22.1555\n    > [Test ]\tLoss:\t4.4223\tAcc:\t18.9700\n    > [Stats]\tMany:\t0.4517\tMedium:\t0.0883\tFew:\t0.0023\n    > [Best ]\tAcc:\t18.9700\tMany:\t45.1714\tMedium:\t8.8286\tFew:\t0.2333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.758634169561182\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [13 | 200]\n    > [Train]\tLoss:\t21.8072\n    > [Test ]\tLoss:\t4.7701\tAcc:\t18.9000\n    > [Stats]\tMany:\t0.4377\tMedium:\t0.0949\tFew:\t0.0087\n    > [Best ]\tAcc:\t18.9700\tMany:\t45.1714\tMedium:\t8.8286\tFew:\t0.2333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.834765386703596\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [14 | 200]\n    > [Train]\tLoss:\t21.2810\n    > [Test ]\tLoss:\t4.5020\tAcc:\t20.2200\n    > [Stats]\tMany:\t0.4566\tMedium:\t0.1157\tFew:\t0.0063\n    > [Best ]\tAcc:\t20.2200\tMany:\t45.6571\tMedium:\t11.5714\tFew:\t0.6333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.986992456497633\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [15 | 200]\n    > [Train]\tLoss:\t20.9503\n    > [Test ]\tLoss:\t4.5665\tAcc:\t21.1100\n    > [Stats]\tMany:\t0.4729\tMedium:\t0.1134\tFew:\t0.0197\n    > [Best ]\tAcc:\t21.1100\tMany:\t47.2857\tMedium:\t11.3429\tFew:\t1.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"15.053018831322326\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [16 | 200]\n    > [Train]\tLoss:\t20.3762\n    > [Test ]\tLoss:\t4.6140\tAcc:\t20.4800\n    > [Stats]\tMany:\t0.4640\tMedium:\t0.1163\tFew:\t0.0057\n    > [Best ]\tAcc:\t21.1100\tMany:\t47.2857\tMedium:\t11.3429\tFew:\t1.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"15.028133648241349\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [17 | 200]\n    > [Train]\tLoss:\t19.9974\n    > [Test ]\tLoss:\t4.3372\tAcc:\t22.6800\n    > [Stats]\tMany:\t0.5129\tMedium:\t0.1306\tFew:\t0.0053\n    > [Best ]\tAcc:\t22.6800\tMany:\t51.2857\tMedium:\t13.0571\tFew:\t0.5333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.940399765908277\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [18 | 200]\n    > [Train]\tLoss:\t19.5888\n    > [Test ]\tLoss:\t4.4053\tAcc:\t22.7500\n    > [Stats]\tMany:\t0.4954\tMedium:\t0.1460\tFew:\t0.0100\n    > [Best ]\tAcc:\t22.7500\tMany:\t49.5429\tMedium:\t14.6000\tFew:\t1.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.980495860292402\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [19 | 200]\n    > [Train]\tLoss:\t19.3047\n    > [Test ]\tLoss:\t4.3015\tAcc:\t24.0300\n    > [Stats]\tMany:\t0.5271\tMedium:\t0.1523\tFew:\t0.0083\n    > [Best ]\tAcc:\t24.0300\tMany:\t52.7143\tMedium:\t15.2286\tFew:\t0.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.904459717204087\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [20 | 200]\n    > [Train]\tLoss:\t18.9348\n    > [Test ]\tLoss:\t4.7153\tAcc:\t21.6300\n    > [Stats]\tMany:\t0.4966\tMedium:\t0.1137\tFew:\t0.0090\n    > [Best ]\tAcc:\t24.0300\tMany:\t52.7143\tMedium:\t15.2286\tFew:\t0.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.821547340719752\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [21 | 200]\n    > [Train]\tLoss:\t18.6552\n    > [Test ]\tLoss:\t4.5948\tAcc:\t22.2600\n    > [Stats]\tMany:\t0.4854\tMedium:\t0.1386\tFew:\t0.0140\n    > [Best ]\tAcc:\t24.0300\tMany:\t52.7143\tMedium:\t15.2286\tFew:\t0.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.804152355422605\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [22 | 200]\n    > [Train]\tLoss:\t18.2945\n    > [Test ]\tLoss:\t4.2619\tAcc:\t24.5300\n    > [Stats]\tMany:\t0.5440\tMedium:\t0.1491\tFew:\t0.0090\n    > [Best ]\tAcc:\t24.5300\tMany:\t54.4000\tMedium:\t14.9143\tFew:\t0.9000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.695735813978267\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [23 | 200]\n    > [Train]\tLoss:\t18.1147\n    > [Test ]\tLoss:\t4.3184\tAcc:\t26.1300\n    > [Stats]\tMany:\t0.5471\tMedium:\t0.1826\tFew:\t0.0197\n    > [Best ]\tAcc:\t26.1300\tMany:\t54.7143\tMedium:\t18.2571\tFew:\t1.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.610923326611728\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [24 | 200]\n    > [Train]\tLoss:\t17.7716\n    > [Test ]\tLoss:\t4.8046\tAcc:\t22.6800\n    > [Stats]\tMany:\t0.5054\tMedium:\t0.1266\tFew:\t0.0187\n    > [Best ]\tAcc:\t26.1300\tMany:\t54.7143\tMedium:\t18.2571\tFew:\t1.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.47650754929152\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [25 | 200]\n    > [Train]\tLoss:\t17.5639\n    > [Test ]\tLoss:\t4.2655\tAcc:\t25.7500\n    > [Stats]\tMany:\t0.5620\tMedium:\t0.1631\tFew:\t0.0123\n    > [Best ]\tAcc:\t26.1300\tMany:\t54.7143\tMedium:\t18.2571\tFew:\t1.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.357034116968146\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [26 | 200]\n    > [Train]\tLoss:\t17.1901\n    > [Test ]\tLoss:\t4.2035\tAcc:\t26.9800\n    > [Stats]\tMany:\t0.5757\tMedium:\t0.1869\tFew:\t0.0097\n    > [Best ]\tAcc:\t26.9800\tMany:\t57.5714\tMedium:\t18.6857\tFew:\t0.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.277514471828209\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [27 | 200]\n    > [Train]\tLoss:\t16.9084\n    > [Test ]\tLoss:\t4.1075\tAcc:\t27.6900\n    > [Stats]\tMany:\t0.5654\tMedium:\t0.2137\tFew:\t0.0140\n    > [Best ]\tAcc:\t27.6900\tMany:\t56.5429\tMedium:\t21.3714\tFew:\t1.4000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.126882852302165\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [28 | 200]\n    > [Train]\tLoss:\t16.7494\n    > [Test ]\tLoss:\t4.1939\tAcc:\t26.7500\n    > [Stats]\tMany:\t0.5806\tMedium:\t0.1657\tFew:\t0.0210\n    > [Best ]\tAcc:\t27.6900\tMany:\t56.5429\tMedium:\t21.3714\tFew:\t1.4000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.007218180993236\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [29 | 200]\n    > [Train]\tLoss:\t16.3515\n    > [Test ]\tLoss:\t4.3477\tAcc:\t28.0500\n    > [Stats]\tMany:\t0.5857\tMedium:\t0.2057\tFew:\t0.0117\n    > [Best ]\tAcc:\t28.0500\tMany:\t58.5714\tMedium:\t20.5714\tFew:\t1.1667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.901697598614053\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [30 | 200]\n    > [Train]\tLoss:\t16.1732\n    > [Test ]\tLoss:\t4.2317\tAcc:\t27.6900\n    > [Stats]\tMany:\t0.5663\tMedium:\t0.2057\tFew:\t0.0223\n    > [Best ]\tAcc:\t28.0500\tMany:\t58.5714\tMedium:\t20.5714\tFew:\t1.1667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.80548916568714\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [31 | 200]\n    > [Train]\tLoss:\t16.0023\n    > [Test ]\tLoss:\t3.8138\tAcc:\t30.5000\n    > [Stats]\tMany:\t0.5974\tMedium:\t0.2477\tFew:\t0.0307\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.656866916791532\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [32 | 200]\n    > [Train]\tLoss:\t15.9280\n    > [Test ]\tLoss:\t4.2175\tAcc:\t27.5800\n    > [Stats]\tMany:\t0.5460\tMedium:\t0.2257\tFew:\t0.0190\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.574357772793238\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [33 | 200]\n    > [Train]\tLoss:\t15.6974\n    > [Test ]\tLoss:\t4.1687\tAcc:\t29.0600\n    > [Stats]\tMany:\t0.5894\tMedium:\t0.2280\tFew:\t0.0150\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.512570535697455\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [34 | 200]\n    > [Train]\tLoss:\t15.4566\n    > [Test ]\tLoss:\t4.0876\tAcc:\t29.6500\n    > [Stats]\tMany:\t0.5911\tMedium:\t0.2309\tFew:\t0.0293\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.45848698573586\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [35 | 200]\n    > [Train]\tLoss:\t15.2857\n    > [Test ]\tLoss:\t4.0868\tAcc:\t29.5100\n    > [Stats]\tMany:\t0.5980\tMedium:\t0.2357\tFew:\t0.0110\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.317704633248576\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [36 | 200]\n    > [Train]\tLoss:\t15.0149\n    > [Test ]\tLoss:\t4.1260\tAcc:\t29.5300\n    > [Stats]\tMany:\t0.6034\tMedium:\t0.2246\tFew:\t0.0183\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.190841490025376\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [37 | 200]\n    > [Train]\tLoss:\t14.8742\n    > [Test ]\tLoss:\t4.4353\tAcc:\t28.4000\n    > [Stats]\tMany:\t0.5637\tMedium:\t0.2211\tFew:\t0.0310\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.121905257130273\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [38 | 200]\n    > [Train]\tLoss:\t14.7098\n    > [Test ]\tLoss:\t4.1225\tAcc:\t30.0000\n    > [Stats]\tMany:\t0.6211\tMedium:\t0.2294\tFew:\t0.0077\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.040509647496673\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [39 | 200]\n    > [Train]\tLoss:\t14.5820\n    > [Test ]\tLoss:\t4.2301\tAcc:\t28.6100\n    > [Stats]\tMany:\t0.5877\tMedium:\t0.2217\tFew:\t0.0093\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.945723757482915\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [40 | 200]\n    > [Train]\tLoss:\t14.4887\n    > [Test ]\tLoss:\t4.1948\tAcc:\t29.9100\n    > [Stats]\tMany:\t0.6054\tMedium:\t0.2403\tFew:\t0.0103\n    > [Best ]\tAcc:\t30.5000\tMany:\t59.7429\tMedium:\t24.7714\tFew:\t3.0667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.934415043562685\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [41 | 200]\n    > [Train]\tLoss:\t14.3076\n    > [Test ]\tLoss:\t3.9598\tAcc:\t32.0300\n    > [Stats]\tMany:\t0.6409\tMedium:\t0.2500\tFew:\t0.0283\n    > [Best ]\tAcc:\t32.0300\tMany:\t64.0857\tMedium:\t25.0000\tFew:\t2.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.905234421076486\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [42 | 200]\n    > [Train]\tLoss:\t14.2816\n    > [Test ]\tLoss:\t4.1483\tAcc:\t31.5800\n    > [Stats]\tMany:\t0.6263\tMedium:\t0.2646\tFew:\t0.0133\n    > [Best ]\tAcc:\t32.0300\tMany:\t64.0857\tMedium:\t25.0000\tFew:\t2.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.794793077655132\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [43 | 200]\n    > [Train]\tLoss:\t13.9941\n    > [Test ]\tLoss:\t4.1619\tAcc:\t30.8900\n    > [Stats]\tMany:\t0.6100\tMedium:\t0.2543\tFew:\t0.0213\n    > [Best ]\tAcc:\t32.0300\tMany:\t64.0857\tMedium:\t25.0000\tFew:\t2.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.745569967611328\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [44 | 200]\n    > [Train]\tLoss:\t13.7131\n    > [Test ]\tLoss:\t4.2594\tAcc:\t30.7500\n    > [Stats]\tMany:\t0.6054\tMedium:\t0.2586\tFew:\t0.0170\n    > [Best ]\tAcc:\t32.0300\tMany:\t64.0857\tMedium:\t25.0000\tFew:\t2.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.653857951640754\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [45 | 200]\n    > [Train]\tLoss:\t13.7237\n    > [Test ]\tLoss:\t4.2063\tAcc:\t31.1600\n    > [Stats]\tMany:\t0.6146\tMedium:\t0.2537\tFew:\t0.0257\n    > [Best ]\tAcc:\t32.0300\tMany:\t64.0857\tMedium:\t25.0000\tFew:\t2.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.537519742431943\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [46 | 200]\n    > [Train]\tLoss:\t13.6622\n    > [Test ]\tLoss:\t4.2287\tAcc:\t32.1400\n    > [Stats]\tMany:\t0.6220\tMedium:\t0.2749\tFew:\t0.0250\n    > [Best ]\tAcc:\t32.1400\tMany:\t62.2000\tMedium:\t27.4857\tFew:\t2.5000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.434714325706237\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [47 | 200]\n    > [Train]\tLoss:\t13.2760\n    > [Test ]\tLoss:\t4.0642\tAcc:\t32.3000\n    > [Stats]\tMany:\t0.6477\tMedium:\t0.2591\tFew:\t0.0187\n    > [Best ]\tAcc:\t32.3000\tMany:\t64.7714\tMedium:\t25.9143\tFew:\t1.8667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.34823965956289\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [48 | 200]\n    > [Train]\tLoss:\t13.2761\n    > [Test ]\tLoss:\t4.4496\tAcc:\t30.2400\n    > [Stats]\tMany:\t0.6163\tMedium:\t0.2303\tFew:\t0.0203\n    > [Best ]\tAcc:\t32.3000\tMany:\t64.7714\tMedium:\t25.9143\tFew:\t1.8667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.215561716776874\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [49 | 200]\n    > [Train]\tLoss:\t13.1807\n    > [Test ]\tLoss:\t3.9648\tAcc:\t33.2200\n    > [Stats]\tMany:\t0.6274\tMedium:\t0.2937\tFew:\t0.0327\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.15674873116881\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [50 | 200]\n    > [Train]\tLoss:\t12.9468\n    > [Test ]\tLoss:\t4.2031\tAcc:\t32.2100\n    > [Stats]\tMany:\t0.6357\tMedium:\t0.2680\tFew:\t0.0193\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.9562127929166\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [51 | 200]\n    > [Train]\tLoss:\t12.8445\n    > [Test ]\tLoss:\t4.7359\tAcc:\t29.6400\n    > [Stats]\tMany:\t0.6014\tMedium:\t0.2331\tFew:\t0.0143\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.857300116852176\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [52 | 200]\n    > [Train]\tLoss:\t12.9030\n    > [Test ]\tLoss:\t4.2069\tAcc:\t30.9700\n    > [Stats]\tMany:\t0.6029\tMedium:\t0.2663\tFew:\t0.0183\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.828533873133589\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [53 | 200]\n    > [Train]\tLoss:\t12.6850\n    > [Test ]\tLoss:\t4.5751\tAcc:\t30.3500\n    > [Stats]\tMany:\t0.5934\tMedium:\t0.2603\tFew:\t0.0157\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.800060009555132\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [54 | 200]\n    > [Train]\tLoss:\t12.5781\n    > [Test ]\tLoss:\t4.0528\tAcc:\t32.8600\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.2857\tFew:\t0.0323\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.705980625320809\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [55 | 200]\n    > [Train]\tLoss:\t12.4409\n    > [Test ]\tLoss:\t4.4708\tAcc:\t31.4500\n    > [Stats]\tMany:\t0.6286\tMedium:\t0.2451\tFew:\t0.0290\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.526198175342923\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [56 | 200]\n    > [Train]\tLoss:\t12.3962\n    > [Test ]\tLoss:\t4.2039\tAcc:\t32.7200\n    > [Stats]\tMany:\t0.6443\tMedium:\t0.2754\tFew:\t0.0177\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.453715043861763\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [57 | 200]\n    > [Train]\tLoss:\t12.2920\n    > [Test ]\tLoss:\t4.3055\tAcc:\t32.8300\n    > [Stats]\tMany:\t0.6346\tMedium:\t0.2869\tFew:\t0.0193\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.408489337564445\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [58 | 200]\n    > [Train]\tLoss:\t12.4072\n    > [Test ]\tLoss:\t4.2427\tAcc:\t31.0900\n    > [Stats]\tMany:\t0.6263\tMedium:\t0.2414\tFew:\t0.0240\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.322513685654666\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [59 | 200]\n    > [Train]\tLoss:\t12.0921\n    > [Test ]\tLoss:\t4.1531\tAcc:\t32.8800\n    > [Stats]\tMany:\t0.6486\tMedium:\t0.2649\tFew:\t0.0303\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.17134834592805\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [60 | 200]\n    > [Train]\tLoss:\t12.1477\n    > [Test ]\tLoss:\t4.4928\tAcc:\t30.8800\n    > [Stats]\tMany:\t0.6174\tMedium:\t0.2497\tFew:\t0.0177\n    > [Best ]\tAcc:\t33.2200\tMany:\t62.7428\tMedium:\t29.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.22767266161683\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [61 | 200]\n    > [Train]\tLoss:\t11.9483\n    > [Test ]\tLoss:\t4.0728\tAcc:\t34.2600\n    > [Stats]\tMany:\t0.6620\tMedium:\t0.2829\tFew:\t0.0397\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.16811060803465\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [62 | 200]\n    > [Train]\tLoss:\t11.9609\n    > [Test ]\tLoss:\t4.5318\tAcc:\t31.3000\n    > [Stats]\tMany:\t0.6051\tMedium:\t0.2546\tFew:\t0.0403\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.164458443820763\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [63 | 200]\n    > [Train]\tLoss:\t11.8661\n    > [Test ]\tLoss:\t4.5004\tAcc:\t31.3800\n    > [Stats]\tMany:\t0.5983\tMedium:\t0.2769\tFew:\t0.0250\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.107972077129197\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [64 | 200]\n    > [Train]\tLoss:\t11.5367\n    > [Test ]\tLoss:\t4.2140\tAcc:\t33.9000\n    > [Stats]\tMany:\t0.6383\tMedium:\t0.3120\tFew:\t0.0213\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.024193243970942\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [65 | 200]\n    > [Train]\tLoss:\t11.8301\n    > [Test ]\tLoss:\t4.7013\tAcc:\t30.1600\n    > [Stats]\tMany:\t0.5994\tMedium:\t0.2460\tFew:\t0.0190\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.924635700946222\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [66 | 200]\n    > [Train]\tLoss:\t11.5041\n    > [Test ]\tLoss:\t4.2795\tAcc:\t32.5000\n    > [Stats]\tMany:\t0.6229\tMedium:\t0.2794\tFew:\t0.0307\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.848927428466528\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [67 | 200]\n    > [Train]\tLoss:\t11.2957\n    > [Test ]\tLoss:\t4.0194\tAcc:\t34.1900\n    > [Stats]\tMany:\t0.6266\tMedium:\t0.3280\tFew:\t0.0260\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.806747736334556\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [68 | 200]\n    > [Train]\tLoss:\t11.4190\n    > [Test ]\tLoss:\t4.0284\tAcc:\t34.1800\n    > [Stats]\tMany:\t0.6380\tMedium:\t0.3203\tFew:\t0.0213\n    > [Best ]\tAcc:\t34.2600\tMany:\t66.2000\tMedium:\t28.2857\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.767353835761968\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [69 | 200]\n    > [Train]\tLoss:\t11.2705\n    > [Test ]\tLoss:\t4.1090\tAcc:\t34.9300\n    > [Stats]\tMany:\t0.6617\tMedium:\t0.3111\tFew:\t0.0293\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.6849325530945\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [70 | 200]\n    > [Train]\tLoss:\t11.2210\n    > [Test ]\tLoss:\t4.1159\tAcc:\t34.8400\n    > [Stats]\tMany:\t0.6691\tMedium:\t0.3011\tFew:\t0.0293\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.628747524683837\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [71 | 200]\n    > [Train]\tLoss:\t10.9692\n    > [Test ]\tLoss:\t4.3094\tAcc:\t33.1900\n    > [Stats]\tMany:\t0.6389\tMedium:\t0.2911\tFew:\t0.0213\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.511302008439081\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [72 | 200]\n    > [Train]\tLoss:\t10.9931\n    > [Test ]\tLoss:\t4.1897\tAcc:\t34.1100\n    > [Stats]\tMany:\t0.6437\tMedium:\t0.3057\tFew:\t0.0293\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.516588731310515\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [73 | 200]\n    > [Train]\tLoss:\t11.0320\n    > [Test ]\tLoss:\t4.0957\tAcc:\t34.0100\n    > [Stats]\tMany:\t0.6471\tMedium:\t0.3071\tFew:\t0.0203\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.355102039395815\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [74 | 200]\n    > [Train]\tLoss:\t10.7836\n    > [Test ]\tLoss:\t4.2085\tAcc:\t33.3000\n    > [Stats]\tMany:\t0.6329\tMedium:\t0.2917\tFew:\t0.0313\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.244993908327105\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [75 | 200]\n    > [Train]\tLoss:\t10.9750\n    > [Test ]\tLoss:\t4.6445\tAcc:\t32.4600\n    > [Stats]\tMany:\t0.6329\tMedium:\t0.2706\tFew:\t0.0280\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.295483612250722\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [76 | 200]\n    > [Train]\tLoss:\t10.7257\n    > [Test ]\tLoss:\t4.2963\tAcc:\t34.3500\n    > [Stats]\tMany:\t0.6503\tMedium:\t0.3143\tFew:\t0.0197\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.269005692402125\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [77 | 200]\n    > [Train]\tLoss:\t10.6856\n    > [Test ]\tLoss:\t4.6586\tAcc:\t33.4000\n    > [Stats]\tMany:\t0.6280\tMedium:\t0.3034\tFew:\t0.0267\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.12798058936985\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [78 | 200]\n    > [Train]\tLoss:\t10.7214\n    > [Test ]\tLoss:\t4.3592\tAcc:\t32.9000\n    > [Stats]\tMany:\t0.6214\tMedium:\t0.2949\tFew:\t0.0277\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.061377881137755\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [79 | 200]\n    > [Train]\tLoss:\t10.7934\n    > [Test ]\tLoss:\t4.4385\tAcc:\t33.3300\n    > [Stats]\tMany:\t0.6289\tMedium:\t0.2986\tFew:\t0.0290\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.069374226712982\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [80 | 200]\n    > [Train]\tLoss:\t10.6789\n    > [Test ]\tLoss:\t4.2628\tAcc:\t34.1600\n    > [Stats]\tMany:\t0.6374\tMedium:\t0.3200\tFew:\t0.0217\n    > [Best ]\tAcc:\t34.9300\tMany:\t66.1714\tMedium:\t31.1143\tFew:\t2.9333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.021252307952672\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [81 | 200]\n    > [Train]\tLoss:\t10.5261\n    > [Test ]\tLoss:\t3.9971\tAcc:\t36.2400\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.3466\tFew:\t0.0403\n    > [Best ]\tAcc:\t36.2400\tMany:\t65.4286\tMedium:\t34.6571\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.944721240711754\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [82 | 200]\n    > [Train]\tLoss:\t10.4094\n    > [Test ]\tLoss:\t4.5031\tAcc:\t33.1700\n    > [Stats]\tMany:\t0.6260\tMedium:\t0.2951\tFew:\t0.0310\n    > [Best ]\tAcc:\t36.2400\tMany:\t65.4286\tMedium:\t34.6571\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.891061866964186\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [83 | 200]\n    > [Train]\tLoss:\t10.3391\n    > [Test ]\tLoss:\t4.1896\tAcc:\t36.2200\n    > [Stats]\tMany:\t0.6606\tMedium:\t0.3486\tFew:\t0.0300\n    > [Best ]\tAcc:\t36.2400\tMany:\t65.4286\tMedium:\t34.6571\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.889553780283572\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [84 | 200]\n    > [Train]\tLoss:\t10.4167\n    > [Test ]\tLoss:\t4.0703\tAcc:\t36.3700\n    > [Stats]\tMany:\t0.6623\tMedium:\t0.3440\tFew:\t0.0383\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.85098268135135\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [85 | 200]\n    > [Train]\tLoss:\t10.4677\n    > [Test ]\tLoss:\t4.5352\tAcc:\t33.1300\n    > [Stats]\tMany:\t0.6331\tMedium:\t0.2980\tFew:\t0.0180\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.76850873805451\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [86 | 200]\n    > [Train]\tLoss:\t10.2452\n    > [Test ]\tLoss:\t4.3167\tAcc:\t34.0100\n    > [Stats]\tMany:\t0.6506\tMedium:\t0.2980\tFew:\t0.0270\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.659318328407801\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [87 | 200]\n    > [Train]\tLoss:\t10.2118\n    > [Test ]\tLoss:\t4.2964\tAcc:\t34.5600\n    > [Stats]\tMany:\t0.6366\tMedium:\t0.3177\tFew:\t0.0387\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.608080267330877\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [88 | 200]\n    > [Train]\tLoss:\t10.0849\n    > [Test ]\tLoss:\t4.7177\tAcc:\t32.0100\n    > [Stats]\tMany:\t0.6071\tMedium:\t0.2903\tFew:\t0.0200\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.591850982479928\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [89 | 200]\n    > [Train]\tLoss:\t10.1326\n    > [Test ]\tLoss:\t4.5013\tAcc:\t33.6200\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.3194\tFew:\t0.0183\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.512249319576892\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [90 | 200]\n    > [Train]\tLoss:\t10.0344\n    > [Test ]\tLoss:\t4.2453\tAcc:\t34.8100\n    > [Stats]\tMany:\t0.6434\tMedium:\t0.3334\tFew:\t0.0207\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.535477734454778\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [91 | 200]\n    > [Train]\tLoss:\t10.1874\n    > [Test ]\tLoss:\t4.5147\tAcc:\t33.5600\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.2929\tFew:\t0.0173\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.445672650826955\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [92 | 200]\n    > [Train]\tLoss:\t9.9994\n    > [Test ]\tLoss:\t4.2542\tAcc:\t35.5500\n    > [Stats]\tMany:\t0.6763\tMedium:\t0.3137\tFew:\t0.0300\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.46084943515081\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [93 | 200]\n    > [Train]\tLoss:\t9.8649\n    > [Test ]\tLoss:\t4.1848\tAcc:\t35.7300\n    > [Stats]\tMany:\t0.6514\tMedium:\t0.3414\tFew:\t0.0327\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.390729152385473\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [94 | 200]\n    > [Train]\tLoss:\t9.7783\n    > [Test ]\tLoss:\t4.3588\tAcc:\t34.8600\n    > [Stats]\tMany:\t0.6494\tMedium:\t0.3243\tFew:\t0.0260\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.489143646246667\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [95 | 200]\n    > [Train]\tLoss:\t9.9156\n    > [Test ]\tLoss:\t4.3271\tAcc:\t34.6100\n    > [Stats]\tMany:\t0.6366\tMedium:\t0.3306\tFew:\t0.0253\n    > [Best ]\tAcc:\t36.3700\tMany:\t66.2286\tMedium:\t34.4000\tFew:\t3.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.389755473233993\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [96 | 200]\n    > [Train]\tLoss:\t9.7540\n    > [Test ]\tLoss:\t4.0636\tAcc:\t36.6500\n    > [Stats]\tMany:\t0.6731\tMedium:\t0.3394\tFew:\t0.0403\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.32315946934765\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [97 | 200]\n    > [Train]\tLoss:\t9.8577\n    > [Test ]\tLoss:\t4.5206\tAcc:\t34.5700\n    > [Stats]\tMany:\t0.6500\tMedium:\t0.3080\tFew:\t0.0347\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.37643023348974\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [98 | 200]\n    > [Train]\tLoss:\t9.6123\n    > [Test ]\tLoss:\t4.6396\tAcc:\t34.5800\n    > [Stats]\tMany:\t0.6446\tMedium:\t0.3157\tFew:\t0.0323\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.273728120357495\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [99 | 200]\n    > [Train]\tLoss:\t9.7100\n    > [Test ]\tLoss:\t4.2329\tAcc:\t35.2500\n    > [Stats]\tMany:\t0.6517\tMedium:\t0.3377\tFew:\t0.0207\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.238133843529761\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [100 | 200]\n    > [Train]\tLoss:\t9.7006\n    > [Test ]\tLoss:\t4.7371\tAcc:\t32.4600\n    > [Stats]\tMany:\t0.6091\tMedium:\t0.3000\tFew:\t0.0213\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.189991496826565\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [101 | 200]\n    > [Train]\tLoss:\t9.5166\n    > [Test ]\tLoss:\t4.2188\tAcc:\t34.9600\n    > [Stats]\tMany:\t0.6417\tMedium:\t0.3291\tFew:\t0.0327\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.181028909104382\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [102 | 200]\n    > [Train]\tLoss:\t9.6862\n    > [Test ]\tLoss:\t4.3424\tAcc:\t34.4800\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.3174\tFew:\t0.0197\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.141774075023209\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [103 | 200]\n    > [Train]\tLoss:\t9.4455\n    > [Test ]\tLoss:\t4.4673\tAcc:\t34.1600\n    > [Stats]\tMany:\t0.6406\tMedium:\t0.3054\tFew:\t0.0350\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.086607257787712\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [104 | 200]\n    > [Train]\tLoss:\t9.5460\n    > [Test ]\tLoss:\t4.3206\tAcc:\t35.2400\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.3366\tFew:\t0.0227\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.03970040075081\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [105 | 200]\n    > [Train]\tLoss:\t9.5057\n    > [Test ]\tLoss:\t4.2336\tAcc:\t35.8600\n    > [Stats]\tMany:\t0.6563\tMedium:\t0.3443\tFew:\t0.0280\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.994548845336064\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [106 | 200]\n    > [Train]\tLoss:\t9.3993\n    > [Test ]\tLoss:\t4.3922\tAcc:\t35.1700\n    > [Stats]\tMany:\t0.6160\tMedium:\t0.3611\tFew:\t0.0323\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.942147704751275\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [107 | 200]\n    > [Train]\tLoss:\t9.3615\n    > [Test ]\tLoss:\t4.4455\tAcc:\t34.3800\n    > [Stats]\tMany:\t0.6400\tMedium:\t0.3163\tFew:\t0.0303\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.824258257878196\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [108 | 200]\n    > [Train]\tLoss:\t9.2105\n    > [Test ]\tLoss:\t4.5931\tAcc:\t34.7500\n    > [Stats]\tMany:\t0.6426\tMedium:\t0.3240\tFew:\t0.0307\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.831148459625476\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [109 | 200]\n    > [Train]\tLoss:\t9.2062\n    > [Test ]\tLoss:\t4.4220\tAcc:\t34.5100\n    > [Stats]\tMany:\t0.6240\tMedium:\t0.3414\tFew:\t0.0240\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.771610739444867\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [110 | 200]\n    > [Train]\tLoss:\t9.3251\n    > [Test ]\tLoss:\t4.3616\tAcc:\t35.2000\n    > [Stats]\tMany:\t0.6657\tMedium:\t0.3049\tFew:\t0.0410\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.70029473816341\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [111 | 200]\n    > [Train]\tLoss:\t9.2459\n    > [Test ]\tLoss:\t4.7288\tAcc:\t33.0300\n    > [Stats]\tMany:\t0.6251\tMedium:\t0.2949\tFew:\t0.0277\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.7235248626998\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [112 | 200]\n    > [Train]\tLoss:\t9.3221\n    > [Test ]\tLoss:\t4.7150\tAcc:\t32.6500\n    > [Stats]\tMany:\t0.6114\tMedium:\t0.3006\tFew:\t0.0243\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.734439725108833\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [113 | 200]\n    > [Train]\tLoss:\t9.0598\n    > [Test ]\tLoss:\t4.3746\tAcc:\t35.3200\n    > [Stats]\tMany:\t0.6491\tMedium:\t0.3340\tFew:\t0.0303\n    > [Best ]\tAcc:\t36.6500\tMany:\t67.3143\tMedium:\t33.9429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.595613636795642\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [114 | 200]\n    > [Train]\tLoss:\t9.2490\n    > [Test ]\tLoss:\t4.2367\tAcc:\t37.6400\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3817\tFew:\t0.0463\n    > [Best ]\tAcc:\t37.6400\tMany:\t65.4000\tMedium:\t38.1714\tFew:\t4.6333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.624785133451017\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [115 | 200]\n    > [Train]\tLoss:\t9.1736\n    > [Test ]\tLoss:\t4.0748\tAcc:\t37.9200\n    > [Stats]\tMany:\t0.6669\tMedium:\t0.3826\tFew:\t0.0397\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.594536515922204\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [116 | 200]\n    > [Train]\tLoss:\t8.8104\n    > [Test ]\tLoss:\t4.2282\tAcc:\t36.3000\n    > [Stats]\tMany:\t0.6737\tMedium:\t0.3394\tFew:\t0.0280\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.523947472549276\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [117 | 200]\n    > [Train]\tLoss:\t9.0212\n    > [Test ]\tLoss:\t4.4008\tAcc:\t34.7500\n    > [Stats]\tMany:\t0.6451\tMedium:\t0.3231\tFew:\t0.0287\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.406249538227918\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [118 | 200]\n    > [Train]\tLoss:\t8.9468\n    > [Test ]\tLoss:\t4.1468\tAcc:\t36.9900\n    > [Stats]\tMany:\t0.6783\tMedium:\t0.3383\tFew:\t0.0470\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.387937830031696\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [119 | 200]\n    > [Train]\tLoss:\t9.0908\n    > [Test ]\tLoss:\t4.3300\tAcc:\t35.3000\n    > [Stats]\tMany:\t0.6400\tMedium:\t0.3446\tFew:\t0.0280\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.390520613239795\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [120 | 200]\n    > [Train]\tLoss:\t8.9199\n    > [Test ]\tLoss:\t4.4973\tAcc:\t35.4500\n    > [Stats]\tMany:\t0.6666\tMedium:\t0.3083\tFew:\t0.0443\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.28631586578875\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [121 | 200]\n    > [Train]\tLoss:\t8.9615\n    > [Test ]\tLoss:\t5.0061\tAcc:\t32.7400\n    > [Stats]\tMany:\t0.6223\tMedium:\t0.2911\tFew:\t0.0257\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.269119801215302\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [122 | 200]\n    > [Train]\tLoss:\t8.8446\n    > [Test ]\tLoss:\t4.4278\tAcc:\t35.6900\n    > [Stats]\tMany:\t0.6580\tMedium:\t0.3354\tFew:\t0.0307\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.213693773250425\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [123 | 200]\n    > [Train]\tLoss:\t8.8091\n    > [Test ]\tLoss:\t4.4562\tAcc:\t35.6300\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.3097\tFew:\t0.0327\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.167303250136433\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [124 | 200]\n    > [Train]\tLoss:\t8.8647\n    > [Test ]\tLoss:\t4.4036\tAcc:\t35.8500\n    > [Stats]\tMany:\t0.6594\tMedium:\t0.3337\tFew:\t0.0363\n    > [Best ]\tAcc:\t37.9200\tMany:\t66.6857\tMedium:\t38.2571\tFew:\t3.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.219164379100473\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [125 | 200]\n    > [Train]\tLoss:\t8.8061\n    > [Test ]\tLoss:\t4.1361\tAcc:\t38.4600\n    > [Stats]\tMany:\t0.6657\tMedium:\t0.3917\tFew:\t0.0483\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.201381177307288\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [126 | 200]\n    > [Train]\tLoss:\t8.6651\n    > [Test ]\tLoss:\t4.4871\tAcc:\t33.9400\n    > [Stats]\tMany:\t0.6391\tMedium:\t0.3037\tFew:\t0.0313\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.172195588079225\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [127 | 200]\n    > [Train]\tLoss:\t8.8073\n    > [Test ]\tLoss:\t4.6450\tAcc:\t34.6100\n    > [Stats]\tMany:\t0.6454\tMedium:\t0.3163\tFew:\t0.0317\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.105734318631182\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [128 | 200]\n    > [Train]\tLoss:\t8.5954\n    > [Test ]\tLoss:\t4.5072\tAcc:\t35.3700\n    > [Stats]\tMany:\t0.6743\tMedium:\t0.3120\tFew:\t0.0283\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.041967128030311\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [129 | 200]\n    > [Train]\tLoss:\t8.8629\n    > [Test ]\tLoss:\t4.2859\tAcc:\t36.9300\n    > [Stats]\tMany:\t0.6651\tMedium:\t0.3643\tFew:\t0.0300\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.055448768001003\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [130 | 200]\n    > [Train]\tLoss:\t8.5913\n    > [Test ]\tLoss:\t4.2766\tAcc:\t35.7900\n    > [Stats]\tMany:\t0.6571\tMedium:\t0.3337\tFew:\t0.0370\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.082052524931163\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [131 | 200]\n    > [Train]\tLoss:\t8.5759\n    > [Test ]\tLoss:\t4.3385\tAcc:\t35.7300\n    > [Stats]\tMany:\t0.6554\tMedium:\t0.3377\tFew:\t0.0323\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.013355454224355\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [132 | 200]\n    > [Train]\tLoss:\t8.4871\n    > [Test ]\tLoss:\t4.1061\tAcc:\t37.7900\n    > [Stats]\tMany:\t0.6711\tMedium:\t0.3786\tFew:\t0.0350\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.9401622204730575\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [133 | 200]\n    > [Train]\tLoss:\t8.6313\n    > [Test ]\tLoss:\t4.0080\tAcc:\t37.9100\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3786\tFew:\t0.0420\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.933617361037261\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [134 | 200]\n    > [Train]\tLoss:\t8.7271\n    > [Test ]\tLoss:\t4.4682\tAcc:\t36.2800\n    > [Stats]\tMany:\t0.6689\tMedium:\t0.3380\tFew:\t0.0347\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.887843128581746\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [135 | 200]\n    > [Train]\tLoss:\t8.6011\n    > [Test ]\tLoss:\t4.2039\tAcc:\t36.8500\n    > [Stats]\tMany:\t0.6729\tMedium:\t0.3331\tFew:\t0.0547\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.964408823068051\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [136 | 200]\n    > [Train]\tLoss:\t8.3802\n    > [Test ]\tLoss:\t4.3603\tAcc:\t36.8800\n    > [Stats]\tMany:\t0.6654\tMedium:\t0.3551\tFew:\t0.0387\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.914398941749153\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [137 | 200]\n    > [Train]\tLoss:\t8.5295\n    > [Test ]\tLoss:\t4.2446\tAcc:\t37.2800\n    > [Stats]\tMany:\t0.6734\tMedium:\t0.3477\tFew:\t0.0513\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.9136463004584785\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [138 | 200]\n    > [Train]\tLoss:\t8.4700\n    > [Test ]\tLoss:\t4.4599\tAcc:\t36.4800\n    > [Stats]\tMany:\t0.6769\tMedium:\t0.3337\tFew:\t0.0370\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.741742287451336\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [139 | 200]\n    > [Train]\tLoss:\t8.4305\n    > [Test ]\tLoss:\t4.0857\tAcc:\t37.5400\n    > [Stats]\tMany:\t0.6546\tMedium:\t0.3777\tFew:\t0.0470\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.858930163256071\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [140 | 200]\n    > [Train]\tLoss:\t8.4298\n    > [Test ]\tLoss:\t4.2933\tAcc:\t36.1500\n    > [Stats]\tMany:\t0.6617\tMedium:\t0.3411\tFew:\t0.0350\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.763677884221545\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [141 | 200]\n    > [Train]\tLoss:\t8.3610\n    > [Test ]\tLoss:\t4.2158\tAcc:\t37.3500\n    > [Stats]\tMany:\t0.6826\tMedium:\t0.3414\tFew:\t0.0503\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.705378412351367\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [142 | 200]\n    > [Train]\tLoss:\t8.3529\n    > [Test ]\tLoss:\t4.8873\tAcc:\t33.5300\n    > [Stats]\tMany:\t0.6426\tMedium:\t0.2909\tFew:\t0.0287\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.731084286505097\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [143 | 200]\n    > [Train]\tLoss:\t8.4604\n    > [Test ]\tLoss:\t4.4662\tAcc:\t35.5500\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3431\tFew:\t0.0217\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.776524876198948\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [144 | 200]\n    > [Train]\tLoss:\t8.3890\n    > [Test ]\tLoss:\t4.5427\tAcc:\t37.2400\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3811\tFew:\t0.0323\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.683944835706669\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [145 | 200]\n    > [Train]\tLoss:\t8.4623\n    > [Test ]\tLoss:\t4.4002\tAcc:\t36.2000\n    > [Stats]\tMany:\t0.6577\tMedium:\t0.3460\tFew:\t0.0357\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.7734421397883615\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [146 | 200]\n    > [Train]\tLoss:\t8.3186\n    > [Test ]\tLoss:\t4.6661\tAcc:\t35.0200\n    > [Stats]\tMany:\t0.6694\tMedium:\t0.3040\tFew:\t0.0317\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.654561954028284\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [147 | 200]\n    > [Train]\tLoss:\t8.1191\n    > [Test ]\tLoss:\t4.8560\tAcc:\t32.5000\n    > [Stats]\tMany:\t0.6246\tMedium:\t0.2849\tFew:\t0.0223\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.657318478756773\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [148 | 200]\n    > [Train]\tLoss:\t8.5160\n    > [Test ]\tLoss:\t4.5157\tAcc:\t36.0100\n    > [Stats]\tMany:\t0.6623\tMedium:\t0.3417\tFew:\t0.0290\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.73497898411838\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [149 | 200]\n    > [Train]\tLoss:\t8.3763\n    > [Test ]\tLoss:\t4.6421\tAcc:\t35.2200\n    > [Stats]\tMany:\t0.6411\tMedium:\t0.3400\tFew:\t0.0293\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.716165880632263\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [150 | 200]\n    > [Train]\tLoss:\t8.2009\n    > [Test ]\tLoss:\t4.3350\tAcc:\t36.1000\n    > [Stats]\tMany:\t0.6477\tMedium:\t0.3511\tFew:\t0.0380\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.699855559320397\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [151 | 200]\n    > [Train]\tLoss:\t8.1345\n    > [Test ]\tLoss:\t4.5858\tAcc:\t35.5800\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3406\tFew:\t0.0290\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.644454677451702\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [152 | 200]\n    > [Train]\tLoss:\t8.0764\n    > [Test ]\tLoss:\t4.4920\tAcc:\t36.1000\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.3517\tFew:\t0.0297\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.640183378153501\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [153 | 200]\n    > [Train]\tLoss:\t8.3045\n    > [Test ]\tLoss:\t4.8018\tAcc:\t35.4000\n    > [Stats]\tMany:\t0.6574\tMedium:\t0.3297\tFew:\t0.0283\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.640952538788202\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [154 | 200]\n    > [Train]\tLoss:\t8.1761\n    > [Test ]\tLoss:\t4.4359\tAcc:\t37.2200\n    > [Stats]\tMany:\t0.6769\tMedium:\t0.3520\tFew:\t0.0403\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.586110047793184\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [155 | 200]\n    > [Train]\tLoss:\t8.2320\n    > [Test ]\tLoss:\t4.5413\tAcc:\t36.1800\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3417\tFew:\t0.0273\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.607848131300492\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [156 | 200]\n    > [Train]\tLoss:\t8.1107\n    > [Test ]\tLoss:\t4.5002\tAcc:\t36.2700\n    > [Stats]\tMany:\t0.6571\tMedium:\t0.3554\tFew:\t0.0277\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.604448264314174\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [157 | 200]\n    > [Train]\tLoss:\t8.2055\n    > [Test ]\tLoss:\t4.6555\tAcc:\t34.5500\n    > [Stats]\tMany:\t0.6286\tMedium:\t0.3340\tFew:\t0.0287\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.593050518569474\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [158 | 200]\n    > [Train]\tLoss:\t8.2096\n    > [Test ]\tLoss:\t4.5233\tAcc:\t35.2700\n    > [Stats]\tMany:\t0.6420\tMedium:\t0.3397\tFew:\t0.0303\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.511512354253072\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [159 | 200]\n    > [Train]\tLoss:\t8.1010\n    > [Test ]\tLoss:\t4.5023\tAcc:\t35.5100\n    > [Stats]\tMany:\t0.6363\tMedium:\t0.3471\tFew:\t0.0363\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.508025669723353\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [160 | 200]\n    > [Train]\tLoss:\t7.9234\n    > [Test ]\tLoss:\t4.3611\tAcc:\t36.2800\n    > [Stats]\tMany:\t0.6506\tMedium:\t0.3537\tFew:\t0.0377\n    > [Best ]\tAcc:\t38.4600\tMany:\t66.5714\tMedium:\t39.1714\tFew:\t4.8333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"7.409651263335373\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [161 | 200]\n    > [Train]\tLoss:\t7.0364\n    > [Test ]\tLoss:\t4.2158\tAcc:\t39.7800\n    > [Stats]\tMany:\t0.7031\tMedium:\t0.3937\tFew:\t0.0463\n    > [Best ]\tAcc:\t39.7800\tMany:\t70.3143\tMedium:\t39.3714\tFew:\t4.6333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.410390815518588\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [162 | 200]\n    > [Train]\tLoss:\t19.7442\n    > [Test ]\tLoss:\t3.7443\tAcc:\t41.8800\n    > [Stats]\tMany:\t0.7071\tMedium:\t0.4277\tFew:\t0.0720\n    > [Best ]\tAcc:\t41.8800\tMany:\t70.7143\tMedium:\t42.7714\tFew:\t7.2000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.523222120852478\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [163 | 200]\n    > [Train]\tLoss:\t18.1628\n    > [Test ]\tLoss:\t3.4443\tAcc:\t43.5200\n    > [Stats]\tMany:\t0.7031\tMedium:\t0.4520\tFew:\t0.1030\n    > [Best ]\tAcc:\t43.5200\tMany:\t70.3143\tMedium:\t45.2000\tFew:\t10.3000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.62660105055605\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [164 | 200]\n    > [Train]\tLoss:\t17.0556\n    > [Test ]\tLoss:\t3.2364\tAcc:\t44.2700\n    > [Stats]\tMany:\t0.6946\tMedium:\t0.4586\tFew:\t0.1303\n    > [Best ]\tAcc:\t44.2700\tMany:\t69.4571\tMedium:\t45.8571\tFew:\t13.0333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.712627390260248\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [165 | 200]\n    > [Train]\tLoss:\t16.1731\n    > [Test ]\tLoss:\t3.1320\tAcc:\t45.1800\n    > [Stats]\tMany:\t0.6866\tMedium:\t0.4683\tFew:\t0.1587\n    > [Best ]\tAcc:\t45.1800\tMany:\t68.6571\tMedium:\t46.8286\tFew:\t15.8667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.792358990235029\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [166 | 200]\n    > [Train]\tLoss:\t15.6031\n    > [Test ]\tLoss:\t3.0502\tAcc:\t45.6900\n    > [Stats]\tMany:\t0.6843\tMedium:\t0.4709\tFew:\t0.1753\n    > [Best ]\tAcc:\t45.6900\tMany:\t68.4286\tMedium:\t47.0857\tFew:\t17.5333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.852684212093326\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [167 | 200]\n    > [Train]\tLoss:\t15.3646\n    > [Test ]\tLoss:\t2.9960\tAcc:\t46.2600\n    > [Stats]\tMany:\t0.6840\tMedium:\t0.4743\tFew:\t0.1907\n    > [Best ]\tAcc:\t46.2600\tMany:\t68.4000\tMedium:\t47.4286\tFew:\t19.0667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.907040520008601\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [168 | 200]\n    > [Train]\tLoss:\t14.8097\n    > [Test ]\tLoss:\t2.9599\tAcc:\t46.3600\n    > [Stats]\tMany:\t0.6797\tMedium:\t0.4700\tFew:\t0.2040\n    > [Best ]\tAcc:\t46.3600\tMany:\t67.9714\tMedium:\t47.0000\tFew:\t20.4000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.951909675833049\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [169 | 200]\n    > [Train]\tLoss:\t14.5428\n    > [Test ]\tLoss:\t2.9499\tAcc:\t46.7200\n    > [Stats]\tMany:\t0.6769\tMedium:\t0.4791\tFew:\t0.2087\n    > [Best ]\tAcc:\t46.7200\tMany:\t67.6857\tMedium:\t47.9143\tFew:\t20.8667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"7.99441028268772\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [170 | 200]\n    > [Train]\tLoss:\t14.1583\n    > [Test ]\tLoss:\t2.9356\tAcc:\t46.7200\n    > [Stats]\tMany:\t0.6734\tMedium:\t0.4783\tFew:\t0.2137\n    > [Best ]\tAcc:\t46.7200\tMany:\t67.3428\tMedium:\t47.8286\tFew:\t21.3667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.027508430878981\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [171 | 200]\n    > [Train]\tLoss:\t13.9862\n    > [Test ]\tLoss:\t2.9118\tAcc:\t47.1000\n    > [Stats]\tMany:\t0.6737\tMedium:\t0.4834\tFew:\t0.2200\n    > [Best ]\tAcc:\t47.1000\tMany:\t67.3714\tMedium:\t48.3429\tFew:\t22.0000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.062903553393813\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [172 | 200]\n    > [Train]\tLoss:\t13.5757\n    > [Test ]\tLoss:\t2.9276\tAcc:\t47.0100\n    > [Stats]\tMany:\t0.6749\tMedium:\t0.4766\tFew:\t0.2237\n    > [Best ]\tAcc:\t47.1000\tMany:\t67.3714\tMedium:\t48.3429\tFew:\t22.0000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.090810901586803\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [173 | 200]\n    > [Train]\tLoss:\t13.7883\n    > [Test ]\tLoss:\t2.9212\tAcc:\t47.1900\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.4806\tFew:\t0.2237\n    > [Best ]\tAcc:\t47.1900\tMany:\t67.6000\tMedium:\t48.0571\tFew:\t22.3667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.122531451771756\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [174 | 200]\n    > [Train]\tLoss:\t13.4496\n    > [Test ]\tLoss:\t2.9203\tAcc:\t47.3100\n    > [Stats]\tMany:\t0.6751\tMedium:\t0.4809\tFew:\t0.2283\n    > [Best ]\tAcc:\t47.3100\tMany:\t67.5143\tMedium:\t48.0857\tFew:\t22.8333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.146977712335632\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [175 | 200]\n    > [Train]\tLoss:\t13.3400\n    > [Test ]\tLoss:\t2.9246\tAcc:\t47.2200\n    > [Stats]\tMany:\t0.6706\tMedium:\t0.4800\tFew:\t0.2317\n    > [Best ]\tAcc:\t47.3100\tMany:\t67.5143\tMedium:\t48.0857\tFew:\t22.8333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.168716110411587\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [176 | 200]\n    > [Train]\tLoss:\t13.2324\n    > [Test ]\tLoss:\t2.9241\tAcc:\t47.3700\n    > [Stats]\tMany:\t0.6714\tMedium:\t0.4823\tFew:\t0.2330\n    > [Best ]\tAcc:\t47.3700\tMany:\t67.1429\tMedium:\t48.2286\tFew:\t23.3000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.194919351690745\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [177 | 200]\n    > [Train]\tLoss:\t12.9964\n    > [Test ]\tLoss:\t2.9176\tAcc:\t47.5300\n    > [Stats]\tMany:\t0.6674\tMedium:\t0.4897\tFew:\t0.2343\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.224640514091364\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [178 | 200]\n    > [Train]\tLoss:\t12.7696\n    > [Test ]\tLoss:\t2.9392\tAcc:\t47.2800\n    > [Stats]\tMany:\t0.6700\tMedium:\t0.4823\tFew:\t0.2317\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.243510231637107\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [179 | 200]\n    > [Train]\tLoss:\t12.6837\n    > [Test ]\tLoss:\t2.9436\tAcc:\t47.2300\n    > [Stats]\tMany:\t0.6683\tMedium:\t0.4797\tFew:\t0.2350\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.267772433950178\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [180 | 200]\n    > [Train]\tLoss:\t12.6296\n    > [Test ]\tLoss:\t2.9346\tAcc:\t47.3900\n    > [Stats]\tMany:\t0.6689\tMedium:\t0.4814\tFew:\t0.2377\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.29243300548862\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [181 | 200]\n    > [Train]\tLoss:\t12.1959\n    > [Test ]\tLoss:\t2.9319\tAcc:\t47.4100\n    > [Stats]\tMany:\t0.6689\tMedium:\t0.4829\tFew:\t0.2367\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.292617131184446\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [182 | 200]\n    > [Train]\tLoss:\t12.3492\n    > [Test ]\tLoss:\t2.9353\tAcc:\t47.3200\n    > [Stats]\tMany:\t0.6700\tMedium:\t0.4789\tFew:\t0.2370\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.29287484978625\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [183 | 200]\n    > [Train]\tLoss:\t12.2874\n    > [Test ]\tLoss:\t2.9321\tAcc:\t47.3700\n    > [Stats]\tMany:\t0.6671\tMedium:\t0.4820\tFew:\t0.2383\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.293116358020386\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [184 | 200]\n    > [Train]\tLoss:\t12.4052\n    > [Test ]\tLoss:\t2.9377\tAcc:\t47.2100\n    > [Stats]\tMany:\t0.6660\tMedium:\t0.4777\tFew:\t0.2393\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.293323113204513\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [185 | 200]\n    > [Train]\tLoss:\t12.3187\n    > [Test ]\tLoss:\t2.9338\tAcc:\t47.3300\n    > [Stats]\tMany:\t0.6663\tMedium:\t0.4811\tFew:\t0.2390\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.29351907564438\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [186 | 200]\n    > [Train]\tLoss:\t12.1920\n    > [Test ]\tLoss:\t2.9292\tAcc:\t47.2700\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.4809\tFew:\t0.2393\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.293792249699463\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [187 | 200]\n    > [Train]\tLoss:\t12.3827\n    > [Test ]\tLoss:\t2.9372\tAcc:\t47.3500\n    > [Stats]\tMany:\t0.6689\tMedium:\t0.4811\tFew:\t0.2367\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.294031148921125\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [188 | 200]\n    > [Train]\tLoss:\t12.2927\n    > [Test ]\tLoss:\t2.9291\tAcc:\t47.3700\n    > [Stats]\tMany:\t0.6671\tMedium:\t0.4817\tFew:\t0.2387\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.294252263627543\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [189 | 200]\n    > [Train]\tLoss:\t12.3744\n    > [Test ]\tLoss:\t2.9417\tAcc:\t47.3700\n    > [Stats]\tMany:\t0.6657\tMedium:\t0.4814\tFew:\t0.2407\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.294560681555563\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [190 | 200]\n    > [Train]\tLoss:\t12.3686\n    > [Test ]\tLoss:\t2.9329\tAcc:\t47.2900\n    > [Stats]\tMany:\t0.6671\tMedium:\t0.4806\tFew:\t0.2373\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.29478246962666\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [191 | 200]\n    > [Train]\tLoss:\t12.3584\n    > [Test ]\tLoss:\t2.9368\tAcc:\t47.3600\n    > [Stats]\tMany:\t0.6680\tMedium:\t0.4800\tFew:\t0.2393\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.29500462936318\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [192 | 200]\n    > [Train]\tLoss:\t12.3779\n    > [Test ]\tLoss:\t2.9365\tAcc:\t47.4500\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.4800\tFew:\t0.2417\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.295302721589545\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [193 | 200]\n    > [Train]\tLoss:\t12.3814\n    > [Test ]\tLoss:\t2.9407\tAcc:\t47.2200\n    > [Stats]\tMany:\t0.6651\tMedium:\t0.4803\tFew:\t0.2377\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.295500393140298\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [194 | 200]\n    > [Train]\tLoss:\t12.3102\n    > [Test ]\tLoss:\t2.9295\tAcc:\t47.4100\n    > [Stats]\tMany:\t0.6677\tMedium:\t0.4809\tFew:\t0.2403\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.295684959877613\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [195 | 200]\n    > [Train]\tLoss:\t12.3461\n    > [Test ]\tLoss:\t2.9274\tAcc:\t47.4000\n    > [Stats]\tMany:\t0.6674\tMedium:\t0.4814\tFew:\t0.2397\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.295953626180241\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [196 | 200]\n    > [Train]\tLoss:\t12.2399\n    > [Test ]\tLoss:\t2.9331\tAcc:\t47.3700\n    > [Stats]\tMany:\t0.6666\tMedium:\t0.4834\tFew:\t0.2373\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.29620289172589\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [197 | 200]\n    > [Train]\tLoss:\t12.2464\n    > [Test ]\tLoss:\t2.9394\tAcc:\t47.3200\n    > [Stats]\tMany:\t0.6683\tMedium:\t0.4817\tFew:\t0.2357\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.296384207041706\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [198 | 200]\n    > [Train]\tLoss:\t12.3705\n    > [Test ]\tLoss:\t2.9362\tAcc:\t47.4100\n    > [Stats]\tMany:\t0.6689\tMedium:\t0.4829\tFew:\t0.2367\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.296586172534749\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [199 | 200]\n    > [Train]\tLoss:\t12.4180\n    > [Test ]\tLoss:\t2.9333\tAcc:\t47.2800\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.4814\tFew:\t0.2390\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"8.296806931378907\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [200 | 200]\n    > [Train]\tLoss:\t12.3805\n    > [Test ]\tLoss:\t2.9336\tAcc:\t47.3700\n    > [Stats]\tMany:\t0.6677\tMedium:\t0.4806\tFew:\t0.2393\n    > [Best ]\tAcc:\t47.5300\tMany:\t66.7429\tMedium:\t48.9714\tFew:\t23.4333\n    > [Param]\tLR:\t0.00001000\n---> Final performance...\n    > best bAcc (test):\t47.53\n    > best statistics:\tMany:\t0.6674285531044006\tMed:\t0.48971426486968994\tFew:\t0.2343333214521408\n---> Training Time: 0:23:37.22\n","output_type":"stream"},{"name":"stdout","text":"8.297007436497328\n","output_type":"stream"}]},{"cell_type":"code","source":"variance_list1","metadata":{"execution":{"iopub.status.busy":"2024-01-26T04:22:37.856357Z","iopub.execute_input":"2024-01-26T04:22:37.856698Z","iopub.status.idle":"2024-01-26T04:22:37.866359Z","shell.execute_reply.started":"2024-01-26T04:22:37.856665Z","shell.execute_reply":"2024-01-26T04:22:37.865325Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[2.9233015779622535,\n 5.031301948596366,\n 7.5654318566466285,\n 9.704695166064162,\n 11.340183952383676,\n 12.395697847689462,\n 13.053884649426136,\n 13.566071986446048,\n 14.137371400169636,\n 14.403944744224878,\n 14.588420739947418,\n 14.758634169561182,\n 14.834765386703596,\n 14.986992456497633,\n 15.053018831322326,\n 15.028133648241349,\n 14.940399765908277,\n 14.980495860292402,\n 14.904459717204087,\n 14.821547340719752,\n 14.804152355422605,\n 14.695735813978267,\n 14.610923326611728,\n 14.47650754929152,\n 14.357034116968146,\n 14.277514471828209,\n 14.126882852302165,\n 14.007218180993236,\n 13.901697598614053,\n 13.80548916568714,\n 13.656866916791532,\n 13.574357772793238,\n 13.512570535697455,\n 13.45848698573586,\n 13.317704633248576,\n 13.190841490025376,\n 13.121905257130273,\n 13.040509647496673,\n 12.945723757482915,\n 12.934415043562685,\n 12.905234421076486,\n 12.794793077655132,\n 12.745569967611328,\n 12.653857951640754,\n 12.537519742431943,\n 12.434714325706237,\n 12.34823965956289,\n 12.215561716776874,\n 12.15674873116881,\n 11.9562127929166,\n 11.857300116852176,\n 11.828533873133589,\n 11.800060009555132,\n 11.705980625320809,\n 11.526198175342923,\n 11.453715043861763,\n 11.408489337564445,\n 11.322513685654666,\n 11.17134834592805,\n 11.22767266161683,\n 11.16811060803465,\n 11.164458443820763,\n 11.107972077129197,\n 11.024193243970942,\n 10.924635700946222,\n 10.848927428466528,\n 10.806747736334556,\n 10.767353835761968,\n 10.6849325530945,\n 10.628747524683837,\n 10.511302008439081,\n 10.516588731310515,\n 10.355102039395815,\n 10.244993908327105,\n 10.295483612250722,\n 10.269005692402125,\n 10.12798058936985,\n 10.061377881137755,\n 10.069374226712982,\n 10.021252307952672,\n 9.944721240711754,\n 9.891061866964186,\n 9.889553780283572,\n 9.85098268135135,\n 9.76850873805451,\n 9.659318328407801,\n 9.608080267330877,\n 9.591850982479928,\n 9.512249319576892,\n 9.535477734454778,\n 9.445672650826955,\n 9.46084943515081,\n 9.390729152385473,\n 9.489143646246667,\n 9.389755473233993,\n 9.32315946934765,\n 9.37643023348974,\n 9.273728120357495,\n 9.238133843529761,\n 9.189991496826565,\n 9.181028909104382,\n 9.141774075023209,\n 9.086607257787712,\n 9.03970040075081,\n 8.994548845336064,\n 8.942147704751275,\n 8.824258257878196,\n 8.831148459625476,\n 8.771610739444867,\n 8.70029473816341,\n 8.7235248626998,\n 8.734439725108833,\n 8.595613636795642,\n 8.624785133451017,\n 8.594536515922204,\n 8.523947472549276,\n 8.406249538227918,\n 8.387937830031696,\n 8.390520613239795,\n 8.28631586578875,\n 8.269119801215302,\n 8.213693773250425,\n 8.167303250136433,\n 8.219164379100473,\n 8.201381177307288,\n 8.172195588079225,\n 8.105734318631182,\n 8.041967128030311,\n 8.055448768001003,\n 8.082052524931163,\n 8.013355454224355,\n 7.9401622204730575,\n 7.933617361037261,\n 7.887843128581746,\n 7.964408823068051,\n 7.914398941749153,\n 7.9136463004584785,\n 7.741742287451336,\n 7.858930163256071,\n 7.763677884221545,\n 7.705378412351367,\n 7.731084286505097,\n 7.776524876198948,\n 7.683944835706669,\n 7.7734421397883615,\n 7.654561954028284,\n 7.657318478756773,\n 7.73497898411838,\n 7.716165880632263,\n 7.699855559320397,\n 7.644454677451702,\n 7.640183378153501,\n 7.640952538788202,\n 7.586110047793184,\n 7.607848131300492,\n 7.604448264314174,\n 7.593050518569474,\n 7.511512354253072,\n 7.508025669723353,\n 7.409651263335373,\n 7.410390815518588,\n 7.523222120852478,\n 7.62660105055605,\n 7.712627390260248,\n 7.792358990235029,\n 7.852684212093326,\n 7.907040520008601,\n 7.951909675833049,\n 7.99441028268772,\n 8.027508430878981,\n 8.062903553393813,\n 8.090810901586803,\n 8.122531451771756,\n 8.146977712335632,\n 8.168716110411587,\n 8.194919351690745,\n 8.224640514091364,\n 8.243510231637107,\n 8.267772433950178,\n 8.29243300548862,\n 8.292617131184446,\n 8.29287484978625,\n 8.293116358020386,\n 8.293323113204513,\n 8.29351907564438,\n 8.293792249699463,\n 8.294031148921125,\n 8.294252263627543,\n 8.294560681555563,\n 8.29478246962666,\n 8.29500462936318,\n 8.295302721589545,\n 8.295500393140298,\n 8.295684959877613,\n 8.295953626180241,\n 8.29620289172589,\n 8.296384207041706,\n 8.296586172534749,\n 8.296806931378907,\n 8.297007436497328]"},"metadata":{}}]},{"cell_type":"code","source":"'''\nimport matplotlib.pyplot as plt\n\n# Assuming variance_l1_norm is the calculated variance # If you have multiple variances, create a list\n\nplt.figure(figsize=(8, 6))\nplt.plot(range(len(variance_list)), variance_list, color='blue', linestyle='-', linewidth=2)\nplt.xlabel('Classes')\nplt.ylabel('Variance of L1-norm')\nplt.title('Variance of L1-norm Among Classes')\nplt.xticks(range(len(variance_list)), [f'Class_{i}' for i in range(len(variance_list))])\nplt.grid(True)\nplt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2024-01-26T04:22:37.867848Z","iopub.execute_input":"2024-01-26T04:22:37.868227Z","iopub.status.idle":"2024-01-26T04:22:37.877141Z","shell.execute_reply.started":"2024-01-26T04:22:37.868199Z","shell.execute_reply":"2024-01-26T04:22:37.876255Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"\"\\nimport matplotlib.pyplot as plt\\n\\n# Assuming variance_l1_norm is the calculated variance # If you have multiple variances, create a list\\n\\nplt.figure(figsize=(8, 6))\\nplt.plot(range(len(variance_list)), variance_list, color='blue', linestyle='-', linewidth=2)\\nplt.xlabel('Classes')\\nplt.ylabel('Variance of L1-norm')\\nplt.title('Variance of L1-norm Among Classes')\\nplt.xticks(range(len(variance_list)), [f'Class_{i}' for i in range(len(variance_list))])\\nplt.grid(True)\\nplt.show()\\n\""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import losses\n\n#from datasets.cifar100 import *\n\n#from train.train import *\n#from train.validate import *\n\n#from models.net import *\n\n#from losses.loss import *\n\n#from utils.config import *\n#from utils.plot import *\n#from utils.common import make_imb_data, save_checkpoint, hms_string\n\n#from utils.logger import logger\n\n#args = parse_args()\n\nfrom argparse import Namespace\n\n# Replace the command below with your actual values\nargs=Namespace(network='resnet32', epochs=200, batch_size=128, update_epoch=1,\n               lr=0.1, lr_decay=0.01, momentum=0.9, wd=0.0002, nesterov=False,\n               scheduler='warmup', warmup=5, aug_prob=0.5, cutout=False, cmo=False,\n               posthoc_la=False, cuda=True, aug_type='none', sim_type='none', max_d=30,\n               num_test=10, accept_rate=0.6, verbose=False, use_norm=False,\n               out='/kaggle/working/log3',\n               data_dir='~/dataset/', workers=4, seed='None',\n               gpu='0', dataset='cifar100', num_max=500, imb_ratio=100,\n               loss_fn='ride', num_experts=3, ride_distill=False)\n\nreproducibility(args.seed)\nargs = dataset_argument(args)\nargs.logger = logger(args)\n\nbest_acc = 0 # best test accuracy\ncurr_state_ac=[]\nlabel_ac=[]\nvariance_list2=[]\n\ndef main():\n    global best_acc,curr_state_ac,label_ac,variance_list\n\n    try:\n        assert args.num_max <= 50000. / args.num_class\n    except AssertionError:\n        args.num_max = int(50000 / args.num_class)\n    \n    print(f'==> Preparing imbalanced CIFAR-100')\n    # N_SAMPLES_PER_CLASS = make_imb_data(args.num_max, args.num_class, args.imb_ratio)\n    trainset, testset = get_cifar100(os.path.join(args.data_dir, 'cifar100/'), args)\n    N_SAMPLES_PER_CLASS = trainset.img_num_list\n        \n    trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, drop_last= args.loss_fn == 'ncl', pin_memory=True, sampler=None)\n    testloader = data.DataLoader(testset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True) \n    \n    if args.cmo:\n        cls_num_list = N_SAMPLES_PER_CLASS\n        cls_weight = 1.0 / (np.array(cls_num_list))\n        cls_weight = cls_weight / np.sum(cls_weight) * len(cls_num_list)\n        labels = trainloader.dataset.targets\n        samples_weight = np.array([cls_weight[t] for t in labels])\n        samples_weight = torch.from_numpy(samples_weight)\n        samples_weight = samples_weight.double()\n        print(\"samples_weight\", samples_weight)\n        sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(labels), replacement=True)\n        weighted_trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, sampler=sampler)\n    else:\n        weighted_trainloader = None\n    \n\n    # Model\n    print (\"==> creating {}\".format(args.network))\n    model = get_model(args, N_SAMPLES_PER_CLASS)\n    train_criterion = get_loss(args, N_SAMPLES_PER_CLASS)\n    criterion = nn.CrossEntropyLoss() # For test, validation \n    optimizer = get_optimizer(args, model)\n    scheduler = get_scheduler(args,optimizer)\n\n    teacher = load_model(args)\n\n\n    train = get_train_fn(args)\n    validate = get_valid_fn(args)\n    update_score = get_update_score_fn(args)\n    \n    start_time = time.time()\n    \n    test_accs = []\n    for epoch in range(args.epochs):\n        \n        lr = adjust_learning_rate(optimizer, epoch, scheduler, args)\n        if args.cuda:\n            if epoch % args.update_epoch == 0:\n                curr_state_ac, label_ac = update_score(trainloader, model, N_SAMPLES_PER_CLASS, posthoc_la = args.posthoc_la, num_test = args.num_test, accept_rate = args.accept_rate)\n                print(curr_state_ac)\n                \n            if args.verbose:\n                if epoch == 0:\n                    maps = np.zeros((args.epochs,args.num_class))\n                maps = plot_score_epoch(curr_state_ac,label_ac, epoch, maps, args.out)\n        train_loss = train(args, trainloader, model, optimizer,train_criterion, epoch, weighted_trainloader, teacher) \n\n\n        test_loss, test_acc, test_cls = validate(args, testloader, model, criterion, N_SAMPLES_PER_CLASS,  num_class=args.num_class, mode='test Valid')\n\n        if best_acc <= test_acc:\n            best_acc = test_acc\n            many_best = test_cls[0]\n            med_best = test_cls[1]\n            few_best = test_cls[2]\n            # Save models\n            save_checkpoint({\n                'epoch': epoch + 1,\n                'state_dict': model['model'].state_dict() if args.loss_fn == 'ncl' else model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, epoch + 1, args.out)\n        test_accs.append(test_acc)\n        \n        \n        #code for weight L1 norm\n        \n        model_weights = model.state_dict()\n        classwise_l1_norms = {}\n        for class_label in range(args.num_class):\n            if args.loss_fn=='ride':\n                trans_weight1=model_weights['linears.0.weight'].transpose(0, 1)\n                trans_weight2=model_weights['linears.1.weight'].transpose(0, 1)\n                trans_weight3=model_weights['linears.2.weight'].transpose(0, 1)\n                \n                class_l1_norm1 = torch.abs(trans_weight1[class_label]).sum()\n                class_l1_norm2 = torch.abs(trans_weight2[class_label]).sum()\n                class_l1_norm3 = torch.abs(trans_weight3[class_label]).sum()\n\n                class_l1_norm = class_l1_norm1 + class_l1_norm2 + class_l1_norm3\n                \n            elif args.loss_fn=='ldam_drw':\n                trans_weight = model_weights['linear.weight'].transpose(0, 1)\n                linear_weight = trans_weight[class_label]\n                class_l1_norm = torch.abs(linear_weight).sum()\n            else:\n                trans_weight = model_weights['linear.weight']\n                linear_weight = trans_weight[class_label]\n                class_l1_norm = torch.abs(linear_weight).sum()\n            classwise_l1_norms[f'Class_{class_label}'] = class_l1_norm\n        l1_norm_values = [tensor.item() for tensor in classwise_l1_norms.values()]\n        variance_l1_norm = np.var(l1_norm_values)\n        variance_list2.append(np.sqrt(variance_l1_norm))\n        print(np.sqrt(variance_l1_norm))\n        \n        #endu\n        \n        args.logger(f'Epoch: [{epoch+1} | {args.epochs}]', level=1)\n        if args.cuda:\n            args.logger(f'Max_state: {int(torch.max(curr_state_ac))}, min_state: {int(torch.min(curr_state_ac))}', level=2)\n        args.logger(f'[Train]\\tLoss:\\t{train_loss:.4f}', level=2)\n        args.logger(f'[Test ]\\tLoss:\\t{test_loss:.4f}\\tAcc:\\t{test_acc:.4f}', level=2)\n        args.logger(f'[Stats]\\tMany:\\t{test_cls[0]:.4f}\\tMedium:\\t{test_cls[1]:.4f}\\tFew:\\t{test_cls[2]:.4f}', level=2)\n        args.logger(f'[Best ]\\tAcc:\\t{np.max(test_accs):.4f}\\tMany:\\t{100*many_best:.4f}\\tMedium:\\t{100*med_best:.4f}\\tFew:\\t{100*few_best:.4f}', level=2)\n        args.logger(f'[Param]\\tLR:\\t{lr:.8f}', level=2)\n    \n    end_time = time.time()\n\n    # Print the final results\n    args.logger(f'Final performance...', level=1)\n    args.logger(f'best bAcc (test):\\t{np.max(test_accs)}', level=2)\n    args.logger(f'best statistics:\\tMany:\\t{many_best}\\tMed:\\t{med_best}\\tFew:\\t{few_best}', level=2)\n    args.logger(f'Training Time: {hms_string(end_time - start_time)}', level=1)\n\n    \n    if args.verbose:\n        args.logger.map_save(maps)\n\nif __name__ == '__main__':\n    main()\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T04:30:01.214838Z","iopub.execute_input":"2024-01-26T04:30:01.215244Z","iopub.status.idle":"2024-01-26T05:01:48.357174Z","shell.execute_reply.started":"2024-01-26T04:30:01.215211Z","shell.execute_reply":"2024-01-26T05:01:48.356097Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"---> ---cifar100---\n---> ---cifar100---\n---> ---cifar100---\n---> ---cifar100---\n---> Argument\n---> Argument\n---> Argument\n---> Argument\n    > network     : resnet32\n    > network     : resnet32\n    > network     : resnet32\n    > network     : resnet32\n    > epochs      : 200\n    > epochs      : 200\n    > epochs      : 200\n    > epochs      : 200\n    > batch_size  : 128\n    > batch_size  : 128\n    > batch_size  : 128\n    > batch_size  : 128\n    > update_epoch: 1\n    > update_epoch: 1\n    > update_epoch: 1\n    > update_epoch: 1\n    > lr          : 0.1\n    > lr          : 0.1\n    > lr          : 0.1\n    > lr          : 0.1\n    > lr_decay    : 0.01\n    > lr_decay    : 0.01\n    > lr_decay    : 0.01\n    > lr_decay    : 0.01\n    > momentum    : 0.9\n    > momentum    : 0.9\n    > momentum    : 0.9\n    > momentum    : 0.9\n    > wd          : 0.0002\n    > wd          : 0.0002\n    > wd          : 0.0002\n    > wd          : 0.0002\n    > nesterov    : False\n    > nesterov    : False\n    > nesterov    : False\n    > nesterov    : False\n    > scheduler   : warmup\n    > scheduler   : warmup\n    > scheduler   : warmup\n    > scheduler   : warmup\n    > warmup      : 5\n    > warmup      : 5\n    > warmup      : 5\n    > warmup      : 5\n    > aug_prob    : 0.5\n    > aug_prob    : 0.5\n    > aug_prob    : 0.5\n    > aug_prob    : 0.5\n    > cutout      : False\n    > cutout      : False\n    > cutout      : False\n    > cutout      : False\n    > cmo         : False\n    > cmo         : False\n    > cmo         : False\n    > cmo         : False\n    > posthoc_la  : False\n    > posthoc_la  : False\n    > posthoc_la  : False\n    > posthoc_la  : False\n    > cuda        : True\n    > cuda        : True\n    > cuda        : True\n    > cuda        : True\n    > aug_type    : none\n    > aug_type    : none\n    > aug_type    : none\n    > aug_type    : none\n    > sim_type    : none\n    > sim_type    : none\n    > sim_type    : none\n    > sim_type    : none\n    > max_d       : 30\n    > max_d       : 30\n    > max_d       : 30\n    > max_d       : 30\n    > num_test    : 10\n    > num_test    : 10\n    > num_test    : 10\n    > num_test    : 10\n    > accept_rate : 0.6\n    > accept_rate : 0.6\n    > accept_rate : 0.6\n    > accept_rate : 0.6\n    > verbose     : False\n    > verbose     : False\n    > verbose     : False\n    > verbose     : False\n    > use_norm    : False\n    > use_norm    : False\n    > use_norm    : False\n    > use_norm    : False\n    > out         : /kaggle/working/log3\n    > out         : /kaggle/working/log3\n    > out         : /kaggle/working/log3\n    > out         : /kaggle/working/log3\n    > data_dir    : ~/dataset/\n    > data_dir    : ~/dataset/\n    > data_dir    : ~/dataset/\n    > data_dir    : ~/dataset/\n    > workers     : 4\n    > workers     : 4\n    > workers     : 4\n    > workers     : 4\n    > seed        : None\n    > seed        : None\n    > seed        : None\n    > seed        : None\n    > gpu         : 0\n    > gpu         : 0\n    > gpu         : 0\n    > gpu         : 0\n    > dataset     : cifar100\n    > dataset     : cifar100\n    > dataset     : cifar100\n    > dataset     : cifar100\n    > num_max     : 500\n    > num_max     : 500\n    > num_max     : 500\n    > num_max     : 500\n    > imb_ratio   : 100\n    > imb_ratio   : 100\n    > imb_ratio   : 100\n    > imb_ratio   : 100\n    > loss_fn     : ride\n    > loss_fn     : ride\n    > loss_fn     : ride\n    > loss_fn     : ride\n    > num_experts : 3\n    > num_experts : 3\n    > num_experts : 3\n    > num_experts : 3\n    > ride_distill: False\n    > ride_distill: False\n    > ride_distill: False\n    > ride_distill: False\n    > num_class   : 100\n    > num_class   : 100\n    > num_class   : 100\n    > num_class   : 100\n","output_type":"stream"},{"name":"stdout","text":"==> Preparing imbalanced CIFAR-100\nFiles already downloaded and verified\nMagnitude set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nOperation set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nFiles already downloaded and verified\n#Train: 10847, #Test: 10000\n==> creating resnet32\n    Total params: 0.79M\nMax state: 0 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [1 | 200]\n---> Epoch: [1 | 200]\n---> Epoch: [1 | 200]\n---> Epoch: [1 | 200]\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > [Train]\tLoss:\t31.8228\n    > [Train]\tLoss:\t31.8228\n    > [Train]\tLoss:\t31.8228\n    > [Train]\tLoss:\t31.8228\n    > [Test ]\tLoss:\t5.6949\tAcc:\t5.7300\n    > [Test ]\tLoss:\t5.6949\tAcc:\t5.7300\n    > [Test ]\tLoss:\t5.6949\tAcc:\t5.7300\n    > [Test ]\tLoss:\t5.6949\tAcc:\t5.7300\n    > [Stats]\tMany:\t0.1549\tMedium:\t0.0089\tFew:\t0.0000\n    > [Stats]\tMany:\t0.1549\tMedium:\t0.0089\tFew:\t0.0000\n    > [Stats]\tMany:\t0.1549\tMedium:\t0.0089\tFew:\t0.0000\n    > [Stats]\tMany:\t0.1549\tMedium:\t0.0089\tFew:\t0.0000\n    > [Best ]\tAcc:\t5.7300\tMany:\t15.4857\tMedium:\t0.8857\tFew:\t0.0000\n    > [Best ]\tAcc:\t5.7300\tMany:\t15.4857\tMedium:\t0.8857\tFew:\t0.0000\n    > [Best ]\tAcc:\t5.7300\tMany:\t15.4857\tMedium:\t0.8857\tFew:\t0.0000\n    > [Best ]\tAcc:\t5.7300\tMany:\t15.4857\tMedium:\t0.8857\tFew:\t0.0000\n    > [Param]\tLR:\t0.02000000\n    > [Param]\tLR:\t0.02000000\n    > [Param]\tLR:\t0.02000000\n    > [Param]\tLR:\t0.02000000\n","output_type":"stream"},{"name":"stdout","text":"2.6169450599932924\nMax state: 0 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [2 | 200]\n---> Epoch: [2 | 200]\n---> Epoch: [2 | 200]\n---> Epoch: [2 | 200]\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > [Train]\tLoss:\t29.7927\n    > [Train]\tLoss:\t29.7927\n    > [Train]\tLoss:\t29.7927\n    > [Train]\tLoss:\t29.7927\n    > [Test ]\tLoss:\t5.5277\tAcc:\t8.1400\n    > [Test ]\tLoss:\t5.5277\tAcc:\t8.1400\n    > [Test ]\tLoss:\t5.5277\tAcc:\t8.1400\n    > [Test ]\tLoss:\t5.5277\tAcc:\t8.1400\n    > [Stats]\tMany:\t0.2226\tMedium:\t0.0100\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2226\tMedium:\t0.0100\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2226\tMedium:\t0.0100\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2226\tMedium:\t0.0100\tFew:\t0.0000\n    > [Best ]\tAcc:\t8.1400\tMany:\t22.2571\tMedium:\t1.0000\tFew:\t0.0000\n    > [Best ]\tAcc:\t8.1400\tMany:\t22.2571\tMedium:\t1.0000\tFew:\t0.0000\n    > [Best ]\tAcc:\t8.1400\tMany:\t22.2571\tMedium:\t1.0000\tFew:\t0.0000\n    > [Best ]\tAcc:\t8.1400\tMany:\t22.2571\tMedium:\t1.0000\tFew:\t0.0000\n    > [Param]\tLR:\t0.04000000\n    > [Param]\tLR:\t0.04000000\n    > [Param]\tLR:\t0.04000000\n    > [Param]\tLR:\t0.04000000\n","output_type":"stream"},{"name":"stdout","text":"5.264145290177183\nMax state: 0 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [3 | 200]\n---> Epoch: [3 | 200]\n---> Epoch: [3 | 200]\n---> Epoch: [3 | 200]\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > [Train]\tLoss:\t28.8884\n    > [Train]\tLoss:\t28.8884\n    > [Train]\tLoss:\t28.8884\n    > [Train]\tLoss:\t28.8884\n    > [Test ]\tLoss:\t5.5809\tAcc:\t9.1600\n    > [Test ]\tLoss:\t5.5809\tAcc:\t9.1600\n    > [Test ]\tLoss:\t5.5809\tAcc:\t9.1600\n    > [Test ]\tLoss:\t5.5809\tAcc:\t9.1600\n    > [Stats]\tMany:\t0.2377\tMedium:\t0.0240\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2377\tMedium:\t0.0240\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2377\tMedium:\t0.0240\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2377\tMedium:\t0.0240\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.1600\tMany:\t23.7714\tMedium:\t2.4000\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.1600\tMany:\t23.7714\tMedium:\t2.4000\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.1600\tMany:\t23.7714\tMedium:\t2.4000\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.1600\tMany:\t23.7714\tMedium:\t2.4000\tFew:\t0.0000\n    > [Param]\tLR:\t0.06000000\n    > [Param]\tLR:\t0.06000000\n    > [Param]\tLR:\t0.06000000\n    > [Param]\tLR:\t0.06000000\n","output_type":"stream"},{"name":"stdout","text":"7.483072768167486\nMax state: 0 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [4 | 200]\n---> Epoch: [4 | 200]\n---> Epoch: [4 | 200]\n---> Epoch: [4 | 200]\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > [Train]\tLoss:\t28.0600\n    > [Train]\tLoss:\t28.0600\n    > [Train]\tLoss:\t28.0600\n    > [Train]\tLoss:\t28.0600\n    > [Test ]\tLoss:\t5.4392\tAcc:\t9.8200\n    > [Test ]\tLoss:\t5.4392\tAcc:\t9.8200\n    > [Test ]\tLoss:\t5.4392\tAcc:\t9.8200\n    > [Test ]\tLoss:\t5.4392\tAcc:\t9.8200\n    > [Stats]\tMany:\t0.2537\tMedium:\t0.0269\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2537\tMedium:\t0.0269\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2537\tMedium:\t0.0269\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2537\tMedium:\t0.0269\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Param]\tLR:\t0.08000000\n    > [Param]\tLR:\t0.08000000\n    > [Param]\tLR:\t0.08000000\n    > [Param]\tLR:\t0.08000000\n","output_type":"stream"},{"name":"stdout","text":"9.64288658274472\nMax state: 0 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [5 | 200]\n---> Epoch: [5 | 200]\n---> Epoch: [5 | 200]\n---> Epoch: [5 | 200]\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > [Train]\tLoss:\t27.4674\n    > [Train]\tLoss:\t27.4674\n    > [Train]\tLoss:\t27.4674\n    > [Train]\tLoss:\t27.4674\n    > [Test ]\tLoss:\t5.6490\tAcc:\t9.5000\n    > [Test ]\tLoss:\t5.6490\tAcc:\t9.5000\n    > [Test ]\tLoss:\t5.6490\tAcc:\t9.5000\n    > [Test ]\tLoss:\t5.6490\tAcc:\t9.5000\n    > [Stats]\tMany:\t0.2343\tMedium:\t0.0371\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2343\tMedium:\t0.0371\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2343\tMedium:\t0.0371\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2343\tMedium:\t0.0371\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8200\tMany:\t25.3714\tMedium:\t2.6857\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.555419241220704\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [6 | 200]\n---> Epoch: [6 | 200]\n---> Epoch: [6 | 200]\n---> Epoch: [6 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t26.7086\n    > [Train]\tLoss:\t26.7086\n    > [Train]\tLoss:\t26.7086\n    > [Train]\tLoss:\t26.7086\n    > [Test ]\tLoss:\t5.0937\tAcc:\t12.1000\n    > [Test ]\tLoss:\t5.0937\tAcc:\t12.1000\n    > [Test ]\tLoss:\t5.0937\tAcc:\t12.1000\n    > [Test ]\tLoss:\t5.0937\tAcc:\t12.1000\n    > [Stats]\tMany:\t0.3020\tMedium:\t0.0437\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3020\tMedium:\t0.0437\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3020\tMedium:\t0.0437\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3020\tMedium:\t0.0437\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.1000\tMany:\t30.2000\tMedium:\t4.3714\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.1000\tMany:\t30.2000\tMedium:\t4.3714\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.1000\tMany:\t30.2000\tMedium:\t4.3714\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.1000\tMany:\t30.2000\tMedium:\t4.3714\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.578502359796268\nMax state: 0 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [7 | 200]\n---> Epoch: [7 | 200]\n---> Epoch: [7 | 200]\n---> Epoch: [7 | 200]\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > [Train]\tLoss:\t25.5458\n    > [Train]\tLoss:\t25.5458\n    > [Train]\tLoss:\t25.5458\n    > [Train]\tLoss:\t25.5458\n    > [Test ]\tLoss:\t5.0411\tAcc:\t12.6000\n    > [Test ]\tLoss:\t5.0411\tAcc:\t12.6000\n    > [Test ]\tLoss:\t5.0411\tAcc:\t12.6000\n    > [Test ]\tLoss:\t5.0411\tAcc:\t12.6000\n    > [Stats]\tMany:\t0.3243\tMedium:\t0.0357\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3243\tMedium:\t0.0357\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3243\tMedium:\t0.0357\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3243\tMedium:\t0.0357\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.6000\tMany:\t32.4286\tMedium:\t3.5714\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.6000\tMany:\t32.4286\tMedium:\t3.5714\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.6000\tMany:\t32.4286\tMedium:\t3.5714\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.6000\tMany:\t32.4286\tMedium:\t3.5714\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.303141996993883\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [8 | 200]\n---> Epoch: [8 | 200]\n---> Epoch: [8 | 200]\n---> Epoch: [8 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t25.0277\n    > [Train]\tLoss:\t25.0277\n    > [Train]\tLoss:\t25.0277\n    > [Train]\tLoss:\t25.0277\n    > [Test ]\tLoss:\t4.9856\tAcc:\t13.5500\n    > [Test ]\tLoss:\t4.9856\tAcc:\t13.5500\n    > [Test ]\tLoss:\t4.9856\tAcc:\t13.5500\n    > [Test ]\tLoss:\t4.9856\tAcc:\t13.5500\n    > [Stats]\tMany:\t0.3571\tMedium:\t0.0291\tFew:\t0.0010\n    > [Stats]\tMany:\t0.3571\tMedium:\t0.0291\tFew:\t0.0010\n    > [Stats]\tMany:\t0.3571\tMedium:\t0.0291\tFew:\t0.0010\n    > [Stats]\tMany:\t0.3571\tMedium:\t0.0291\tFew:\t0.0010\n    > [Best ]\tAcc:\t13.5500\tMany:\t35.7143\tMedium:\t2.9143\tFew:\t0.1000\n    > [Best ]\tAcc:\t13.5500\tMany:\t35.7143\tMedium:\t2.9143\tFew:\t0.1000\n    > [Best ]\tAcc:\t13.5500\tMany:\t35.7143\tMedium:\t2.9143\tFew:\t0.1000\n    > [Best ]\tAcc:\t13.5500\tMany:\t35.7143\tMedium:\t2.9143\tFew:\t0.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.896273085194924\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [9 | 200]\n---> Epoch: [9 | 200]\n---> Epoch: [9 | 200]\n---> Epoch: [9 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t24.3153\n    > [Train]\tLoss:\t24.3153\n    > [Train]\tLoss:\t24.3153\n    > [Train]\tLoss:\t24.3153\n    > [Test ]\tLoss:\t4.3352\tAcc:\t17.5800\n    > [Test ]\tLoss:\t4.3352\tAcc:\t17.5800\n    > [Test ]\tLoss:\t4.3352\tAcc:\t17.5800\n    > [Test ]\tLoss:\t4.3352\tAcc:\t17.5800\n    > [Stats]\tMany:\t0.4083\tMedium:\t0.0891\tFew:\t0.0057\n    > [Stats]\tMany:\t0.4083\tMedium:\t0.0891\tFew:\t0.0057\n    > [Stats]\tMany:\t0.4083\tMedium:\t0.0891\tFew:\t0.0057\n    > [Stats]\tMany:\t0.4083\tMedium:\t0.0891\tFew:\t0.0057\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.30798901594291\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [10 | 200]\n---> Epoch: [10 | 200]\n---> Epoch: [10 | 200]\n---> Epoch: [10 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t23.7297\n    > [Train]\tLoss:\t23.7297\n    > [Train]\tLoss:\t23.7297\n    > [Train]\tLoss:\t23.7297\n    > [Test ]\tLoss:\t4.8313\tAcc:\t15.8400\n    > [Test ]\tLoss:\t4.8313\tAcc:\t15.8400\n    > [Test ]\tLoss:\t4.8313\tAcc:\t15.8400\n    > [Test ]\tLoss:\t4.8313\tAcc:\t15.8400\n    > [Stats]\tMany:\t0.3869\tMedium:\t0.0594\tFew:\t0.0073\n    > [Stats]\tMany:\t0.3869\tMedium:\t0.0594\tFew:\t0.0073\n    > [Stats]\tMany:\t0.3869\tMedium:\t0.0594\tFew:\t0.0073\n    > [Stats]\tMany:\t0.3869\tMedium:\t0.0594\tFew:\t0.0073\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.533676684469489\nMax state: 0 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [11 | 200]\n---> Epoch: [11 | 200]\n---> Epoch: [11 | 200]\n---> Epoch: [11 | 200]\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > Max_state: 0, min_state: 0\n    > [Train]\tLoss:\t22.9496\n    > [Train]\tLoss:\t22.9496\n    > [Train]\tLoss:\t22.9496\n    > [Train]\tLoss:\t22.9496\n    > [Test ]\tLoss:\t4.8077\tAcc:\t16.5700\n    > [Test ]\tLoss:\t4.8077\tAcc:\t16.5700\n    > [Test ]\tLoss:\t4.8077\tAcc:\t16.5700\n    > [Test ]\tLoss:\t4.8077\tAcc:\t16.5700\n    > [Stats]\tMany:\t0.3903\tMedium:\t0.0817\tFew:\t0.0017\n    > [Stats]\tMany:\t0.3903\tMedium:\t0.0817\tFew:\t0.0017\n    > [Stats]\tMany:\t0.3903\tMedium:\t0.0817\tFew:\t0.0017\n    > [Stats]\tMany:\t0.3903\tMedium:\t0.0817\tFew:\t0.0017\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.708157864332785\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [12 | 200]\n---> Epoch: [12 | 200]\n---> Epoch: [12 | 200]\n---> Epoch: [12 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t22.6665\n    > [Train]\tLoss:\t22.6665\n    > [Train]\tLoss:\t22.6665\n    > [Train]\tLoss:\t22.6665\n    > [Test ]\tLoss:\t5.0748\tAcc:\t14.2200\n    > [Test ]\tLoss:\t5.0748\tAcc:\t14.2200\n    > [Test ]\tLoss:\t5.0748\tAcc:\t14.2200\n    > [Test ]\tLoss:\t5.0748\tAcc:\t14.2200\n    > [Stats]\tMany:\t0.3360\tMedium:\t0.0623\tFew:\t0.0093\n    > [Stats]\tMany:\t0.3360\tMedium:\t0.0623\tFew:\t0.0093\n    > [Stats]\tMany:\t0.3360\tMedium:\t0.0623\tFew:\t0.0093\n    > [Stats]\tMany:\t0.3360\tMedium:\t0.0623\tFew:\t0.0093\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Best ]\tAcc:\t17.5800\tMany:\t40.8286\tMedium:\t8.9143\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.818820127148088\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [13 | 200]\n---> Epoch: [13 | 200]\n---> Epoch: [13 | 200]\n---> Epoch: [13 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t22.1244\n    > [Train]\tLoss:\t22.1244\n    > [Train]\tLoss:\t22.1244\n    > [Train]\tLoss:\t22.1244\n    > [Test ]\tLoss:\t4.5187\tAcc:\t19.4900\n    > [Test ]\tLoss:\t4.5187\tAcc:\t19.4900\n    > [Test ]\tLoss:\t4.5187\tAcc:\t19.4900\n    > [Test ]\tLoss:\t4.5187\tAcc:\t19.4900\n    > [Stats]\tMany:\t0.4337\tMedium:\t0.1174\tFew:\t0.0067\n    > [Stats]\tMany:\t0.4337\tMedium:\t0.1174\tFew:\t0.0067\n    > [Stats]\tMany:\t0.4337\tMedium:\t0.1174\tFew:\t0.0067\n    > [Stats]\tMany:\t0.4337\tMedium:\t0.1174\tFew:\t0.0067\n    > [Best ]\tAcc:\t19.4900\tMany:\t43.3714\tMedium:\t11.7429\tFew:\t0.6667\n    > [Best ]\tAcc:\t19.4900\tMany:\t43.3714\tMedium:\t11.7429\tFew:\t0.6667\n    > [Best ]\tAcc:\t19.4900\tMany:\t43.3714\tMedium:\t11.7429\tFew:\t0.6667\n    > [Best ]\tAcc:\t19.4900\tMany:\t43.3714\tMedium:\t11.7429\tFew:\t0.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.842551562215583\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [14 | 200]\n---> Epoch: [14 | 200]\n---> Epoch: [14 | 200]\n---> Epoch: [14 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t21.8677\n    > [Train]\tLoss:\t21.8677\n    > [Train]\tLoss:\t21.8677\n    > [Train]\tLoss:\t21.8677\n    > [Test ]\tLoss:\t4.5141\tAcc:\t19.8100\n    > [Test ]\tLoss:\t4.5141\tAcc:\t19.8100\n    > [Test ]\tLoss:\t4.5141\tAcc:\t19.8100\n    > [Test ]\tLoss:\t4.5141\tAcc:\t19.8100\n    > [Stats]\tMany:\t0.4560\tMedium:\t0.1046\tFew:\t0.0063\n    > [Stats]\tMany:\t0.4560\tMedium:\t0.1046\tFew:\t0.0063\n    > [Stats]\tMany:\t0.4560\tMedium:\t0.1046\tFew:\t0.0063\n    > [Stats]\tMany:\t0.4560\tMedium:\t0.1046\tFew:\t0.0063\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.960119929046659\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [15 | 200]\n---> Epoch: [15 | 200]\n---> Epoch: [15 | 200]\n---> Epoch: [15 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t21.3269\n    > [Train]\tLoss:\t21.3269\n    > [Train]\tLoss:\t21.3269\n    > [Train]\tLoss:\t21.3269\n    > [Test ]\tLoss:\t5.2734\tAcc:\t15.1500\n    > [Test ]\tLoss:\t5.2734\tAcc:\t15.1500\n    > [Test ]\tLoss:\t5.2734\tAcc:\t15.1500\n    > [Test ]\tLoss:\t5.2734\tAcc:\t15.1500\n    > [Stats]\tMany:\t0.3520\tMedium:\t0.0709\tFew:\t0.0117\n    > [Stats]\tMany:\t0.3520\tMedium:\t0.0709\tFew:\t0.0117\n    > [Stats]\tMany:\t0.3520\tMedium:\t0.0709\tFew:\t0.0117\n    > [Stats]\tMany:\t0.3520\tMedium:\t0.0709\tFew:\t0.0117\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Best ]\tAcc:\t19.8100\tMany:\t45.6000\tMedium:\t10.4571\tFew:\t0.6333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.965604102961821\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [16 | 200]\n---> Epoch: [16 | 200]\n---> Epoch: [16 | 200]\n---> Epoch: [16 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t20.9468\n    > [Train]\tLoss:\t20.9468\n    > [Train]\tLoss:\t20.9468\n    > [Train]\tLoss:\t20.9468\n    > [Test ]\tLoss:\t4.4735\tAcc:\t20.1100\n    > [Test ]\tLoss:\t4.4735\tAcc:\t20.1100\n    > [Test ]\tLoss:\t4.4735\tAcc:\t20.1100\n    > [Test ]\tLoss:\t4.4735\tAcc:\t20.1100\n    > [Stats]\tMany:\t0.4686\tMedium:\t0.1020\tFew:\t0.0047\n    > [Stats]\tMany:\t0.4686\tMedium:\t0.1020\tFew:\t0.0047\n    > [Stats]\tMany:\t0.4686\tMedium:\t0.1020\tFew:\t0.0047\n    > [Stats]\tMany:\t0.4686\tMedium:\t0.1020\tFew:\t0.0047\n    > [Best ]\tAcc:\t20.1100\tMany:\t46.8571\tMedium:\t10.2000\tFew:\t0.4667\n    > [Best ]\tAcc:\t20.1100\tMany:\t46.8571\tMedium:\t10.2000\tFew:\t0.4667\n    > [Best ]\tAcc:\t20.1100\tMany:\t46.8571\tMedium:\t10.2000\tFew:\t0.4667\n    > [Best ]\tAcc:\t20.1100\tMany:\t46.8571\tMedium:\t10.2000\tFew:\t0.4667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.975066942900865\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [17 | 200]\n---> Epoch: [17 | 200]\n---> Epoch: [17 | 200]\n---> Epoch: [17 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t20.7322\n    > [Train]\tLoss:\t20.7322\n    > [Train]\tLoss:\t20.7322\n    > [Train]\tLoss:\t20.7322\n    > [Test ]\tLoss:\t4.4610\tAcc:\t22.4700\n    > [Test ]\tLoss:\t4.4610\tAcc:\t22.4700\n    > [Test ]\tLoss:\t4.4610\tAcc:\t22.4700\n    > [Test ]\tLoss:\t4.4610\tAcc:\t22.4700\n    > [Stats]\tMany:\t0.5006\tMedium:\t0.1317\tFew:\t0.0113\n    > [Stats]\tMany:\t0.5006\tMedium:\t0.1317\tFew:\t0.0113\n    > [Stats]\tMany:\t0.5006\tMedium:\t0.1317\tFew:\t0.0113\n    > [Stats]\tMany:\t0.5006\tMedium:\t0.1317\tFew:\t0.0113\n    > [Best ]\tAcc:\t22.4700\tMany:\t50.0571\tMedium:\t13.1714\tFew:\t1.1333\n    > [Best ]\tAcc:\t22.4700\tMany:\t50.0571\tMedium:\t13.1714\tFew:\t1.1333\n    > [Best ]\tAcc:\t22.4700\tMany:\t50.0571\tMedium:\t13.1714\tFew:\t1.1333\n    > [Best ]\tAcc:\t22.4700\tMany:\t50.0571\tMedium:\t13.1714\tFew:\t1.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.967752450003827\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [18 | 200]\n---> Epoch: [18 | 200]\n---> Epoch: [18 | 200]\n---> Epoch: [18 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t20.3980\n    > [Train]\tLoss:\t20.3980\n    > [Train]\tLoss:\t20.3980\n    > [Train]\tLoss:\t20.3980\n    > [Test ]\tLoss:\t4.2231\tAcc:\t22.7600\n    > [Test ]\tLoss:\t4.2231\tAcc:\t22.7600\n    > [Test ]\tLoss:\t4.2231\tAcc:\t22.7600\n    > [Test ]\tLoss:\t4.2231\tAcc:\t22.7600\n    > [Stats]\tMany:\t0.5000\tMedium:\t0.1394\tFew:\t0.0127\n    > [Stats]\tMany:\t0.5000\tMedium:\t0.1394\tFew:\t0.0127\n    > [Stats]\tMany:\t0.5000\tMedium:\t0.1394\tFew:\t0.0127\n    > [Stats]\tMany:\t0.5000\tMedium:\t0.1394\tFew:\t0.0127\n    > [Best ]\tAcc:\t22.7600\tMany:\t50.0000\tMedium:\t13.9429\tFew:\t1.2667\n    > [Best ]\tAcc:\t22.7600\tMany:\t50.0000\tMedium:\t13.9429\tFew:\t1.2667\n    > [Best ]\tAcc:\t22.7600\tMany:\t50.0000\tMedium:\t13.9429\tFew:\t1.2667\n    > [Best ]\tAcc:\t22.7600\tMany:\t50.0000\tMedium:\t13.9429\tFew:\t1.2667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.99330177730009\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [19 | 200]\n---> Epoch: [19 | 200]\n---> Epoch: [19 | 200]\n---> Epoch: [19 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t19.7665\n    > [Train]\tLoss:\t19.7665\n    > [Train]\tLoss:\t19.7665\n    > [Train]\tLoss:\t19.7665\n    > [Test ]\tLoss:\t4.3636\tAcc:\t24.3400\n    > [Test ]\tLoss:\t4.3636\tAcc:\t24.3400\n    > [Test ]\tLoss:\t4.3636\tAcc:\t24.3400\n    > [Test ]\tLoss:\t4.3636\tAcc:\t24.3400\n    > [Stats]\tMany:\t0.5374\tMedium:\t0.1500\tFew:\t0.0093\n    > [Stats]\tMany:\t0.5374\tMedium:\t0.1500\tFew:\t0.0093\n    > [Stats]\tMany:\t0.5374\tMedium:\t0.1500\tFew:\t0.0093\n    > [Stats]\tMany:\t0.5374\tMedium:\t0.1500\tFew:\t0.0093\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"15.00653899466142\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [20 | 200]\n---> Epoch: [20 | 200]\n---> Epoch: [20 | 200]\n---> Epoch: [20 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t19.5971\n    > [Train]\tLoss:\t19.5971\n    > [Train]\tLoss:\t19.5971\n    > [Train]\tLoss:\t19.5971\n    > [Test ]\tLoss:\t4.4295\tAcc:\t23.9400\n    > [Test ]\tLoss:\t4.4295\tAcc:\t23.9400\n    > [Test ]\tLoss:\t4.4295\tAcc:\t23.9400\n    > [Test ]\tLoss:\t4.4295\tAcc:\t23.9400\n    > [Stats]\tMany:\t0.5143\tMedium:\t0.1634\tFew:\t0.0073\n    > [Stats]\tMany:\t0.5143\tMedium:\t0.1634\tFew:\t0.0073\n    > [Stats]\tMany:\t0.5143\tMedium:\t0.1634\tFew:\t0.0073\n    > [Stats]\tMany:\t0.5143\tMedium:\t0.1634\tFew:\t0.0073\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"15.001834422407727\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [21 | 200]\n---> Epoch: [21 | 200]\n---> Epoch: [21 | 200]\n---> Epoch: [21 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t19.4955\n    > [Train]\tLoss:\t19.4955\n    > [Train]\tLoss:\t19.4955\n    > [Train]\tLoss:\t19.4955\n    > [Test ]\tLoss:\t4.4877\tAcc:\t22.4200\n    > [Test ]\tLoss:\t4.4877\tAcc:\t22.4200\n    > [Test ]\tLoss:\t4.4877\tAcc:\t22.4200\n    > [Test ]\tLoss:\t4.4877\tAcc:\t22.4200\n    > [Stats]\tMany:\t0.4840\tMedium:\t0.1517\tFew:\t0.0057\n    > [Stats]\tMany:\t0.4840\tMedium:\t0.1517\tFew:\t0.0057\n    > [Stats]\tMany:\t0.4840\tMedium:\t0.1517\tFew:\t0.0057\n    > [Stats]\tMany:\t0.4840\tMedium:\t0.1517\tFew:\t0.0057\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.991754157888012\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [22 | 200]\n---> Epoch: [22 | 200]\n---> Epoch: [22 | 200]\n---> Epoch: [22 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t19.0309\n    > [Train]\tLoss:\t19.0309\n    > [Train]\tLoss:\t19.0309\n    > [Train]\tLoss:\t19.0309\n    > [Test ]\tLoss:\t5.4099\tAcc:\t18.1500\n    > [Test ]\tLoss:\t5.4099\tAcc:\t18.1500\n    > [Test ]\tLoss:\t5.4099\tAcc:\t18.1500\n    > [Test ]\tLoss:\t5.4099\tAcc:\t18.1500\n    > [Stats]\tMany:\t0.4131\tMedium:\t0.0977\tFew:\t0.0090\n    > [Stats]\tMany:\t0.4131\tMedium:\t0.0977\tFew:\t0.0090\n    > [Stats]\tMany:\t0.4131\tMedium:\t0.0977\tFew:\t0.0090\n    > [Stats]\tMany:\t0.4131\tMedium:\t0.0977\tFew:\t0.0090\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Best ]\tAcc:\t24.3400\tMany:\t53.7429\tMedium:\t15.0000\tFew:\t0.9333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.897437669789515\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [23 | 200]\n---> Epoch: [23 | 200]\n---> Epoch: [23 | 200]\n---> Epoch: [23 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t18.6735\n    > [Train]\tLoss:\t18.6735\n    > [Train]\tLoss:\t18.6735\n    > [Train]\tLoss:\t18.6735\n    > [Test ]\tLoss:\t4.1472\tAcc:\t26.1400\n    > [Test ]\tLoss:\t4.1472\tAcc:\t26.1400\n    > [Test ]\tLoss:\t4.1472\tAcc:\t26.1400\n    > [Test ]\tLoss:\t4.1472\tAcc:\t26.1400\n    > [Stats]\tMany:\t0.5406\tMedium:\t0.1951\tFew:\t0.0130\n    > [Stats]\tMany:\t0.5406\tMedium:\t0.1951\tFew:\t0.0130\n    > [Stats]\tMany:\t0.5406\tMedium:\t0.1951\tFew:\t0.0130\n    > [Stats]\tMany:\t0.5406\tMedium:\t0.1951\tFew:\t0.0130\n    > [Best ]\tAcc:\t26.1400\tMany:\t54.0571\tMedium:\t19.5143\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.1400\tMany:\t54.0571\tMedium:\t19.5143\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.1400\tMany:\t54.0571\tMedium:\t19.5143\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.1400\tMany:\t54.0571\tMedium:\t19.5143\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.85931904115633\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [24 | 200]\n---> Epoch: [24 | 200]\n---> Epoch: [24 | 200]\n---> Epoch: [24 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t18.4741\n    > [Train]\tLoss:\t18.4741\n    > [Train]\tLoss:\t18.4741\n    > [Train]\tLoss:\t18.4741\n    > [Test ]\tLoss:\t4.1487\tAcc:\t26.3000\n    > [Test ]\tLoss:\t4.1487\tAcc:\t26.3000\n    > [Test ]\tLoss:\t4.1487\tAcc:\t26.3000\n    > [Test ]\tLoss:\t4.1487\tAcc:\t26.3000\n    > [Stats]\tMany:\t0.5449\tMedium:\t0.1991\tFew:\t0.0087\n    > [Stats]\tMany:\t0.5449\tMedium:\t0.1991\tFew:\t0.0087\n    > [Stats]\tMany:\t0.5449\tMedium:\t0.1991\tFew:\t0.0087\n    > [Stats]\tMany:\t0.5449\tMedium:\t0.1991\tFew:\t0.0087\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.818078726807544\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [25 | 200]\n---> Epoch: [25 | 200]\n---> Epoch: [25 | 200]\n---> Epoch: [25 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t18.1798\n    > [Train]\tLoss:\t18.1798\n    > [Train]\tLoss:\t18.1798\n    > [Train]\tLoss:\t18.1798\n    > [Test ]\tLoss:\t4.4696\tAcc:\t24.6500\n    > [Test ]\tLoss:\t4.4696\tAcc:\t24.6500\n    > [Test ]\tLoss:\t4.4696\tAcc:\t24.6500\n    > [Test ]\tLoss:\t4.4696\tAcc:\t24.6500\n    > [Stats]\tMany:\t0.5151\tMedium:\t0.1849\tFew:\t0.0050\n    > [Stats]\tMany:\t0.5151\tMedium:\t0.1849\tFew:\t0.0050\n    > [Stats]\tMany:\t0.5151\tMedium:\t0.1849\tFew:\t0.0050\n    > [Stats]\tMany:\t0.5151\tMedium:\t0.1849\tFew:\t0.0050\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.737203601871235\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [26 | 200]\n---> Epoch: [26 | 200]\n---> Epoch: [26 | 200]\n---> Epoch: [26 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t17.9337\n    > [Train]\tLoss:\t17.9337\n    > [Train]\tLoss:\t17.9337\n    > [Train]\tLoss:\t17.9337\n    > [Test ]\tLoss:\t4.5383\tAcc:\t24.2400\n    > [Test ]\tLoss:\t4.5383\tAcc:\t24.2400\n    > [Test ]\tLoss:\t4.5383\tAcc:\t24.2400\n    > [Test ]\tLoss:\t4.5383\tAcc:\t24.2400\n    > [Stats]\tMany:\t0.5177\tMedium:\t0.1714\tFew:\t0.0040\n    > [Stats]\tMany:\t0.5177\tMedium:\t0.1714\tFew:\t0.0040\n    > [Stats]\tMany:\t0.5177\tMedium:\t0.1714\tFew:\t0.0040\n    > [Stats]\tMany:\t0.5177\tMedium:\t0.1714\tFew:\t0.0040\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Best ]\tAcc:\t26.3000\tMany:\t54.4857\tMedium:\t19.9143\tFew:\t0.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.655431914907616\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [27 | 200]\n---> Epoch: [27 | 200]\n---> Epoch: [27 | 200]\n---> Epoch: [27 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t17.6210\n    > [Train]\tLoss:\t17.6210\n    > [Train]\tLoss:\t17.6210\n    > [Train]\tLoss:\t17.6210\n    > [Test ]\tLoss:\t4.0901\tAcc:\t27.4200\n    > [Test ]\tLoss:\t4.0901\tAcc:\t27.4200\n    > [Test ]\tLoss:\t4.0901\tAcc:\t27.4200\n    > [Test ]\tLoss:\t4.0901\tAcc:\t27.4200\n    > [Stats]\tMany:\t0.5626\tMedium:\t0.2006\tFew:\t0.0237\n    > [Stats]\tMany:\t0.5626\tMedium:\t0.2006\tFew:\t0.0237\n    > [Stats]\tMany:\t0.5626\tMedium:\t0.2006\tFew:\t0.0237\n    > [Stats]\tMany:\t0.5626\tMedium:\t0.2006\tFew:\t0.0237\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.651813859413776\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [28 | 200]\n---> Epoch: [28 | 200]\n---> Epoch: [28 | 200]\n---> Epoch: [28 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t17.9317\n    > [Train]\tLoss:\t17.9317\n    > [Train]\tLoss:\t17.9317\n    > [Train]\tLoss:\t17.9317\n    > [Test ]\tLoss:\t4.3841\tAcc:\t25.6100\n    > [Test ]\tLoss:\t4.3841\tAcc:\t25.6100\n    > [Test ]\tLoss:\t4.3841\tAcc:\t25.6100\n    > [Test ]\tLoss:\t4.3841\tAcc:\t25.6100\n    > [Stats]\tMany:\t0.5471\tMedium:\t0.1689\tFew:\t0.0183\n    > [Stats]\tMany:\t0.5471\tMedium:\t0.1689\tFew:\t0.0183\n    > [Stats]\tMany:\t0.5471\tMedium:\t0.1689\tFew:\t0.0183\n    > [Stats]\tMany:\t0.5471\tMedium:\t0.1689\tFew:\t0.0183\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Best ]\tAcc:\t27.4200\tMany:\t56.2571\tMedium:\t20.0571\tFew:\t2.3667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.566340153020583\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [29 | 200]\n---> Epoch: [29 | 200]\n---> Epoch: [29 | 200]\n---> Epoch: [29 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t16.9791\n    > [Train]\tLoss:\t16.9791\n    > [Train]\tLoss:\t16.9791\n    > [Train]\tLoss:\t16.9791\n    > [Test ]\tLoss:\t4.0658\tAcc:\t27.6400\n    > [Test ]\tLoss:\t4.0658\tAcc:\t27.6400\n    > [Test ]\tLoss:\t4.0658\tAcc:\t27.6400\n    > [Test ]\tLoss:\t4.0658\tAcc:\t27.6400\n    > [Stats]\tMany:\t0.5580\tMedium:\t0.2180\tFew:\t0.0160\n    > [Stats]\tMany:\t0.5580\tMedium:\t0.2180\tFew:\t0.0160\n    > [Stats]\tMany:\t0.5580\tMedium:\t0.2180\tFew:\t0.0160\n    > [Stats]\tMany:\t0.5580\tMedium:\t0.2180\tFew:\t0.0160\n    > [Best ]\tAcc:\t27.6400\tMany:\t55.8000\tMedium:\t21.8000\tFew:\t1.6000\n    > [Best ]\tAcc:\t27.6400\tMany:\t55.8000\tMedium:\t21.8000\tFew:\t1.6000\n    > [Best ]\tAcc:\t27.6400\tMany:\t55.8000\tMedium:\t21.8000\tFew:\t1.6000\n    > [Best ]\tAcc:\t27.6400\tMany:\t55.8000\tMedium:\t21.8000\tFew:\t1.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.437289152294172\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [30 | 200]\n---> Epoch: [30 | 200]\n---> Epoch: [30 | 200]\n---> Epoch: [30 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t16.9090\n    > [Train]\tLoss:\t16.9090\n    > [Train]\tLoss:\t16.9090\n    > [Train]\tLoss:\t16.9090\n    > [Test ]\tLoss:\t4.1454\tAcc:\t27.9400\n    > [Test ]\tLoss:\t4.1454\tAcc:\t27.9400\n    > [Test ]\tLoss:\t4.1454\tAcc:\t27.9400\n    > [Test ]\tLoss:\t4.1454\tAcc:\t27.9400\n    > [Stats]\tMany:\t0.5826\tMedium:\t0.1974\tFew:\t0.0213\n    > [Stats]\tMany:\t0.5826\tMedium:\t0.1974\tFew:\t0.0213\n    > [Stats]\tMany:\t0.5826\tMedium:\t0.1974\tFew:\t0.0213\n    > [Stats]\tMany:\t0.5826\tMedium:\t0.1974\tFew:\t0.0213\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.322335992809231\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [31 | 200]\n---> Epoch: [31 | 200]\n---> Epoch: [31 | 200]\n---> Epoch: [31 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.7340\n    > [Train]\tLoss:\t16.7340\n    > [Train]\tLoss:\t16.7340\n    > [Train]\tLoss:\t16.7340\n    > [Test ]\tLoss:\t4.3220\tAcc:\t27.3900\n    > [Test ]\tLoss:\t4.3220\tAcc:\t27.3900\n    > [Test ]\tLoss:\t4.3220\tAcc:\t27.3900\n    > [Test ]\tLoss:\t4.3220\tAcc:\t27.3900\n    > [Stats]\tMany:\t0.5709\tMedium:\t0.1954\tFew:\t0.0190\n    > [Stats]\tMany:\t0.5709\tMedium:\t0.1954\tFew:\t0.0190\n    > [Stats]\tMany:\t0.5709\tMedium:\t0.1954\tFew:\t0.0190\n    > [Stats]\tMany:\t0.5709\tMedium:\t0.1954\tFew:\t0.0190\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Best ]\tAcc:\t27.9400\tMany:\t58.2571\tMedium:\t19.7429\tFew:\t2.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.292035622704722\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [32 | 200]\n---> Epoch: [32 | 200]\n---> Epoch: [32 | 200]\n---> Epoch: [32 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t16.4977\n    > [Train]\tLoss:\t16.4977\n    > [Train]\tLoss:\t16.4977\n    > [Train]\tLoss:\t16.4977\n    > [Test ]\tLoss:\t3.9949\tAcc:\t28.3200\n    > [Test ]\tLoss:\t3.9949\tAcc:\t28.3200\n    > [Test ]\tLoss:\t3.9949\tAcc:\t28.3200\n    > [Test ]\tLoss:\t3.9949\tAcc:\t28.3200\n    > [Stats]\tMany:\t0.5777\tMedium:\t0.2163\tFew:\t0.0177\n    > [Stats]\tMany:\t0.5777\tMedium:\t0.2163\tFew:\t0.0177\n    > [Stats]\tMany:\t0.5777\tMedium:\t0.2163\tFew:\t0.0177\n    > [Stats]\tMany:\t0.5777\tMedium:\t0.2163\tFew:\t0.0177\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.215803930652589\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [33 | 200]\n---> Epoch: [33 | 200]\n---> Epoch: [33 | 200]\n---> Epoch: [33 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.4202\n    > [Train]\tLoss:\t16.4202\n    > [Train]\tLoss:\t16.4202\n    > [Train]\tLoss:\t16.4202\n    > [Test ]\tLoss:\t4.2541\tAcc:\t26.5500\n    > [Test ]\tLoss:\t4.2541\tAcc:\t26.5500\n    > [Test ]\tLoss:\t4.2541\tAcc:\t26.5500\n    > [Test ]\tLoss:\t4.2541\tAcc:\t26.5500\n    > [Stats]\tMany:\t0.5543\tMedium:\t0.1883\tFew:\t0.0187\n    > [Stats]\tMany:\t0.5543\tMedium:\t0.1883\tFew:\t0.0187\n    > [Stats]\tMany:\t0.5543\tMedium:\t0.1883\tFew:\t0.0187\n    > [Stats]\tMany:\t0.5543\tMedium:\t0.1883\tFew:\t0.0187\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.06244634904086\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [34 | 200]\n---> Epoch: [34 | 200]\n---> Epoch: [34 | 200]\n---> Epoch: [34 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t16.4741\n    > [Train]\tLoss:\t16.4741\n    > [Train]\tLoss:\t16.4741\n    > [Train]\tLoss:\t16.4741\n    > [Test ]\tLoss:\t4.5090\tAcc:\t24.9100\n    > [Test ]\tLoss:\t4.5090\tAcc:\t24.9100\n    > [Test ]\tLoss:\t4.5090\tAcc:\t24.9100\n    > [Test ]\tLoss:\t4.5090\tAcc:\t24.9100\n    > [Stats]\tMany:\t0.5420\tMedium:\t0.1609\tFew:\t0.0103\n    > [Stats]\tMany:\t0.5420\tMedium:\t0.1609\tFew:\t0.0103\n    > [Stats]\tMany:\t0.5420\tMedium:\t0.1609\tFew:\t0.0103\n    > [Stats]\tMany:\t0.5420\tMedium:\t0.1609\tFew:\t0.0103\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"14.002435393194434\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [35 | 200]\n---> Epoch: [35 | 200]\n---> Epoch: [35 | 200]\n---> Epoch: [35 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.9443\n    > [Train]\tLoss:\t15.9443\n    > [Train]\tLoss:\t15.9443\n    > [Train]\tLoss:\t15.9443\n    > [Test ]\tLoss:\t4.6001\tAcc:\t25.4400\n    > [Test ]\tLoss:\t4.6001\tAcc:\t25.4400\n    > [Test ]\tLoss:\t4.6001\tAcc:\t25.4400\n    > [Test ]\tLoss:\t4.6001\tAcc:\t25.4400\n    > [Stats]\tMany:\t0.5454\tMedium:\t0.1783\tFew:\t0.0037\n    > [Stats]\tMany:\t0.5454\tMedium:\t0.1783\tFew:\t0.0037\n    > [Stats]\tMany:\t0.5454\tMedium:\t0.1783\tFew:\t0.0037\n    > [Stats]\tMany:\t0.5454\tMedium:\t0.1783\tFew:\t0.0037\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Best ]\tAcc:\t28.3200\tMany:\t57.7714\tMedium:\t21.6286\tFew:\t1.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.928431963822721\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [36 | 200]\n---> Epoch: [36 | 200]\n---> Epoch: [36 | 200]\n---> Epoch: [36 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t15.9368\n    > [Train]\tLoss:\t15.9368\n    > [Train]\tLoss:\t15.9368\n    > [Train]\tLoss:\t15.9368\n    > [Test ]\tLoss:\t4.2540\tAcc:\t29.6000\n    > [Test ]\tLoss:\t4.2540\tAcc:\t29.6000\n    > [Test ]\tLoss:\t4.2540\tAcc:\t29.6000\n    > [Test ]\tLoss:\t4.2540\tAcc:\t29.6000\n    > [Stats]\tMany:\t0.5854\tMedium:\t0.2509\tFew:\t0.0110\n    > [Stats]\tMany:\t0.5854\tMedium:\t0.2509\tFew:\t0.0110\n    > [Stats]\tMany:\t0.5854\tMedium:\t0.2509\tFew:\t0.0110\n    > [Stats]\tMany:\t0.5854\tMedium:\t0.2509\tFew:\t0.0110\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.89304612677786\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [37 | 200]\n---> Epoch: [37 | 200]\n---> Epoch: [37 | 200]\n---> Epoch: [37 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.6500\n    > [Train]\tLoss:\t15.6500\n    > [Train]\tLoss:\t15.6500\n    > [Train]\tLoss:\t15.6500\n    > [Test ]\tLoss:\t4.2958\tAcc:\t29.1300\n    > [Test ]\tLoss:\t4.2958\tAcc:\t29.1300\n    > [Test ]\tLoss:\t4.2958\tAcc:\t29.1300\n    > [Test ]\tLoss:\t4.2958\tAcc:\t29.1300\n    > [Stats]\tMany:\t0.6171\tMedium:\t0.2023\tFew:\t0.0150\n    > [Stats]\tMany:\t0.6171\tMedium:\t0.2023\tFew:\t0.0150\n    > [Stats]\tMany:\t0.6171\tMedium:\t0.2023\tFew:\t0.0150\n    > [Stats]\tMany:\t0.6171\tMedium:\t0.2023\tFew:\t0.0150\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.792397360920864\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [38 | 200]\n---> Epoch: [38 | 200]\n---> Epoch: [38 | 200]\n---> Epoch: [38 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t15.9084\n    > [Train]\tLoss:\t15.9084\n    > [Train]\tLoss:\t15.9084\n    > [Train]\tLoss:\t15.9084\n    > [Test ]\tLoss:\t4.4099\tAcc:\t28.4100\n    > [Test ]\tLoss:\t4.4099\tAcc:\t28.4100\n    > [Test ]\tLoss:\t4.4099\tAcc:\t28.4100\n    > [Test ]\tLoss:\t4.4099\tAcc:\t28.4100\n    > [Stats]\tMany:\t0.5731\tMedium:\t0.2226\tFew:\t0.0187\n    > [Stats]\tMany:\t0.5731\tMedium:\t0.2226\tFew:\t0.0187\n    > [Stats]\tMany:\t0.5731\tMedium:\t0.2226\tFew:\t0.0187\n    > [Stats]\tMany:\t0.5731\tMedium:\t0.2226\tFew:\t0.0187\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Best ]\tAcc:\t29.6000\tMany:\t58.5429\tMedium:\t25.0857\tFew:\t1.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.709413831961179\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [39 | 200]\n---> Epoch: [39 | 200]\n---> Epoch: [39 | 200]\n---> Epoch: [39 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.2603\n    > [Train]\tLoss:\t16.2603\n    > [Train]\tLoss:\t16.2603\n    > [Train]\tLoss:\t16.2603\n    > [Test ]\tLoss:\t4.1038\tAcc:\t30.0300\n    > [Test ]\tLoss:\t4.1038\tAcc:\t30.0300\n    > [Test ]\tLoss:\t4.1038\tAcc:\t30.0300\n    > [Test ]\tLoss:\t4.1038\tAcc:\t30.0300\n    > [Stats]\tMany:\t0.5763\tMedium:\t0.2606\tFew:\t0.0247\n    > [Stats]\tMany:\t0.5763\tMedium:\t0.2606\tFew:\t0.0247\n    > [Stats]\tMany:\t0.5763\tMedium:\t0.2606\tFew:\t0.0247\n    > [Stats]\tMany:\t0.5763\tMedium:\t0.2606\tFew:\t0.0247\n    > [Best ]\tAcc:\t30.0300\tMany:\t57.6286\tMedium:\t26.0571\tFew:\t2.4667\n    > [Best ]\tAcc:\t30.0300\tMany:\t57.6286\tMedium:\t26.0571\tFew:\t2.4667\n    > [Best ]\tAcc:\t30.0300\tMany:\t57.6286\tMedium:\t26.0571\tFew:\t2.4667\n    > [Best ]\tAcc:\t30.0300\tMany:\t57.6286\tMedium:\t26.0571\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.738447203020176\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [40 | 200]\n---> Epoch: [40 | 200]\n---> Epoch: [40 | 200]\n---> Epoch: [40 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.4756\n    > [Train]\tLoss:\t15.4756\n    > [Train]\tLoss:\t15.4756\n    > [Train]\tLoss:\t15.4756\n    > [Test ]\tLoss:\t3.9982\tAcc:\t30.0300\n    > [Test ]\tLoss:\t3.9982\tAcc:\t30.0300\n    > [Test ]\tLoss:\t3.9982\tAcc:\t30.0300\n    > [Test ]\tLoss:\t3.9982\tAcc:\t30.0300\n    > [Stats]\tMany:\t0.5897\tMedium:\t0.2597\tFew:\t0.0100\n    > [Stats]\tMany:\t0.5897\tMedium:\t0.2597\tFew:\t0.0100\n    > [Stats]\tMany:\t0.5897\tMedium:\t0.2597\tFew:\t0.0100\n    > [Stats]\tMany:\t0.5897\tMedium:\t0.2597\tFew:\t0.0100\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.569516836251271\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [41 | 200]\n---> Epoch: [41 | 200]\n---> Epoch: [41 | 200]\n---> Epoch: [41 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.3553\n    > [Train]\tLoss:\t15.3553\n    > [Train]\tLoss:\t15.3553\n    > [Train]\tLoss:\t15.3553\n    > [Test ]\tLoss:\t4.2959\tAcc:\t29.2500\n    > [Test ]\tLoss:\t4.2959\tAcc:\t29.2500\n    > [Test ]\tLoss:\t4.2959\tAcc:\t29.2500\n    > [Test ]\tLoss:\t4.2959\tAcc:\t29.2500\n    > [Stats]\tMany:\t0.5846\tMedium:\t0.2391\tFew:\t0.0140\n    > [Stats]\tMany:\t0.5846\tMedium:\t0.2391\tFew:\t0.0140\n    > [Stats]\tMany:\t0.5846\tMedium:\t0.2391\tFew:\t0.0140\n    > [Stats]\tMany:\t0.5846\tMedium:\t0.2391\tFew:\t0.0140\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.528080474647709\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [42 | 200]\n---> Epoch: [42 | 200]\n---> Epoch: [42 | 200]\n---> Epoch: [42 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t15.1126\n    > [Train]\tLoss:\t15.1126\n    > [Train]\tLoss:\t15.1126\n    > [Train]\tLoss:\t15.1126\n    > [Test ]\tLoss:\t4.3095\tAcc:\t29.1900\n    > [Test ]\tLoss:\t4.3095\tAcc:\t29.1900\n    > [Test ]\tLoss:\t4.3095\tAcc:\t29.1900\n    > [Test ]\tLoss:\t4.3095\tAcc:\t29.1900\n    > [Stats]\tMany:\t0.5923\tMedium:\t0.2249\tFew:\t0.0197\n    > [Stats]\tMany:\t0.5923\tMedium:\t0.2249\tFew:\t0.0197\n    > [Stats]\tMany:\t0.5923\tMedium:\t0.2249\tFew:\t0.0197\n    > [Stats]\tMany:\t0.5923\tMedium:\t0.2249\tFew:\t0.0197\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Best ]\tAcc:\t30.0300\tMany:\t58.9714\tMedium:\t25.9714\tFew:\t1.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.479261401519244\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [43 | 200]\n---> Epoch: [43 | 200]\n---> Epoch: [43 | 200]\n---> Epoch: [43 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.0198\n    > [Train]\tLoss:\t15.0198\n    > [Train]\tLoss:\t15.0198\n    > [Train]\tLoss:\t15.0198\n    > [Test ]\tLoss:\t4.0237\tAcc:\t31.0200\n    > [Test ]\tLoss:\t4.0237\tAcc:\t31.0200\n    > [Test ]\tLoss:\t4.0237\tAcc:\t31.0200\n    > [Test ]\tLoss:\t4.0237\tAcc:\t31.0200\n    > [Stats]\tMany:\t0.6137\tMedium:\t0.2591\tFew:\t0.0157\n    > [Stats]\tMany:\t0.6137\tMedium:\t0.2591\tFew:\t0.0157\n    > [Stats]\tMany:\t0.6137\tMedium:\t0.2591\tFew:\t0.0157\n    > [Stats]\tMany:\t0.6137\tMedium:\t0.2591\tFew:\t0.0157\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.381426705971352\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [44 | 200]\n---> Epoch: [44 | 200]\n---> Epoch: [44 | 200]\n---> Epoch: [44 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t14.8166\n    > [Train]\tLoss:\t14.8166\n    > [Train]\tLoss:\t14.8166\n    > [Train]\tLoss:\t14.8166\n    > [Test ]\tLoss:\t4.6867\tAcc:\t27.1300\n    > [Test ]\tLoss:\t4.6867\tAcc:\t27.1300\n    > [Test ]\tLoss:\t4.6867\tAcc:\t27.1300\n    > [Test ]\tLoss:\t4.6867\tAcc:\t27.1300\n    > [Stats]\tMany:\t0.5643\tMedium:\t0.1963\tFew:\t0.0170\n    > [Stats]\tMany:\t0.5643\tMedium:\t0.1963\tFew:\t0.0170\n    > [Stats]\tMany:\t0.5643\tMedium:\t0.1963\tFew:\t0.0170\n    > [Stats]\tMany:\t0.5643\tMedium:\t0.1963\tFew:\t0.0170\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.354000246697655\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [45 | 200]\n---> Epoch: [45 | 200]\n---> Epoch: [45 | 200]\n---> Epoch: [45 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.0844\n    > [Train]\tLoss:\t15.0844\n    > [Train]\tLoss:\t15.0844\n    > [Train]\tLoss:\t15.0844\n    > [Test ]\tLoss:\t4.1936\tAcc:\t30.6200\n    > [Test ]\tLoss:\t4.1936\tAcc:\t30.6200\n    > [Test ]\tLoss:\t4.1936\tAcc:\t30.6200\n    > [Test ]\tLoss:\t4.1936\tAcc:\t30.6200\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2517\tFew:\t0.0123\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2517\tFew:\t0.0123\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2517\tFew:\t0.0123\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2517\tFew:\t0.0123\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.297477939433067\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [46 | 200]\n---> Epoch: [46 | 200]\n---> Epoch: [46 | 200]\n---> Epoch: [46 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t14.8876\n    > [Train]\tLoss:\t14.8876\n    > [Train]\tLoss:\t14.8876\n    > [Train]\tLoss:\t14.8876\n    > [Test ]\tLoss:\t4.2820\tAcc:\t29.6200\n    > [Test ]\tLoss:\t4.2820\tAcc:\t29.6200\n    > [Test ]\tLoss:\t4.2820\tAcc:\t29.6200\n    > [Test ]\tLoss:\t4.2820\tAcc:\t29.6200\n    > [Stats]\tMany:\t0.5963\tMedium:\t0.2371\tFew:\t0.0150\n    > [Stats]\tMany:\t0.5963\tMedium:\t0.2371\tFew:\t0.0150\n    > [Stats]\tMany:\t0.5963\tMedium:\t0.2371\tFew:\t0.0150\n    > [Stats]\tMany:\t0.5963\tMedium:\t0.2371\tFew:\t0.0150\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.229482937123606\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [47 | 200]\n---> Epoch: [47 | 200]\n---> Epoch: [47 | 200]\n---> Epoch: [47 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t14.5423\n    > [Train]\tLoss:\t14.5423\n    > [Train]\tLoss:\t14.5423\n    > [Train]\tLoss:\t14.5423\n    > [Test ]\tLoss:\t4.2820\tAcc:\t28.9700\n    > [Test ]\tLoss:\t4.2820\tAcc:\t28.9700\n    > [Test ]\tLoss:\t4.2820\tAcc:\t28.9700\n    > [Test ]\tLoss:\t4.2820\tAcc:\t28.9700\n    > [Stats]\tMany:\t0.5869\tMedium:\t0.2269\tFew:\t0.0163\n    > [Stats]\tMany:\t0.5869\tMedium:\t0.2269\tFew:\t0.0163\n    > [Stats]\tMany:\t0.5869\tMedium:\t0.2269\tFew:\t0.0163\n    > [Stats]\tMany:\t0.5869\tMedium:\t0.2269\tFew:\t0.0163\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.21088567110144\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [48 | 200]\n---> Epoch: [48 | 200]\n---> Epoch: [48 | 200]\n---> Epoch: [48 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t14.4353\n    > [Train]\tLoss:\t14.4353\n    > [Train]\tLoss:\t14.4353\n    > [Train]\tLoss:\t14.4353\n    > [Test ]\tLoss:\t4.1706\tAcc:\t30.6100\n    > [Test ]\tLoss:\t4.1706\tAcc:\t30.6100\n    > [Test ]\tLoss:\t4.1706\tAcc:\t30.6100\n    > [Test ]\tLoss:\t4.1706\tAcc:\t30.6100\n    > [Stats]\tMany:\t0.6131\tMedium:\t0.2489\tFew:\t0.0147\n    > [Stats]\tMany:\t0.6131\tMedium:\t0.2489\tFew:\t0.0147\n    > [Stats]\tMany:\t0.6131\tMedium:\t0.2489\tFew:\t0.0147\n    > [Stats]\tMany:\t0.6131\tMedium:\t0.2489\tFew:\t0.0147\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Best ]\tAcc:\t31.0200\tMany:\t61.3714\tMedium:\t25.9143\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.048248371211091\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [49 | 200]\n---> Epoch: [49 | 200]\n---> Epoch: [49 | 200]\n---> Epoch: [49 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t14.5676\n    > [Train]\tLoss:\t14.5676\n    > [Train]\tLoss:\t14.5676\n    > [Train]\tLoss:\t14.5676\n    > [Test ]\tLoss:\t4.0509\tAcc:\t32.0700\n    > [Test ]\tLoss:\t4.0509\tAcc:\t32.0700\n    > [Test ]\tLoss:\t4.0509\tAcc:\t32.0700\n    > [Test ]\tLoss:\t4.0509\tAcc:\t32.0700\n    > [Stats]\tMany:\t0.6329\tMedium:\t0.2674\tFew:\t0.0187\n    > [Stats]\tMany:\t0.6329\tMedium:\t0.2674\tFew:\t0.0187\n    > [Stats]\tMany:\t0.6329\tMedium:\t0.2674\tFew:\t0.0187\n    > [Stats]\tMany:\t0.6329\tMedium:\t0.2674\tFew:\t0.0187\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"13.00939760114946\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [50 | 200]\n---> Epoch: [50 | 200]\n---> Epoch: [50 | 200]\n---> Epoch: [50 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t14.0896\n    > [Train]\tLoss:\t14.0896\n    > [Train]\tLoss:\t14.0896\n    > [Train]\tLoss:\t14.0896\n    > [Test ]\tLoss:\t4.1659\tAcc:\t31.4400\n    > [Test ]\tLoss:\t4.1659\tAcc:\t31.4400\n    > [Test ]\tLoss:\t4.1659\tAcc:\t31.4400\n    > [Test ]\tLoss:\t4.1659\tAcc:\t31.4400\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.2534\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.2534\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.2534\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.2534\tFew:\t0.0227\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.906278500145232\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [51 | 200]\n---> Epoch: [51 | 200]\n---> Epoch: [51 | 200]\n---> Epoch: [51 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t14.0054\n    > [Train]\tLoss:\t14.0054\n    > [Train]\tLoss:\t14.0054\n    > [Train]\tLoss:\t14.0054\n    > [Test ]\tLoss:\t4.4872\tAcc:\t30.5300\n    > [Test ]\tLoss:\t4.4872\tAcc:\t30.5300\n    > [Test ]\tLoss:\t4.4872\tAcc:\t30.5300\n    > [Test ]\tLoss:\t4.4872\tAcc:\t30.5300\n    > [Stats]\tMany:\t0.5917\tMedium:\t0.2700\tFew:\t0.0123\n    > [Stats]\tMany:\t0.5917\tMedium:\t0.2700\tFew:\t0.0123\n    > [Stats]\tMany:\t0.5917\tMedium:\t0.2700\tFew:\t0.0123\n    > [Stats]\tMany:\t0.5917\tMedium:\t0.2700\tFew:\t0.0123\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.836379980811751\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [52 | 200]\n---> Epoch: [52 | 200]\n---> Epoch: [52 | 200]\n---> Epoch: [52 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t14.3530\n    > [Train]\tLoss:\t14.3530\n    > [Train]\tLoss:\t14.3530\n    > [Train]\tLoss:\t14.3530\n    > [Test ]\tLoss:\t4.3120\tAcc:\t29.7900\n    > [Test ]\tLoss:\t4.3120\tAcc:\t29.7900\n    > [Test ]\tLoss:\t4.3120\tAcc:\t29.7900\n    > [Test ]\tLoss:\t4.3120\tAcc:\t29.7900\n    > [Stats]\tMany:\t0.5914\tMedium:\t0.2457\tFew:\t0.0163\n    > [Stats]\tMany:\t0.5914\tMedium:\t0.2457\tFew:\t0.0163\n    > [Stats]\tMany:\t0.5914\tMedium:\t0.2457\tFew:\t0.0163\n    > [Stats]\tMany:\t0.5914\tMedium:\t0.2457\tFew:\t0.0163\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Best ]\tAcc:\t32.0700\tMany:\t63.2857\tMedium:\t26.7429\tFew:\t1.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.76355407663721\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [53 | 200]\n---> Epoch: [53 | 200]\n---> Epoch: [53 | 200]\n---> Epoch: [53 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.5768\n    > [Train]\tLoss:\t13.5768\n    > [Train]\tLoss:\t13.5768\n    > [Train]\tLoss:\t13.5768\n    > [Test ]\tLoss:\t4.0306\tAcc:\t32.5600\n    > [Test ]\tLoss:\t4.0306\tAcc:\t32.5600\n    > [Test ]\tLoss:\t4.0306\tAcc:\t32.5600\n    > [Test ]\tLoss:\t4.0306\tAcc:\t32.5600\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2823\tFew:\t0.0200\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2823\tFew:\t0.0200\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2823\tFew:\t0.0200\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2823\tFew:\t0.0200\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.723989216507679\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [54 | 200]\n---> Epoch: [54 | 200]\n---> Epoch: [54 | 200]\n---> Epoch: [54 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t13.7616\n    > [Train]\tLoss:\t13.7616\n    > [Train]\tLoss:\t13.7616\n    > [Train]\tLoss:\t13.7616\n    > [Test ]\tLoss:\t4.1751\tAcc:\t31.8900\n    > [Test ]\tLoss:\t4.1751\tAcc:\t31.8900\n    > [Test ]\tLoss:\t4.1751\tAcc:\t31.8900\n    > [Test ]\tLoss:\t4.1751\tAcc:\t31.8900\n    > [Stats]\tMany:\t0.6283\tMedium:\t0.2649\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6283\tMedium:\t0.2649\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6283\tMedium:\t0.2649\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6283\tMedium:\t0.2649\tFew:\t0.0210\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Best ]\tAcc:\t32.5600\tMany:\t63.0857\tMedium:\t28.2286\tFew:\t2.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.680443640374964\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [55 | 200]\n---> Epoch: [55 | 200]\n---> Epoch: [55 | 200]\n---> Epoch: [55 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.5760\n    > [Train]\tLoss:\t13.5760\n    > [Train]\tLoss:\t13.5760\n    > [Train]\tLoss:\t13.5760\n    > [Test ]\tLoss:\t3.8085\tAcc:\t34.0500\n    > [Test ]\tLoss:\t3.8085\tAcc:\t34.0500\n    > [Test ]\tLoss:\t3.8085\tAcc:\t34.0500\n    > [Test ]\tLoss:\t3.8085\tAcc:\t34.0500\n    > [Stats]\tMany:\t0.6297\tMedium:\t0.3186\tFew:\t0.0287\n    > [Stats]\tMany:\t0.6297\tMedium:\t0.3186\tFew:\t0.0287\n    > [Stats]\tMany:\t0.6297\tMedium:\t0.3186\tFew:\t0.0287\n    > [Stats]\tMany:\t0.6297\tMedium:\t0.3186\tFew:\t0.0287\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.67055468798702\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [56 | 200]\n---> Epoch: [56 | 200]\n---> Epoch: [56 | 200]\n---> Epoch: [56 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t13.6326\n    > [Train]\tLoss:\t13.6326\n    > [Train]\tLoss:\t13.6326\n    > [Train]\tLoss:\t13.6326\n    > [Test ]\tLoss:\t4.3215\tAcc:\t30.9400\n    > [Test ]\tLoss:\t4.3215\tAcc:\t30.9400\n    > [Test ]\tLoss:\t4.3215\tAcc:\t30.9400\n    > [Test ]\tLoss:\t4.3215\tAcc:\t30.9400\n    > [Stats]\tMany:\t0.6094\tMedium:\t0.2569\tFew:\t0.0207\n    > [Stats]\tMany:\t0.6094\tMedium:\t0.2569\tFew:\t0.0207\n    > [Stats]\tMany:\t0.6094\tMedium:\t0.2569\tFew:\t0.0207\n    > [Stats]\tMany:\t0.6094\tMedium:\t0.2569\tFew:\t0.0207\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.650355332954472\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [57 | 200]\n---> Epoch: [57 | 200]\n---> Epoch: [57 | 200]\n---> Epoch: [57 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.5951\n    > [Train]\tLoss:\t13.5951\n    > [Train]\tLoss:\t13.5951\n    > [Train]\tLoss:\t13.5951\n    > [Test ]\tLoss:\t3.9828\tAcc:\t32.5300\n    > [Test ]\tLoss:\t3.9828\tAcc:\t32.5300\n    > [Test ]\tLoss:\t3.9828\tAcc:\t32.5300\n    > [Test ]\tLoss:\t3.9828\tAcc:\t32.5300\n    > [Stats]\tMany:\t0.6340\tMedium:\t0.2774\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6340\tMedium:\t0.2774\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6340\tMedium:\t0.2774\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6340\tMedium:\t0.2774\tFew:\t0.0210\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.559945104037217\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [58 | 200]\n---> Epoch: [58 | 200]\n---> Epoch: [58 | 200]\n---> Epoch: [58 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t13.2348\n    > [Train]\tLoss:\t13.2348\n    > [Train]\tLoss:\t13.2348\n    > [Train]\tLoss:\t13.2348\n    > [Test ]\tLoss:\t4.3858\tAcc:\t30.5300\n    > [Test ]\tLoss:\t4.3858\tAcc:\t30.5300\n    > [Test ]\tLoss:\t4.3858\tAcc:\t30.5300\n    > [Test ]\tLoss:\t4.3858\tAcc:\t30.5300\n    > [Stats]\tMany:\t0.6143\tMedium:\t0.2477\tFew:\t0.0120\n    > [Stats]\tMany:\t0.6143\tMedium:\t0.2477\tFew:\t0.0120\n    > [Stats]\tMany:\t0.6143\tMedium:\t0.2477\tFew:\t0.0120\n    > [Stats]\tMany:\t0.6143\tMedium:\t0.2477\tFew:\t0.0120\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.440598778830525\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [59 | 200]\n---> Epoch: [59 | 200]\n---> Epoch: [59 | 200]\n---> Epoch: [59 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.9598\n    > [Train]\tLoss:\t13.9598\n    > [Train]\tLoss:\t13.9598\n    > [Train]\tLoss:\t13.9598\n    > [Test ]\tLoss:\t4.2210\tAcc:\t32.3900\n    > [Test ]\tLoss:\t4.2210\tAcc:\t32.3900\n    > [Test ]\tLoss:\t4.2210\tAcc:\t32.3900\n    > [Test ]\tLoss:\t4.2210\tAcc:\t32.3900\n    > [Stats]\tMany:\t0.6149\tMedium:\t0.2906\tFew:\t0.0233\n    > [Stats]\tMany:\t0.6149\tMedium:\t0.2906\tFew:\t0.0233\n    > [Stats]\tMany:\t0.6149\tMedium:\t0.2906\tFew:\t0.0233\n    > [Stats]\tMany:\t0.6149\tMedium:\t0.2906\tFew:\t0.0233\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.479049336225593\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [60 | 200]\n---> Epoch: [60 | 200]\n---> Epoch: [60 | 200]\n---> Epoch: [60 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t12.8832\n    > [Train]\tLoss:\t12.8832\n    > [Train]\tLoss:\t12.8832\n    > [Train]\tLoss:\t12.8832\n    > [Test ]\tLoss:\t3.8850\tAcc:\t33.7000\n    > [Test ]\tLoss:\t3.8850\tAcc:\t33.7000\n    > [Test ]\tLoss:\t3.8850\tAcc:\t33.7000\n    > [Test ]\tLoss:\t3.8850\tAcc:\t33.7000\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.2966\tFew:\t0.0180\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.2966\tFew:\t0.0180\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.2966\tFew:\t0.0180\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.2966\tFew:\t0.0180\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Best ]\tAcc:\t34.0500\tMany:\t62.9714\tMedium:\t31.8571\tFew:\t2.8667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.317254930243337\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [61 | 200]\n---> Epoch: [61 | 200]\n---> Epoch: [61 | 200]\n---> Epoch: [61 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.7692\n    > [Train]\tLoss:\t13.7692\n    > [Train]\tLoss:\t13.7692\n    > [Train]\tLoss:\t13.7692\n    > [Test ]\tLoss:\t3.9141\tAcc:\t34.1000\n    > [Test ]\tLoss:\t3.9141\tAcc:\t34.1000\n    > [Test ]\tLoss:\t3.9141\tAcc:\t34.1000\n    > [Test ]\tLoss:\t3.9141\tAcc:\t34.1000\n    > [Stats]\tMany:\t0.6451\tMedium:\t0.3006\tFew:\t0.0333\n    > [Stats]\tMany:\t0.6451\tMedium:\t0.3006\tFew:\t0.0333\n    > [Stats]\tMany:\t0.6451\tMedium:\t0.3006\tFew:\t0.0333\n    > [Stats]\tMany:\t0.6451\tMedium:\t0.3006\tFew:\t0.0333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.283871646589564\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [62 | 200]\n---> Epoch: [62 | 200]\n---> Epoch: [62 | 200]\n---> Epoch: [62 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t13.2651\n    > [Train]\tLoss:\t13.2651\n    > [Train]\tLoss:\t13.2651\n    > [Train]\tLoss:\t13.2651\n    > [Test ]\tLoss:\t4.2922\tAcc:\t32.2000\n    > [Test ]\tLoss:\t4.2922\tAcc:\t32.2000\n    > [Test ]\tLoss:\t4.2922\tAcc:\t32.2000\n    > [Test ]\tLoss:\t4.2922\tAcc:\t32.2000\n    > [Stats]\tMany:\t0.6420\tMedium:\t0.2671\tFew:\t0.0127\n    > [Stats]\tMany:\t0.6420\tMedium:\t0.2671\tFew:\t0.0127\n    > [Stats]\tMany:\t0.6420\tMedium:\t0.2671\tFew:\t0.0127\n    > [Stats]\tMany:\t0.6420\tMedium:\t0.2671\tFew:\t0.0127\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.165903964476103\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [63 | 200]\n---> Epoch: [63 | 200]\n---> Epoch: [63 | 200]\n---> Epoch: [63 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.1451\n    > [Train]\tLoss:\t13.1451\n    > [Train]\tLoss:\t13.1451\n    > [Train]\tLoss:\t13.1451\n    > [Test ]\tLoss:\t4.2164\tAcc:\t32.5600\n    > [Test ]\tLoss:\t4.2164\tAcc:\t32.5600\n    > [Test ]\tLoss:\t4.2164\tAcc:\t32.5600\n    > [Test ]\tLoss:\t4.2164\tAcc:\t32.5600\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.2854\tFew:\t0.0240\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.2854\tFew:\t0.0240\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.2854\tFew:\t0.0240\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.2854\tFew:\t0.0240\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.151869198816005\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [64 | 200]\n---> Epoch: [64 | 200]\n---> Epoch: [64 | 200]\n---> Epoch: [64 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.9409\n    > [Train]\tLoss:\t12.9409\n    > [Train]\tLoss:\t12.9409\n    > [Train]\tLoss:\t12.9409\n    > [Test ]\tLoss:\t4.0815\tAcc:\t32.6900\n    > [Test ]\tLoss:\t4.0815\tAcc:\t32.6900\n    > [Test ]\tLoss:\t4.0815\tAcc:\t32.6900\n    > [Test ]\tLoss:\t4.0815\tAcc:\t32.6900\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.2789\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.2789\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.2789\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.2789\tFew:\t0.0213\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Best ]\tAcc:\t34.1000\tMany:\t64.5143\tMedium:\t30.0571\tFew:\t3.3333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.04211079931484\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [65 | 200]\n---> Epoch: [65 | 200]\n---> Epoch: [65 | 200]\n---> Epoch: [65 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.3499\n    > [Train]\tLoss:\t13.3499\n    > [Train]\tLoss:\t13.3499\n    > [Train]\tLoss:\t13.3499\n    > [Test ]\tLoss:\t3.9393\tAcc:\t34.9900\n    > [Test ]\tLoss:\t3.9393\tAcc:\t34.9900\n    > [Test ]\tLoss:\t3.9393\tAcc:\t34.9900\n    > [Test ]\tLoss:\t3.9393\tAcc:\t34.9900\n    > [Stats]\tMany:\t0.6434\tMedium:\t0.3320\tFew:\t0.0283\n    > [Stats]\tMany:\t0.6434\tMedium:\t0.3320\tFew:\t0.0283\n    > [Stats]\tMany:\t0.6434\tMedium:\t0.3320\tFew:\t0.0283\n    > [Stats]\tMany:\t0.6434\tMedium:\t0.3320\tFew:\t0.0283\n    > [Best ]\tAcc:\t34.9900\tMany:\t64.3428\tMedium:\t33.2000\tFew:\t2.8333\n    > [Best ]\tAcc:\t34.9900\tMany:\t64.3428\tMedium:\t33.2000\tFew:\t2.8333\n    > [Best ]\tAcc:\t34.9900\tMany:\t64.3428\tMedium:\t33.2000\tFew:\t2.8333\n    > [Best ]\tAcc:\t34.9900\tMany:\t64.3428\tMedium:\t33.2000\tFew:\t2.8333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"12.050122884085527\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [66 | 200]\n---> Epoch: [66 | 200]\n---> Epoch: [66 | 200]\n---> Epoch: [66 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t12.6968\n    > [Train]\tLoss:\t12.6968\n    > [Train]\tLoss:\t12.6968\n    > [Train]\tLoss:\t12.6968\n    > [Test ]\tLoss:\t3.8935\tAcc:\t35.2300\n    > [Test ]\tLoss:\t3.8935\tAcc:\t35.2300\n    > [Test ]\tLoss:\t3.8935\tAcc:\t35.2300\n    > [Test ]\tLoss:\t3.8935\tAcc:\t35.2300\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3046\tFew:\t0.0440\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3046\tFew:\t0.0440\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3046\tFew:\t0.0440\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3046\tFew:\t0.0440\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.881304817180098\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [67 | 200]\n---> Epoch: [67 | 200]\n---> Epoch: [67 | 200]\n---> Epoch: [67 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.3839\n    > [Train]\tLoss:\t12.3839\n    > [Train]\tLoss:\t12.3839\n    > [Train]\tLoss:\t12.3839\n    > [Test ]\tLoss:\t4.2349\tAcc:\t32.2500\n    > [Test ]\tLoss:\t4.2349\tAcc:\t32.2500\n    > [Test ]\tLoss:\t4.2349\tAcc:\t32.2500\n    > [Test ]\tLoss:\t4.2349\tAcc:\t32.2500\n    > [Stats]\tMany:\t0.6580\tMedium:\t0.2517\tFew:\t0.0137\n    > [Stats]\tMany:\t0.6580\tMedium:\t0.2517\tFew:\t0.0137\n    > [Stats]\tMany:\t0.6580\tMedium:\t0.2517\tFew:\t0.0137\n    > [Stats]\tMany:\t0.6580\tMedium:\t0.2517\tFew:\t0.0137\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.807905892493977\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [68 | 200]\n---> Epoch: [68 | 200]\n---> Epoch: [68 | 200]\n---> Epoch: [68 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t13.0416\n    > [Train]\tLoss:\t13.0416\n    > [Train]\tLoss:\t13.0416\n    > [Train]\tLoss:\t13.0416\n    > [Test ]\tLoss:\t3.8481\tAcc:\t34.7400\n    > [Test ]\tLoss:\t3.8481\tAcc:\t34.7400\n    > [Test ]\tLoss:\t3.8481\tAcc:\t34.7400\n    > [Test ]\tLoss:\t3.8481\tAcc:\t34.7400\n    > [Stats]\tMany:\t0.6400\tMedium:\t0.3254\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6400\tMedium:\t0.3254\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6400\tMedium:\t0.3254\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6400\tMedium:\t0.3254\tFew:\t0.0317\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.770702055774189\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [69 | 200]\n---> Epoch: [69 | 200]\n---> Epoch: [69 | 200]\n---> Epoch: [69 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.6858\n    > [Train]\tLoss:\t12.6858\n    > [Train]\tLoss:\t12.6858\n    > [Train]\tLoss:\t12.6858\n    > [Test ]\tLoss:\t4.7613\tAcc:\t30.4500\n    > [Test ]\tLoss:\t4.7613\tAcc:\t30.4500\n    > [Test ]\tLoss:\t4.7613\tAcc:\t30.4500\n    > [Test ]\tLoss:\t4.7613\tAcc:\t30.4500\n    > [Stats]\tMany:\t0.5703\tMedium:\t0.2846\tFew:\t0.0177\n    > [Stats]\tMany:\t0.5703\tMedium:\t0.2846\tFew:\t0.0177\n    > [Stats]\tMany:\t0.5703\tMedium:\t0.2846\tFew:\t0.0177\n    > [Stats]\tMany:\t0.5703\tMedium:\t0.2846\tFew:\t0.0177\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.666218303713801\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [70 | 200]\n---> Epoch: [70 | 200]\n---> Epoch: [70 | 200]\n---> Epoch: [70 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t12.2329\n    > [Train]\tLoss:\t12.2329\n    > [Train]\tLoss:\t12.2329\n    > [Train]\tLoss:\t12.2329\n    > [Test ]\tLoss:\t4.1575\tAcc:\t32.6300\n    > [Test ]\tLoss:\t4.1575\tAcc:\t32.6300\n    > [Test ]\tLoss:\t4.1575\tAcc:\t32.6300\n    > [Test ]\tLoss:\t4.1575\tAcc:\t32.6300\n    > [Stats]\tMany:\t0.6194\tMedium:\t0.2934\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6194\tMedium:\t0.2934\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6194\tMedium:\t0.2934\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6194\tMedium:\t0.2934\tFew:\t0.0227\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.54982310514862\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [71 | 200]\n---> Epoch: [71 | 200]\n---> Epoch: [71 | 200]\n---> Epoch: [71 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.3477\n    > [Train]\tLoss:\t12.3477\n    > [Train]\tLoss:\t12.3477\n    > [Train]\tLoss:\t12.3477\n    > [Test ]\tLoss:\t3.9962\tAcc:\t34.5000\n    > [Test ]\tLoss:\t3.9962\tAcc:\t34.5000\n    > [Test ]\tLoss:\t3.9962\tAcc:\t34.5000\n    > [Test ]\tLoss:\t3.9962\tAcc:\t34.5000\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3034\tFew:\t0.0363\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3034\tFew:\t0.0363\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3034\tFew:\t0.0363\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3034\tFew:\t0.0363\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.535613665433258\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [72 | 200]\n---> Epoch: [72 | 200]\n---> Epoch: [72 | 200]\n---> Epoch: [72 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.8209\n    > [Train]\tLoss:\t12.8209\n    > [Train]\tLoss:\t12.8209\n    > [Train]\tLoss:\t12.8209\n    > [Test ]\tLoss:\t3.9847\tAcc:\t34.8600\n    > [Test ]\tLoss:\t3.9847\tAcc:\t34.8600\n    > [Test ]\tLoss:\t3.9847\tAcc:\t34.8600\n    > [Test ]\tLoss:\t3.9847\tAcc:\t34.8600\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3180\tFew:\t0.0160\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3180\tFew:\t0.0160\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3180\tFew:\t0.0160\n    > [Stats]\tMany:\t0.6643\tMedium:\t0.3180\tFew:\t0.0160\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.470983874034948\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [73 | 200]\n---> Epoch: [73 | 200]\n---> Epoch: [73 | 200]\n---> Epoch: [73 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.4046\n    > [Train]\tLoss:\t12.4046\n    > [Train]\tLoss:\t12.4046\n    > [Train]\tLoss:\t12.4046\n    > [Test ]\tLoss:\t4.4556\tAcc:\t32.1600\n    > [Test ]\tLoss:\t4.4556\tAcc:\t32.1600\n    > [Test ]\tLoss:\t4.4556\tAcc:\t32.1600\n    > [Test ]\tLoss:\t4.4556\tAcc:\t32.1600\n    > [Stats]\tMany:\t0.6234\tMedium:\t0.2811\tFew:\t0.0167\n    > [Stats]\tMany:\t0.6234\tMedium:\t0.2811\tFew:\t0.0167\n    > [Stats]\tMany:\t0.6234\tMedium:\t0.2811\tFew:\t0.0167\n    > [Stats]\tMany:\t0.6234\tMedium:\t0.2811\tFew:\t0.0167\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.415446156122064\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [74 | 200]\n---> Epoch: [74 | 200]\n---> Epoch: [74 | 200]\n---> Epoch: [74 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.7466\n    > [Train]\tLoss:\t12.7466\n    > [Train]\tLoss:\t12.7466\n    > [Train]\tLoss:\t12.7466\n    > [Test ]\tLoss:\t4.1848\tAcc:\t33.5000\n    > [Test ]\tLoss:\t4.1848\tAcc:\t33.5000\n    > [Test ]\tLoss:\t4.1848\tAcc:\t33.5000\n    > [Test ]\tLoss:\t4.1848\tAcc:\t33.5000\n    > [Stats]\tMany:\t0.6374\tMedium:\t0.3069\tFew:\t0.0150\n    > [Stats]\tMany:\t0.6374\tMedium:\t0.3069\tFew:\t0.0150\n    > [Stats]\tMany:\t0.6374\tMedium:\t0.3069\tFew:\t0.0150\n    > [Stats]\tMany:\t0.6374\tMedium:\t0.3069\tFew:\t0.0150\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.341110993548948\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [75 | 200]\n---> Epoch: [75 | 200]\n---> Epoch: [75 | 200]\n---> Epoch: [75 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t12.0103\n    > [Train]\tLoss:\t12.0103\n    > [Train]\tLoss:\t12.0103\n    > [Train]\tLoss:\t12.0103\n    > [Test ]\tLoss:\t4.2597\tAcc:\t33.5200\n    > [Test ]\tLoss:\t4.2597\tAcc:\t33.5200\n    > [Test ]\tLoss:\t4.2597\tAcc:\t33.5200\n    > [Test ]\tLoss:\t4.2597\tAcc:\t33.5200\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.2989\tFew:\t0.0280\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.2989\tFew:\t0.0280\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.2989\tFew:\t0.0280\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.2989\tFew:\t0.0280\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.279557299861553\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [76 | 200]\n---> Epoch: [76 | 200]\n---> Epoch: [76 | 200]\n---> Epoch: [76 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t13.0121\n    > [Train]\tLoss:\t13.0121\n    > [Train]\tLoss:\t13.0121\n    > [Train]\tLoss:\t13.0121\n    > [Test ]\tLoss:\t4.1831\tAcc:\t33.6300\n    > [Test ]\tLoss:\t4.1831\tAcc:\t33.6300\n    > [Test ]\tLoss:\t4.1831\tAcc:\t33.6300\n    > [Test ]\tLoss:\t4.1831\tAcc:\t33.6300\n    > [Stats]\tMany:\t0.6331\tMedium:\t0.3040\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6331\tMedium:\t0.3040\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6331\tMedium:\t0.3040\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6331\tMedium:\t0.3040\tFew:\t0.0277\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.337466198530262\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [77 | 200]\n---> Epoch: [77 | 200]\n---> Epoch: [77 | 200]\n---> Epoch: [77 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.7234\n    > [Train]\tLoss:\t11.7234\n    > [Train]\tLoss:\t11.7234\n    > [Train]\tLoss:\t11.7234\n    > [Test ]\tLoss:\t4.1885\tAcc:\t34.0400\n    > [Test ]\tLoss:\t4.1885\tAcc:\t34.0400\n    > [Test ]\tLoss:\t4.1885\tAcc:\t34.0400\n    > [Test ]\tLoss:\t4.1885\tAcc:\t34.0400\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2960\tFew:\t0.0263\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2960\tFew:\t0.0263\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2960\tFew:\t0.0263\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2960\tFew:\t0.0263\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.282299268407458\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [78 | 200]\n---> Epoch: [78 | 200]\n---> Epoch: [78 | 200]\n---> Epoch: [78 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.3387\n    > [Train]\tLoss:\t12.3387\n    > [Train]\tLoss:\t12.3387\n    > [Train]\tLoss:\t12.3387\n    > [Test ]\tLoss:\t4.1601\tAcc:\t33.5700\n    > [Test ]\tLoss:\t4.1601\tAcc:\t33.5700\n    > [Test ]\tLoss:\t4.1601\tAcc:\t33.5700\n    > [Test ]\tLoss:\t4.1601\tAcc:\t33.5700\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2894\tFew:\t0.0183\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2894\tFew:\t0.0183\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2894\tFew:\t0.0183\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.2894\tFew:\t0.0183\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.272536841571206\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [79 | 200]\n---> Epoch: [79 | 200]\n---> Epoch: [79 | 200]\n---> Epoch: [79 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.7765\n    > [Train]\tLoss:\t11.7765\n    > [Train]\tLoss:\t11.7765\n    > [Train]\tLoss:\t11.7765\n    > [Test ]\tLoss:\t4.1702\tAcc:\t33.9100\n    > [Test ]\tLoss:\t4.1702\tAcc:\t33.9100\n    > [Test ]\tLoss:\t4.1702\tAcc:\t33.9100\n    > [Test ]\tLoss:\t4.1702\tAcc:\t33.9100\n    > [Stats]\tMany:\t0.6377\tMedium:\t0.3143\tFew:\t0.0197\n    > [Stats]\tMany:\t0.6377\tMedium:\t0.3143\tFew:\t0.0197\n    > [Stats]\tMany:\t0.6377\tMedium:\t0.3143\tFew:\t0.0197\n    > [Stats]\tMany:\t0.6377\tMedium:\t0.3143\tFew:\t0.0197\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.21515190934516\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [80 | 200]\n---> Epoch: [80 | 200]\n---> Epoch: [80 | 200]\n---> Epoch: [80 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t12.1500\n    > [Train]\tLoss:\t12.1500\n    > [Train]\tLoss:\t12.1500\n    > [Train]\tLoss:\t12.1500\n    > [Test ]\tLoss:\t4.0176\tAcc:\t34.6500\n    > [Test ]\tLoss:\t4.0176\tAcc:\t34.6500\n    > [Test ]\tLoss:\t4.0176\tAcc:\t34.6500\n    > [Test ]\tLoss:\t4.0176\tAcc:\t34.6500\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3071\tFew:\t0.0323\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3071\tFew:\t0.0323\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3071\tFew:\t0.0323\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3071\tFew:\t0.0323\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.198485304962482\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [81 | 200]\n---> Epoch: [81 | 200]\n---> Epoch: [81 | 200]\n---> Epoch: [81 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.7259\n    > [Train]\tLoss:\t11.7259\n    > [Train]\tLoss:\t11.7259\n    > [Train]\tLoss:\t11.7259\n    > [Test ]\tLoss:\t4.4187\tAcc:\t32.3900\n    > [Test ]\tLoss:\t4.4187\tAcc:\t32.3900\n    > [Test ]\tLoss:\t4.4187\tAcc:\t32.3900\n    > [Test ]\tLoss:\t4.4187\tAcc:\t32.3900\n    > [Stats]\tMany:\t0.6360\tMedium:\t0.2743\tFew:\t0.0177\n    > [Stats]\tMany:\t0.6360\tMedium:\t0.2743\tFew:\t0.0177\n    > [Stats]\tMany:\t0.6360\tMedium:\t0.2743\tFew:\t0.0177\n    > [Stats]\tMany:\t0.6360\tMedium:\t0.2743\tFew:\t0.0177\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.119678057768114\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [82 | 200]\n---> Epoch: [82 | 200]\n---> Epoch: [82 | 200]\n---> Epoch: [82 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t12.4916\n    > [Train]\tLoss:\t12.4916\n    > [Train]\tLoss:\t12.4916\n    > [Train]\tLoss:\t12.4916\n    > [Test ]\tLoss:\t4.2628\tAcc:\t33.5100\n    > [Test ]\tLoss:\t4.2628\tAcc:\t33.5100\n    > [Test ]\tLoss:\t4.2628\tAcc:\t33.5100\n    > [Test ]\tLoss:\t4.2628\tAcc:\t33.5100\n    > [Stats]\tMany:\t0.6506\tMedium:\t0.2929\tFew:\t0.0163\n    > [Stats]\tMany:\t0.6506\tMedium:\t0.2929\tFew:\t0.0163\n    > [Stats]\tMany:\t0.6506\tMedium:\t0.2929\tFew:\t0.0163\n    > [Stats]\tMany:\t0.6506\tMedium:\t0.2929\tFew:\t0.0163\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.09091098242151\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [83 | 200]\n---> Epoch: [83 | 200]\n---> Epoch: [83 | 200]\n---> Epoch: [83 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t12.1163\n    > [Train]\tLoss:\t12.1163\n    > [Train]\tLoss:\t12.1163\n    > [Train]\tLoss:\t12.1163\n    > [Test ]\tLoss:\t4.4582\tAcc:\t32.8400\n    > [Test ]\tLoss:\t4.4582\tAcc:\t32.8400\n    > [Test ]\tLoss:\t4.4582\tAcc:\t32.8400\n    > [Test ]\tLoss:\t4.4582\tAcc:\t32.8400\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2843\tFew:\t0.0270\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2843\tFew:\t0.0270\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2843\tFew:\t0.0270\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.2843\tFew:\t0.0270\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Best ]\tAcc:\t35.2300\tMany:\t66.4286\tMedium:\t30.4571\tFew:\t4.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.100632402820441\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [84 | 200]\n---> Epoch: [84 | 200]\n---> Epoch: [84 | 200]\n---> Epoch: [84 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.8771\n    > [Train]\tLoss:\t11.8771\n    > [Train]\tLoss:\t11.8771\n    > [Train]\tLoss:\t11.8771\n    > [Test ]\tLoss:\t3.8920\tAcc:\t36.1100\n    > [Test ]\tLoss:\t3.8920\tAcc:\t36.1100\n    > [Test ]\tLoss:\t3.8920\tAcc:\t36.1100\n    > [Test ]\tLoss:\t3.8920\tAcc:\t36.1100\n    > [Stats]\tMany:\t0.6623\tMedium:\t0.3514\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6623\tMedium:\t0.3514\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6623\tMedium:\t0.3514\tFew:\t0.0210\n    > [Stats]\tMany:\t0.6623\tMedium:\t0.3514\tFew:\t0.0210\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.034141425962076\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [85 | 200]\n---> Epoch: [85 | 200]\n---> Epoch: [85 | 200]\n---> Epoch: [85 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.6967\n    > [Train]\tLoss:\t11.6967\n    > [Train]\tLoss:\t11.6967\n    > [Train]\tLoss:\t11.6967\n    > [Test ]\tLoss:\t4.0524\tAcc:\t35.9200\n    > [Test ]\tLoss:\t4.0524\tAcc:\t35.9200\n    > [Test ]\tLoss:\t4.0524\tAcc:\t35.9200\n    > [Test ]\tLoss:\t4.0524\tAcc:\t35.9200\n    > [Stats]\tMany:\t0.6417\tMedium:\t0.3637\tFew:\t0.0243\n    > [Stats]\tMany:\t0.6417\tMedium:\t0.3637\tFew:\t0.0243\n    > [Stats]\tMany:\t0.6417\tMedium:\t0.3637\tFew:\t0.0243\n    > [Stats]\tMany:\t0.6417\tMedium:\t0.3637\tFew:\t0.0243\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"11.00664510611227\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [86 | 200]\n---> Epoch: [86 | 200]\n---> Epoch: [86 | 200]\n---> Epoch: [86 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t11.8265\n    > [Train]\tLoss:\t11.8265\n    > [Train]\tLoss:\t11.8265\n    > [Train]\tLoss:\t11.8265\n    > [Test ]\tLoss:\t4.1314\tAcc:\t34.1400\n    > [Test ]\tLoss:\t4.1314\tAcc:\t34.1400\n    > [Test ]\tLoss:\t4.1314\tAcc:\t34.1400\n    > [Test ]\tLoss:\t4.1314\tAcc:\t34.1400\n    > [Stats]\tMany:\t0.6577\tMedium:\t0.3014\tFew:\t0.0190\n    > [Stats]\tMany:\t0.6577\tMedium:\t0.3014\tFew:\t0.0190\n    > [Stats]\tMany:\t0.6577\tMedium:\t0.3014\tFew:\t0.0190\n    > [Stats]\tMany:\t0.6577\tMedium:\t0.3014\tFew:\t0.0190\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.909478337385968\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [87 | 200]\n---> Epoch: [87 | 200]\n---> Epoch: [87 | 200]\n---> Epoch: [87 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.6817\n    > [Train]\tLoss:\t11.6817\n    > [Train]\tLoss:\t11.6817\n    > [Train]\tLoss:\t11.6817\n    > [Test ]\tLoss:\t4.2819\tAcc:\t33.1600\n    > [Test ]\tLoss:\t4.2819\tAcc:\t33.1600\n    > [Test ]\tLoss:\t4.2819\tAcc:\t33.1600\n    > [Test ]\tLoss:\t4.2819\tAcc:\t33.1600\n    > [Stats]\tMany:\t0.6389\tMedium:\t0.2829\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6389\tMedium:\t0.2829\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6389\tMedium:\t0.2829\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6389\tMedium:\t0.2829\tFew:\t0.0300\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.869427398656438\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [88 | 200]\n---> Epoch: [88 | 200]\n---> Epoch: [88 | 200]\n---> Epoch: [88 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t11.6609\n    > [Train]\tLoss:\t11.6609\n    > [Train]\tLoss:\t11.6609\n    > [Train]\tLoss:\t11.6609\n    > [Test ]\tLoss:\t4.2403\tAcc:\t35.1700\n    > [Test ]\tLoss:\t4.2403\tAcc:\t35.1700\n    > [Test ]\tLoss:\t4.2403\tAcc:\t35.1700\n    > [Test ]\tLoss:\t4.2403\tAcc:\t35.1700\n    > [Stats]\tMany:\t0.6634\tMedium:\t0.3154\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6634\tMedium:\t0.3154\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6634\tMedium:\t0.3154\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6634\tMedium:\t0.3154\tFew:\t0.0303\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.746461730924493\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [89 | 200]\n---> Epoch: [89 | 200]\n---> Epoch: [89 | 200]\n---> Epoch: [89 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.5569\n    > [Train]\tLoss:\t11.5569\n    > [Train]\tLoss:\t11.5569\n    > [Train]\tLoss:\t11.5569\n    > [Test ]\tLoss:\t3.9577\tAcc:\t35.3300\n    > [Test ]\tLoss:\t3.9577\tAcc:\t35.3300\n    > [Test ]\tLoss:\t3.9577\tAcc:\t35.3300\n    > [Test ]\tLoss:\t3.9577\tAcc:\t35.3300\n    > [Stats]\tMany:\t0.6517\tMedium:\t0.3403\tFew:\t0.0203\n    > [Stats]\tMany:\t0.6517\tMedium:\t0.3403\tFew:\t0.0203\n    > [Stats]\tMany:\t0.6517\tMedium:\t0.3403\tFew:\t0.0203\n    > [Stats]\tMany:\t0.6517\tMedium:\t0.3403\tFew:\t0.0203\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.744034738556845\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [90 | 200]\n---> Epoch: [90 | 200]\n---> Epoch: [90 | 200]\n---> Epoch: [90 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.9183\n    > [Train]\tLoss:\t11.9183\n    > [Train]\tLoss:\t11.9183\n    > [Train]\tLoss:\t11.9183\n    > [Test ]\tLoss:\t4.1900\tAcc:\t34.7800\n    > [Test ]\tLoss:\t4.1900\tAcc:\t34.7800\n    > [Test ]\tLoss:\t4.1900\tAcc:\t34.7800\n    > [Test ]\tLoss:\t4.1900\tAcc:\t34.7800\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.3200\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.3200\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.3200\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.3200\tFew:\t0.0227\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.739737579345318\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [91 | 200]\n---> Epoch: [91 | 200]\n---> Epoch: [91 | 200]\n---> Epoch: [91 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t11.4495\n    > [Train]\tLoss:\t11.4495\n    > [Train]\tLoss:\t11.4495\n    > [Train]\tLoss:\t11.4495\n    > [Test ]\tLoss:\t4.2618\tAcc:\t34.5900\n    > [Test ]\tLoss:\t4.2618\tAcc:\t34.5900\n    > [Test ]\tLoss:\t4.2618\tAcc:\t34.5900\n    > [Test ]\tLoss:\t4.2618\tAcc:\t34.5900\n    > [Stats]\tMany:\t0.6537\tMedium:\t0.3160\tFew:\t0.0217\n    > [Stats]\tMany:\t0.6537\tMedium:\t0.3160\tFew:\t0.0217\n    > [Stats]\tMany:\t0.6537\tMedium:\t0.3160\tFew:\t0.0217\n    > [Stats]\tMany:\t0.6537\tMedium:\t0.3160\tFew:\t0.0217\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Best ]\tAcc:\t36.1100\tMany:\t66.2286\tMedium:\t35.1429\tFew:\t2.1000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.723846548353904\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [92 | 200]\n---> Epoch: [92 | 200]\n---> Epoch: [92 | 200]\n---> Epoch: [92 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.6413\n    > [Train]\tLoss:\t11.6413\n    > [Train]\tLoss:\t11.6413\n    > [Train]\tLoss:\t11.6413\n    > [Test ]\tLoss:\t4.0964\tAcc:\t36.7300\n    > [Test ]\tLoss:\t4.0964\tAcc:\t36.7300\n    > [Test ]\tLoss:\t4.0964\tAcc:\t36.7300\n    > [Test ]\tLoss:\t4.0964\tAcc:\t36.7300\n    > [Stats]\tMany:\t0.6669\tMedium:\t0.3534\tFew:\t0.0340\n    > [Stats]\tMany:\t0.6669\tMedium:\t0.3534\tFew:\t0.0340\n    > [Stats]\tMany:\t0.6669\tMedium:\t0.3534\tFew:\t0.0340\n    > [Stats]\tMany:\t0.6669\tMedium:\t0.3534\tFew:\t0.0340\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.687391291919415\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [93 | 200]\n---> Epoch: [93 | 200]\n---> Epoch: [93 | 200]\n---> Epoch: [93 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.4059\n    > [Train]\tLoss:\t11.4059\n    > [Train]\tLoss:\t11.4059\n    > [Train]\tLoss:\t11.4059\n    > [Test ]\tLoss:\t4.7953\tAcc:\t31.5600\n    > [Test ]\tLoss:\t4.7953\tAcc:\t31.5600\n    > [Test ]\tLoss:\t4.7953\tAcc:\t31.5600\n    > [Test ]\tLoss:\t4.7953\tAcc:\t31.5600\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2743\tFew:\t0.0173\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2743\tFew:\t0.0173\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2743\tFew:\t0.0173\n    > [Stats]\tMany:\t0.6126\tMedium:\t0.2743\tFew:\t0.0173\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.649379766515588\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [94 | 200]\n---> Epoch: [94 | 200]\n---> Epoch: [94 | 200]\n---> Epoch: [94 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t11.5828\n    > [Train]\tLoss:\t11.5828\n    > [Train]\tLoss:\t11.5828\n    > [Train]\tLoss:\t11.5828\n    > [Test ]\tLoss:\t4.2310\tAcc:\t34.9100\n    > [Test ]\tLoss:\t4.2310\tAcc:\t34.9100\n    > [Test ]\tLoss:\t4.2310\tAcc:\t34.9100\n    > [Test ]\tLoss:\t4.2310\tAcc:\t34.9100\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3340\tFew:\t0.0177\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3340\tFew:\t0.0177\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3340\tFew:\t0.0177\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3340\tFew:\t0.0177\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.614527393771082\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [95 | 200]\n---> Epoch: [95 | 200]\n---> Epoch: [95 | 200]\n---> Epoch: [95 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.7440\n    > [Train]\tLoss:\t11.7440\n    > [Train]\tLoss:\t11.7440\n    > [Train]\tLoss:\t11.7440\n    > [Test ]\tLoss:\t4.2836\tAcc:\t34.9100\n    > [Test ]\tLoss:\t4.2836\tAcc:\t34.9100\n    > [Test ]\tLoss:\t4.2836\tAcc:\t34.9100\n    > [Test ]\tLoss:\t4.2836\tAcc:\t34.9100\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3229\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3229\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3229\tFew:\t0.0227\n    > [Stats]\tMany:\t0.6551\tMedium:\t0.3229\tFew:\t0.0227\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.584836780622258\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [96 | 200]\n---> Epoch: [96 | 200]\n---> Epoch: [96 | 200]\n---> Epoch: [96 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t11.5148\n    > [Train]\tLoss:\t11.5148\n    > [Train]\tLoss:\t11.5148\n    > [Train]\tLoss:\t11.5148\n    > [Test ]\tLoss:\t4.5002\tAcc:\t32.8600\n    > [Test ]\tLoss:\t4.5002\tAcc:\t32.8600\n    > [Test ]\tLoss:\t4.5002\tAcc:\t32.8600\n    > [Test ]\tLoss:\t4.5002\tAcc:\t32.8600\n    > [Stats]\tMany:\t0.6109\tMedium:\t0.3069\tFew:\t0.0247\n    > [Stats]\tMany:\t0.6109\tMedium:\t0.3069\tFew:\t0.0247\n    > [Stats]\tMany:\t0.6109\tMedium:\t0.3069\tFew:\t0.0247\n    > [Stats]\tMany:\t0.6109\tMedium:\t0.3069\tFew:\t0.0247\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.541662437500412\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [97 | 200]\n---> Epoch: [97 | 200]\n---> Epoch: [97 | 200]\n---> Epoch: [97 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.7923\n    > [Train]\tLoss:\t10.7923\n    > [Train]\tLoss:\t10.7923\n    > [Train]\tLoss:\t10.7923\n    > [Test ]\tLoss:\t4.1714\tAcc:\t35.7000\n    > [Test ]\tLoss:\t4.1714\tAcc:\t35.7000\n    > [Test ]\tLoss:\t4.1714\tAcc:\t35.7000\n    > [Test ]\tLoss:\t4.1714\tAcc:\t35.7000\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3249\tFew:\t0.0310\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3249\tFew:\t0.0310\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3249\tFew:\t0.0310\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3249\tFew:\t0.0310\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.423921568138908\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [98 | 200]\n---> Epoch: [98 | 200]\n---> Epoch: [98 | 200]\n---> Epoch: [98 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.1847\n    > [Train]\tLoss:\t11.1847\n    > [Train]\tLoss:\t11.1847\n    > [Train]\tLoss:\t11.1847\n    > [Test ]\tLoss:\t4.1562\tAcc:\t36.1000\n    > [Test ]\tLoss:\t4.1562\tAcc:\t36.1000\n    > [Test ]\tLoss:\t4.1562\tAcc:\t36.1000\n    > [Test ]\tLoss:\t4.1562\tAcc:\t36.1000\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3309\tFew:\t0.0427\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3309\tFew:\t0.0427\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3309\tFew:\t0.0427\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3309\tFew:\t0.0427\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.336658241909538\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [99 | 200]\n---> Epoch: [99 | 200]\n---> Epoch: [99 | 200]\n---> Epoch: [99 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.4433\n    > [Train]\tLoss:\t11.4433\n    > [Train]\tLoss:\t11.4433\n    > [Train]\tLoss:\t11.4433\n    > [Test ]\tLoss:\t4.1090\tAcc:\t35.9200\n    > [Test ]\tLoss:\t4.1090\tAcc:\t35.9200\n    > [Test ]\tLoss:\t4.1090\tAcc:\t35.9200\n    > [Test ]\tLoss:\t4.1090\tAcc:\t35.9200\n    > [Stats]\tMany:\t0.6731\tMedium:\t0.3309\tFew:\t0.0260\n    > [Stats]\tMany:\t0.6731\tMedium:\t0.3309\tFew:\t0.0260\n    > [Stats]\tMany:\t0.6731\tMedium:\t0.3309\tFew:\t0.0260\n    > [Stats]\tMany:\t0.6731\tMedium:\t0.3309\tFew:\t0.0260\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.319909288227715\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [100 | 200]\n---> Epoch: [100 | 200]\n---> Epoch: [100 | 200]\n---> Epoch: [100 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.1919\n    > [Train]\tLoss:\t11.1919\n    > [Train]\tLoss:\t11.1919\n    > [Train]\tLoss:\t11.1919\n    > [Test ]\tLoss:\t4.1768\tAcc:\t35.5700\n    > [Test ]\tLoss:\t4.1768\tAcc:\t35.5700\n    > [Test ]\tLoss:\t4.1768\tAcc:\t35.5700\n    > [Test ]\tLoss:\t4.1768\tAcc:\t35.5700\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3246\tFew:\t0.0323\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3246\tFew:\t0.0323\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3246\tFew:\t0.0323\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3246\tFew:\t0.0323\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.264494542989617\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [101 | 200]\n---> Epoch: [101 | 200]\n---> Epoch: [101 | 200]\n---> Epoch: [101 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.4210\n    > [Train]\tLoss:\t11.4210\n    > [Train]\tLoss:\t11.4210\n    > [Train]\tLoss:\t11.4210\n    > [Test ]\tLoss:\t4.1512\tAcc:\t35.8500\n    > [Test ]\tLoss:\t4.1512\tAcc:\t35.8500\n    > [Test ]\tLoss:\t4.1512\tAcc:\t35.8500\n    > [Test ]\tLoss:\t4.1512\tAcc:\t35.8500\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3300\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3300\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3300\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6686\tMedium:\t0.3300\tFew:\t0.0300\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.246134363638888\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [102 | 200]\n---> Epoch: [102 | 200]\n---> Epoch: [102 | 200]\n---> Epoch: [102 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.1466\n    > [Train]\tLoss:\t11.1466\n    > [Train]\tLoss:\t11.1466\n    > [Train]\tLoss:\t11.1466\n    > [Test ]\tLoss:\t4.1300\tAcc:\t36.2400\n    > [Test ]\tLoss:\t4.1300\tAcc:\t36.2400\n    > [Test ]\tLoss:\t4.1300\tAcc:\t36.2400\n    > [Test ]\tLoss:\t4.1300\tAcc:\t36.2400\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.3280\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.3280\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.3280\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.3280\tFew:\t0.0277\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.24405026651963\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [103 | 200]\n---> Epoch: [103 | 200]\n---> Epoch: [103 | 200]\n---> Epoch: [103 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.1960\n    > [Train]\tLoss:\t11.1960\n    > [Train]\tLoss:\t11.1960\n    > [Train]\tLoss:\t11.1960\n    > [Test ]\tLoss:\t4.1440\tAcc:\t35.6300\n    > [Test ]\tLoss:\t4.1440\tAcc:\t35.6300\n    > [Test ]\tLoss:\t4.1440\tAcc:\t35.6300\n    > [Test ]\tLoss:\t4.1440\tAcc:\t35.6300\n    > [Stats]\tMany:\t0.6597\tMedium:\t0.3291\tFew:\t0.0340\n    > [Stats]\tMany:\t0.6597\tMedium:\t0.3291\tFew:\t0.0340\n    > [Stats]\tMany:\t0.6597\tMedium:\t0.3291\tFew:\t0.0340\n    > [Stats]\tMany:\t0.6597\tMedium:\t0.3291\tFew:\t0.0340\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.176179994877439\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [104 | 200]\n---> Epoch: [104 | 200]\n---> Epoch: [104 | 200]\n---> Epoch: [104 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.5071\n    > [Train]\tLoss:\t11.5071\n    > [Train]\tLoss:\t11.5071\n    > [Train]\tLoss:\t11.5071\n    > [Test ]\tLoss:\t4.3389\tAcc:\t34.8700\n    > [Test ]\tLoss:\t4.3389\tAcc:\t34.8700\n    > [Test ]\tLoss:\t4.3389\tAcc:\t34.8700\n    > [Test ]\tLoss:\t4.3389\tAcc:\t34.8700\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3246\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3246\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3246\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3246\tFew:\t0.0273\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.227074904391507\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [105 | 200]\n---> Epoch: [105 | 200]\n---> Epoch: [105 | 200]\n---> Epoch: [105 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.1353\n    > [Train]\tLoss:\t11.1353\n    > [Train]\tLoss:\t11.1353\n    > [Train]\tLoss:\t11.1353\n    > [Test ]\tLoss:\t4.0971\tAcc:\t36.6900\n    > [Test ]\tLoss:\t4.0971\tAcc:\t36.6900\n    > [Test ]\tLoss:\t4.0971\tAcc:\t36.6900\n    > [Test ]\tLoss:\t4.0971\tAcc:\t36.6900\n    > [Stats]\tMany:\t0.6497\tMedium:\t0.3629\tFew:\t0.0417\n    > [Stats]\tMany:\t0.6497\tMedium:\t0.3629\tFew:\t0.0417\n    > [Stats]\tMany:\t0.6497\tMedium:\t0.3629\tFew:\t0.0417\n    > [Stats]\tMany:\t0.6497\tMedium:\t0.3629\tFew:\t0.0417\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.272841848257363\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [106 | 200]\n---> Epoch: [106 | 200]\n---> Epoch: [106 | 200]\n---> Epoch: [106 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.3708\n    > [Train]\tLoss:\t11.3708\n    > [Train]\tLoss:\t11.3708\n    > [Train]\tLoss:\t11.3708\n    > [Test ]\tLoss:\t4.6594\tAcc:\t33.3300\n    > [Test ]\tLoss:\t4.6594\tAcc:\t33.3300\n    > [Test ]\tLoss:\t4.6594\tAcc:\t33.3300\n    > [Test ]\tLoss:\t4.6594\tAcc:\t33.3300\n    > [Stats]\tMany:\t0.6403\tMedium:\t0.2989\tFew:\t0.0153\n    > [Stats]\tMany:\t0.6403\tMedium:\t0.2989\tFew:\t0.0153\n    > [Stats]\tMany:\t0.6403\tMedium:\t0.2989\tFew:\t0.0153\n    > [Stats]\tMany:\t0.6403\tMedium:\t0.2989\tFew:\t0.0153\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Best ]\tAcc:\t36.7300\tMany:\t66.6857\tMedium:\t35.3429\tFew:\t3.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.169708277456651\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [107 | 200]\n---> Epoch: [107 | 200]\n---> Epoch: [107 | 200]\n---> Epoch: [107 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.0229\n    > [Train]\tLoss:\t11.0229\n    > [Train]\tLoss:\t11.0229\n    > [Train]\tLoss:\t11.0229\n    > [Test ]\tLoss:\t4.0633\tAcc:\t37.1400\n    > [Test ]\tLoss:\t4.0633\tAcc:\t37.1400\n    > [Test ]\tLoss:\t4.0633\tAcc:\t37.1400\n    > [Test ]\tLoss:\t4.0633\tAcc:\t37.1400\n    > [Stats]\tMany:\t0.6917\tMedium:\t0.3460\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6917\tMedium:\t0.3460\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6917\tMedium:\t0.3460\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6917\tMedium:\t0.3460\tFew:\t0.0273\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.12226740065128\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [108 | 200]\n---> Epoch: [108 | 200]\n---> Epoch: [108 | 200]\n---> Epoch: [108 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.5902\n    > [Train]\tLoss:\t11.5902\n    > [Train]\tLoss:\t11.5902\n    > [Train]\tLoss:\t11.5902\n    > [Test ]\tLoss:\t4.5347\tAcc:\t33.7100\n    > [Test ]\tLoss:\t4.5347\tAcc:\t33.7100\n    > [Test ]\tLoss:\t4.5347\tAcc:\t33.7100\n    > [Test ]\tLoss:\t4.5347\tAcc:\t33.7100\n    > [Stats]\tMany:\t0.6583\tMedium:\t0.2769\tFew:\t0.0327\n    > [Stats]\tMany:\t0.6583\tMedium:\t0.2769\tFew:\t0.0327\n    > [Stats]\tMany:\t0.6583\tMedium:\t0.2769\tFew:\t0.0327\n    > [Stats]\tMany:\t0.6583\tMedium:\t0.2769\tFew:\t0.0327\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.104065824597987\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [109 | 200]\n---> Epoch: [109 | 200]\n---> Epoch: [109 | 200]\n---> Epoch: [109 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.9790\n    > [Train]\tLoss:\t10.9790\n    > [Train]\tLoss:\t10.9790\n    > [Train]\tLoss:\t10.9790\n    > [Test ]\tLoss:\t4.3171\tAcc:\t34.5000\n    > [Test ]\tLoss:\t4.3171\tAcc:\t34.5000\n    > [Test ]\tLoss:\t4.3171\tAcc:\t34.5000\n    > [Test ]\tLoss:\t4.3171\tAcc:\t34.5000\n    > [Stats]\tMany:\t0.6414\tMedium:\t0.3183\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6414\tMedium:\t0.3183\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6414\tMedium:\t0.3183\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6414\tMedium:\t0.3183\tFew:\t0.0303\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.110393163833544\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [110 | 200]\n---> Epoch: [110 | 200]\n---> Epoch: [110 | 200]\n---> Epoch: [110 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.3572\n    > [Train]\tLoss:\t11.3572\n    > [Train]\tLoss:\t11.3572\n    > [Train]\tLoss:\t11.3572\n    > [Test ]\tLoss:\t4.2963\tAcc:\t33.8700\n    > [Test ]\tLoss:\t4.2963\tAcc:\t33.8700\n    > [Test ]\tLoss:\t4.2963\tAcc:\t33.8700\n    > [Test ]\tLoss:\t4.2963\tAcc:\t33.8700\n    > [Stats]\tMany:\t0.6443\tMedium:\t0.3043\tFew:\t0.0223\n    > [Stats]\tMany:\t0.6443\tMedium:\t0.3043\tFew:\t0.0223\n    > [Stats]\tMany:\t0.6443\tMedium:\t0.3043\tFew:\t0.0223\n    > [Stats]\tMany:\t0.6443\tMedium:\t0.3043\tFew:\t0.0223\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.038396346637565\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [111 | 200]\n---> Epoch: [111 | 200]\n---> Epoch: [111 | 200]\n---> Epoch: [111 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.3377\n    > [Train]\tLoss:\t10.3377\n    > [Train]\tLoss:\t10.3377\n    > [Train]\tLoss:\t10.3377\n    > [Test ]\tLoss:\t4.0941\tAcc:\t35.0300\n    > [Test ]\tLoss:\t4.0941\tAcc:\t35.0300\n    > [Test ]\tLoss:\t4.0941\tAcc:\t35.0300\n    > [Test ]\tLoss:\t4.0941\tAcc:\t35.0300\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3383\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3383\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3383\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3383\tFew:\t0.0300\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.035795820797425\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [112 | 200]\n---> Epoch: [112 | 200]\n---> Epoch: [112 | 200]\n---> Epoch: [112 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.8862\n    > [Train]\tLoss:\t10.8862\n    > [Train]\tLoss:\t10.8862\n    > [Train]\tLoss:\t10.8862\n    > [Test ]\tLoss:\t4.1489\tAcc:\t36.7700\n    > [Test ]\tLoss:\t4.1489\tAcc:\t36.7700\n    > [Test ]\tLoss:\t4.1489\tAcc:\t36.7700\n    > [Test ]\tLoss:\t4.1489\tAcc:\t36.7700\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.3471\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.3471\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.3471\tFew:\t0.0300\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.3471\tFew:\t0.0300\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.967301413119278\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [113 | 200]\n---> Epoch: [113 | 200]\n---> Epoch: [113 | 200]\n---> Epoch: [113 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.9093\n    > [Train]\tLoss:\t10.9093\n    > [Train]\tLoss:\t10.9093\n    > [Train]\tLoss:\t10.9093\n    > [Test ]\tLoss:\t4.3095\tAcc:\t35.5900\n    > [Test ]\tLoss:\t4.3095\tAcc:\t35.5900\n    > [Test ]\tLoss:\t4.3095\tAcc:\t35.5900\n    > [Test ]\tLoss:\t4.3095\tAcc:\t35.5900\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3400\tFew:\t0.0187\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3400\tFew:\t0.0187\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3400\tFew:\t0.0187\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3400\tFew:\t0.0187\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"10.003235115569451\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [114 | 200]\n---> Epoch: [114 | 200]\n---> Epoch: [114 | 200]\n---> Epoch: [114 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.9178\n    > [Train]\tLoss:\t10.9178\n    > [Train]\tLoss:\t10.9178\n    > [Train]\tLoss:\t10.9178\n    > [Test ]\tLoss:\t4.3449\tAcc:\t34.3800\n    > [Test ]\tLoss:\t4.3449\tAcc:\t34.3800\n    > [Test ]\tLoss:\t4.3449\tAcc:\t34.3800\n    > [Test ]\tLoss:\t4.3449\tAcc:\t34.3800\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3017\tFew:\t0.0230\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3017\tFew:\t0.0230\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3017\tFew:\t0.0230\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3017\tFew:\t0.0230\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Best ]\tAcc:\t37.1400\tMany:\t69.1714\tMedium:\t34.6000\tFew:\t2.7333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.959705206282619\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [115 | 200]\n---> Epoch: [115 | 200]\n---> Epoch: [115 | 200]\n---> Epoch: [115 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.5255\n    > [Train]\tLoss:\t10.5255\n    > [Train]\tLoss:\t10.5255\n    > [Train]\tLoss:\t10.5255\n    > [Test ]\tLoss:\t4.1073\tAcc:\t37.5300\n    > [Test ]\tLoss:\t4.1073\tAcc:\t37.5300\n    > [Test ]\tLoss:\t4.1073\tAcc:\t37.5300\n    > [Test ]\tLoss:\t4.1073\tAcc:\t37.5300\n    > [Stats]\tMany:\t0.6700\tMedium:\t0.3751\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6700\tMedium:\t0.3751\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6700\tMedium:\t0.3751\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6700\tMedium:\t0.3751\tFew:\t0.0317\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.90052240049546\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [116 | 200]\n---> Epoch: [116 | 200]\n---> Epoch: [116 | 200]\n---> Epoch: [116 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.3671\n    > [Train]\tLoss:\t11.3671\n    > [Train]\tLoss:\t11.3671\n    > [Train]\tLoss:\t11.3671\n    > [Test ]\tLoss:\t4.2975\tAcc:\t35.8400\n    > [Test ]\tLoss:\t4.2975\tAcc:\t35.8400\n    > [Test ]\tLoss:\t4.2975\tAcc:\t35.8400\n    > [Test ]\tLoss:\t4.2975\tAcc:\t35.8400\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3531\tFew:\t0.0197\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3531\tFew:\t0.0197\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3531\tFew:\t0.0197\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3531\tFew:\t0.0197\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.923529922003262\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [117 | 200]\n---> Epoch: [117 | 200]\n---> Epoch: [117 | 200]\n---> Epoch: [117 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.1175\n    > [Train]\tLoss:\t10.1175\n    > [Train]\tLoss:\t10.1175\n    > [Train]\tLoss:\t10.1175\n    > [Test ]\tLoss:\t4.4736\tAcc:\t34.3600\n    > [Test ]\tLoss:\t4.4736\tAcc:\t34.3600\n    > [Test ]\tLoss:\t4.4736\tAcc:\t34.3600\n    > [Test ]\tLoss:\t4.4736\tAcc:\t34.3600\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.2980\tFew:\t0.0337\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.2980\tFew:\t0.0337\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.2980\tFew:\t0.0337\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.2980\tFew:\t0.0337\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.839483250398288\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [118 | 200]\n---> Epoch: [118 | 200]\n---> Epoch: [118 | 200]\n---> Epoch: [118 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t10.4339\n    > [Train]\tLoss:\t10.4339\n    > [Train]\tLoss:\t10.4339\n    > [Train]\tLoss:\t10.4339\n    > [Test ]\tLoss:\t4.1859\tAcc:\t35.7600\n    > [Test ]\tLoss:\t4.1859\tAcc:\t35.7600\n    > [Test ]\tLoss:\t4.1859\tAcc:\t35.7600\n    > [Test ]\tLoss:\t4.1859\tAcc:\t35.7600\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3469\tFew:\t0.0253\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3469\tFew:\t0.0253\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3469\tFew:\t0.0253\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3469\tFew:\t0.0253\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.85058056707946\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [119 | 200]\n---> Epoch: [119 | 200]\n---> Epoch: [119 | 200]\n---> Epoch: [119 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.3186\n    > [Train]\tLoss:\t10.3186\n    > [Train]\tLoss:\t10.3186\n    > [Train]\tLoss:\t10.3186\n    > [Test ]\tLoss:\t4.1955\tAcc:\t36.1800\n    > [Test ]\tLoss:\t4.1955\tAcc:\t36.1800\n    > [Test ]\tLoss:\t4.1955\tAcc:\t36.1800\n    > [Test ]\tLoss:\t4.1955\tAcc:\t36.1800\n    > [Stats]\tMany:\t0.6666\tMedium:\t0.3469\tFew:\t0.0237\n    > [Stats]\tMany:\t0.6666\tMedium:\t0.3469\tFew:\t0.0237\n    > [Stats]\tMany:\t0.6666\tMedium:\t0.3469\tFew:\t0.0237\n    > [Stats]\tMany:\t0.6666\tMedium:\t0.3469\tFew:\t0.0237\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.826433436644074\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [120 | 200]\n---> Epoch: [120 | 200]\n---> Epoch: [120 | 200]\n---> Epoch: [120 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t11.0381\n    > [Train]\tLoss:\t11.0381\n    > [Train]\tLoss:\t11.0381\n    > [Train]\tLoss:\t11.0381\n    > [Test ]\tLoss:\t4.1884\tAcc:\t36.0600\n    > [Test ]\tLoss:\t4.1884\tAcc:\t36.0600\n    > [Test ]\tLoss:\t4.1884\tAcc:\t36.0600\n    > [Test ]\tLoss:\t4.1884\tAcc:\t36.0600\n    > [Stats]\tMany:\t0.6534\tMedium:\t0.3586\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6534\tMedium:\t0.3586\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6534\tMedium:\t0.3586\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6534\tMedium:\t0.3586\tFew:\t0.0213\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.838032722179923\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [121 | 200]\n---> Epoch: [121 | 200]\n---> Epoch: [121 | 200]\n---> Epoch: [121 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.6062\n    > [Train]\tLoss:\t10.6062\n    > [Train]\tLoss:\t10.6062\n    > [Train]\tLoss:\t10.6062\n    > [Test ]\tLoss:\t4.1479\tAcc:\t36.7900\n    > [Test ]\tLoss:\t4.1479\tAcc:\t36.7900\n    > [Test ]\tLoss:\t4.1479\tAcc:\t36.7900\n    > [Test ]\tLoss:\t4.1479\tAcc:\t36.7900\n    > [Stats]\tMany:\t0.6714\tMedium:\t0.3574\tFew:\t0.0260\n    > [Stats]\tMany:\t0.6714\tMedium:\t0.3574\tFew:\t0.0260\n    > [Stats]\tMany:\t0.6714\tMedium:\t0.3574\tFew:\t0.0260\n    > [Stats]\tMany:\t0.6714\tMedium:\t0.3574\tFew:\t0.0260\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.810382818298438\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [122 | 200]\n---> Epoch: [122 | 200]\n---> Epoch: [122 | 200]\n---> Epoch: [122 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.3322\n    > [Train]\tLoss:\t10.3322\n    > [Train]\tLoss:\t10.3322\n    > [Train]\tLoss:\t10.3322\n    > [Test ]\tLoss:\t4.3138\tAcc:\t34.7800\n    > [Test ]\tLoss:\t4.3138\tAcc:\t34.7800\n    > [Test ]\tLoss:\t4.3138\tAcc:\t34.7800\n    > [Test ]\tLoss:\t4.3138\tAcc:\t34.7800\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3060\tFew:\t0.0313\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3060\tFew:\t0.0313\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3060\tFew:\t0.0313\n    > [Stats]\tMany:\t0.6609\tMedium:\t0.3060\tFew:\t0.0313\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.712763911560693\nMax state: 4 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [123 | 200]\n---> Epoch: [123 | 200]\n---> Epoch: [123 | 200]\n---> Epoch: [123 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t10.8169\n    > [Train]\tLoss:\t10.8169\n    > [Train]\tLoss:\t10.8169\n    > [Train]\tLoss:\t10.8169\n    > [Test ]\tLoss:\t4.3570\tAcc:\t34.9200\n    > [Test ]\tLoss:\t4.3570\tAcc:\t34.9200\n    > [Test ]\tLoss:\t4.3570\tAcc:\t34.9200\n    > [Test ]\tLoss:\t4.3570\tAcc:\t34.9200\n    > [Stats]\tMany:\t0.6500\tMedium:\t0.3294\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6500\tMedium:\t0.3294\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6500\tMedium:\t0.3294\tFew:\t0.0213\n    > [Stats]\tMany:\t0.6500\tMedium:\t0.3294\tFew:\t0.0213\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Best ]\tAcc:\t37.5300\tMany:\t67.0000\tMedium:\t37.5143\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.864837932773929\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [124 | 200]\n---> Epoch: [124 | 200]\n---> Epoch: [124 | 200]\n---> Epoch: [124 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.5199\n    > [Train]\tLoss:\t10.5199\n    > [Train]\tLoss:\t10.5199\n    > [Train]\tLoss:\t10.5199\n    > [Test ]\tLoss:\t3.8943\tAcc:\t38.0600\n    > [Test ]\tLoss:\t3.8943\tAcc:\t38.0600\n    > [Test ]\tLoss:\t3.8943\tAcc:\t38.0600\n    > [Test ]\tLoss:\t3.8943\tAcc:\t38.0600\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.4043\tFew:\t0.0377\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.4043\tFew:\t0.0377\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.4043\tFew:\t0.0377\n    > [Stats]\tMany:\t0.6509\tMedium:\t0.4043\tFew:\t0.0377\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.806599305580074\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [125 | 200]\n---> Epoch: [125 | 200]\n---> Epoch: [125 | 200]\n---> Epoch: [125 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t11.1685\n    > [Train]\tLoss:\t11.1685\n    > [Train]\tLoss:\t11.1685\n    > [Train]\tLoss:\t11.1685\n    > [Test ]\tLoss:\t4.3872\tAcc:\t34.6800\n    > [Test ]\tLoss:\t4.3872\tAcc:\t34.6800\n    > [Test ]\tLoss:\t4.3872\tAcc:\t34.6800\n    > [Test ]\tLoss:\t4.3872\tAcc:\t34.6800\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3246\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3246\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3246\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3246\tFew:\t0.0273\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.727987389393347\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [126 | 200]\n---> Epoch: [126 | 200]\n---> Epoch: [126 | 200]\n---> Epoch: [126 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.5004\n    > [Train]\tLoss:\t10.5004\n    > [Train]\tLoss:\t10.5004\n    > [Train]\tLoss:\t10.5004\n    > [Test ]\tLoss:\t4.4884\tAcc:\t33.5000\n    > [Test ]\tLoss:\t4.4884\tAcc:\t33.5000\n    > [Test ]\tLoss:\t4.4884\tAcc:\t33.5000\n    > [Test ]\tLoss:\t4.4884\tAcc:\t33.5000\n    > [Stats]\tMany:\t0.6471\tMedium:\t0.2937\tFew:\t0.0190\n    > [Stats]\tMany:\t0.6471\tMedium:\t0.2937\tFew:\t0.0190\n    > [Stats]\tMany:\t0.6471\tMedium:\t0.2937\tFew:\t0.0190\n    > [Stats]\tMany:\t0.6471\tMedium:\t0.2937\tFew:\t0.0190\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.66131672784565\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [127 | 200]\n---> Epoch: [127 | 200]\n---> Epoch: [127 | 200]\n---> Epoch: [127 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t10.7350\n    > [Train]\tLoss:\t10.7350\n    > [Train]\tLoss:\t10.7350\n    > [Train]\tLoss:\t10.7350\n    > [Test ]\tLoss:\t4.3035\tAcc:\t36.0400\n    > [Test ]\tLoss:\t4.3035\tAcc:\t36.0400\n    > [Test ]\tLoss:\t4.3035\tAcc:\t36.0400\n    > [Test ]\tLoss:\t4.3035\tAcc:\t36.0400\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.3449\tFew:\t0.0350\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.3449\tFew:\t0.0350\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.3449\tFew:\t0.0350\n    > [Stats]\tMany:\t0.6549\tMedium:\t0.3449\tFew:\t0.0350\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.68868656482811\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [128 | 200]\n---> Epoch: [128 | 200]\n---> Epoch: [128 | 200]\n---> Epoch: [128 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.6240\n    > [Train]\tLoss:\t10.6240\n    > [Train]\tLoss:\t10.6240\n    > [Train]\tLoss:\t10.6240\n    > [Test ]\tLoss:\t4.3840\tAcc:\t34.1500\n    > [Test ]\tLoss:\t4.3840\tAcc:\t34.1500\n    > [Test ]\tLoss:\t4.3840\tAcc:\t34.1500\n    > [Test ]\tLoss:\t4.3840\tAcc:\t34.1500\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.2949\tFew:\t0.0310\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.2949\tFew:\t0.0310\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.2949\tFew:\t0.0310\n    > [Stats]\tMany:\t0.6543\tMedium:\t0.2949\tFew:\t0.0310\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.664590965496723\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [129 | 200]\n---> Epoch: [129 | 200]\n---> Epoch: [129 | 200]\n---> Epoch: [129 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.2748\n    > [Train]\tLoss:\t10.2748\n    > [Train]\tLoss:\t10.2748\n    > [Train]\tLoss:\t10.2748\n    > [Test ]\tLoss:\t4.5395\tAcc:\t34.1300\n    > [Test ]\tLoss:\t4.5395\tAcc:\t34.1300\n    > [Test ]\tLoss:\t4.5395\tAcc:\t34.1300\n    > [Test ]\tLoss:\t4.5395\tAcc:\t34.1300\n    > [Stats]\tMany:\t0.6554\tMedium:\t0.2977\tFew:\t0.0257\n    > [Stats]\tMany:\t0.6554\tMedium:\t0.2977\tFew:\t0.0257\n    > [Stats]\tMany:\t0.6554\tMedium:\t0.2977\tFew:\t0.0257\n    > [Stats]\tMany:\t0.6554\tMedium:\t0.2977\tFew:\t0.0257\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.599592405241077\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [130 | 200]\n---> Epoch: [130 | 200]\n---> Epoch: [130 | 200]\n---> Epoch: [130 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.3333\n    > [Train]\tLoss:\t10.3333\n    > [Train]\tLoss:\t10.3333\n    > [Train]\tLoss:\t10.3333\n    > [Test ]\tLoss:\t4.4890\tAcc:\t34.9300\n    > [Test ]\tLoss:\t4.4890\tAcc:\t34.9300\n    > [Test ]\tLoss:\t4.4890\tAcc:\t34.9300\n    > [Test ]\tLoss:\t4.4890\tAcc:\t34.9300\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3237\tFew:\t0.0437\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3237\tFew:\t0.0437\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3237\tFew:\t0.0437\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.3237\tFew:\t0.0437\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.62721911821479\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [131 | 200]\n---> Epoch: [131 | 200]\n---> Epoch: [131 | 200]\n---> Epoch: [131 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.4961\n    > [Train]\tLoss:\t10.4961\n    > [Train]\tLoss:\t10.4961\n    > [Train]\tLoss:\t10.4961\n    > [Test ]\tLoss:\t4.1413\tAcc:\t36.5800\n    > [Test ]\tLoss:\t4.1413\tAcc:\t36.5800\n    > [Test ]\tLoss:\t4.1413\tAcc:\t36.5800\n    > [Test ]\tLoss:\t4.1413\tAcc:\t36.5800\n    > [Stats]\tMany:\t0.6897\tMedium:\t0.3234\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6897\tMedium:\t0.3234\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6897\tMedium:\t0.3234\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6897\tMedium:\t0.3234\tFew:\t0.0373\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.649862607304831\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [132 | 200]\n---> Epoch: [132 | 200]\n---> Epoch: [132 | 200]\n---> Epoch: [132 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t10.1400\n    > [Train]\tLoss:\t10.1400\n    > [Train]\tLoss:\t10.1400\n    > [Train]\tLoss:\t10.1400\n    > [Test ]\tLoss:\t4.2431\tAcc:\t36.3700\n    > [Test ]\tLoss:\t4.2431\tAcc:\t36.3700\n    > [Test ]\tLoss:\t4.2431\tAcc:\t36.3700\n    > [Test ]\tLoss:\t4.2431\tAcc:\t36.3700\n    > [Stats]\tMany:\t0.6560\tMedium:\t0.3511\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6560\tMedium:\t0.3511\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6560\tMedium:\t0.3511\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6560\tMedium:\t0.3511\tFew:\t0.0373\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.566330157603224\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [133 | 200]\n---> Epoch: [133 | 200]\n---> Epoch: [133 | 200]\n---> Epoch: [133 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.0441\n    > [Train]\tLoss:\t10.0441\n    > [Train]\tLoss:\t10.0441\n    > [Train]\tLoss:\t10.0441\n    > [Test ]\tLoss:\t4.2137\tAcc:\t36.5300\n    > [Test ]\tLoss:\t4.2137\tAcc:\t36.5300\n    > [Test ]\tLoss:\t4.2137\tAcc:\t36.5300\n    > [Test ]\tLoss:\t4.2137\tAcc:\t36.5300\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3749\tFew:\t0.0207\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3749\tFew:\t0.0207\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3749\tFew:\t0.0207\n    > [Stats]\tMany:\t0.6511\tMedium:\t0.3749\tFew:\t0.0207\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.553927123283849\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [134 | 200]\n---> Epoch: [134 | 200]\n---> Epoch: [134 | 200]\n---> Epoch: [134 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t10.1941\n    > [Train]\tLoss:\t10.1941\n    > [Train]\tLoss:\t10.1941\n    > [Train]\tLoss:\t10.1941\n    > [Test ]\tLoss:\t4.1178\tAcc:\t37.9000\n    > [Test ]\tLoss:\t4.1178\tAcc:\t37.9000\n    > [Test ]\tLoss:\t4.1178\tAcc:\t37.9000\n    > [Test ]\tLoss:\t4.1178\tAcc:\t37.9000\n    > [Stats]\tMany:\t0.6603\tMedium:\t0.3900\tFew:\t0.0380\n    > [Stats]\tMany:\t0.6603\tMedium:\t0.3900\tFew:\t0.0380\n    > [Stats]\tMany:\t0.6603\tMedium:\t0.3900\tFew:\t0.0380\n    > [Stats]\tMany:\t0.6603\tMedium:\t0.3900\tFew:\t0.0380\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.497875269145341\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [135 | 200]\n---> Epoch: [135 | 200]\n---> Epoch: [135 | 200]\n---> Epoch: [135 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t9.8566\n    > [Train]\tLoss:\t9.8566\n    > [Train]\tLoss:\t9.8566\n    > [Train]\tLoss:\t9.8566\n    > [Test ]\tLoss:\t4.3893\tAcc:\t35.8300\n    > [Test ]\tLoss:\t4.3893\tAcc:\t35.8300\n    > [Test ]\tLoss:\t4.3893\tAcc:\t35.8300\n    > [Test ]\tLoss:\t4.3893\tAcc:\t35.8300\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3331\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3331\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3331\tFew:\t0.0303\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3331\tFew:\t0.0303\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.437562015312235\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [136 | 200]\n---> Epoch: [136 | 200]\n---> Epoch: [136 | 200]\n---> Epoch: [136 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.5637\n    > [Train]\tLoss:\t10.5637\n    > [Train]\tLoss:\t10.5637\n    > [Train]\tLoss:\t10.5637\n    > [Test ]\tLoss:\t4.1691\tAcc:\t36.7500\n    > [Test ]\tLoss:\t4.1691\tAcc:\t36.7500\n    > [Test ]\tLoss:\t4.1691\tAcc:\t36.7500\n    > [Test ]\tLoss:\t4.1691\tAcc:\t36.7500\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.3277\tFew:\t0.0403\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.3277\tFew:\t0.0403\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.3277\tFew:\t0.0403\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.3277\tFew:\t0.0403\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.507171231799711\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [137 | 200]\n---> Epoch: [137 | 200]\n---> Epoch: [137 | 200]\n---> Epoch: [137 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t10.4851\n    > [Train]\tLoss:\t10.4851\n    > [Train]\tLoss:\t10.4851\n    > [Train]\tLoss:\t10.4851\n    > [Test ]\tLoss:\t4.1541\tAcc:\t36.1800\n    > [Test ]\tLoss:\t4.1541\tAcc:\t36.1800\n    > [Test ]\tLoss:\t4.1541\tAcc:\t36.1800\n    > [Test ]\tLoss:\t4.1541\tAcc:\t36.1800\n    > [Stats]\tMany:\t0.6709\tMedium:\t0.3297\tFew:\t0.0387\n    > [Stats]\tMany:\t0.6709\tMedium:\t0.3297\tFew:\t0.0387\n    > [Stats]\tMany:\t0.6709\tMedium:\t0.3297\tFew:\t0.0387\n    > [Stats]\tMany:\t0.6709\tMedium:\t0.3297\tFew:\t0.0387\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.52594629060701\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [138 | 200]\n---> Epoch: [138 | 200]\n---> Epoch: [138 | 200]\n---> Epoch: [138 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t9.7860\n    > [Train]\tLoss:\t9.7860\n    > [Train]\tLoss:\t9.7860\n    > [Train]\tLoss:\t9.7860\n    > [Test ]\tLoss:\t4.2021\tAcc:\t37.0900\n    > [Test ]\tLoss:\t4.2021\tAcc:\t37.0900\n    > [Test ]\tLoss:\t4.2021\tAcc:\t37.0900\n    > [Test ]\tLoss:\t4.2021\tAcc:\t37.0900\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3771\tFew:\t0.0333\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3771\tFew:\t0.0333\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3771\tFew:\t0.0333\n    > [Stats]\tMany:\t0.6540\tMedium:\t0.3771\tFew:\t0.0333\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.404372450386019\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [139 | 200]\n---> Epoch: [139 | 200]\n---> Epoch: [139 | 200]\n---> Epoch: [139 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.8009\n    > [Train]\tLoss:\t10.8009\n    > [Train]\tLoss:\t10.8009\n    > [Train]\tLoss:\t10.8009\n    > [Test ]\tLoss:\t3.9975\tAcc:\t37.3800\n    > [Test ]\tLoss:\t3.9975\tAcc:\t37.3800\n    > [Test ]\tLoss:\t3.9975\tAcc:\t37.3800\n    > [Test ]\tLoss:\t3.9975\tAcc:\t37.3800\n    > [Stats]\tMany:\t0.6637\tMedium:\t0.3686\tFew:\t0.0417\n    > [Stats]\tMany:\t0.6637\tMedium:\t0.3686\tFew:\t0.0417\n    > [Stats]\tMany:\t0.6637\tMedium:\t0.3686\tFew:\t0.0417\n    > [Stats]\tMany:\t0.6637\tMedium:\t0.3686\tFew:\t0.0417\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.465824616441573\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [140 | 200]\n---> Epoch: [140 | 200]\n---> Epoch: [140 | 200]\n---> Epoch: [140 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.1528\n    > [Train]\tLoss:\t10.1528\n    > [Train]\tLoss:\t10.1528\n    > [Train]\tLoss:\t10.1528\n    > [Test ]\tLoss:\t3.9533\tAcc:\t37.7600\n    > [Test ]\tLoss:\t3.9533\tAcc:\t37.7600\n    > [Test ]\tLoss:\t3.9533\tAcc:\t37.7600\n    > [Test ]\tLoss:\t3.9533\tAcc:\t37.7600\n    > [Stats]\tMany:\t0.6846\tMedium:\t0.3623\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6846\tMedium:\t0.3623\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6846\tMedium:\t0.3623\tFew:\t0.0373\n    > [Stats]\tMany:\t0.6846\tMedium:\t0.3623\tFew:\t0.0373\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.279823518843182\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [141 | 200]\n---> Epoch: [141 | 200]\n---> Epoch: [141 | 200]\n---> Epoch: [141 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.3958\n    > [Train]\tLoss:\t10.3958\n    > [Train]\tLoss:\t10.3958\n    > [Train]\tLoss:\t10.3958\n    > [Test ]\tLoss:\t4.0901\tAcc:\t37.0800\n    > [Test ]\tLoss:\t4.0901\tAcc:\t37.0800\n    > [Test ]\tLoss:\t4.0901\tAcc:\t37.0800\n    > [Test ]\tLoss:\t4.0901\tAcc:\t37.0800\n    > [Stats]\tMany:\t0.6514\tMedium:\t0.3777\tFew:\t0.0353\n    > [Stats]\tMany:\t0.6514\tMedium:\t0.3777\tFew:\t0.0353\n    > [Stats]\tMany:\t0.6514\tMedium:\t0.3777\tFew:\t0.0353\n    > [Stats]\tMany:\t0.6514\tMedium:\t0.3777\tFew:\t0.0353\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.311277522562161\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [142 | 200]\n---> Epoch: [142 | 200]\n---> Epoch: [142 | 200]\n---> Epoch: [142 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t9.8864\n    > [Train]\tLoss:\t9.8864\n    > [Train]\tLoss:\t9.8864\n    > [Train]\tLoss:\t9.8864\n    > [Test ]\tLoss:\t4.2945\tAcc:\t36.5800\n    > [Test ]\tLoss:\t4.2945\tAcc:\t36.5800\n    > [Test ]\tLoss:\t4.2945\tAcc:\t36.5800\n    > [Test ]\tLoss:\t4.2945\tAcc:\t36.5800\n    > [Stats]\tMany:\t0.6766\tMedium:\t0.3389\tFew:\t0.0347\n    > [Stats]\tMany:\t0.6766\tMedium:\t0.3389\tFew:\t0.0347\n    > [Stats]\tMany:\t0.6766\tMedium:\t0.3389\tFew:\t0.0347\n    > [Stats]\tMany:\t0.6766\tMedium:\t0.3389\tFew:\t0.0347\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.204304263762921\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [143 | 200]\n---> Epoch: [143 | 200]\n---> Epoch: [143 | 200]\n---> Epoch: [143 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.4141\n    > [Train]\tLoss:\t10.4141\n    > [Train]\tLoss:\t10.4141\n    > [Train]\tLoss:\t10.4141\n    > [Test ]\tLoss:\t4.0519\tAcc:\t37.4300\n    > [Test ]\tLoss:\t4.0519\tAcc:\t37.4300\n    > [Test ]\tLoss:\t4.0519\tAcc:\t37.4300\n    > [Test ]\tLoss:\t4.0519\tAcc:\t37.4300\n    > [Stats]\tMany:\t0.6820\tMedium:\t0.3534\tFew:\t0.0397\n    > [Stats]\tMany:\t0.6820\tMedium:\t0.3534\tFew:\t0.0397\n    > [Stats]\tMany:\t0.6820\tMedium:\t0.3534\tFew:\t0.0397\n    > [Stats]\tMany:\t0.6820\tMedium:\t0.3534\tFew:\t0.0397\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.266294596568292\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [144 | 200]\n---> Epoch: [144 | 200]\n---> Epoch: [144 | 200]\n---> Epoch: [144 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.2186\n    > [Train]\tLoss:\t10.2186\n    > [Train]\tLoss:\t10.2186\n    > [Train]\tLoss:\t10.2186\n    > [Test ]\tLoss:\t4.4664\tAcc:\t35.1400\n    > [Test ]\tLoss:\t4.4664\tAcc:\t35.1400\n    > [Test ]\tLoss:\t4.4664\tAcc:\t35.1400\n    > [Test ]\tLoss:\t4.4664\tAcc:\t35.1400\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3383\tFew:\t0.0267\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3383\tFew:\t0.0267\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3383\tFew:\t0.0267\n    > [Stats]\tMany:\t0.6429\tMedium:\t0.3383\tFew:\t0.0267\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.201473229710638\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [145 | 200]\n---> Epoch: [145 | 200]\n---> Epoch: [145 | 200]\n---> Epoch: [145 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t9.3397\n    > [Train]\tLoss:\t9.3397\n    > [Train]\tLoss:\t9.3397\n    > [Train]\tLoss:\t9.3397\n    > [Test ]\tLoss:\t4.4851\tAcc:\t34.3900\n    > [Test ]\tLoss:\t4.4851\tAcc:\t34.3900\n    > [Test ]\tLoss:\t4.4851\tAcc:\t34.3900\n    > [Test ]\tLoss:\t4.4851\tAcc:\t34.3900\n    > [Stats]\tMany:\t0.6266\tMedium:\t0.3289\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6266\tMedium:\t0.3289\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6266\tMedium:\t0.3289\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6266\tMedium:\t0.3289\tFew:\t0.0317\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.099013366030277\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [146 | 200]\n---> Epoch: [146 | 200]\n---> Epoch: [146 | 200]\n---> Epoch: [146 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t10.2175\n    > [Train]\tLoss:\t10.2175\n    > [Train]\tLoss:\t10.2175\n    > [Train]\tLoss:\t10.2175\n    > [Test ]\tLoss:\t4.1735\tAcc:\t35.9500\n    > [Test ]\tLoss:\t4.1735\tAcc:\t35.9500\n    > [Test ]\tLoss:\t4.1735\tAcc:\t35.9500\n    > [Test ]\tLoss:\t4.1735\tAcc:\t35.9500\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3540\tFew:\t0.0233\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3540\tFew:\t0.0233\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3540\tFew:\t0.0233\n    > [Stats]\tMany:\t0.6531\tMedium:\t0.3540\tFew:\t0.0233\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.15320828696061\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [147 | 200]\n---> Epoch: [147 | 200]\n---> Epoch: [147 | 200]\n---> Epoch: [147 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t9.6299\n    > [Train]\tLoss:\t9.6299\n    > [Train]\tLoss:\t9.6299\n    > [Train]\tLoss:\t9.6299\n    > [Test ]\tLoss:\t4.3772\tAcc:\t36.1100\n    > [Test ]\tLoss:\t4.3772\tAcc:\t36.1100\n    > [Test ]\tLoss:\t4.3772\tAcc:\t36.1100\n    > [Test ]\tLoss:\t4.3772\tAcc:\t36.1100\n    > [Stats]\tMany:\t0.6571\tMedium:\t0.3451\tFew:\t0.0343\n    > [Stats]\tMany:\t0.6571\tMedium:\t0.3451\tFew:\t0.0343\n    > [Stats]\tMany:\t0.6571\tMedium:\t0.3451\tFew:\t0.0343\n    > [Stats]\tMany:\t0.6571\tMedium:\t0.3451\tFew:\t0.0343\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.060892350011935\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [148 | 200]\n---> Epoch: [148 | 200]\n---> Epoch: [148 | 200]\n---> Epoch: [148 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t9.9740\n    > [Train]\tLoss:\t9.9740\n    > [Train]\tLoss:\t9.9740\n    > [Train]\tLoss:\t9.9740\n    > [Test ]\tLoss:\t4.1928\tAcc:\t37.8200\n    > [Test ]\tLoss:\t4.1928\tAcc:\t37.8200\n    > [Test ]\tLoss:\t4.1928\tAcc:\t37.8200\n    > [Test ]\tLoss:\t4.1928\tAcc:\t37.8200\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3754\tFew:\t0.0473\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3754\tFew:\t0.0473\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3754\tFew:\t0.0473\n    > [Stats]\tMany:\t0.6646\tMedium:\t0.3754\tFew:\t0.0473\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.064947770807319\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [149 | 200]\n---> Epoch: [149 | 200]\n---> Epoch: [149 | 200]\n---> Epoch: [149 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t9.5441\n    > [Train]\tLoss:\t9.5441\n    > [Train]\tLoss:\t9.5441\n    > [Train]\tLoss:\t9.5441\n    > [Test ]\tLoss:\t4.1213\tAcc:\t37.5700\n    > [Test ]\tLoss:\t4.1213\tAcc:\t37.5700\n    > [Test ]\tLoss:\t4.1213\tAcc:\t37.5700\n    > [Test ]\tLoss:\t4.1213\tAcc:\t37.5700\n    > [Stats]\tMany:\t0.6840\tMedium:\t0.3580\tFew:\t0.0367\n    > [Stats]\tMany:\t0.6840\tMedium:\t0.3580\tFew:\t0.0367\n    > [Stats]\tMany:\t0.6840\tMedium:\t0.3580\tFew:\t0.0367\n    > [Stats]\tMany:\t0.6840\tMedium:\t0.3580\tFew:\t0.0367\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.979925930780054\nMax state: 4 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [150 | 200]\n---> Epoch: [150 | 200]\n---> Epoch: [150 | 200]\n---> Epoch: [150 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t10.2095\n    > [Train]\tLoss:\t10.2095\n    > [Train]\tLoss:\t10.2095\n    > [Train]\tLoss:\t10.2095\n    > [Test ]\tLoss:\t4.2521\tAcc:\t36.7900\n    > [Test ]\tLoss:\t4.2521\tAcc:\t36.7900\n    > [Test ]\tLoss:\t4.2521\tAcc:\t36.7900\n    > [Test ]\tLoss:\t4.2521\tAcc:\t36.7900\n    > [Stats]\tMany:\t0.6743\tMedium:\t0.3560\tFew:\t0.0243\n    > [Stats]\tMany:\t0.6743\tMedium:\t0.3560\tFew:\t0.0243\n    > [Stats]\tMany:\t0.6743\tMedium:\t0.3560\tFew:\t0.0243\n    > [Stats]\tMany:\t0.6743\tMedium:\t0.3560\tFew:\t0.0243\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.020682520476795\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [151 | 200]\n---> Epoch: [151 | 200]\n---> Epoch: [151 | 200]\n---> Epoch: [151 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t10.0186\n    > [Train]\tLoss:\t10.0186\n    > [Train]\tLoss:\t10.0186\n    > [Train]\tLoss:\t10.0186\n    > [Test ]\tLoss:\t4.4457\tAcc:\t34.4500\n    > [Test ]\tLoss:\t4.4457\tAcc:\t34.4500\n    > [Test ]\tLoss:\t4.4457\tAcc:\t34.4500\n    > [Test ]\tLoss:\t4.4457\tAcc:\t34.4500\n    > [Stats]\tMany:\t0.6557\tMedium:\t0.3003\tFew:\t0.0330\n    > [Stats]\tMany:\t0.6557\tMedium:\t0.3003\tFew:\t0.0330\n    > [Stats]\tMany:\t0.6557\tMedium:\t0.3003\tFew:\t0.0330\n    > [Stats]\tMany:\t0.6557\tMedium:\t0.3003\tFew:\t0.0330\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.041654880316147\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [152 | 200]\n---> Epoch: [152 | 200]\n---> Epoch: [152 | 200]\n---> Epoch: [152 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.2318\n    > [Train]\tLoss:\t10.2318\n    > [Train]\tLoss:\t10.2318\n    > [Train]\tLoss:\t10.2318\n    > [Test ]\tLoss:\t4.2299\tAcc:\t36.8000\n    > [Test ]\tLoss:\t4.2299\tAcc:\t36.8000\n    > [Test ]\tLoss:\t4.2299\tAcc:\t36.8000\n    > [Test ]\tLoss:\t4.2299\tAcc:\t36.8000\n    > [Stats]\tMany:\t0.6563\tMedium:\t0.3714\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6563\tMedium:\t0.3714\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6563\tMedium:\t0.3714\tFew:\t0.0277\n    > [Stats]\tMany:\t0.6563\tMedium:\t0.3714\tFew:\t0.0277\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.092497161428765\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [153 | 200]\n---> Epoch: [153 | 200]\n---> Epoch: [153 | 200]\n---> Epoch: [153 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t9.9687\n    > [Train]\tLoss:\t9.9687\n    > [Train]\tLoss:\t9.9687\n    > [Train]\tLoss:\t9.9687\n    > [Test ]\tLoss:\t4.4466\tAcc:\t35.8900\n    > [Test ]\tLoss:\t4.4466\tAcc:\t35.8900\n    > [Test ]\tLoss:\t4.4466\tAcc:\t35.8900\n    > [Test ]\tLoss:\t4.4466\tAcc:\t35.8900\n    > [Stats]\tMany:\t0.6694\tMedium:\t0.3357\tFew:\t0.0237\n    > [Stats]\tMany:\t0.6694\tMedium:\t0.3357\tFew:\t0.0237\n    > [Stats]\tMany:\t0.6694\tMedium:\t0.3357\tFew:\t0.0237\n    > [Stats]\tMany:\t0.6694\tMedium:\t0.3357\tFew:\t0.0237\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.020225585597258\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [154 | 200]\n---> Epoch: [154 | 200]\n---> Epoch: [154 | 200]\n---> Epoch: [154 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.3113\n    > [Train]\tLoss:\t10.3113\n    > [Train]\tLoss:\t10.3113\n    > [Train]\tLoss:\t10.3113\n    > [Test ]\tLoss:\t4.1172\tAcc:\t37.0000\n    > [Test ]\tLoss:\t4.1172\tAcc:\t37.0000\n    > [Test ]\tLoss:\t4.1172\tAcc:\t37.0000\n    > [Test ]\tLoss:\t4.1172\tAcc:\t37.0000\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.3603\tFew:\t0.0193\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.3603\tFew:\t0.0193\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.3603\tFew:\t0.0193\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.3603\tFew:\t0.0193\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.064217589887477\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [155 | 200]\n---> Epoch: [155 | 200]\n---> Epoch: [155 | 200]\n---> Epoch: [155 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t9.6701\n    > [Train]\tLoss:\t9.6701\n    > [Train]\tLoss:\t9.6701\n    > [Train]\tLoss:\t9.6701\n    > [Test ]\tLoss:\t4.1905\tAcc:\t37.8000\n    > [Test ]\tLoss:\t4.1905\tAcc:\t37.8000\n    > [Test ]\tLoss:\t4.1905\tAcc:\t37.8000\n    > [Test ]\tLoss:\t4.1905\tAcc:\t37.8000\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3843\tFew:\t0.0370\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3843\tFew:\t0.0370\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3843\tFew:\t0.0370\n    > [Stats]\tMany:\t0.6640\tMedium:\t0.3843\tFew:\t0.0370\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Best ]\tAcc:\t38.0600\tMany:\t65.0857\tMedium:\t40.4286\tFew:\t3.7667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"9.039423798764066\nMax state: 4 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [156 | 200]\n---> Epoch: [156 | 200]\n---> Epoch: [156 | 200]\n---> Epoch: [156 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t9.8964\n    > [Train]\tLoss:\t9.8964\n    > [Train]\tLoss:\t9.8964\n    > [Train]\tLoss:\t9.8964\n    > [Test ]\tLoss:\t4.1889\tAcc:\t38.0800\n    > [Test ]\tLoss:\t4.1889\tAcc:\t38.0800\n    > [Test ]\tLoss:\t4.1889\tAcc:\t38.0800\n    > [Test ]\tLoss:\t4.1889\tAcc:\t38.0800\n    > [Stats]\tMany:\t0.6740\tMedium:\t0.3869\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6740\tMedium:\t0.3869\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6740\tMedium:\t0.3869\tFew:\t0.0317\n    > [Stats]\tMany:\t0.6740\tMedium:\t0.3869\tFew:\t0.0317\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.931134488295388\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [157 | 200]\n---> Epoch: [157 | 200]\n---> Epoch: [157 | 200]\n---> Epoch: [157 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t9.7803\n    > [Train]\tLoss:\t9.7803\n    > [Train]\tLoss:\t9.7803\n    > [Train]\tLoss:\t9.7803\n    > [Test ]\tLoss:\t4.3396\tAcc:\t36.7000\n    > [Test ]\tLoss:\t4.3396\tAcc:\t36.7000\n    > [Test ]\tLoss:\t4.3396\tAcc:\t36.7000\n    > [Test ]\tLoss:\t4.3396\tAcc:\t36.7000\n    > [Stats]\tMany:\t0.6600\tMedium:\t0.3651\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6600\tMedium:\t0.3651\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6600\tMedium:\t0.3651\tFew:\t0.0273\n    > [Stats]\tMany:\t0.6600\tMedium:\t0.3651\tFew:\t0.0273\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Best ]\tAcc:\t38.0800\tMany:\t67.4000\tMedium:\t38.6857\tFew:\t3.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.779983623046098\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [158 | 200]\n---> Epoch: [158 | 200]\n---> Epoch: [158 | 200]\n---> Epoch: [158 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t10.0300\n    > [Train]\tLoss:\t10.0300\n    > [Train]\tLoss:\t10.0300\n    > [Train]\tLoss:\t10.0300\n    > [Test ]\tLoss:\t3.8985\tAcc:\t38.5000\n    > [Test ]\tLoss:\t3.8985\tAcc:\t38.5000\n    > [Test ]\tLoss:\t3.8985\tAcc:\t38.5000\n    > [Test ]\tLoss:\t3.8985\tAcc:\t38.5000\n    > [Stats]\tMany:\t0.6720\tMedium:\t0.3934\tFew:\t0.0403\n    > [Stats]\tMany:\t0.6720\tMedium:\t0.3934\tFew:\t0.0403\n    > [Stats]\tMany:\t0.6720\tMedium:\t0.3934\tFew:\t0.0403\n    > [Stats]\tMany:\t0.6720\tMedium:\t0.3934\tFew:\t0.0403\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.880532177597601\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [159 | 200]\n---> Epoch: [159 | 200]\n---> Epoch: [159 | 200]\n---> Epoch: [159 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t10.3335\n    > [Train]\tLoss:\t10.3335\n    > [Train]\tLoss:\t10.3335\n    > [Train]\tLoss:\t10.3335\n    > [Test ]\tLoss:\t4.4038\tAcc:\t34.9400\n    > [Test ]\tLoss:\t4.4038\tAcc:\t34.9400\n    > [Test ]\tLoss:\t4.4038\tAcc:\t34.9400\n    > [Test ]\tLoss:\t4.4038\tAcc:\t34.9400\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3203\tFew:\t0.0347\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3203\tFew:\t0.0347\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3203\tFew:\t0.0347\n    > [Stats]\tMany:\t0.6483\tMedium:\t0.3203\tFew:\t0.0347\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.917781370412166\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [160 | 200]\n---> Epoch: [160 | 200]\n---> Epoch: [160 | 200]\n---> Epoch: [160 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t9.2013\n    > [Train]\tLoss:\t9.2013\n    > [Train]\tLoss:\t9.2013\n    > [Train]\tLoss:\t9.2013\n    > [Test ]\tLoss:\t4.3142\tAcc:\t37.1600\n    > [Test ]\tLoss:\t4.3142\tAcc:\t37.1600\n    > [Test ]\tLoss:\t4.3142\tAcc:\t37.1600\n    > [Test ]\tLoss:\t4.3142\tAcc:\t37.1600\n    > [Stats]\tMany:\t0.6880\tMedium:\t0.3366\tFew:\t0.0433\n    > [Stats]\tMany:\t0.6880\tMedium:\t0.3366\tFew:\t0.0433\n    > [Stats]\tMany:\t0.6880\tMedium:\t0.3366\tFew:\t0.0433\n    > [Stats]\tMany:\t0.6880\tMedium:\t0.3366\tFew:\t0.0433\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Best ]\tAcc:\t38.5000\tMany:\t67.2000\tMedium:\t39.3429\tFew:\t4.0333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"8.870974381104697\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [161 | 200]\n---> Epoch: [161 | 200]\n---> Epoch: [161 | 200]\n---> Epoch: [161 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t9.2418\n    > [Train]\tLoss:\t9.2418\n    > [Train]\tLoss:\t9.2418\n    > [Train]\tLoss:\t9.2418\n    > [Test ]\tLoss:\t4.0388\tAcc:\t40.2100\n    > [Test ]\tLoss:\t4.0388\tAcc:\t40.2100\n    > [Test ]\tLoss:\t4.0388\tAcc:\t40.2100\n    > [Test ]\tLoss:\t4.0388\tAcc:\t40.2100\n    > [Stats]\tMany:\t0.7171\tMedium:\t0.3911\tFew:\t0.0473\n    > [Stats]\tMany:\t0.7171\tMedium:\t0.3911\tFew:\t0.0473\n    > [Stats]\tMany:\t0.7171\tMedium:\t0.3911\tFew:\t0.0473\n    > [Stats]\tMany:\t0.7171\tMedium:\t0.3911\tFew:\t0.0473\n    > [Best ]\tAcc:\t40.2100\tMany:\t71.7143\tMedium:\t39.1143\tFew:\t4.7333\n    > [Best ]\tAcc:\t40.2100\tMany:\t71.7143\tMedium:\t39.1143\tFew:\t4.7333\n    > [Best ]\tAcc:\t40.2100\tMany:\t71.7143\tMedium:\t39.1143\tFew:\t4.7333\n    > [Best ]\tAcc:\t40.2100\tMany:\t71.7143\tMedium:\t39.1143\tFew:\t4.7333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.870495405296694\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [162 | 200]\n---> Epoch: [162 | 200]\n---> Epoch: [162 | 200]\n---> Epoch: [162 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t21.4093\n    > [Train]\tLoss:\t21.4093\n    > [Train]\tLoss:\t21.4093\n    > [Train]\tLoss:\t21.4093\n    > [Test ]\tLoss:\t3.5499\tAcc:\t42.7200\n    > [Test ]\tLoss:\t3.5499\tAcc:\t42.7200\n    > [Test ]\tLoss:\t3.5499\tAcc:\t42.7200\n    > [Test ]\tLoss:\t3.5499\tAcc:\t42.7200\n    > [Stats]\tMany:\t0.7154\tMedium:\t0.4389\tFew:\t0.0773\n    > [Stats]\tMany:\t0.7154\tMedium:\t0.4389\tFew:\t0.0773\n    > [Stats]\tMany:\t0.7154\tMedium:\t0.4389\tFew:\t0.0773\n    > [Stats]\tMany:\t0.7154\tMedium:\t0.4389\tFew:\t0.0773\n    > [Best ]\tAcc:\t42.7200\tMany:\t71.5429\tMedium:\t43.8857\tFew:\t7.7333\n    > [Best ]\tAcc:\t42.7200\tMany:\t71.5429\tMedium:\t43.8857\tFew:\t7.7333\n    > [Best ]\tAcc:\t42.7200\tMany:\t71.5429\tMedium:\t43.8857\tFew:\t7.7333\n    > [Best ]\tAcc:\t42.7200\tMany:\t71.5429\tMedium:\t43.8857\tFew:\t7.7333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"8.979431847239795\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [163 | 200]\n---> Epoch: [163 | 200]\n---> Epoch: [163 | 200]\n---> Epoch: [163 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t20.7311\n    > [Train]\tLoss:\t20.7311\n    > [Train]\tLoss:\t20.7311\n    > [Train]\tLoss:\t20.7311\n    > [Test ]\tLoss:\t3.2086\tAcc:\t44.6500\n    > [Test ]\tLoss:\t3.2086\tAcc:\t44.6500\n    > [Test ]\tLoss:\t3.2086\tAcc:\t44.6500\n    > [Test ]\tLoss:\t3.2086\tAcc:\t44.6500\n    > [Stats]\tMany:\t0.7100\tMedium:\t0.4706\tFew:\t0.1110\n    > [Stats]\tMany:\t0.7100\tMedium:\t0.4706\tFew:\t0.1110\n    > [Stats]\tMany:\t0.7100\tMedium:\t0.4706\tFew:\t0.1110\n    > [Stats]\tMany:\t0.7100\tMedium:\t0.4706\tFew:\t0.1110\n    > [Best ]\tAcc:\t44.6500\tMany:\t71.0000\tMedium:\t47.0571\tFew:\t11.1000\n    > [Best ]\tAcc:\t44.6500\tMany:\t71.0000\tMedium:\t47.0571\tFew:\t11.1000\n    > [Best ]\tAcc:\t44.6500\tMany:\t71.0000\tMedium:\t47.0571\tFew:\t11.1000\n    > [Best ]\tAcc:\t44.6500\tMany:\t71.0000\tMedium:\t47.0571\tFew:\t11.1000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.085367857794887\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [164 | 200]\n---> Epoch: [164 | 200]\n---> Epoch: [164 | 200]\n---> Epoch: [164 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t18.9061\n    > [Train]\tLoss:\t18.9061\n    > [Train]\tLoss:\t18.9061\n    > [Train]\tLoss:\t18.9061\n    > [Test ]\tLoss:\t3.0299\tAcc:\t45.5300\n    > [Test ]\tLoss:\t3.0299\tAcc:\t45.5300\n    > [Test ]\tLoss:\t3.0299\tAcc:\t45.5300\n    > [Test ]\tLoss:\t3.0299\tAcc:\t45.5300\n    > [Stats]\tMany:\t0.7057\tMedium:\t0.4774\tFew:\t0.1373\n    > [Stats]\tMany:\t0.7057\tMedium:\t0.4774\tFew:\t0.1373\n    > [Stats]\tMany:\t0.7057\tMedium:\t0.4774\tFew:\t0.1373\n    > [Stats]\tMany:\t0.7057\tMedium:\t0.4774\tFew:\t0.1373\n    > [Best ]\tAcc:\t45.5300\tMany:\t70.5714\tMedium:\t47.7429\tFew:\t13.7333\n    > [Best ]\tAcc:\t45.5300\tMany:\t70.5714\tMedium:\t47.7429\tFew:\t13.7333\n    > [Best ]\tAcc:\t45.5300\tMany:\t70.5714\tMedium:\t47.7429\tFew:\t13.7333\n    > [Best ]\tAcc:\t45.5300\tMany:\t70.5714\tMedium:\t47.7429\tFew:\t13.7333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.165501338215066\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [165 | 200]\n---> Epoch: [165 | 200]\n---> Epoch: [165 | 200]\n---> Epoch: [165 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t19.2742\n    > [Train]\tLoss:\t19.2742\n    > [Train]\tLoss:\t19.2742\n    > [Train]\tLoss:\t19.2742\n    > [Test ]\tLoss:\t2.9082\tAcc:\t46.3600\n    > [Test ]\tLoss:\t2.9082\tAcc:\t46.3600\n    > [Test ]\tLoss:\t2.9082\tAcc:\t46.3600\n    > [Test ]\tLoss:\t2.9082\tAcc:\t46.3600\n    > [Stats]\tMany:\t0.6986\tMedium:\t0.4843\tFew:\t0.1653\n    > [Stats]\tMany:\t0.6986\tMedium:\t0.4843\tFew:\t0.1653\n    > [Stats]\tMany:\t0.6986\tMedium:\t0.4843\tFew:\t0.1653\n    > [Stats]\tMany:\t0.6986\tMedium:\t0.4843\tFew:\t0.1653\n    > [Best ]\tAcc:\t46.3600\tMany:\t69.8571\tMedium:\t48.4286\tFew:\t16.5333\n    > [Best ]\tAcc:\t46.3600\tMany:\t69.8571\tMedium:\t48.4286\tFew:\t16.5333\n    > [Best ]\tAcc:\t46.3600\tMany:\t69.8571\tMedium:\t48.4286\tFew:\t16.5333\n    > [Best ]\tAcc:\t46.3600\tMany:\t69.8571\tMedium:\t48.4286\tFew:\t16.5333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.238530231771707\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [166 | 200]\n---> Epoch: [166 | 200]\n---> Epoch: [166 | 200]\n---> Epoch: [166 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t18.2325\n    > [Train]\tLoss:\t18.2325\n    > [Train]\tLoss:\t18.2325\n    > [Train]\tLoss:\t18.2325\n    > [Test ]\tLoss:\t2.8365\tAcc:\t47.0100\n    > [Test ]\tLoss:\t2.8365\tAcc:\t47.0100\n    > [Test ]\tLoss:\t2.8365\tAcc:\t47.0100\n    > [Test ]\tLoss:\t2.8365\tAcc:\t47.0100\n    > [Stats]\tMany:\t0.6994\tMedium:\t0.4900\tFew:\t0.1793\n    > [Stats]\tMany:\t0.6994\tMedium:\t0.4900\tFew:\t0.1793\n    > [Stats]\tMany:\t0.6994\tMedium:\t0.4900\tFew:\t0.1793\n    > [Stats]\tMany:\t0.6994\tMedium:\t0.4900\tFew:\t0.1793\n    > [Best ]\tAcc:\t47.0100\tMany:\t69.9429\tMedium:\t49.0000\tFew:\t17.9333\n    > [Best ]\tAcc:\t47.0100\tMany:\t69.9429\tMedium:\t49.0000\tFew:\t17.9333\n    > [Best ]\tAcc:\t47.0100\tMany:\t69.9429\tMedium:\t49.0000\tFew:\t17.9333\n    > [Best ]\tAcc:\t47.0100\tMany:\t69.9429\tMedium:\t49.0000\tFew:\t17.9333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.297667269019716\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [167 | 200]\n---> Epoch: [167 | 200]\n---> Epoch: [167 | 200]\n---> Epoch: [167 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t18.3324\n    > [Train]\tLoss:\t18.3324\n    > [Train]\tLoss:\t18.3324\n    > [Train]\tLoss:\t18.3324\n    > [Test ]\tLoss:\t2.7889\tAcc:\t47.6600\n    > [Test ]\tLoss:\t2.7889\tAcc:\t47.6600\n    > [Test ]\tLoss:\t2.7889\tAcc:\t47.6600\n    > [Test ]\tLoss:\t2.7889\tAcc:\t47.6600\n    > [Stats]\tMany:\t0.6966\tMedium:\t0.4920\tFew:\t0.2020\n    > [Stats]\tMany:\t0.6966\tMedium:\t0.4920\tFew:\t0.2020\n    > [Stats]\tMany:\t0.6966\tMedium:\t0.4920\tFew:\t0.2020\n    > [Stats]\tMany:\t0.6966\tMedium:\t0.4920\tFew:\t0.2020\n    > [Best ]\tAcc:\t47.6600\tMany:\t69.6572\tMedium:\t49.2000\tFew:\t20.2000\n    > [Best ]\tAcc:\t47.6600\tMany:\t69.6572\tMedium:\t49.2000\tFew:\t20.2000\n    > [Best ]\tAcc:\t47.6600\tMany:\t69.6572\tMedium:\t49.2000\tFew:\t20.2000\n    > [Best ]\tAcc:\t47.6600\tMany:\t69.6572\tMedium:\t49.2000\tFew:\t20.2000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.345452481588126\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [168 | 200]\n---> Epoch: [168 | 200]\n---> Epoch: [168 | 200]\n---> Epoch: [168 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t17.7005\n    > [Train]\tLoss:\t17.7005\n    > [Train]\tLoss:\t17.7005\n    > [Train]\tLoss:\t17.7005\n    > [Test ]\tLoss:\t2.7567\tAcc:\t47.8700\n    > [Test ]\tLoss:\t2.7567\tAcc:\t47.8700\n    > [Test ]\tLoss:\t2.7567\tAcc:\t47.8700\n    > [Test ]\tLoss:\t2.7567\tAcc:\t47.8700\n    > [Stats]\tMany:\t0.6946\tMedium:\t0.4926\tFew:\t0.2107\n    > [Stats]\tMany:\t0.6946\tMedium:\t0.4926\tFew:\t0.2107\n    > [Stats]\tMany:\t0.6946\tMedium:\t0.4926\tFew:\t0.2107\n    > [Stats]\tMany:\t0.6946\tMedium:\t0.4926\tFew:\t0.2107\n    > [Best ]\tAcc:\t47.8700\tMany:\t69.4572\tMedium:\t49.2571\tFew:\t21.0667\n    > [Best ]\tAcc:\t47.8700\tMany:\t69.4572\tMedium:\t49.2571\tFew:\t21.0667\n    > [Best ]\tAcc:\t47.8700\tMany:\t69.4572\tMedium:\t49.2571\tFew:\t21.0667\n    > [Best ]\tAcc:\t47.8700\tMany:\t69.4572\tMedium:\t49.2571\tFew:\t21.0667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.384703856576744\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [169 | 200]\n---> Epoch: [169 | 200]\n---> Epoch: [169 | 200]\n---> Epoch: [169 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t18.1524\n    > [Train]\tLoss:\t18.1524\n    > [Train]\tLoss:\t18.1524\n    > [Train]\tLoss:\t18.1524\n    > [Test ]\tLoss:\t2.7432\tAcc:\t47.9800\n    > [Test ]\tLoss:\t2.7432\tAcc:\t47.9800\n    > [Test ]\tLoss:\t2.7432\tAcc:\t47.9800\n    > [Test ]\tLoss:\t2.7432\tAcc:\t47.9800\n    > [Stats]\tMany:\t0.6914\tMedium:\t0.4986\tFew:\t0.2110\n    > [Stats]\tMany:\t0.6914\tMedium:\t0.4986\tFew:\t0.2110\n    > [Stats]\tMany:\t0.6914\tMedium:\t0.4986\tFew:\t0.2110\n    > [Stats]\tMany:\t0.6914\tMedium:\t0.4986\tFew:\t0.2110\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.422409154501366\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [170 | 200]\n---> Epoch: [170 | 200]\n---> Epoch: [170 | 200]\n---> Epoch: [170 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t17.0586\n    > [Train]\tLoss:\t17.0586\n    > [Train]\tLoss:\t17.0586\n    > [Train]\tLoss:\t17.0586\n    > [Test ]\tLoss:\t2.7267\tAcc:\t47.9700\n    > [Test ]\tLoss:\t2.7267\tAcc:\t47.9700\n    > [Test ]\tLoss:\t2.7267\tAcc:\t47.9700\n    > [Test ]\tLoss:\t2.7267\tAcc:\t47.9700\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.4963\tFew:\t0.2177\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.4963\tFew:\t0.2177\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.4963\tFew:\t0.2177\n    > [Stats]\tMany:\t0.6877\tMedium:\t0.4963\tFew:\t0.2177\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Best ]\tAcc:\t47.9800\tMany:\t69.1429\tMedium:\t49.8571\tFew:\t21.1000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.457428521061285\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [171 | 200]\n---> Epoch: [171 | 200]\n---> Epoch: [171 | 200]\n---> Epoch: [171 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t17.5200\n    > [Train]\tLoss:\t17.5200\n    > [Train]\tLoss:\t17.5200\n    > [Train]\tLoss:\t17.5200\n    > [Test ]\tLoss:\t2.7163\tAcc:\t48.5000\n    > [Test ]\tLoss:\t2.7163\tAcc:\t48.5000\n    > [Test ]\tLoss:\t2.7163\tAcc:\t48.5000\n    > [Test ]\tLoss:\t2.7163\tAcc:\t48.5000\n    > [Stats]\tMany:\t0.6851\tMedium:\t0.5003\tFew:\t0.2337\n    > [Stats]\tMany:\t0.6851\tMedium:\t0.5003\tFew:\t0.2337\n    > [Stats]\tMany:\t0.6851\tMedium:\t0.5003\tFew:\t0.2337\n    > [Stats]\tMany:\t0.6851\tMedium:\t0.5003\tFew:\t0.2337\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.5143\tMedium:\t50.0286\tFew:\t23.3667\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.5143\tMedium:\t50.0286\tFew:\t23.3667\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.5143\tMedium:\t50.0286\tFew:\t23.3667\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.5143\tMedium:\t50.0286\tFew:\t23.3667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.490958734820131\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [172 | 200]\n---> Epoch: [172 | 200]\n---> Epoch: [172 | 200]\n---> Epoch: [172 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.8088\n    > [Train]\tLoss:\t16.8088\n    > [Train]\tLoss:\t16.8088\n    > [Train]\tLoss:\t16.8088\n    > [Test ]\tLoss:\t2.7086\tAcc:\t48.5000\n    > [Test ]\tLoss:\t2.7086\tAcc:\t48.5000\n    > [Test ]\tLoss:\t2.7086\tAcc:\t48.5000\n    > [Test ]\tLoss:\t2.7086\tAcc:\t48.5000\n    > [Stats]\tMany:\t0.6863\tMedium:\t0.5020\tFew:\t0.2303\n    > [Stats]\tMany:\t0.6863\tMedium:\t0.5020\tFew:\t0.2303\n    > [Stats]\tMany:\t0.6863\tMedium:\t0.5020\tFew:\t0.2303\n    > [Stats]\tMany:\t0.6863\tMedium:\t0.5020\tFew:\t0.2303\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.6286\tMedium:\t50.2000\tFew:\t23.0333\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.6286\tMedium:\t50.2000\tFew:\t23.0333\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.6286\tMedium:\t50.2000\tFew:\t23.0333\n    > [Best ]\tAcc:\t48.5000\tMany:\t68.6286\tMedium:\t50.2000\tFew:\t23.0333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.514262520403799\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [173 | 200]\n---> Epoch: [173 | 200]\n---> Epoch: [173 | 200]\n---> Epoch: [173 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t17.8681\n    > [Train]\tLoss:\t17.8681\n    > [Train]\tLoss:\t17.8681\n    > [Train]\tLoss:\t17.8681\n    > [Test ]\tLoss:\t2.7140\tAcc:\t48.5800\n    > [Test ]\tLoss:\t2.7140\tAcc:\t48.5800\n    > [Test ]\tLoss:\t2.7140\tAcc:\t48.5800\n    > [Test ]\tLoss:\t2.7140\tAcc:\t48.5800\n    > [Stats]\tMany:\t0.6854\tMedium:\t0.5026\tFew:\t0.2333\n    > [Stats]\tMany:\t0.6854\tMedium:\t0.5026\tFew:\t0.2333\n    > [Stats]\tMany:\t0.6854\tMedium:\t0.5026\tFew:\t0.2333\n    > [Stats]\tMany:\t0.6854\tMedium:\t0.5026\tFew:\t0.2333\n    > [Best ]\tAcc:\t48.5800\tMany:\t68.5429\tMedium:\t50.2571\tFew:\t23.3333\n    > [Best ]\tAcc:\t48.5800\tMany:\t68.5429\tMedium:\t50.2571\tFew:\t23.3333\n    > [Best ]\tAcc:\t48.5800\tMany:\t68.5429\tMedium:\t50.2571\tFew:\t23.3333\n    > [Best ]\tAcc:\t48.5800\tMany:\t68.5429\tMedium:\t50.2571\tFew:\t23.3333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.54081644148722\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [174 | 200]\n---> Epoch: [174 | 200]\n---> Epoch: [174 | 200]\n---> Epoch: [174 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t17.6661\n    > [Train]\tLoss:\t17.6661\n    > [Train]\tLoss:\t17.6661\n    > [Train]\tLoss:\t17.6661\n    > [Test ]\tLoss:\t2.6995\tAcc:\t48.8400\n    > [Test ]\tLoss:\t2.6995\tAcc:\t48.8400\n    > [Test ]\tLoss:\t2.6995\tAcc:\t48.8400\n    > [Test ]\tLoss:\t2.6995\tAcc:\t48.8400\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5077\tFew:\t0.2407\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5077\tFew:\t0.2407\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5077\tFew:\t0.2407\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5077\tFew:\t0.2407\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.567831681807045\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [175 | 200]\n---> Epoch: [175 | 200]\n---> Epoch: [175 | 200]\n---> Epoch: [175 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.6438\n    > [Train]\tLoss:\t16.6438\n    > [Train]\tLoss:\t16.6438\n    > [Train]\tLoss:\t16.6438\n    > [Test ]\tLoss:\t2.6987\tAcc:\t48.7600\n    > [Test ]\tLoss:\t2.6987\tAcc:\t48.7600\n    > [Test ]\tLoss:\t2.6987\tAcc:\t48.7600\n    > [Test ]\tLoss:\t2.6987\tAcc:\t48.7600\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5054\tFew:\t0.2403\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5054\tFew:\t0.2403\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5054\tFew:\t0.2403\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5054\tFew:\t0.2403\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.590055697526514\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [176 | 200]\n---> Epoch: [176 | 200]\n---> Epoch: [176 | 200]\n---> Epoch: [176 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t17.0505\n    > [Train]\tLoss:\t17.0505\n    > [Train]\tLoss:\t17.0505\n    > [Train]\tLoss:\t17.0505\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.8200\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.8200\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.8200\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.8200\n    > [Stats]\tMany:\t0.6831\tMedium:\t0.5023\tFew:\t0.2443\n    > [Stats]\tMany:\t0.6831\tMedium:\t0.5023\tFew:\t0.2443\n    > [Stats]\tMany:\t0.6831\tMedium:\t0.5023\tFew:\t0.2443\n    > [Stats]\tMany:\t0.6831\tMedium:\t0.5023\tFew:\t0.2443\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Best ]\tAcc:\t48.8400\tMany:\t68.1429\tMedium:\t50.7714\tFew:\t24.0667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.60995914943067\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [177 | 200]\n---> Epoch: [177 | 200]\n---> Epoch: [177 | 200]\n---> Epoch: [177 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.9877\n    > [Train]\tLoss:\t16.9877\n    > [Train]\tLoss:\t16.9877\n    > [Train]\tLoss:\t16.9877\n    > [Test ]\tLoss:\t2.7112\tAcc:\t48.9100\n    > [Test ]\tLoss:\t2.7112\tAcc:\t48.9100\n    > [Test ]\tLoss:\t2.7112\tAcc:\t48.9100\n    > [Test ]\tLoss:\t2.7112\tAcc:\t48.9100\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5091\tFew:\t0.2430\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5091\tFew:\t0.2430\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5091\tFew:\t0.2430\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5091\tFew:\t0.2430\n    > [Best ]\tAcc:\t48.9100\tMany:\t68.0000\tMedium:\t50.9143\tFew:\t24.3000\n    > [Best ]\tAcc:\t48.9100\tMany:\t68.0000\tMedium:\t50.9143\tFew:\t24.3000\n    > [Best ]\tAcc:\t48.9100\tMany:\t68.0000\tMedium:\t50.9143\tFew:\t24.3000\n    > [Best ]\tAcc:\t48.9100\tMany:\t68.0000\tMedium:\t50.9143\tFew:\t24.3000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.62618647842238\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [178 | 200]\n---> Epoch: [178 | 200]\n---> Epoch: [178 | 200]\n---> Epoch: [178 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.5983\n    > [Train]\tLoss:\t16.5983\n    > [Train]\tLoss:\t16.5983\n    > [Train]\tLoss:\t16.5983\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.9600\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.9600\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.9600\n    > [Test ]\tLoss:\t2.7060\tAcc:\t48.9600\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.5071\tFew:\t0.2427\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.5071\tFew:\t0.2427\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.5071\tFew:\t0.2427\n    > [Stats]\tMany:\t0.6837\tMedium:\t0.5071\tFew:\t0.2427\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.644811391336756\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [179 | 200]\n---> Epoch: [179 | 200]\n---> Epoch: [179 | 200]\n---> Epoch: [179 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.9272\n    > [Train]\tLoss:\t16.9272\n    > [Train]\tLoss:\t16.9272\n    > [Train]\tLoss:\t16.9272\n    > [Test ]\tLoss:\t2.7059\tAcc:\t48.8200\n    > [Test ]\tLoss:\t2.7059\tAcc:\t48.8200\n    > [Test ]\tLoss:\t2.7059\tAcc:\t48.8200\n    > [Test ]\tLoss:\t2.7059\tAcc:\t48.8200\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5074\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5074\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5074\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5074\tFew:\t0.2467\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.668163170692502\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [180 | 200]\n---> Epoch: [180 | 200]\n---> Epoch: [180 | 200]\n---> Epoch: [180 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.0956\n    > [Train]\tLoss:\t16.0956\n    > [Train]\tLoss:\t16.0956\n    > [Train]\tLoss:\t16.0956\n    > [Test ]\tLoss:\t2.6897\tAcc:\t48.9200\n    > [Test ]\tLoss:\t2.6897\tAcc:\t48.9200\n    > [Test ]\tLoss:\t2.6897\tAcc:\t48.9200\n    > [Test ]\tLoss:\t2.6897\tAcc:\t48.9200\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5069\tFew:\t0.2440\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5069\tFew:\t0.2440\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5069\tFew:\t0.2440\n    > [Stats]\tMany:\t0.6817\tMedium:\t0.5069\tFew:\t0.2440\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Best ]\tAcc:\t48.9600\tMany:\t68.3714\tMedium:\t50.7143\tFew:\t24.2667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"9.686358203004893\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [181 | 200]\n---> Epoch: [181 | 200]\n---> Epoch: [181 | 200]\n---> Epoch: [181 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.0839\n    > [Train]\tLoss:\t16.0839\n    > [Train]\tLoss:\t16.0839\n    > [Train]\tLoss:\t16.0839\n    > [Test ]\tLoss:\t2.6815\tAcc:\t49.0000\n    > [Test ]\tLoss:\t2.6815\tAcc:\t49.0000\n    > [Test ]\tLoss:\t2.6815\tAcc:\t49.0000\n    > [Test ]\tLoss:\t2.6815\tAcc:\t49.0000\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5066\tFew:\t0.2480\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5066\tFew:\t0.2480\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5066\tFew:\t0.2480\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5066\tFew:\t0.2480\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.686575196291036\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [182 | 200]\n---> Epoch: [182 | 200]\n---> Epoch: [182 | 200]\n---> Epoch: [182 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.8679\n    > [Train]\tLoss:\t15.8679\n    > [Train]\tLoss:\t15.8679\n    > [Train]\tLoss:\t15.8679\n    > [Test ]\tLoss:\t2.6893\tAcc:\t48.9000\n    > [Test ]\tLoss:\t2.6893\tAcc:\t48.9000\n    > [Test ]\tLoss:\t2.6893\tAcc:\t48.9000\n    > [Test ]\tLoss:\t2.6893\tAcc:\t48.9000\n    > [Stats]\tMany:\t0.6757\tMedium:\t0.5083\tFew:\t0.2487\n    > [Stats]\tMany:\t0.6757\tMedium:\t0.5083\tFew:\t0.2487\n    > [Stats]\tMany:\t0.6757\tMedium:\t0.5083\tFew:\t0.2487\n    > [Stats]\tMany:\t0.6757\tMedium:\t0.5083\tFew:\t0.2487\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.686796830961041\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [183 | 200]\n---> Epoch: [183 | 200]\n---> Epoch: [183 | 200]\n---> Epoch: [183 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t15.8962\n    > [Train]\tLoss:\t15.8962\n    > [Train]\tLoss:\t15.8962\n    > [Train]\tLoss:\t15.8962\n    > [Test ]\tLoss:\t2.6856\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6856\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6856\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6856\tAcc:\t48.9300\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5063\tFew:\t0.2470\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5063\tFew:\t0.2470\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5063\tFew:\t0.2470\n    > [Stats]\tMany:\t0.6800\tMedium:\t0.5063\tFew:\t0.2470\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Best ]\tAcc:\t49.0000\tMany:\t68.0857\tMedium:\t50.6571\tFew:\t24.8000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.686995573015189\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [184 | 200]\n---> Epoch: [184 | 200]\n---> Epoch: [184 | 200]\n---> Epoch: [184 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.2285\n    > [Train]\tLoss:\t16.2285\n    > [Train]\tLoss:\t16.2285\n    > [Train]\tLoss:\t16.2285\n    > [Test ]\tLoss:\t2.6902\tAcc:\t49.2000\n    > [Test ]\tLoss:\t2.6902\tAcc:\t49.2000\n    > [Test ]\tLoss:\t2.6902\tAcc:\t49.2000\n    > [Test ]\tLoss:\t2.6902\tAcc:\t49.2000\n    > [Stats]\tMany:\t0.6797\tMedium:\t0.5106\tFew:\t0.2513\n    > [Stats]\tMany:\t0.6797\tMedium:\t0.5106\tFew:\t0.2513\n    > [Stats]\tMany:\t0.6797\tMedium:\t0.5106\tFew:\t0.2513\n    > [Stats]\tMany:\t0.6797\tMedium:\t0.5106\tFew:\t0.2513\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.687165919124014\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [185 | 200]\n---> Epoch: [185 | 200]\n---> Epoch: [185 | 200]\n---> Epoch: [185 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.8486\n    > [Train]\tLoss:\t16.8486\n    > [Train]\tLoss:\t16.8486\n    > [Train]\tLoss:\t16.8486\n    > [Test ]\tLoss:\t2.6851\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6851\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6851\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6851\tAcc:\t48.9300\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5046\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5046\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5046\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6814\tMedium:\t0.5046\tFew:\t0.2473\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.687350612645805\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [186 | 200]\n---> Epoch: [186 | 200]\n---> Epoch: [186 | 200]\n---> Epoch: [186 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.2570\n    > [Train]\tLoss:\t16.2570\n    > [Train]\tLoss:\t16.2570\n    > [Train]\tLoss:\t16.2570\n    > [Test ]\tLoss:\t2.6845\tAcc:\t48.8900\n    > [Test ]\tLoss:\t2.6845\tAcc:\t48.8900\n    > [Test ]\tLoss:\t2.6845\tAcc:\t48.8900\n    > [Test ]\tLoss:\t2.6845\tAcc:\t48.8900\n    > [Stats]\tMany:\t0.6769\tMedium:\t0.5060\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6769\tMedium:\t0.5060\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6769\tMedium:\t0.5060\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6769\tMedium:\t0.5060\tFew:\t0.2497\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.687581680651068\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [187 | 200]\n---> Epoch: [187 | 200]\n---> Epoch: [187 | 200]\n---> Epoch: [187 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.2502\n    > [Train]\tLoss:\t16.2502\n    > [Train]\tLoss:\t16.2502\n    > [Train]\tLoss:\t16.2502\n    > [Test ]\tLoss:\t2.7000\tAcc:\t49.0300\n    > [Test ]\tLoss:\t2.7000\tAcc:\t49.0300\n    > [Test ]\tLoss:\t2.7000\tAcc:\t49.0300\n    > [Test ]\tLoss:\t2.7000\tAcc:\t49.0300\n    > [Stats]\tMany:\t0.6789\tMedium:\t0.5080\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6789\tMedium:\t0.5080\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6789\tMedium:\t0.5080\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6789\tMedium:\t0.5080\tFew:\t0.2497\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.687754191076587\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [188 | 200]\n---> Epoch: [188 | 200]\n---> Epoch: [188 | 200]\n---> Epoch: [188 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.1505\n    > [Train]\tLoss:\t16.1505\n    > [Train]\tLoss:\t16.1505\n    > [Train]\tLoss:\t16.1505\n    > [Test ]\tLoss:\t2.6921\tAcc:\t49.0900\n    > [Test ]\tLoss:\t2.6921\tAcc:\t49.0900\n    > [Test ]\tLoss:\t2.6921\tAcc:\t49.0900\n    > [Test ]\tLoss:\t2.6921\tAcc:\t49.0900\n    > [Stats]\tMany:\t0.6786\tMedium:\t0.5089\tFew:\t0.2510\n    > [Stats]\tMany:\t0.6786\tMedium:\t0.5089\tFew:\t0.2510\n    > [Stats]\tMany:\t0.6786\tMedium:\t0.5089\tFew:\t0.2510\n    > [Stats]\tMany:\t0.6786\tMedium:\t0.5089\tFew:\t0.2510\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.687985724885916\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [189 | 200]\n---> Epoch: [189 | 200]\n---> Epoch: [189 | 200]\n---> Epoch: [189 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t16.1081\n    > [Train]\tLoss:\t16.1081\n    > [Train]\tLoss:\t16.1081\n    > [Train]\tLoss:\t16.1081\n    > [Test ]\tLoss:\t2.6929\tAcc:\t48.8800\n    > [Test ]\tLoss:\t2.6929\tAcc:\t48.8800\n    > [Test ]\tLoss:\t2.6929\tAcc:\t48.8800\n    > [Test ]\tLoss:\t2.6929\tAcc:\t48.8800\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.5091\tFew:\t0.2447\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.5091\tFew:\t0.2447\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.5091\tFew:\t0.2447\n    > [Stats]\tMany:\t0.6777\tMedium:\t0.5091\tFew:\t0.2447\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.6882082338447\nMax state: 3 // Min state: 0\ntensor([1., 1., 1.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [190 | 200]\n---> Epoch: [190 | 200]\n---> Epoch: [190 | 200]\n---> Epoch: [190 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.4412\n    > [Train]\tLoss:\t16.4412\n    > [Train]\tLoss:\t16.4412\n    > [Train]\tLoss:\t16.4412\n    > [Test ]\tLoss:\t2.6992\tAcc:\t48.8900\n    > [Test ]\tLoss:\t2.6992\tAcc:\t48.8900\n    > [Test ]\tLoss:\t2.6992\tAcc:\t48.8900\n    > [Test ]\tLoss:\t2.6992\tAcc:\t48.8900\n    > [Stats]\tMany:\t0.6783\tMedium:\t0.5046\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6783\tMedium:\t0.5046\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6783\tMedium:\t0.5046\tFew:\t0.2497\n    > [Stats]\tMany:\t0.6783\tMedium:\t0.5046\tFew:\t0.2497\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.688472074588418\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [191 | 200]\n---> Epoch: [191 | 200]\n---> Epoch: [191 | 200]\n---> Epoch: [191 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.3009\n    > [Train]\tLoss:\t16.3009\n    > [Train]\tLoss:\t16.3009\n    > [Train]\tLoss:\t16.3009\n    > [Test ]\tLoss:\t2.6891\tAcc:\t48.9700\n    > [Test ]\tLoss:\t2.6891\tAcc:\t48.9700\n    > [Test ]\tLoss:\t2.6891\tAcc:\t48.9700\n    > [Test ]\tLoss:\t2.6891\tAcc:\t48.9700\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5071\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5071\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5071\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5071\tFew:\t0.2467\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.688617424218403\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [192 | 200]\n---> Epoch: [192 | 200]\n---> Epoch: [192 | 200]\n---> Epoch: [192 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.3544\n    > [Train]\tLoss:\t16.3544\n    > [Train]\tLoss:\t16.3544\n    > [Train]\tLoss:\t16.3544\n    > [Test ]\tLoss:\t2.6998\tAcc:\t48.8700\n    > [Test ]\tLoss:\t2.6998\tAcc:\t48.8700\n    > [Test ]\tLoss:\t2.6998\tAcc:\t48.8700\n    > [Test ]\tLoss:\t2.6998\tAcc:\t48.8700\n    > [Stats]\tMany:\t0.6751\tMedium:\t0.5106\tFew:\t0.2457\n    > [Stats]\tMany:\t0.6751\tMedium:\t0.5106\tFew:\t0.2457\n    > [Stats]\tMany:\t0.6751\tMedium:\t0.5106\tFew:\t0.2457\n    > [Stats]\tMany:\t0.6751\tMedium:\t0.5106\tFew:\t0.2457\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.68877583815726\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [193 | 200]\n---> Epoch: [193 | 200]\n---> Epoch: [193 | 200]\n---> Epoch: [193 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.5730\n    > [Train]\tLoss:\t16.5730\n    > [Train]\tLoss:\t16.5730\n    > [Train]\tLoss:\t16.5730\n    > [Test ]\tLoss:\t2.6882\tAcc:\t49.0400\n    > [Test ]\tLoss:\t2.6882\tAcc:\t49.0400\n    > [Test ]\tLoss:\t2.6882\tAcc:\t49.0400\n    > [Test ]\tLoss:\t2.6882\tAcc:\t49.0400\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.5086\tFew:\t0.2477\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.5086\tFew:\t0.2477\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.5086\tFew:\t0.2477\n    > [Stats]\tMany:\t0.6803\tMedium:\t0.5086\tFew:\t0.2477\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.688986694166058\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [194 | 200]\n---> Epoch: [194 | 200]\n---> Epoch: [194 | 200]\n---> Epoch: [194 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.6754\n    > [Train]\tLoss:\t16.6754\n    > [Train]\tLoss:\t16.6754\n    > [Train]\tLoss:\t16.6754\n    > [Test ]\tLoss:\t2.7052\tAcc:\t48.9700\n    > [Test ]\tLoss:\t2.7052\tAcc:\t48.9700\n    > [Test ]\tLoss:\t2.7052\tAcc:\t48.9700\n    > [Test ]\tLoss:\t2.7052\tAcc:\t48.9700\n    > [Stats]\tMany:\t0.6774\tMedium:\t0.5100\tFew:\t0.2470\n    > [Stats]\tMany:\t0.6774\tMedium:\t0.5100\tFew:\t0.2470\n    > [Stats]\tMany:\t0.6774\tMedium:\t0.5100\tFew:\t0.2470\n    > [Stats]\tMany:\t0.6774\tMedium:\t0.5100\tFew:\t0.2470\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.689206903307301\nMax state: 2 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [195 | 200]\n---> Epoch: [195 | 200]\n---> Epoch: [195 | 200]\n---> Epoch: [195 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t15.8969\n    > [Train]\tLoss:\t15.8969\n    > [Train]\tLoss:\t15.8969\n    > [Train]\tLoss:\t15.8969\n    > [Test ]\tLoss:\t2.6901\tAcc:\t48.9900\n    > [Test ]\tLoss:\t2.6901\tAcc:\t48.9900\n    > [Test ]\tLoss:\t2.6901\tAcc:\t48.9900\n    > [Test ]\tLoss:\t2.6901\tAcc:\t48.9900\n    > [Stats]\tMany:\t0.6794\tMedium:\t0.5089\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6794\tMedium:\t0.5089\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6794\tMedium:\t0.5089\tFew:\t0.2467\n    > [Stats]\tMany:\t0.6794\tMedium:\t0.5089\tFew:\t0.2467\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.689390968152361\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [196 | 200]\n---> Epoch: [196 | 200]\n---> Epoch: [196 | 200]\n---> Epoch: [196 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t17.1377\n    > [Train]\tLoss:\t17.1377\n    > [Train]\tLoss:\t17.1377\n    > [Train]\tLoss:\t17.1377\n    > [Test ]\tLoss:\t2.6953\tAcc:\t49.0000\n    > [Test ]\tLoss:\t2.6953\tAcc:\t49.0000\n    > [Test ]\tLoss:\t2.6953\tAcc:\t49.0000\n    > [Test ]\tLoss:\t2.6953\tAcc:\t49.0000\n    > [Stats]\tMany:\t0.6780\tMedium:\t0.5100\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6780\tMedium:\t0.5100\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6780\tMedium:\t0.5100\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6780\tMedium:\t0.5100\tFew:\t0.2473\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.689618625435957\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [197 | 200]\n---> Epoch: [197 | 200]\n---> Epoch: [197 | 200]\n---> Epoch: [197 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t15.7495\n    > [Train]\tLoss:\t15.7495\n    > [Train]\tLoss:\t15.7495\n    > [Train]\tLoss:\t15.7495\n    > [Test ]\tLoss:\t2.6860\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6860\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6860\tAcc:\t48.9300\n    > [Test ]\tLoss:\t2.6860\tAcc:\t48.9300\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5063\tFew:\t0.2460\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5063\tFew:\t0.2460\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5063\tFew:\t0.2460\n    > [Stats]\tMany:\t0.6809\tMedium:\t0.5063\tFew:\t0.2460\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.689803130616482\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [198 | 200]\n---> Epoch: [198 | 200]\n---> Epoch: [198 | 200]\n---> Epoch: [198 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.5157\n    > [Train]\tLoss:\t16.5157\n    > [Train]\tLoss:\t16.5157\n    > [Train]\tLoss:\t16.5157\n    > [Test ]\tLoss:\t2.7001\tAcc:\t49.0100\n    > [Test ]\tLoss:\t2.7001\tAcc:\t49.0100\n    > [Test ]\tLoss:\t2.7001\tAcc:\t49.0100\n    > [Test ]\tLoss:\t2.7001\tAcc:\t49.0100\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5077\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5077\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5077\tFew:\t0.2473\n    > [Stats]\tMany:\t0.6806\tMedium:\t0.5077\tFew:\t0.2473\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.69009750715915\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [199 | 200]\n---> Epoch: [199 | 200]\n---> Epoch: [199 | 200]\n---> Epoch: [199 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.2027\n    > [Train]\tLoss:\t16.2027\n    > [Train]\tLoss:\t16.2027\n    > [Train]\tLoss:\t16.2027\n    > [Test ]\tLoss:\t2.6897\tAcc:\t49.1300\n    > [Test ]\tLoss:\t2.6897\tAcc:\t49.1300\n    > [Test ]\tLoss:\t2.6897\tAcc:\t49.1300\n    > [Test ]\tLoss:\t2.6897\tAcc:\t49.1300\n    > [Stats]\tMany:\t0.6834\tMedium:\t0.5071\tFew:\t0.2487\n    > [Stats]\tMany:\t0.6834\tMedium:\t0.5071\tFew:\t0.2487\n    > [Stats]\tMany:\t0.6834\tMedium:\t0.5071\tFew:\t0.2487\n    > [Stats]\tMany:\t0.6834\tMedium:\t0.5071\tFew:\t0.2487\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"9.690300572208564\nMax state: 3 // Min state: 0\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [200 | 200]\n---> Epoch: [200 | 200]\n---> Epoch: [200 | 200]\n---> Epoch: [200 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t16.5171\n    > [Train]\tLoss:\t16.5171\n    > [Train]\tLoss:\t16.5171\n    > [Train]\tLoss:\t16.5171\n    > [Test ]\tLoss:\t2.7062\tAcc:\t48.8800\n    > [Test ]\tLoss:\t2.7062\tAcc:\t48.8800\n    > [Test ]\tLoss:\t2.7062\tAcc:\t48.8800\n    > [Test ]\tLoss:\t2.7062\tAcc:\t48.8800\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5097\tFew:\t0.2460\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5097\tFew:\t0.2460\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5097\tFew:\t0.2460\n    > [Stats]\tMany:\t0.6760\tMedium:\t0.5097\tFew:\t0.2460\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Best ]\tAcc:\t49.2000\tMany:\t67.9714\tMedium:\t51.0571\tFew:\t25.1333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n---> Final performance...\n---> Final performance...\n---> Final performance...\n---> Final performance...\n    > best bAcc (test):\t49.2\n    > best bAcc (test):\t49.2\n    > best bAcc (test):\t49.2\n    > best bAcc (test):\t49.2\n    > best statistics:\tMany:\t0.6797143220901489\tMed:\t0.5105714797973633\tFew:\t0.2513333559036255\n    > best statistics:\tMany:\t0.6797143220901489\tMed:\t0.5105714797973633\tFew:\t0.2513333559036255\n    > best statistics:\tMany:\t0.6797143220901489\tMed:\t0.5105714797973633\tFew:\t0.2513333559036255\n    > best statistics:\tMany:\t0.6797143220901489\tMed:\t0.5105714797973633\tFew:\t0.2513333559036255\n---> Training Time: 0:31:44.54\n---> Training Time: 0:31:44.54\n---> Training Time: 0:31:44.54\n---> Training Time: 0:31:44.54\n","output_type":"stream"},{"name":"stdout","text":"9.690464260534412\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming variance_l1_norm is the calculated variance # If you have multiple variances, create a list\n\nplt.figure(figsize=(8, 6))\nplt.plot(range(len(variance_list1)), variance_list1, color='blue', linestyle='-', linewidth=2)\nplt.plot(range(len(variance_list2)), variance_list2, color='red', linestyle='-', linewidth=2)\nplt.xlabel('Classes')\nplt.ylabel('Variance of L1-norm')\nplt.title('Variance of L1-norm Among Classes')\nplt.xticks(range(len(variance_list1)), [f'Class_{i}' for i in range(len(variance_list1))])\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T05:02:23.233046Z","iopub.execute_input":"2024-01-26T05:02:23.233489Z","iopub.status.idle":"2024-01-26T05:02:25.717506Z","shell.execute_reply.started":"2024-01-26T05:02:23.233451Z","shell.execute_reply":"2024-01-26T05:02:25.716509Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAArUAAAIjCAYAAAAdn+MfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAChYElEQVR4nOzdd3gUVRfA4d9syW4qkITeQRJUBCMgvSMdAcFCr9KRpggIKCJdVJqAgFSliKDSpKqI9CICgiCISP0gIX032TLfH0M2CTWBJJuE8z5PHu7emb1zNqScnL1zr6KqqooQQgghhBBZmM7dAQghhBBCCPG4JKkVQgghhBBZniS1QgghhBAiy5OkVgghhBBCZHmS1AohhBBCiCxPklohhBBCCJHlSVIrhBBCCCGyPElqhRBCCCFElidJrRBCCCGEyPIkqRUim9m/fz/BwcHs37/f3aFkmAsXLtCtWzfKly9PcHAw27dvd3dI4gly6dIlgoODWbt2rbtDEeKJJkmtEOmsd+/elCtXjujo6PueM3ToUMqUKcOtW7cyMLLsY/jw4Zw5c4bBgwczZcoUypQpc8/zEpKPhQsXPnC83bt3M3LkSJo1a8bTTz9N3bp10yPsLGPgwIEEBwczdepUd4eS4fbv30///v2pVq0aZcqUoUqVKvTu3ZutW7e6OzQhxB0kqRUinb388stYrdb7Vg8tFgs7d+6kevXq5MqV67GvV7FiRf744w8qVqz42GNlBVarlaNHj9K6dWs6dOhAixYtyJcv32ONuWHDBjZs2ICPjw958uRJo0izpujoaH766ScKFizIxo0bUVXV3SFlmBkzZtCpUyfOnj3L66+/zgcffED37t2JiYlhwIABrF+/3t0hCiGSkKRWiHRWt25dvL297/sLcMeOHcTGxvLyyy8/1nXi4uJwOp3odDpMJhM63ZPx7R0WFgaAn59fmo05ePBgDh8+zMqVKyldunSajZuWVFXFarWm+3W2bNmC0+lkwoQJXL16lYMHD6b7NTODH3/8kdmzZ9OwYUM2bNjAW2+9RZs2bejRowfLli1jwYIF+Pj4uDtMIUQST8ZvPSHcyGw206BBA/bt20doaOhdxzds2IC3tzd169YlPDycyZMn07x5c0JCQnjhhRfo0aMHp0+fTvachHmzGzdu5NNPP6VGjRquKQ73mlN76NAh3nrrLWrXrk2ZMmWoVasWEyZMuCspGj58OCEhIVy/fp2+ffsSEhJC5cqVmTx5Mg6HI9m5TqeTJUuW0Lx5c5577jkqV65M9+7dOX78eLLzvv/+e1555RXKli3Liy++yODBg7l69WqKPnd//vknPXr04IUXXiAkJITOnTvz+++/u47PnDmTOnXqADBlyhSCg4PTZKpA3rx5MRqNj/z8mTNnEhwczL///svw4cOpUKEC5cuXZ8SIEVgslmTn2u12Zs+eTf369SlTpgx169blk08+IT4+Ptl5devWpVevXvz666+uz+fKlStd/9+bNm1i1qxZ1KhRg5CQEN566y2ioqKIj49n/PjxVKlShZCQEEaMGHHX2A+yfv16qlatSuXKlSlZsuQ9/zhbu3YtwcHBHDp0iI8++ojKlStToUIFxowZQ3x8PJGRkQwbNoyKFStSsWJFpkyZclfFNzY2lkmTJlGrVi3KlClDw4YNWbhw4V3nBQcH8+GHH7J9+3aaNWtGmTJlaNq0Kbt27borrv379/PKK6/w3HPPUb9+fVauXOn6v3mY6dOnkzNnTiZMmHDPr4UaNWq4vvbu5fTp0wwfPpx69erx3HPPUa1aNUaMGHHXFKPo6GjGjx9P3bp1XdMbunbtysmTJ13nXLhwgQEDBlCtWjWee+45atasyeDBg4mKiko2Vkq+11I6lhBZkcHdAQjxJGjevDnr1q1j8+bNdOjQwdUfHh7O7t27adq0KWazmbNnz7J9+3YaNWpEoUKFuHnzJqtWraJDhw5s3LiRvHnzJhv3888/x2g00r17d+Lj4++biP34449YrVbatm1Lzpw5+eOPP1i+fDnXrl1jxowZyc51OBx0796dsmXLMmzYMPbu3cuXX35J4cKFadeuneu89957j7Vr11KzZk3atGmDw+Hg0KFDHDt2jOeeew6AOXPmMH36dBo3bkybNm0ICwtj+fLltG/fnu++++6B1dWzZ8/Svn17vL296dGjBwaDgVWrVtGxY0eWL19OuXLleOmll/D19WXixIk0a9aMmjVr4u3tner/n/QyaNAgChUqxJAhQ/jzzz/55ptv8Pf355133nGdM2rUKNatW0fDhg3p2rUrf/zxB/PmzePcuXPMnj072Xj//PMPQ4cO5fXXX+e1116jePHirmNffPEFZrOZnj178u+//7J8+XIMBgOKohAZGUn//v05duwYa9eupWDBgvTv3/+h8V+/fp39+/czadIkAJo2bcqSJUsYPXo0Hh4ed53/0UcfERgYyIABAzh27BirVq3C19eXo0ePkj9/fgYPHsyuXbtYuHAhQUFBtGzZEtCqzn369GH//v20adOGp59+ml9//ZUpU6Zw/fp1Ro4cmew6hw8fZuvWrbRr1w5vb2+WLVvGW2+9xU8//eSawpPwB1Hu3LkZMGAATqeT2bNn4+/v/9DXfeHCBc6fP0/r1q0fuRq7Z88e/vvvP1555RVy587N2bNnWb16NX///TerV69GURQA3n//fbZs2UKHDh0oWbIk4eHhHD58mHPnzvHss88SHx/v+v7u0KEDgYGBXL9+nZ9//pnIyEh8fX2BlH2vpXQsIbIsVQiR7ux2u1qtWjX19ddfT9a/YsUKNSgoSP31119VVVXVuLg41eFwJDvnv//+U8uUKaPOmjXL1bdv3z41KChIrVevnmqxWJKdn3Bs3759rr47z1FVVZ03b54aHBysXr582dX37rvvqkFBQcmupaqq2rJlS7VVq1aux3v37lWDgoLUcePG3TWu0+lUVVVVL126pD799NPqnDlzkh3/66+/1Geeeeau/jv17dtXffbZZ9WLFy+6+q5fv66GhISo7du3d/X9999/alBQkLpgwYIHjpfacxP07NlTrVOnTorPV1VVnTFjhhoUFKSOGDEiWX+/fv3UF1980fX41KlTalBQkPree+8lO2/SpElqUFCQunfvXldfnTp11KCgIHXXrl3Jzk34/27WrJkaHx/v6h8yZIgaHBys9ujRI9n5r7/+eopfz8KFC9WyZcuqUVFRqqqq6j///KMGBQWp27ZtS3bet99+qwYFBandunVz/f8nXCs4OFgdM2aMq89ut6s1a9ZUO3To4Orbtm2bGhQUpH7++efJxh0wYIAaHBys/vvvv66+oKAg9dlnn03Wl/B5XLZsmauvV69early5dRr1665+i5cuKA+88wzalBQ0ANf9/bt29WgoCB10aJFDzwvQcLX1bfffuvqu9f33IYNG9SgoCD14MGDrr7y5curY8eOve/Yf/75pxoUFKRu3rz5vuek9HstJWMJkZXJ9AMhMoBer6dp06YcPXqUS5cuufo3bNhAYGAgVapUAcDDw8M1F9bhcHDr1i28vLwoXrw4f/75513jtmzZErPZ/NDrJz0nNjaWsLAwQkJCUFX1nuO2bds22ePy5csni3vr1q0oinLPal9CBWrbtm04nU4aN25MWFiY6yMwMJCiRYs+cMkxh8PBb7/9Rv369SlcuLCrP0+ePDRr1ozDhw8/cDWJzOKNN95I9rhChQqEh4e7Yv/ll18A6Nq1a7LzunXrlux4gkKFClGjRo17XqtFixbJKvVly5ZFVVVat26d7LyyZcty9epV7Hb7Q+Nfv349tWrVclUrixUrxrPPPssPP/xwz/PbtGnj+v9PGkObNm1cfXq9njJlyvDff/+5+nbt2oVer6djx47JxuvWrRuqqt41taBq1aoUKVLE9bh06dL4+Pi4xnQ4HOzdu5d69eole3ejaNGi9/38JZXw//M4Vf+k33NxcXGEhYVRrlw5gGRTC/z8/Dh27BjXr1+/5zgJn/vdu3ffNXUlQUq/11IylhBZmUw/ECKDNG/enMWLF7NhwwZ69+7NtWvXOHToEB07dkSv1wPaPNWlS5fy9ddfc+nSpWTzWHPmzHnXmIUKFUrRta9cucKMGTPYuXMnERERyY7dmRyaTKa73qLNkSNHsuddvHiRPHny3DOmBBcuXEBVVRo0aHDP4wbD/X/8hIWFYbFYkr29nqBkyZI4nU6uXr1KqVKl7jtGenM4HK6b1BLkyJEj2dvyBQoUSHY8YbpFREQEPj4+XL58GZ1OlyxBA8idOzd+fn5cvnw5Wf+D/r/vvFbCW8n58+e/q9/pdBIVFfXA1TbOnTvHn3/+SYsWLfj3339d/ZUqVeKrr74iOjr6rrfmUxND0q+ny5cvkydPnrvGK1mypOt4UneOB9rnPjIyEoDQ0FCsVitFixa967x79d0pIY6YmJiHnns/4eHhzJo1i02bNt01lz7p/NW3336b4cOHU7t2bZ599llq1apFy5YtXX/MFS5cmK5du7Jo0SLWr19PhQoVqFu3Li+//LLr85vS77WUjCVEViZJrRAZpEyZMpQoUYKNGzfSu3dvNmzYgKqqNG/e3HXO3LlzmT59Oq1bt2bgwIHkyJEDnU7HhAkT7rmUUkqqtA6Hg65duxIREUGPHj0oUaIEXl5eXL9+neHDh+N0OpOdn5BgPy6n04miKMyfP/+eY3p5eaXJddzl6tWr1KtXL1nf0qVLqVSpkuvx/VaguPP/Mml180Ee9P99v2ulNIY7JVRjJ06cyMSJE+86vmXLlruqwKmN4VHd72v0Ya8ppUqUKAHAmTNnHnmMQYMGcfToUbp3787TTz+Nl5cXTqeTHj16JIuzSZMmVKhQgW3btvHbb7+xcOFC5s+fz8yZM6lVqxag3cDZqlUrduzYwW+//cZHH33EvHnzWL16Nfny5UvV99rDxhIiK5OkVogM1Lx5c6ZPn87p06fZsGEDxYoVo2zZsq7jW7ZsoVKlSkyYMCHZ8yIjIx95DdszZ85w4cIFJk+e7LoxB+C33357pPEAihQpwu7duwkPD79vtbZIkSKoqkqhQoXuWXF9EH9/fzw9Pfnnn3/uOnb+/Hl0Ot09q3UZKXfu3CxatChZX2qX/ypYsCBOp5N///3XVZUEuHnzJpGRkRQsWDBNYk0tVVVZv349lSpVSnZzYILPP/+c9evX35XUPqqCBQuyd+/eu6q/58+fdx1PjYCAAEwmU7IKc4J79d2pePHiFC9enB07dhATE5PqaQgRERHs3buXAQMGJJuic+HChXuenydPHtq3b0/79u0JDQ2lVatWzJ0715XUgrbqQ3BwMH379uXIkSO0bduWFStWMHjw4FR/rz1oLCGyMplTK0QGSqjKzpgxg1OnTiWr0oJWgbqz2rR58+b7zrdLiYQqWdJxVVVl6dKljzxmgwYNUFWVWbNm3XUs4ToNGjRAr9cza9asu16TqqoP3D1Nr9dTrVo1duzYkWwu782bN9mwYQPly5d3+xqhJpOJqlWrJvvIkSNHqsZISFqWLFmSrD8hWU6a1GSkw4cPc/nyZV555RUaNWp010eTJk3Yv3//Y31dJlWzZk0cDgdfffVVsv7FixejKAo1a9ZM1Xh6vZ6qVauyY8eOZDH++++//Prrryka46233iI8PJxRo0bdc/7x7t27+emnn+57/Xu58//Z4XDctZRWQEAAefLkcS27Fh0dfdf1g4KC0Ol0rnNS+r2WkrGEyMqkUitEBipcuDAhISHs2LED4K6ktnbt2syePZsRI0YQEhLCmTNnWL9+fbKbpVKrRIkSFClShMmTJ3P9+nV8fHzYsmWLa/7ho6hcuTItWrRg2bJl/Pvvv9SoUQOn08nhw4epVKkSHTp0oEiRIgwaNIhp06Zx+fJl6tevj7e3N5cuXWL79u289tprdO/e/b7XGDRoEHv27KFdu3a0a9cOvV7PqlWriI+PT7Yk1qPYu3cvcXFxd/XXr1+foKAgTp8+zc6dOwEtEYqKiuLzzz8HtGpsWm2bW7p0aVq1asWqVauIjIykYsWKHD9+nHXr1lG/fn0qV66cJtdJrfXr16PX66ldu/Y9j9etW5dPP/2UTZs23XWT26OoW7culSpV4tNPP+Xy5csEBwfz22+/sWPHDjp37nzXnOOU6N+/P7t376Zt27a0bdsWp9PJ8uXLKVWqFKdOnXro85s0acJff/3F3Llz+fPPP2nWrBkFChQgPDycX3/9lb179zJt2rR7PtfHx4eKFSuyYMECbDYbefPm5bfffkv2Bxpoc3Zr1apFw4YNKV26NF5eXuzZs4fjx48zfPhwAPbt28eHH35Io0aNKFasGA6Hg++//x69Xk/Dhg0BUvy9lpKxhMjKJKkVIoM1b96co0ePUrZs2btuWunduzcWi4X169ezadMmnnnmGebNm3ffX54pYTQamTt3rmvunMlk4qWXXqJ9+/a0aNHikcedOHEiwcHBrFmzhilTpuDr60uZMmUICQlxndOzZ0+KFSvG4sWLXWuu5suXj2rVqj00MSxVqhRfffUV06ZNY968eaiqStmyZZk6darrLvJH9euvv96zYlewYEGCgoL4888/mT59erJjCY9btWqVZkktaGu7FipUiHXr1rF9+3YCAwPp1atXitaRTQ82m40ff/yRkJCQ+04tCQoKolChQvzwww9pktTqdDrmzJnDjBkz2LRpk2st3WHDhrlWgkitMmXKMH/+fKZMmcL06dPJnz8/b731FufPn3dNa3iYwYMHU7lyZZYtW8aKFSuIiIjAz8+PcuXK8fnnn981pzqpadOmMW7cOL7++mtUVaVatWrMnz8/2eoLZrOZtm3b8ttvv7F161ZUVaVIkSK8//77rmkfwcHBVK9enZ9++onr16/j6elJcHAw8+fP5/nnn3eNlZLvtZSOJURWpahpNbNeCCGEyOT69u3L33//zdatW90dihAijcmcWiGEENnSndtAX7hwgV27dvHiiy+6KSIhRHqS6QdCCCGypfr169OqVSsKFy7M5cuXWblyJUajkR49erg7NCFEOpCkVgghRLZUo0YNNm7cyI0bN/Dw8OD5559nyJAhFCtWzN2hCSHSgcypFUIIIYQQWZ7MqRVCCCGEEFmeJLVCCCGEECLLk6RWCCGEEEJkeZLUCiGEEEKILO+JWf0gNDSKjLglTlEgIMCX0FBtP+8HtcPCovD3T9m5MoaMIWO4b4ysHr+MIWPIGDLG44yRkfnT43hiklpVJUP+U5JeL6Xt1JwrY8gYMob7xsjq8csYMoaMIWM8yvOSPs7MZPqBEEIIIYTI8iSpFUIIIYQQWZ4ktUIIIYQQIsuTpFYIIYQQQmR5ktQKIYQQQogsT5JaIYQQQgiR5UlSK4QQQgghsjxJaoUQQgghRJYnSa0QQgghhMjyJKkVQgghhBBZniS1QgghhBAiy5OkVgghhBBCZHmS1AohhBBCiCxPklohhBBCCJHlSVIrhBBCCCGyPElqhRBCCCFElidJ7RNk/349r77qSYcOsHatgfBwd0ckhBBCCJE2DO4OQKQ/VYWZM2HIEE/sdgWAr77yRK9XGTQI3n33Hk+Kj0f/z3k450Tv0KP6+oJvsYwMWwghhBAixSSpzebi42HQIDPffAOg3O5VyUk4eR3X+XqaHzEROfh8WhQeP3xH3JrNxP5xiIBr51EcDgByJQymKOTKkxdnkSLQvRu80hYU5e6LCiGEEEJkMElqs7mZE+Op8s0YunKaXNyiRM5Q/K1XMVhjEk9aAI6FevxUx4MHU1X016+hv34NDh7A8+oNLP0Hpu8LEEIIIYRIAUlqs7HLl1SenzOA11mR2Bl+73P1SRLaWDw5TWluBARTq3VuiAxDiYzAFHoD5z8X0P3vOgDeY0fjzJ8fenVPx1chhBBCCPFwktRmYxvbf0VPx4pkfU5fP3QF8hOfrwDOPHm48peVa3/8Dy9i2U11fs3ZjO22OoTFmCAUyuyBFSuiyZdPxRToS9jNKDynTcF70kcA+AzoA3n8oUY9d7xEIYQQQghAktps69y2f3ljV1/X46g5y4lr2QQMBgIDfYm8GQVAiUBftsyxsGmTJ3XqWPnkdRtXr5po3NjJzZs6TpyAli29+O67WAIDtbEsQ97B+9YNmDcPxWaDV17B74XyMHoUVK0DOllUQwghhBAZS7KP7CYqCo9NG8jVqxN+aInr7+U64Nu7PRju/TfMa6/ZWb8eOnWyYTJBhQqwYUMshQs7ATh3TkeLFl5cvnz7CYoCs2YR17S5awzjkcPQqhU5a1bGtOprsNnS9WUKIYQQQiQlSW124XDg/c5g1IAA/Dq3IyjqKAD/6kuQe+XkVA9XsqTK99/HUry49vj8eR1ly0LHjmamTfPg4hUDUQuXEvnFIihXzvU8w1+n8e3fG4KCMBzYnyYvTQghhBDiYSSpzSa8pkzAc/FCbTrAbdfJw5F3l2AK9H2kMQsXVvn5ZyhWTKvYhoXBjz8amTTJRJkycOackfhWreHoUSJXfAPVqyc++cIFcrzaEuPuXY/zsoQQQgghUkSS2uzgxx/x+mQqAHb0zKIfTdnA6onnqTG43EOe/GBFisD338fSrJmNHDkS+6OioEsXM9HRgKJge6kh/Por4eu3YHuxMgBKbAx+bdvAli2PFYMQQgghxMNIUpvF6S5fgg4dXI9HMJHBhpk0n1OXAcO90+QaBQqoLFpkJSwM9u6N5plntOW/zp7VM3iwGVVNPNdeuQoR3/4AzbX5torVCi+/jHHr5jSJRQghhBDiXiSpzcpUFZ8+PSE0FIAfaM40hjJrlpU2bexpfjmdDp56SuXLLy34+Wl9331n5LPP7jjRbIY1a4hr1kJ7HB+PX+f2eKz/Ps1jEkIIIYQASWqztu3bMe7ZDcAFitKFxZQtp+OVV9I+oU2qZEmVJUsSHw8dCl9/fcfKCh4eRM1fhLX1qwAodju+b3aByZPx2Lge466fwWpN1ziFEEII8eSQpDYrGz/e1RzGFG7hz5gx2opb6a1lSxg8OA4AVYWBA83JEl0ADAaiZ38BXboAoDgcMHw4fl3ak6P1y1CqFPq/z6Z/sEIIIYTI9iSpzaIM+/fBL78AcJpgvqU1Tz/toGXLjIthxIh4evWKB0BVFbp2he++u6Niq9fDwoVYOne7e4BLl/Br1Qzd+XMZEK0QQgghsjNJarMor0+nutqTGI4TPUOGxGfoZl6KAuPGxfHWW9pjVYW33zZz/fodpWKdjpipnxLx3UaYMYOYUR9gf+ZZAPTXrpKjVTM4fz7jAhdCCCFEtiNJbRakP/Y7Hju2Adpc2q9oT1CQg+bN03cu7b0oCnz2GbzyirY+bkSEwpgxpnueaKtWAwYMwDJwCBFrN8BzzwGgv3IZmjSRObZCCCGEeGSS1GZBXjM/c7WnMAw7Rvr3j0evd088igITJ8bh7689XrvWyNatD36OGhAA27djDwrWOv76C6+pk9I3UCGEEEJkW5LUZjWhoXhsWg9oO4Z9STfy5yfdVzx4mIAAlY8/Tnzcpw9YLA95Up48RH25DNXDAwDzrOlw5Ej6BSmEEEKIbEuS2qxmxQrXVrhL6UQcZgYOBNM93vHPaF26QJUqWnJ9/jxMnvzwoBzBpYkd8g5we3WE7t0hyVa/QgghhBApIUltVpNk3awldMbbW6VXLzfGk4SiwLRpcXh4aFuMff65kd9+e/icCMuAwa75tfz+O54zPk3PMIUQQgiRDUlSm4XoT5+CQ4cAOMwLnKQMHTvayJnTvXElVaqUk5EjE9avVejXz0x4+EOe5OEBX36JenvpBq+pEzEcOpC+gQohhBAiW5GkNgsxrfra1V5CZ/R6XOvEZiZ9+tioXVtrX76so3//FDypQgUsg4cC2jQE317deXg2LIQQQgihkaQ2q7DbMX2zCgAbBlbQlvr1oXBh1c2B3U2n02ZJ+PlpsX31FcyY4fHQ51neGQFVqwKgv/gv9O6tLX4rhBBCCPEQktRmEcZffkJ//RoAG2nKTXLTqpWbg3qAIkVg6tTEdWfHjTMxYYLHg3NUgwG+/hpnjpza41WryNG8Eaali+DWrXSNVwghhBBZmyS1WYTph+9c7cV0QVFUWrRwXzwp8cordkaNinM9/vRTE4MHP6T4WrQo0Z/OdD007t+L79CBULQoHls2p2O0QgghhMjKJKnNIgyHDwLa1IMfaUSFCk7y5XNzUCkwcGA8MxNzVKZPh/XrDQ98TnzzFkTNmgulSyd2RkXh27kdpq+Xp1OkQgghhMjKJKnNCqKj0Z/5C4A/KEscZpo0yTprufbvD598knwqQlzcA54AxL3eDv78k1vbfyGuaXPg9g1kA/vClCnpGa4QQgghsiBJarOCo0dRbr9nf4gKADRu7N4dxFKrQwcbNWpoMV+4oGPRIuPDn6QoOMqFEPXlMnjrrcT+d9/F+NOOdIpUCCGEEFmRJLVZwe21aUFLakuXdlCyZNZaFUBR4IMP4lAU7fG0aSbCwlL4ZJ0OPvuMmHdHurq8x44BhyPtAxVCCCFEliRJbVZwR1Kb1aq0CcqWddKpk9YOD1f46KNUPFlRsAwZhu35EAAMJ49jWrMq7YMUQgghRJYkSW1WcDuptWLiBGVo0iRrJrUAH30Enp5alXnmTPjjj1R8Cep0xL4/zvXQa+JHYLGkdYhCCCGEyILcmtQePHiQ3r17U716dYKDg9m+fft9zx0zZgzBwcEsXrw44wLMBJTICDhzBoDfeR5Vb+TZZ51ujurRFSoE/ftru6DZ7dCnjzlVeamtek1o0gQA/eVLJFtaQQghhBBPLLcmtbGxsQQHB/P+++8/8Lxt27Zx7Ngx8uTJk0GRZR6GP4652oeoQIkSYEzBPVaZ2aBB8ZQtq82HPXNGz4cfmlI3wOTJqLrbX7rvv495yZey85gQQgjxhHNrUlurVi0GDx7MSy+9dN9zrl+/zrhx4/j4448xZvVs7hEYjh5xtQ9RgVKl3BhMGvHwgDlzrJjN2uMFCzzYsiUVA5Qpg7VDZ61tteLz9iB8u7SH0NA0j1UIIYQQWUOmnlPrdDp555136N69O6UeM5tTlIz7SHq9h7Ufdtxw7KjrNRyiAkFBqR8jLeJI6zGCg51MnZr4/9OpE1y5oqR4jNgJk7F27e56vmnTBqhYEf3fZ7Pk50PGyPxjZPX4ZQwZQ8aQMR5njIz4eFyKqmaO922Dg4OZPXs29evXd/XNmzeP/fv3s3DhQhRFoW7dunTq1IkuXbq4L9CMVqIE/PMPMXiRgwhmzDbQt6+7g0obqqpNj/3xR+1xpUrwyy9gSs1shO+/h+7dE6u0AQHwww9QtWqaxyuEEEKIzOvB+5W60YkTJ1i6dClr165FSYP0PTQ0KkOmXSoKBAT4EhoaBTy4HRYWhb//A46fvYD/P/8AcJQQHBgICiJVY6RFHOk5xowZUdSr581//+nYvx8GDICJE1MxRosW3CoRjG/bVzGcPKElt/XqETvkHawdu+BfukSW+nzIGJlzjKwev4whY8gYMsbjjJGR+dPjyLTTDw4dOkRoaCh16tThmWee4ZlnnuHy5ctMnjyZunXrpno8Vc24j6TXe1j7Qcf1v/+e+Pm4vZNYqVKpGyMt4kjPMXLlgsWLLa75tfPnw6JFxlSN4chfkIj1P0JCld9qxWvCOHKVexq6dIGboVnm8yFjZN4xsnr8MoaMIWPIGI8zRkZ8PK5MW6lt0aIFVe94C7l79+60aNGCV155xU1RZaykKx8cpjwmk0rhwkrKd+LKIsqWdTJ/PnTsqD0ePtxEoUJO3ngj5WOovn6wcSPWnn0wL10EqooSHw9LluB34iQR320CHu8vQCGEEEJkXm6t1MbExHDq1ClOnToFwKVLlzh16hRXrlwhV65cBAUFJfswGo0EBgZSokQJd4adYfTnz7naJyhD8eJOdJm2tv54OnSAvn219WsdDoUePTxJUqhOGQ8PYqZ9BufOEdt/IM4cOQEwHj6Ez6B+afNnoBBCCCEyJbemSCdOnKBly5a0bNkSgIkTJ9KyZUtmzJjhzrAyDf0/513tc5SkZMmsu+lCSnzwQRwJRfiYGIUmTeDy5UeYT128OLHvjyNi3Qbw8gLA/O03MHFiGkYrhBBCiMzErdMPKlWqxF9//ZXi83fu3JmO0WQ+utuV2uvkIQo/SpSIc3NE6Uung+XLoWZNB4cO6bl6FYYNM/PVV4+2Fa7jubLagAmZ8nvvYfL1J65t+zSMWgghhBCZQTZ9MzsbiIlBf/0aAH/zFAAlSmT/t889PWHZMgv58mlV6a1bDezapX/0AVu1ImbkGNdDn4F9MX21DADlf//DY8MPcHuFCSGEEEJkXZLUZlbnEufTnkXbeCK7Tz9IEBioMmpUYlV6zBgTDsejj2cZNBRLj14AKKqK76B+UK0a/s8F4de1A1SqhCK7kQkhhBBZmiS1mdXffyc2XZXaJyOpBXj1VTvly2vtkyf1LFr0GIMpCjETpsCgQYl9e/agOG9/Pm/cwHPOrMe4gBBCCCHcTZLazOqOpNbHRyVPnuw//SCBTgeffJL4eNQoiIp6jAEVBT75hNh+b7m6HEWLoRqNAJgXzEMJk2qtEEIIkVVJUptZnT3rav7NU5Qo4UyTfZGzkpo1oWlTGwDXr0P79p5ERz/GgIpC7AcfEb55Oxw6xK2Dx7C27wSALiYaz7mz0yBqIYQQQriDJLWZ1R2V2idlPu2dxo6Nw89Pq1Dv3Wvg9dc9H69iC9grvAjly4OiYBk4BBKqtfPnke12thBCCCGeEJLUZla3k9obBBJBzidqPm1SRYuqrF0bS65c2uMDBwy89BJcu5Y2ZWtnocLQtSsAuugobZ5DfHyajC2EEEKIjCNJbWZkscClS0DiTWJPaqUWoFw5Jzt2QK5cWsV2/36oXduL7dsfY6mvpEaMQDXcXrJ5zhxyVnwe5syR5FYIIYTIQiSpzYT0FxLXTU1Iap966slNagFCQmDt2lgKFNA+D6GhOtq29WLIEIiNfczBixUjdthI10P95UvQty+5alTCuPXHxxxcCCGEEBlBktpMKOn2uAlJbalST3ZSC1CmjJOffoqhefPEvk8/hVq1vPn118er2loGv034jzugSRNXn/78OXK0fw2aNEH53/8ea3whhBBCpC9JajOhO5PaokXBx8eNAWUi/v7w/ffw0UdWTCZtOsKFCzpeecWL999/vLHt5SvCxo2Eb/0JqldPPLB5MznatoGYmMe7gBBCCCHSjSS1mZAuSVJ7llI884wbg8mEFAV69bLx888x1KiR2P/hh3D48ON/STteKA+7dhH5xZc48+QFwPDH7/j27s5jbW0mhBBCiHQjSW0mpD+fuEXu3zwlSe19PPWUys8/w5AhiVvqDhtmTpu8U1GIb9WGiLXrwc8PANOPm2DIELDZ0uACQgghhEhLktRmQgnTD8LIxS38Jal9AJ0O3nknnqef1jLZY8f0LFyYduM7gkvDmjWo+ttzdmfMwP/pkvj07w0//5x2FxJCCCHEY5GkNrOxWtFdTr6clyS1D2YwwKRJidXaESPSeA+Fl14ieuqnroe6iHDMq76GOnXwGdAHJTIiDS8mhBBCiEchSW0mo7/4L4qq3QCVkNQ+/bQ7I8oaqlZ10K6d1g4Lg3HjTGk6flzHLkR8+wO0a4fTx9fVb175FTlrVIZt29L0ekIIIYRIHUlqM5k7Vz7Il89JjhxuDCgLmToVvL21PwiWL/dg16402pzhNlvN2vDVV4SdOkfUtOngqyW3+iuXoWFDPGd8Crf/IBFCCCFExpKkNpPRXfrP1b5AMYKDZX3alCpQAMaMSZyGMHiwmejodLiQ2Uxcp65w4gTxtepofaqK97j38e3VDcLD0+GiQgghhHgQSWozmYT5tAAXKUJQkCS1qdG1q41atbT2xYs6hg9Px4sVKULk6nXEvJu4G5lp3bfg70+OGpWhb99kf6QIIYQQIv1IUpvJ3JnUSqU2dXQ6WLgQvLy0aQCzZ8PmzYZ0vaDl7eGwbh1O79s7ZKgqhlN/wpw5+L7ZRaYkCCGEEBlAktpMRn8pMam9RCGp1D6CkiVh5MjEaQhdupj5/HNj+uaWLVsSvuMXLN17QkiIawkw46GDGLf9mI4XFkIIIQRIUpvpJFRqbxCIBS+Cg2UHq0fx5ps2WrTQNklwOhXef99M164QH59+13SWLEXMpI/hyBGiFi1z9XtPHA9O+eNECCGESE+S1GYmdju6a1cBbepB7txO/P3dHFMWpdPBF19YGTMmsW/JEujSxROrNf2vb2vcFMqXB8Bw4g9Yuzb9LyqEEEI8wSSpzUyuXkW5vcfrfxSWqQePSaeDsWNhwQILnp7a3INt2wx07OhJbGw6X1xR4KOPEh+PGUPa7N8rhBBCiHuRpDYzuXgxsSkrH6SZFi3srFhhwdtbe/zzzwaaNAGLJZ0v3LAhtoqVtPapU/j26IL+xPF0vqgQQgjxZJKkNjP5L3H5p/8ozFNPSVKbVqpVc7B1K/j6ahXbX36B3r3N6Vs8VRRiR452PTRt+J5cdarByy+j3ErLfXyFEEIIIUltZnJHpbZoUUlq01LVqvDtt7GuXcc2bTIycqQpXVdFsFWvSfTHn0FgYGLn+vX4vtkV7Pb0u7AQQgjxhJGkNjNJUqm9SBGKFJH1TdNaSIiTRYssGG4vXfvllx507gxffmnkp5/0REWl/TWtnbvBv/8SPeljnLfv/PP45Se8PxiV9hcTQgghnlDpuCq9SLUkldr/KEzhwlKpTQ916jhYsAC6dNEeL1sGYAbA0xMaNNCW/6pSRbvZLE14eWHt3hP7M2XI2bo52Gx4zvscKleEZq3T6CJCCCHEk0sqtZnJ7aTWjh5bQH58fNwcTzbWuTN88IEVgyF5Ndxige+/N9KyJQwYYE7zqQn2KlVh1qzEjp49Ma1ZlbYXEUIIIZ5AktRmIurt6QeXKETREno3R5P99etn4/ffY9ixAz75xErnzvEEBCQeX73ayKJFxrS/cM+eWLp219o2G7593sRrygTZTlcIIYR4DJLUZhaxsSihoYA29aBYMfeG86TIm1elbl3o2NHGxx/HcfWqluAmGD3axKFDaX/dmAlTsXTu5nrsNXUStG9PhuwMIYQQQmRDktRmEvorl13tixSheHE3BvMEMxqhUycbgwZpj+PjFV59FW7cUNL2QgYDMVM/hWnTUJXbY69YQY5XmqPcvJm21xJCCCGeAJLUZhK6S8lXPpCk1r0mT4YKFbRFbC9cgCpVvFmwwJi2q3ApCgwZQtTSFaheXgAYD+4nZ6O6cPhwGl5ICCGEyP4kqc0kdJcuudoy/cD9PDxg/nwLuXNrK1BERCiMGGGmQgW4fDltq7bxjZoQ/sOPUKAAAPp/L0CFCvi+0QZ2707TawkhhBDZlSS1mYT+SmJSK5XazKFQIZWdO2Pp1Cmx79gxePVVT8LSeEMwR7nn4cAB7M+Vc/V5bN8KNWrg90pzDIcOpO0FhRBCiGxGktpM4s5KbdGibgxGuOTLp7JkCWzeHEOxYlrV9uxZPe3aeREdncYXK1iQ8E3biJ44FYoUcXV7/PoLORvXh/r18Ro7GvOCebBtG0p0OuwUIYQQQmRRktRmErrLiUmtNXchzGY3BiPuUqGCk2+/jSV/fu3x4cN62rRJh51uzWasPXrB338TNXsulCyZeGzHDrxmTcdnxDvQoAH+TxUhx0u1YPp0WQ5MCCHEE0+S2kxCuV2pjcKHHEVzuDkacS9Fiqhs2QI5cmgJ5JYt8PHHHulzMaOR+NfbwalTRH0yE0fBQnedojgcGH8/CoMG4f3+e5LYCiGEeKJJUpsZqKpr+sF/FKZIUUlOMqvnnoNlyyyuncg+/dSDPXvScaMMo5G4jp25dfg4nDlDxLc/EPXZbOjTB/vTz7hO85wzC8/PpqVfHEIIIUQmJ0ltJqCEhaGP1xbdv0gRihRxujki8SBVqjh49914AJxOhT59zNy6lc4X1euhVClsNWsT174jfP454bv2EfXJDNcp3hM+hLlz0zkQIYQQInOSpDYT0F276mpfpiBFikilNrMbMCCe2rW19pUrOnr0cM+7/3Edu2iL6ibo3x/D4YMZH4gQQgjhZpLUZgK60MQdpG6QWyq1WYBeD8uWQa5cWia7di3MmJFO82sfZtgwYvsO0NoOB7593iTtl2YQQgghMjdJajMBRZLaLKlQIZg50+J6PH68B1u3puP82geIHfUBtvIVAND/cx6fMSPhxAm8B/aDqlUx7NvrlriEEEKIjCJJbSagu5mY1IYqgRQsKNMPsoqGDR0MHx4HgKoq9OrlyalTbgjEaCRq9hfg7Q2AedlieO45zF8tg7178e3ZFaxWNwQmhBBCZAxJajOBpNMPHP6BGI1uDEak2pAh8bRpo7WjoxWaNEn7rXRTwlnyKfjss3se01+9gnnxwowNSAghhMhAktRmAvaroa62R8EAN0YiHoWiwOLF8OyzDgAuXICWLb24csUNwXTvjvW1N7R2kSLEDnnbdchr+jSZayuEECLbkqQ2E4i/klipNRcOdGMk4lF5e8PKlRaKF9fmQ//zj4569eB//8vgiq2iED1rHmFHT8K5c1hGjoHXXwduT3OZOTNj4xFCCCEyiCS1mcGNxEqtsYAktVlVvnwq69bFUqyY9vj0aejd25zxS30pCs5ChcFg0B6PHYuqu/2tPmUKSmjo/Z8rhBBCZFGS1GYChjCtUhuDF375PN0cjXgcBQuq7NwJ+fJpFdtffzWwcqXBvUEFBxP3WlutHR6O/wtl8BnyFhw75t64hBBCiDQkSW0m4BGpJbU3yI2/v6x8kNUVLw6ffZa40sD775v53//cGBAQ+85wnDlyAqDExmirI5Qvj3HrZrfGJYQQQqQVSWrdzeHAHKO9HXyD3AQESFKbHdSv76Dt7eLorVsKQ4a4Nx5nkaKEb9kJvXvj9PHVOh0OfN/qi3LtmnuDE0IIIdKAJLXuFhaGDi2R1ZJa2Xghu/j0U8iZU/u//eorWLzY6JatdBM4Sz4Fc+YQdvwv4ho2BkAXGorvgN7glK87IYQQWZskte5240ZiUyq12UrevPDBB4nTEN55x0zXrmaS7LXhHj4+RE//HPLlA8Dj550waRJKVKSbAxNCCCEenSS17nZHUitzarOXdu3sdO0a73q8caORcuXcszlDUmpAACxZktjx3nsElChErpBn4ZNPcGtJWQghhHgEktS6W5KkNlTJTY4cboxFpDlFgSlT4li7Fvz9tbf4r1yB6dM93BwZ0KABlj79k3XpL/0HQ4diWr7UTUEJIYQQj0aSWndLktRafHKjk/+RbKlVK/j551i8vLQK6OrVRqKi3BwUEDN2PJHzFsKbb2Kr+KKr32fE2+iP/+HGyIQQQojUcWsKdfDgQXr37k316tUJDg5m+/btrmM2m42pU6fSvHlznn/+eapXr86wYcO4fv26GyNOB0mSWlvO3G4MRKS3/PlVXn3VBkBMjMKqVUY3RwQoCvGvvApffEHEpu1YuvbQuuPi8OvWEX79FY8NP8C334LV+pDBhBBCCPdxa1IbGxtLcHAw77///l3HrFYrf/75J3369GHt2rXMmjWLf/75hz59+rgh0vRju5qY1KqBktRmd9262VztRYvcuxrCvcSMmwgVKgCgv/AP1KyJb5cO0KYNPm8Pcm9wQgghxAO4daujWrVqUatWrXse8/X1ZdGiRcn6Ro8ezauvvsqVK1coUKBARoSY7uIv3yChXqfkkaQ2u3vmGSc1a8KuXXDmjJ6ffoKyZd0dVRImE3zzDc6QEHTh4ckPrV6BZcAgCKzoltCEEEKIB3Hz/p2pEx0djaIo+Pn5pfq5SgbdbJ5wnaTXe1DbcS2xUmsskDvFz3vU68kY7h+jXz8tqQWYPRu++CKTvZZixYhcvQ7zki8x++ck7uIlTN+vQ1FVvKZNhmprMt3nNKPGyOrxyxgyhowhYzzOGOkpLa6jqGrmeAM0ODiY2bNnU79+/Xsej4uLo23bthQvXpxp06ZlcHTpJ6p4WXwvHCcODz56z8q4jzLoq0e4jc0GRYvC1aug18ORI5msWnunmBht798bN7SfOidPwtNPuzsqIYQQIpksUam12WwMHDgQVVUZO3bsI40RGhqVIfMXFQUCAnwJDdVubX9QOywsCs9bWqX2BrkJzK2k6Hl3juHvn7JzZYzMM0anTnFMnmzC4YCmTZ1s2RLLM8/4ZM7XEufE/+234d13tfVrP/qI0BlzM93nND3HyOrxyxgyhowhYzzOGBmZPz2OTL+AlM1mY9CgQVy5coUvv/wSHx+fRxpHVTPuI+n1Hth2qnhEadtL3SA3gYGPMEYqz5UxMscYffvGExLiAODSJR2dOnlisWTi19K3L86AAK1j5Up0p09nus9peo+R1eOXMWQMGUPGeJwxMuLjcWXqpDYhof33339ZvHgxuXLlcndIaUqJCEfvtANaUptb7hN7Ynh5wdKlFgoX1h4fPqynQQNYu9ZAdLR7Y7snHx8sfQZobacTv1dboj95wr0xCSGEEEm4NamNiYnh1KlTnDp1CoBLly5x6tQprly5gs1m46233uLEiRN8/PHHOBwObty4wY0bN4iPj3/IyFmDcvOmq51QqRVPjnz5VNavB29v7c/T3buhVy9PnnnGh9deg/XrDVgsbg4yCUv3ntifKgWA/uoVcjRrCNu2uTkqIYQQQuPWpPbEiRO0bNmSli1bAjBx4kRatmzJjBkzuH79Ojt37uTatWu0aNGC6tWruz6OHj3qzrDTjC401NWWpPbJVK6cVrHNn9/p6rNYFL75Brp29SRfPvj220wy9d3Hh4gffoRKlQDQRUdBw4b4dmqLYc9vafPekRBCCPGI3PrbslKlSvz111/3Pf6gY9mBEnp3pTY21o0BCbeoWdPB0aMxnDrly5Il8axfbyA0VPt7MzIS+vUz4+troV07NwcKqLlzw86dxLV5DdPmjaCqmDZv1Np16qB8uRzV5/Em+gshhBCPIlPPqc3udEmmH0R4BOLl5cZghFvp9VC7NkydGseJEzFs2QJNm2q7jzkcCm++6cmBA+6N0cXLi6hFy4n+cAIk3QTlp5/w6d8bnM77P1cIIYRIJ5LUupEuSaU2zlfmHgiNwQANGsCiRVZef13ri41VaNoU/vknk6xjrNdj7dMf/vmHqDnzcebICYBp43o8P/3YvbEJIYR4IklS605JKrW2nJLUiuR0OliyBKpV01bIuHkTxo41uTmqO3h4ENfmdaLmLXRtB+M1eTysX+/mwIQQQjxpJKl1I8fVxKRWlbvExD2YTNqNZHnzam/pb9pk4O+/M0m1NglbvZdg/HgAFFWFDh3QXfzXzVEJIYR4kkhS60aO64mrH+jySlIr7s3PD3r31paxU1WFWbM83BzRfQwfTlzzllo7MhLf3j3AbndrSEIIIZ4cktS6UcI6tXb0mPPlcHM0IjPr3NlGjttfIt98Y+TKFffGc0+KQvRnM3EULQaA8eB+vD6Z4t6YhBBCPDEkqXUjwy0tqb1JILkCMt9byiLz8PWFvn21dny8wmefuTWc+1L9chA1d4G2nAPgOW0KzJ2L/sRxiItzc3RCCCGyM0lq3cgUpU0/uEkgAQGycL14sIEDwWTSvk7mzoWwMDcHdB/2Ci/C2LEAKE4n9OlDztrVIFcuPKdNliW/hBBCpAtJat3FbsdgswIQQQ5JasVD5c0Lb7yhrV0bFQWtWnlx+XImrfAPH058vZeS91kseE8aj1/bNpBkNz0hhBAiLUhS6y4xMYlNvPH3l6RWPNygQfH4+2uVzj//1NOwoRdHjrg5qHvR64n8+hsiVn4LEycS16q1tkYZ4LFzO7zwAobfdrs5SCGEENmJJLXukiSpjcZHKrUiRQoVUtm0KZaSJbXH16/rqFIFRo0yERqayaq2Op221Nfw4UTPXwTbtuFMWLru4kVytmyC97tDITravXEKIYTIFiSpdZc7KrWS1IqUKllSZd8+qFjRAUB8PMyb50HFit7MmuXm4B6kbl3Cd+7GVrmqq8vzy/lQtiz6U3+6MTAhhBDZgSS17pKkOhWLFzlzSlIrUi4wENaujWXgwDg8PbW+qCiFAQPgs88y6Tq2gDN/ASK+2wiffoqaEPg//5CjWUOMv/3q3uCEEEJkaZLUukuSSq3d5I3B4MZYRJZkNsOoUfH8/Td06BDv6h8/3sTnnxvdGNlD6PUwaBC3ft6DrVwIALrICPxeawUrVyY/NzZWS3ZlioIQQoiHkKTWXZIktaqXlxsDEVldgQLw6adxvP++1dX3/vtm5s51Y1Ap4CxRkojvN0GTJgAo8fHQti3eI97R1rT95RdyVX+RHC2bQunSGLf+6OaIhRBCZGaS1LqJIyoxqXV6+bgxEpFd9O9vY9y4xMeDB5N5l/xK4O0N33+PtUNnV5fngnnkqloB6tRB/99FrfPyZfzavQYdOuCx7lsMB/dn3oV6hRBCuIUktW4SdzPx7VSp1Iq0MmoUdO2qTUWwWmHCBJObI0oBg4HoT2YQPXkamLR49Rf/BVWbZ+7Mkzfx3K++wq9nV3I2eQny5sVr/IfanXJCCCGeeJLUuklcWJJKrae3GyMR2c3IkXGuGw9XrzZw5Ii2ideKFQbGjIH//S8TVm8VBWu3N+HAAeylgrQ+Dw9ixo4n7I/T8OWXOP1yJH+O3Y7XZx+Ts0EdOHzYlQQLIYR4MsntSW4SfysxqcVHKrUi7eTMCUOHxjF6tBlVVejfH1TVk337tG/3OXO8mD7dSrt27o3znsqWJXz7Ljx2bsevZhUsfrm1/q5dCa9WB/8j+4g5dRb9ub8xr/pa25nv5HGoUAF/f3/sZctBu7bQ8nVQMmHyLoQQIt1IUusmtvDEpFbxkUqtSFvdutlYvNjMuXOwdy8k/Va/eVNH+/ZerF0LefOa8PZWadAAnn/eXdHewcuL+GYvQ6Av3IxydasBAfDGG1hu95mHDsLevgOG22vc6sLC8Pj5J/j5J7z37idm0jS3hC+EEMI9ZPqBm9gjE5NanZ9UakXa8vCASZOS9xUt6qRRo8TH334Ln3/uwdSpJl56CXr0MGe+XckeJCSE8G2/EP3hBGjcGGfu3K5DnosW4tOvJ9hsbgxQCCFERpKk1k2cEYk3ihlzSKVWpL3WraFFCxseHtrNYz//HMOmTfDxx1a8vO6ef/r990Zq1PBiwwY3BPuoTCasffrDpk2EnfybqDnztXVwAfOa1VClCuYF89BdvQIXLmDYuwf27QOHw82BCyGESGsy/cBN1OjESq0hh1RqRdpTFFi40EqOHEbCw+NcfZ0722jd2kZYmC+XL8dy9qyO8ePNhIXBjRs6WrSA2bMNtGljd/MrSCVFIa7N6/gWyIP62msocXFw+DA+hw/DiHcASLjVLMeLlYlcuFSb4iCEECJbkEqtm6hJNl8w5pKkVqSfe+1W5+MDL7wAVao46NTJxsmT0KiR9la90wn9+plZsyaL/s378stErFqH/eln7nuK8cA+ctavCXv2ZGBgQggh0pMktW6ixCYmtSZ/mX4g3CtfPliyxOpa49bpVOjXz8yKFW4O7BHZq1UnfNc+OH6c2MFvE1+tBrzyCpaevaFQIQD0169BzZr4vdYK07IlEBrq5qiFEEI8Dklq3UQfmzin1uQvlVrhfjodTJoUR58+2mOnU6FzZ9izR+/ewB5HmTLEjhxD5Hcb4dtviZ0wBQ4f1pJcAIcDj5924DtkAJQsiWH/PvfGK4QQ4pFJUusm+jitUmvDgHcuo5ujEUKj08Hs2dCpk1axtdmgc2dPzp1zc2BpKU8eItd8T8zwUVCkSGJ/RAR+nd5Adz47vVghhHhySFLrJobbSW0M3vj4uDkYIZJQFJg8OY46dbQbxW7dUmjWDCIi3BxYWjIYsAwdBhcuEL71J1flVhcWRo62bWQqghBCZEGS1LqJR7yW1Ebjg4+PbO8pMheDARYssPDM7XutTp+GV1/14ubNLLSObUooCvaQ8kQt/RrKlAFAf/4cNGqE4cB+NwcnhBAiNSSpdRMPe2Kl1tdXklqR+fj5wfr1EBDgBODoUT1Nm3px4YJ740oPql8O2LgRZ568WsehQ+Rs+hJ+LZvCoUPuDU4IIUSKSFLrJp4O7UaxGLzxlsUPRCZVogR8952FAgW0x+fP66hSBdatM2S//QuKFCFixRochRPn2Xr89ivUri3zbIUQIguQpNYd4uMxqNp8RYvOO2EDJCEypaefdrJnDzz1lJbFXrsGPXt6Uq2aN0uWZK+daB1ly3Fr3xFYtAh7yae0zpgYfAb0kV3IhBAik0t1Unvr1i3Gjh1LkyZNqFSpEi+++GKyD/FwSdeojTPIXWIi8ytaFDZujKVGjcRdxs6d09GlC1Sp4s3SpUbi4twXX5ry8IAuXQjfvgtHsWIAGPfvg08+cW9cQgghHijVWwYNGzaMixcv0rp1awIDA1GUbHbjSAZQYmNd7XijzD0QWYO/P3z7rYU//vBlzBg7e/ZoPz7+/VfH0KFm5s6FFSsUihbNJnPEfXyImjGXnC0ag6rCqFGYzL44AwMhfyAGG6ieXvBUEdB7actGCCGEcJtUJ7WHDh1ixYoVlC5dOj3ieTLEJCa1NpMktSLrUBSoVw/KlbOwd6+e2bO92LJFO3b2LLRo4cW6dbEEBro3zrRir1IVhg6Fjz+G+Hh83+rjOpYzyXn+uXNjf/Y5qFcHpeXrqPnyZXisQgjxpEv19IMSJUpgtVrTI5Ynhu1W4m5iDklqRRZVpYqDH3+ELVtiCArS5ptevqyjRQsvzp51c3Bpadw47E8/88BTdDdu4PHzThg9Gv8XnsWnTw84eDCDAhRCCAGPUKl9//33mTZtGv369aNUqVIYjcl3w/KRnQQeyhKaWKl1ekpSK7K2F15wsm6dhddf9+HECbh6VUelSjBhgoHWre0PHyCzM5uJXLcB/13bibnyP4iNwRsHltBwFIsF8/+u4jxyBF1YGACKzYZ5zWpYs5ocFSth6dkHurR384sQQojsL9VJrZ+fH9HR0XTu3DlZv6qqKIrCqVOn0iy47Co+LElS6yV/BIisL08elZ07oU4dBydP6rl1C/r08WT9ehuLFpHlV/hQAwPhzTex3IwCwDvQl5jbbXOgL2E3ItH9ewH/tStxzpvnSnCNB/djPLgfxo7C3LUHDOwPeLjrZQghRLaW6qT27bffxmg0Mm3aNAICAuRGsUcQfysxqZVFakV2kTs3fPddLMOGmVm3TnsHZ9MmI3Xrwo8/ujm49KYoOIsVhwkTCOszCNOa1fgunAsnT2rHL13Ce9wH8PFkfJq9TNwrr0KbFm4NWQghsptUJ7Vnz55l3bp1lChRIj3ieSLYwhOX9FJ8JKkV2UfOnPDFF1batzfSu7eTmzd1nDwJ779vYuFCd0eXQTw9ievYGd9B/YhYtwHzF3Mwbf1RW0HBYsH8zSrM36yCgXnw7NEby5u9IdDX3VELIUSWl+obxcqUKcO1a9fSI5YnhiMisVKr85WkVmQ/rVtrO5GZzdryXl9+6cGGDW4OKqMpCraatYlavgrOnMHSq4+W9Sf43//wnvAh/hXLwmefgdPprkiFECJbSHVS26FDB8aPH8/atWs5ceIEp0+fTvYhHs4RmZjU6nPInFqRPQUHO/nww8QdGbp2hSlTPHjvPRMffABJlmvO/p56itjxk+HaNSKXriCueUvQaT9+dTdvwuDBeH04xr0xCiFEFpfq6QeDBw8GYOTIka4+RVHkRrFUUKMTf5sbc0qlVmRfXbrY2L3bzA8/wM2bMHWqyXXswgUTH3+cXbYhSyGTifjGTYlv3BRT6BWsI0dhWvctiqriNXsGtjr1oPXL7o5SCCGypFQntTt27EiPOJ4oakzinFpJakV2piiwcCGUK+fkypXkbwx99ZWRfv3is81GDakWHEz0vC+xh7yAz2itSODTrxfUroaskCCEEKmXqukHNpuNzp07Y7VaKViw4D0/xMMpSZJac4AktSJ7CwyEbdti+eYbWLEilh494gGw25VkldsnlbVnX2jQAAD99WvQo4d2U5kQQohUSVVSazQaiYt7wt4uTAe6JJMJTQEyp1Zkf3nzqrRpA/XrOxg5Mo6AAK1/zRqDa9WrJ5ZOB4sX40z4pHz3HV4Tx7k3JiGEyIJSfaNY+/btmT9/PnZ7NtgpyE101sRKrWegVGrFk8XXF959V2urqsIYuT8K8ucnevrnroden36M52fT3BiQEEJkPameU3v8+HH27t3L7t27CQ4OxtPTM9nxWbNmpVlw2ZXBmlip9c4jSa148vTrBx9/7OR//9Oxdi1066anUiWHu8Nyq/iGjYmeOBWfEe8A4D1+LNitGGq/hP3Z5wBZy1YIIR4k1ZVaPz8/GjZsSI0aNciTJw++vr7JPsTDGeOjXW1JasWTyMsLhgyJdz3u1cvM7Z1lAbh1C57EN4OsPXrBlCmJHZMnk7NxfQKKF4A33kC5ft19wQkhRCaX6krtxIkT0yOOJ4pHvDb9IA4PfHMZSHLfmBBPjM6dbaxbZ2D/fgOXL+vo29eTRYtgwAAz339vxN8fXnrJTNOmdtq1c3e0Geidd4gJi8B70nhXl+JwwKpV5Ny6FWbOhAbNtaUlUiomBuP+vVCvJrKyghAiu0p1UpsgLCyM8+fPA1CiRAn8/f3TLKjszsOuTT+Ixgd/M5LUiieSwQDz51upV8+HGzdgxw4DJUqA3W4EICwMVq0ysmqVke++g3nz3BtvRrIMfZf4Js3J9cchrL/tw2PrZnShoehu3YIOHciVNx/2ChWhUkXMihE8PKDcsxBS2bWpA6CVu+fPJ9foMdrKCvnzo/txBwQ87b4XJ4QQ6STVSW1sbCzjxo3j+++/x3l7W0e9Xk+LFi0YPXr0XXNsxd3MDi2LtSjeqSq2CJHd5M+v8vXX0KCBiqoqrikHOXOqOBwKUVHa47VroWlTA926uS/WjOZ4+hmoUYno1zuh3LxJwAcjYNUqQFv6S79xPWxcT9L1U3wbNiZ6znwI9MX4y094v/cu/HUafcIJV6/i26k97P0to1+OEEKku1TPqZ00aRIHDx5kzpw5HDp0iEOHDvH5559z8OBBJk2alB4xZjuezttJrV7m0wpRvz6MGKHNr1UU6No1ngMHorlxA6ZOtbrOGz3a9MS+q6EGBsLKlUQuXQEvvYTT1++e55m2bCZHw7rw2mvkaNMCw1+JW5c7fbR7HgzHjsKbb8pauEKIbCfVldotW7YwY8YMKlWq5OqrVasWJpOJQYMGMXbs2DQNMNtRVbxV7UaxOIMktUIADB4cT+3adkqW9MbPT1sL22TS5t3++KOBHTsMXLmiY/x4GDLEzcG6ka1JU+j4BmH/i0B/9gy5/neJyJsR6MJC8Zk8Hm7dwnD2DJw9k/ikypUJH/Uhqq8vuZrU1+Y7ffUV3l6+xI4cDYFyg68QIntIdaXWarUSeI99LQMCArBarfd4hkjKERuHHm3ahiS1QiQKCXFSokTyPkWB8eOteNy+t+njj+HcOZmzg06HI7g0tGpFfKvWWLv3hIMHsZdOnCvrDAggavrn8Ntv2CtVxvHMs7B0qeu45/y55Kr0AixYgBJ+yx2vQggh0lSqk9rnn3+eGTNmJNtZzGq1MmvWLJ5//vm0jC1bstxMfP/U5iFJrRAPU7KkytChWttmg9de8+L48VT/6Mr+SpYkYvN2Yge/DaNHc2vvYeLadUh+49grrxAzfhIYtZvxdP+7Dm++SUCpouSsUh6aNCFH43rkqhQCbdqgu/Sfm16MEEKkXqqnH7z33nt0796dmjVrUrp0aQBOnz6NyWRi4cKFqRrr4MGDLFy4kBMnTnDjxg1mz55N/fr1XcdVVWXGjBl88803REZG8sILL/DBBx9QrFix1IadaVhuWlxtu8nLjZEIkXW89x58/bWTf//VcfGijqZNvZg8GQwGA//7n0JwMNSq5crVnliqjy+xI8fgFeiLejPqnudYe/XF+7XWxA0agmnjele/4e+z8PdZXJ/C8+fI+etuIr9aBfVrpX/wQgjxmFKd1AYFBbF161bWr1/vWtKrWbNmNG/eHLPZnKqxYmNjCQ4OpnXr1vTv3/+u4/Pnz2fZsmVMmjSJQoUKMX36dLp3786mTZswmUypDT1TsCap1NrNUqkVIiW8vWH9+lh69PDhwAGwWBTeegsgcbWVoCAvPvwwjtdfd1uYWcdTTxG1+Css+/aSc+sGbL/twXD8DxSbDQDVaESx2dD97zo5Xm4M772H2eyD6u0NrVuALnU/64UQIiM80jq1np6evPbaa4998Vq1alGr1r0rAKqqsnTpUvr06eOq3k6ZMoWqVauyfft2mjZt+tjXd4e4sMQtcp2ektQKkVIFCqjs2gU9esSzfPndGwicOaPnjTe8WLECPvsMfHzuHkMkZ69cBZo1IOJmFMTFEeihctNhQImIIKBHR9i9G8VigVGjEpcOGzkM44LF8MrLACi3wuDiWShUMvlUByGEyGCPlNReuHCB/fv3Exoa6lqrNsG9Kq6P4tKlS9y4cYOqVau6+nx9fSlXrhxHjx5NdVKbUevBJlwn6fWStm3hiUmt6uX9wHNT05YxZIwnYQyTCT77LI7mze0cP+6Fl5eVHDlUli/3ZO9e7bzvv4cLF7xYudJCYGDaxpEZPgfpNobZBAG+KKFREBgA27cT16ETpjWrSebWLXxfbQXvv4/Pmb8xffsNWK3kLPMcscNHQbtX3f9aZAwZQ8ZIlzHSU1pcR1HV1C1WuHr1aj744ANy5cpFYGAgSpIoFEVh3bp1jxRIcHBwsjm1R44coW3btvz666/kyZPHdd7AgQNRFIXPPvvska7jbntHbaTK+GYA7Kr/ITW3jXZzREJkfaoKK1ZA//5w6/aN/KVKwZYtULy4e2PL0lQVDhyA8+fBaoU1a2DTpgc/p3Jl+OILeO65jIlRCCFuS3Wlds6cOQwaNIiePXumRzzpJjQ0KkPWGlcUCAjwJTRUu0njznbk1cSlc+wmD1ds9zo3Je2wsCj8/VP/PBlDxshuYzRsGMX69Tpef92by5fh7FkoXx7GjrXQtq2dwMBHjyOrfA7SfIywaHjqGQIqVdL6m7Yi4LMpMHEiCZx+OdAVLQLHj2sd+/ahVqhA7OgP8B4ykMgft2PYvw+vyhUJrVk/a38+ZAwZ4wkdIyPzp8eR6qQ2IiKCxo0bP9ZFUyJ37twAhIaGJqvUhoaGulZdSA1VzdgNdJJeK2nbEZF4o5jO1+uB56amLWPIGDIGBAc72bMH6tVz8Pffem7dgrfe8uSbb+w0bw5xcUYKFoRq1cDfP/PFn+nH0OlhwgQiny6L3/q1RFeojPW1tgQWzUfk8lV4ffQBhjN/ocTH4z16JHwwGj+HwzWGeex4LH0HZI7XImPIGDJGittJH2dmqZ7V36hRI3bv3p0esSRTqFAhcufOzd6EiXJAdHQ0x44dIyQkJN2vn16c0YlzavU55E4WIdJakSKwaVMsbdrYXH2//mpg2DAYPdpMt24QEuLDiBEmLlxwX5xZma1JU1i9Gmu3N7U78hSF+MZNCd/xKwwenHhikoQWwPv99zDPmaU9sNshLCzVvy11V6/gNeFD2LnzcV+GECKbSXWltmjRokyfPp1jx44RFBSEwZB8iE6dOqV4rJiYGC5evOh6fOnSJU6dOkWOHDkoUKAAnTp1Ys6cORQtWtS1pFeePHmSrWWb5UQnVmoNOWSdWiHSQ65cMGeOlW7djPTs6eTSpeR/v8fGKixY4MHixTBtmoF27ezuCTS7MZvhk0+IqFYb73eHYrDFY61eC9VsxvPL+QD4jBkJX36B/6VLYLeTq2gx4uvWh1rV8TxzHv2Ff8DbjEeNusTXqQckeTvS6cS3S3uMRw7Dpx/j3bkbzJruntcqhMh0Up3Urlq1Ci8vLw4cOMCBAweSHVMUJVVJ7YkTJ5KdP/H2PK1WrVoxadIk3nzzTSwWC2PGjCEyMpLy5cuzYMGCLLtGLQAxiZVaY05JaoVIT40bw2+/xbB/vx693otbtywcO+bJwoUqsbEKdjsMHOiJ3W5lyBB3R5t92GrVIXzfEQIDfYm+vQmEZ7HCMGaMdsKFCyTcYqz/9wKeixbAogUkXeTQb/58nN4+0LEDjPgAvLxg9Wotob3NvORL2P0LhrkLsT//Qoa8NiFE5pXqpHZnGr7lU6lSJf7666/7HlcUhYEDBzJw4MA0u6a76WITK7WmAElqhUhvXl5Qp46DwEAIDbXTvTv07x/N+PEmli7VbtYcOtSMpye8+qqbg83ORo8mxqbiNXEciqcn9mLFMfj5oh444Nr04U66mGiYOxffS1eJ+vwLGDEi8aDJBHFxcO4cOVo0JXL5SmjVLINejBAiM3qslbIPHz5MfHx8WsXyRNBZE5Nac4BsviCEO/j7w8cfxzF0aGJf377www+PtHS3SCHLW4MJvXQDIiKI+Gk37N5N2JkLRC75Gj7+mMgFS7i1fRds3Ii1bQdUT23HONOG78nZuB4Jk6Dja9eB48exvVAeACU2Br+2bbRFioUQT6zHSmrffPNNrl+/nlaxPBEMyZJazwecKYRIT4oCU6fCW2/FufoGDjRz7lwGrTT+pNLrk62yrvr4Et+kGQwdSnyLVjjKPQ9NmhA943MiFy3XzgcMJ09o5ysKMe9/BKVKEfnDZnj59s5mcXHQujWmpYsy/CUJITKHxypLpHLfBgEY4xPn1HoGSqVWCHdSFBg1Kp7Ll3V8+62R6GiFrl09OXjQ3ZEJAFu9l2DmTK2Mflvca21xlLm9sYPZDGvWYG3XAfOa1eBw4Dt0IIZjv8Pc2Rj27sFj2xbwNmGsVB3bi5Xd80JE9hEVhXH3LgxHDkNEKN6xt/8oNhuTty3xgAomI95WG5gM2r+qCiYDPvdqm434WOLv3bbGg+n2v6qa2AbwMOCbrH17Oo+HHt84u3a+hx6feDsYb/ehau3428eTtj0M+MXZUA0G6NoZajfMyM/wY5H32jKY0ZZYqVV8ZE6tEO6mKDBtmpVTp4z8+SecOqXnzTe1Km5Wvic12+jTh9g//8Jr1nQICCB2xKjkx41Gomd/gRqYG8+5swHwXLoIVn1NzrjEKnwOwOnjCx3aw7tjtKXIklJV9H+dBocFnn4edI/1RqbILuLi4Nff8Vr3A8adO+D4MXI4na7DSd9vvV/b/IC+lLZNKTyeknZKzvVIaOzcDmcvginp1TKvx0pqP/zwQwICAtIqlieC2Z6Y1OIlSa0QmYG3N3z7LZQvr62KsGIFHDzoxeTJcbzyirujE7HvjyP+5ZbkfKYUTpPf3SfodMSMm4hntcqob76JYrVqycidp0VHwdy55Pz5F6IWLQev0nis/x5+3k6uLVvRX7sKgG/Tl4maL9MYnjgOB5w4gWnnrxh+PwzHj+F/7BjYbDyxv62bNdPeEckib8w/VlLbvHnztIrjiWFyaNMPrIrZNVdMCOF+pUvDrFlW3nzTjMOh8Pffelq39qJiRXj2WRPVq0O9encX+ETGsIeUh0BfuL1E2D116EB4/qL49uqG4dJ/xNWtT3yzl/HN6YP1ux8wbdyAEhuD4fQpctarCaj4xmo/k5P+NDZt/AHe7AJr16TnSxLuZrdj+ON3+P0gflu2Ydi/D2Kik66MzF0z7J97Dkv5F7G/UAHfCuUIj7SAopAzpzfhEbGu9q0I7esqVy4fwiNitb5w7XiuXPdoA7n8fR7QjiFXLh/CbmmFMf8A35S1w6JBUfAP8OXWrWhy+Sc/HhqmtQMCfQkN1c51tQ16Ap4q8uDvuUwmzaYfXLx4kVGjRrF06dK0GjJbMju1L1KLTubTCpHZNG9uZ/v2WEaO9CZhM8ODB+HgQW2jhhIlvPn221gCA90apngAR7nnCd9ziMBAX6Ju/8L2DfQlukFzLH+fJVePTnDyJEqS5RUBVC8vbC9WxmPfHrBaMW1cD6+8gkebtjhKPgWVsu5OliKR7uK/eGxaD3t347/rV616T5K325NSFOxPlcJQpTJRFasQX7seAWVKEXM7yfMN9MWekPDd0XYkbYdGQcAdfalsO2+P4Uzad7+2T5K2V5K25+0xTIl9qjFJW++V2FayxnSDO6VZUhsbG8tBubvioRKS2jidJ0Y3xyKEuFuZMk5274YZM6x8/rmRs2cTa3jnz+to3tzLtUPrr78aMJuhbl0wyB0KmYdOd885sY6nSsH+/Vi7dsf8zSoIDMTauBnm9m8QWqY8mEwEHt2H+vLL2hSGjRvx27hRe3KePHh8NJn4lg+Zj2K1wi07cstKJqGq6I//gcfWH2HrJvyPHHEduvMrxJknL7qaNYh5piz2kBfIUbcGETaFgABf4rJQtfJJluLvuodVYGVpr4ez2cALLamNN3hJUitEJqXTQYcONjp0sOHh4ctPP8UybJgXZ87ApUs6QkLAYvHB6dTenGzRwsy8eVY3Ry1SxNub6M/nEzN2AgGlihATYcEckGRaw0svEbl8FX6d2qLEJq5Ww//+h1/PrsT98B0s/AJ0ibf96M6ehfHLybHrVwx/HAO7HfOUT7B26Z6xr01oLBbY8Avea9bB9i3kunz5nqc5c+fBVr0GpoYvcatcRRwlnyIwtx+WhK8FP18IlWQ2K0lxUjthwgRy586N0XjvVMx2nx1hRCKLBTyxAFpSKxMQhMj8/PygenUHu3ZB3boO/vxTT0wMJJ1t9/33RnLkUFm8+P7jfPmlkUWLoEcPI506yc9Ld1Nz575ved1Wqw5hB/8g4I+DxBw7gXH/Pjx+2gFoG0FQZg/Gz2Zja9AI1q0jZ4cOEBubrFDh/d672hJiNW8vI2a1gl3WJk83qgp79uAzfSam9d+DxcK93kC3lQshvmlzvNu9RliewqAomJK+1S+ytBQntQUKFODtt9+mSZMm9zx+6tQpXpHbhB8oNsqBH9oduTbjE3svpRBZUt688N13sXTu7MnevQaeftpBhQoOVqzwwG6HpUs9uHULoqI8+esvHeXKwbRpCnnyqHz9NQwbpv2KHTrUTK5cKl27uvkFiQdS8+SBN97AUj8KCxC4czPOPn3QhYXBjRvkaP8a8XXqwU87kt1M5MydB92N/6HEx+PbtyccPohp+VK8x4wEH290P+7EWaCgu15W9hMVhXnxQsyLF8LJE3cnsiYT8dVrEt+gET6vtybC2x8A74fddCiypBQntWXKlOHkyZP3TWoVRZHNGB7CEmZxte0ektQKkdXkygXff2/B29uX2NtvTTdp4kG7diqqqrB+PST8WL16FY4f92Lo0HiGD08+Tr9+Zp57DooVy9DwxeN47TVulSmPz5ABmLZsBnBVbwFo147QMeNRvb0JbFwXTpzAcPI4lC2L75kz2jlRkXjO/IyYiVPd8AKyF925v/GcNxu+WYVPdHSyY86cOdG1aUNkrfr4tWpGpEVbV9ZHEtlsL8WrS7/11ls0atTovsdLlizJjh077ntcgCU0cX6Ww0PehhIiK1KU5EtMv/EGTJ2afE1UvV77A//yZR1DhpiJv73ZT8HbBTqLReHll+HSpeQLBqmqNvdeZE5qnjxELVsJs2ahJtmZI2bU+7B8OWpAgLam57JlqAlT9RIS2tvMXy9DuRWWkWFnK4ZDB+CVV8hVpTyeixZC0oS2cmWiZs0l7I+/YP58bI2baItQiydGipPap556iueee+6+x41GIwULylsqDxJ3KzGpdZqkUitEdtG5s42dO2PYuhVOnIjm999jePHF5OfUrGnn9GmoVMkOaJXcRo28OHBAh9MJixYZefppb0qVgpMnZTerTEtRoF8/wnf8SuyAwbBzJ9ZBQ7X+BM8/T+ywka6HTr8c2KpW154eG4t5iWzskCpOJ/zwAzmaNSRn4/qwbh1KwjvD3t5YOnfj1s7dsHcvca+3A08pGj2p0mzNkdOnT9OmTRtOnDiRVkNmO/ERidMPnGZJaoXITp57zklgINy8qf2y/fln6NTJxpo1RipUgEWLLPj4+LJ4sZXGjb24cEHH9es6Wrb04tln4ffftdmAoaHQqZMnW7fKeriZmSO4NLFjxuIVeO875C0DBgHgHRFKeNde4HDgXykEVBXP+XNh9IgMjjhrMu76WZuPfPJEshvxHPnyY+3ZB+8hbxFjkz8ChSZNvxIcDkdaDpftxEckVmpVT0lqhcjOPD1hzhwrJ05Es38/5Mih9QcGqmzaFEvt2tpjm03h99+TP/fiRR3du5tlKkJWptdjGTQUZs7EWaQozuIlSNhzWfe/6/DRR3iPeIectarAxIluDjbz0f1zHlq0IEfrlzGcTCyW2YNLw5dfcuvQH9ofDgnfWEKQxkmteDB7kqQ22aQ8IUS2lTevetc+ALlzq2zbBr17x7v6ihd38sUXFvLn1x7/9puBN9+EW7cyMFiRvoYOTWx/9BGeC+Zh+PMkjByJ6atlrkO6y5dgy5Ync4K1qsL8+eSsVRV++CGxv0IFIr5aRfiufdC1KySZ0yxEAklqM5A9UpJaIYTGYIBx4+L47rtYFi+GX36JoVUrO2vXgoeHNoVhyRIoW9aHQYNM/Pmne+MVaaBKFWwVK93zkPewIXDoEOYlX5Kr8gvQqBE5WjRGd+XeGwdkR0poKL6d20HPnq6NLxz58hM1ay7s34+tQeN77hQnRIIUf3VER0c/9EM8mCMqManVectEdiEEVKvmoHPnxHtbKleG6dOtrhUUrFaFr77yoGxZePddE6GhbgxWPLboKZ9gf7YM1KhB1CczsHbsAoASFwc1auDz9iBti17AePAAOetWhydhZaEzZ8jZqA6mzRsT+3r25Nbew9rNX5LMihRI8Y1iFSpUQFGU+x5XVfWBxwU4opMktT5SqRVC3FubNnZCQmJYudKHhQtVoqIUHA5YuNCDb7+FF1/0JH9+J888A40aKRQoIGuEZxWOMs8R/vMeAgN9ibsZRdzr7TCfPQ379mm7jiXw94ewMHShodCgAR7zFxP/cku3xZ2eDPv2Que26MNuL3UWGEjkJzPx6/iGrCsrUiXFSe3SpUvTM44ngjMmcfUDva8ktUKI+ytZUuXTT2HgwGi++MKDGTNMxMRAeDhs3Zr4o3vUKG9at7YzZgzkzu2+eMUj8vCANWtwhoSgu3EDZ46cRH82C7/mjYh/vS0eO7aB04lv/16EFysOdauj3LyJac1KqFYZnqvg7lfwWDw2rse3VzeI09Z6tj9bBsPmTdi8cro3MJElpTipffHORRdF6sUkVmolqRVCpISPDwwZEk///iaGDrWxbp0x4fc/oK2esHKlkVWroGdPEyNHxt1/MJE5FSxI+M7d+O/9hfDKNXHmLwABvkR+/Q0+A/pgXr0CxWLBr1NbGD2KXCNHatv1AqY584lr87qbX8AjWr4c3+5dUG6vnBRfuw5RXy4joHDBey6TJsTDyCSVjBSbmNQac0hSK4RIuQIFYNYsKzExcPx4NNu2xTBqFOTIoU09UFWYN8+DWrW8+fln98YqUk/Nnx/efFNLaBPodERPmw6VtJvL9JcvQe/eroQWwGdAH4w7tqX6ekr4LcyLF8KePY8d+6MwLV0EnTq5Elo6dSLy6zWovn5uiUdkD5LUZiRLkqTWT24UE0Kknl4P+fKpPP+8k3Hj4Pffoxk5Mg6ztncDFy7oqFMHevY037UNr8iCzGZYtw5HvvzJuu1PlQJAsdvx69YRxozB68P3YdgwdOf+vv94qgpLlpCrSnl83hkM1arhOWu61s/t+a1Tp2LcujlZISYtmb5dje/Qga5rWrr2gEWLwGh8yDOFeLA021FMPJwuSVLrkUsqtUKIx+fjA4MHx9O5s4mOHe0cOKD9WF+3zsiPPxp45x3o1g28vd0cqHh0+fMTuXwlfl07ojd5EDn6Q+IbNiawb3dYu1Zb/mrcOBJKJTkXLSJi3UaofnvaoM0Ge/fiuXELHps3wJHDySpa3mNHoz/1J0SEkWPLFgByAKrZDI0aoRvzEc7CRdLmtfzxBz6DB7gexvYfSOyYD/GU1Q1EGkjRV9Hp06dxOp3pHUu2p4tLvFHMlFOSWiFE2gkKgvXrLUydaiUgQOuzWBQ+/BCqVvVmzRpDQmFMZEGOciHcOvQHnD1LfJNmWsn+q6+Ir17zrnN1N2+S45VmcPAgnrOm41/uaahaFe/xYzEeOew6z1Yx8V4Z8+oV2oYPSShWK3z3HX6vv4IS/fhzXJWIcGjdGsVy+3dht27EjvkQZOUkkUZSlNS2atWKW7e3talXr56rLVJHH5dYqTX7S1IrhEhbOh106WLj7Fno1Sseg0HLYq9c0dGnjydVq8KRI1IRy7LurGaazUSu/JaIr1bB+vVErF0PFStqp964AS++iPfY0ehu/C/5855+mohVa4nYtB2WL0f18HAdchQuAtOmYe3YBWdgIACGs2e06urj/FXkdOLTrxf8rU2NsJd9HmbPloRWpKkU/XTz8/Pj0qVLAFy+fBlV/tx/JPr4xKTWJNMPhBDpJFcu+OijOHbtiqVJk8T+ffugQQNvOnWCGzckmcgWTCZtp61mzbDXrAVbtmgJYxKqokDLlkR9MpOw/Ufh5ElsdetrB9u3J+K7jVhffR0+/5zwfYdhyBCiP5lB+Iat4KfduGX6bi3MnPnIYXpO/wTTls0AOHPlInLRMlwTwYVIIymaU9ugQQM6dOhA7ty5URSF1q1bo7vP/JcdT8LOJ4/IGC83igkhMk6pUk42boRVq2IZPdrE2bN6AJYtg0OHPNmyJX1uBBJulCsXEWu+w69TO4yHD2Jt1RrLwKHkqlqBuISNDO6ojtorViK6YiXMgb7JltJylnxK26u5VSutY+hQDKWfw/7CHWvjqirG3bswbtsCTRpCpRrJj2/bhtekj1zXjpqzAGeRomn5qoUAUpjUjhs3jpdeeomLFy/y0Ucf8eqrr+Itdx2kmtGe5BeIlxdYZZ6yECL91avnoGbNWL75xpf331cJD1c4dUrPuHEmvvjC3dGJtKbm8ifih80E5vIiOtzy8Cc8SMuWxA4YhNfMz8Bux/u9d7VpCwBOJ6ZvV8MXn5Pj99+1vs9n4le9Jnz2CRQoju7qFWjbFiXhvpwPPsBW76XHi0mI+0jx6gc1a2qT0U+ePEmnTp3w8fFJt6CyKw97kh8unp5gjXFfMEKIJ4rRCG+9BeXLx1K/vjdWK8yf70GrVq5pmCI7URQwpM0CR7Ejx+CxZTOGM39hPHQQjx++g24d8R42BM8lX951vnH3LqhQgcA7+uPrN8Bj1CgIk999In2k+o6BiRMnuhLaa9euce3atTQPKrsyObRKrVUx3z3hXwghMkDp0k6mTk183LUrjBljol8/M2+/DVevylxbcQeDgZj3x7keen/0Pnz8cbKE1hbyAjFjPoSSJe85hKNYMaLmzJfffSJdpfrPOKfTyeeff86iRYuIvb0ws7e3N127dqVPnz73nWsrwOS8ndTqvJDp8UIId+nXD77/3s727QauX4c5cxLvfl+40JtPPrHStasbAxSZju2lhlC3Luzcif7CBRg2LPHgl18S0aw1KAre771LzLTP8N65DVt0LDidGHMHEDnyA9ScudwWv3gypDqp/fTTT1mzZg1Dhw7lhRdeAODw4cPMmjWL+Ph4Bg8enOZBZgeqCp6qltTG6eQmMSGE+ygKTJ9upW5dL65fT16ICA9X6NbNk99+g/ff12ZKCYGiwMcfo5Yvj5JkBaTYQW/j1bUrJNyE5uGBtWcfvEcMI+J2X2CgL46bj7/OrRAPk+qkdt26dXz00UfUq1fP1Ve6dGny5s3L2LFjJam9D4sFfNCS2ni9LOclhHCvPHlUdu6M5dw5HyAWX1+V2bO9WbNGO75wIRw75sWSJRZuL1dKbCycPAnHjulRVahUCXLmdNcrEBkuJIS4V9/QNmoA4po2J3bEKOQ3msgsUp3URkREUKJEibv6S5QoQURERJoElR1ZLAp5EpJag5Q+hBDulyePyjPPwM2bDgBWr4ZZsywMH24mNlbh0CE9jRp50bEjbNnixdGjOrSb2LU05oUXvNi0SZYFe5LEjJuAYrViCshJ1JjxMkdWZCqp/mosXbo0X3311V39X331FaVLl06ToLIjS4wTM3EA2Izyd60QIvNRFGjb1s6GDbEULKj1/fefjgkT4PBhPU5n8pvIjhzRs2SJ0Q2RCndR/QOIWrgEvvwSZBUkkcmkulL7zjvv0KtXL/bs2cPzzz8PwO+//87Vq1eZP39+WseXbcSFW11tm4cktUKIzOu555wcOACNGzv44w+9q790aQcVKujx9o5n3jzt5rIJE0x06SIFOyGE+6U6qX3xxRf58ccf+frrrzl//jwAL730Eu3atSNv3rxpHmB2EXcr8S06h4esfSCEyNwKFIAffohlxQoj+fKZKV8+mvz5VQIDfQkNjcNi8WDpUoiIUBg2DF5/XccPPxhxOKBmTT116zrc/RKEEE+YR1qZOW/evHJDWCrZIhIrtQ6p1AohsgBvb+jRw0ZgoJmbN9Vkx6ZMge++U4mMVFiyBJYsSdxlcv58L3LlUunaFQYO1DZQFEKI9CZvGGUQW0RipdZplhvFhBBZW968MHJk3H2P37ql8Mkn0KKFF9euyYYOQoj0J0ltBrFHJVZqnWYpWwghsr4uXWw0aWLDbIY6dezMnGlhwwZ45RUbZrNW2f39dz0NG3px9KibgxVCZHtpszG0eChHlMXVVmU1cyFENqDXw5IlVgIDjdy8qf2MCwyESpWsnDypo1Mnby5ehCtXdNSqBdu3K5QooT5kVCGEeDRSqc0g9iRJrWzRI4TI7p59VltBoUIF7YaxqCjo08cTm83NgQkhsq1HSmrtdjt79uxh5cqVREdHA3D9+nViYmLSNLjsRI1OnFOreEtSK4TI/vLmhW++iaV4cSegrWs7daqHm6MSQmRXqZ5+cPnyZXr06MHVq1eJj4+nWrVq+Pj4MH/+fOLj4/nwww/TI84sT41JrNQq3jKnVgjxZPDxgXnzLDRp4o3dDp995kHduvDii+6OTAiR3aS6Ujt+/HjKlCnDgQMHMJlMrv6XXnqJffv2pWlw2Ykam5jU6nykUiuEeHKEhDhJqHeoqkLz5lCypA81a0LLlp40buxFvXpw7JjMiBNCPLpUV2oPHz7MihUr8PBI/hZSwYIFuX79epoFlu1IUiuEeIINGwabNtnZvVv7tRMdrfDrr5D019Dx457s2BFLYKB7YhRCZG2p/rPY6XTidDrv6r927Rre3t73eIYAUCyJSa3BV3YUE0I8WfR6WLHCwvjxVtq0gQIF7v49cuOGji5dPLFa7zGAEEI8RKortdWqVWPJkiWMGzfO1RcTE8PMmTOpVatWmgaXnSjWxBvFDH4yp1YI8eQxm6FnT22HstDQGDw8fAkPjyImRqFxYx8uXNBuJuvdG8aO1XY0EyKzuX5d4aef9Ny6BTExHqiqtmve/dqxsR6Yzdq/qqotgJS8rU3l1M65d9tiMbn6kj5PVROPA5hMYLVq/fdqm0zJz7VYzEnGMCcZw4xeD126QPnyGfwJfgypTmqHDx9O9+7dadKkCfHx8bz99ttcuHCBXLly8cknn6RHjNmC3ppYqTXmkEqtEEL4+kJcHHh6qnz3HVSpomKxaNvuLlvmQ3CwkyZNoHdvyJnT3dGKJ5XTCUeO6Ni2zcBPP8Hhwz5JjppS0b7fcY9UtFNzbkrGMD6wvX49nD6tJbpZQaqT2nz58vH999+zadMmTp8+TWxsLG3atKF58+aYzZKs3Y8uPjGp9cgpc2qFECKpcuVg+nQrPXtqPx+dToVTp/ScOgXLl3szbZqV9u3dHKR4Ijid8PvvOv78E37+2cyePXDjxpP5tkGVKlknoYVH3FHMYDDw8ssv8/LLL6d1PNmWIS5x+oFHTpl+IIQQd2rVyk7u3LFs3OjFvn0OTp3S4XAoXL+uo0MHLzZsgHffVShUSOXKFXjrLTM//QR583oREuKgTh2oWlUhTx7ZtUykjqrCH3/o2LwZvv7am6tXE245Mt51bpkyDurXt1OnjomYmFgUBXLk8CIy8u52zpxaO6EPEvsS2hERWjtXLq2d8LyIiJjbbW8iI2PImdOb8HCtL1euu9sA/v73b0dE3H8Mf39vbt2Kvt32ISwsGqMRQkJ8CA3VPj9ZQaqT2nnz5hEQEECbNm2S9a9Zs4awsDB69uyZZsFlJ0abVGqFEOJhqld30LIl3LwZy5UrCsOH+7B5s3Zs5UpYt86bFi3sbN4MUVFawhEWpufUKT1ffw06nTc1azro1g0aNNBuUBPiXqKj4ZdfDOzeDRs3Jk1kk99D7+MDNWvaqF/fwWuvmTGZtCQ0MNDEzZuO223u2w4NdRAQcP/j9287k4zhvD2G857HU9J++BjqXW1FeZzPcMZL9eoHq1atokSJEnf1lypVipUrV6ZJUNmR0ZZYqZVtcoUQ4uEKFFDZuBFmzrSQK5f2SzYuTmH1aiNRUdo53t6g1yeWkZxOhZ9/NtCpE7zxhiehoVnst7JIN6oKf/2lY/ZsI3XrQlCQD126eLJgAUkSWjAaVRo2tPP55/DzzzGEh8OSJVY6drRRsKD74hcPl+pK7Y0bN8idO/dd/f7+/ty4cSNNgsqOjPbESq0qSa0QQqSIosAbb9hp1CiaefN8mTFDJT5eS1Q7dIjns888iImJ5o8/9Ozd68Xy5U4uXtQSlJ9/NlC/vhdr10Lx4u58FcKdTpzQsXKlkc2b4eLFpHNjE//gMZtVqlVz8OqrBurUicbfHwIDfQkNdUq1PwtJdVKbP39+jhw5QuHChZP1Hz58mDx58qRZYNmNyS6VWiGEeFQ5c8LUqdC2bQwbNhho1MhMyZJxBARoSyNVruygWTMYNCiGnTv1vPWWF//7H1y6pKN6dZg40UjHjra7xv37b4Wff9aWLfLxueuwyKLCwmDBAiOrVsHRo/e+yatYMSf16tlp3dqDMmWi8fTUEtmbNzM4WJFmUp3Uvvrqq0yYMAG73U7lypUB2Lt3L1OnTqVbt25pGpzD4WDmzJn88MMP3Lx5kzx58tCqVSv69u2LksUmeng4tUptnGKSSV5CCPGIihRR6ds3Ya3bu48rCtSr5+DIEWjVysHBg3ri42HoUDMHDugZNQoOHTJw7JiObdvg5Ektky1WzJtlyyxUr57BL0ikGYcDfvpJz9dfG9m0CeLjk6/I5OEBVavaqVfPzmuvmcmVS7tJKjDQQxLZbCLVSW2PHj0IDw9n7Nix2GzaX70mk4kePXrQq1evNA1u/vz5rFixgsmTJ/PUU09x4sQJRowYga+vL506dUrTa6U3s1Or1Fp1svKBEEKkt4IF4bvvYvngAxPz52vrcq5apVXu4O53yy5c0NGokRcrVmjLGIms48IFhZUrjaxeDf/9d/fv2BdecPDGGzZ69DDjcGgFpsBAsySy2VCqk1pFUXjnnXfo27cv586dw2w2U6xYMTw8PB7+5FQ6evQo9erVo3bt2gAUKlSIjRs38scff6T5tdKTzQZeaEltnM4z9XfnCSGESDUPD5gwIY66dT3o3l0lNvbud/gqVnRgteo5fhxiYhRatIDRoz3o3z/eDRGLlLLb4fvvDaxaBT/9dPe8kdy5oU2bePr29SBfvoQlsySRze4eaZ1aAG9vb8qWLZuWsdwlJCSE1atX888//1C8eHFOnz7N4cOHGT58eKrHyqjZCgnXSXo9qxX8bie18QYvPJX7n/uobRlDxpAx0n+MrB7/kzrGG29A4cKxTJnigaenkaJF4wgKctKkiScmUyxmsy/t2tn4/nsjqgoffmjiv/8Uvvji/mNbLLBzp4HatbWd0TLqtTzpYzidsGoVvPeeN+fOJS8R6XRQv76d9u1tvPGGJ9HRcfj7eySbppKZXktWHCM9pcV1FFVN3ZK6sbGxfPHFF+zbt4/Q0FCcTmey4zt27Hj8qG5zOp188sknLFiwAL1ej8PhYPDgwWk+zSG9Xb0KOQt44omVf/zKUjzimLtDEkIIkYSqwrhx8P77iX1160Lt2tq6nS+8AJUqaf1Xr0LDhnD8uFYNfucdGDkSvGR2WbpRVdi4EUaNgmN3/AoNCoJu3aBjRyhQwD3xicwh1ZXaUaNGceDAAVq0aEHu3LlJzxu2Nm/ezPr165k2bRpPPfUUp06dYuLEia4bxlIjNDQqQ3bEUBQICPAlNFRbRDEgwJfL/0WSHysA8QZPQkOjCAjwJSwsCn//5Oemti1jyBgyRvqPkdXjlzEePkZYWBT9+kHx4r50765isyns3Ak7d+JSt66dbt3iGTXKiwsXtL74eBg/HpYsgdKl7SgKFCxoYPDgaAoWVLPs5yMzjbFnj54JE7zYt49kqlSxM2GCgTJlou75uzczvpasOkZG5k+PI9VJ7a5du5g3bx7ly5d/rAunxJQpU+jZsydNmzYFIDg4mCtXrjBv3rxUJ7WqmrHbvCW9ljU8ztW2e3i6jt357+O0ZQwZQ8ZI/zGyevwyxsPH6NgRfHwsdO/uya1byYs2O3ca2Lkz8ddm7txOwsN12Gxw6RJcupR47J9/zKxZY3Hra8nqY4SHw+DBJpYtS37PToUKMGxYLLVrO8idW1uC60HXzAyvJauPkfRxZpbqe5b8/PzImTNnOoRyN6vVelclWK/Xk8oZE24XH564Rq3DKGvUCiFEZlajhoPff4/mt99g+fJYxo+3UrRo8nOeecbBzp2xHD+uzeO80y+/GDh0SPsVe+OGQufOZtq1g8jIjHgFWd/WrXqefZZkCW3p0g4WL7Zw4ADUqePIsLmeIutIdVI7cOBApk+fjsViefjJj6lOnTrMnTuXn3/+mUuXLrFt2zYWLVpE/fr10/3aackWYXW1HSaZdCWEEJmdlxdUrQoNGzro2dPG6dMwdqyVYsWctGoFP/wQS758KsHBsHKlhagoOHMmismTE3/eT5tmwumEvn3NbNpkZMUK6NrVk3hZWOG+LBYYMADatfPiyhWtz9tbZfZs+PnnWJo2tUsyK+4r1dMPFi1axMWLF6latSqFChXCYEg+xLp169IsuFGjRjF9+nTGjh1LaGgoefLk4fXXX6dfv35pdo2MYItIrNQ6zVKpFUKIrMZshr59bbc3frh71ykfH8iVCzp0sDF7tpmLF2H7dgM9emjb9SbYtcvAoEHm2+vl3t8d92A/Ec6e1dG9u5lTpxL76tWz8/HHVp5/3keW4xIPleqkNiOrpD4+Prz33nu89957GXbN9GCPSvzL3ekplVohhMiuPDxg+HDo21d7vGiR9q+iqHh4KMTFwTffGClWDN5+W1uGKoGqam+7T5pk4p9/YPx4A+3aaVMb/vpLR58+Zvz9Ye5chcDArDUN72EOH4ZmzTwJC9M+IWazyqefKrRubZHKrEixVCe1/fv3T484sjV7VJKpGp5SqRVCiOysa1f48EMn164lZqz9+tmoW9eD1q1VVFVh6lQ4cMCTGTOseHnB5s16FiyAX35JLHwMGmTGz89KzZrQurUn169r4w0ZYmLJEutd1921S8+GDVCggAcvvOCgbt30f61pYd8+Pe3bQ2Sk9vrKlIG5c2OpVs1bqrMiVR558wWRcs5kSa35/icKIYTI8sxm6NcvntGjtZ/3Zcs6GDEijgIFPJg0KY5339X6f/nFQLVq3jgcYLHc/S6eqir07m0mTx5cCS3A5s1Gli93MHhw4rmLF0P37p63py2YAG2JpKee8iIkxEmjRtCoERiN6fWqH82vv+rp0MGT2Nuz9CpXtrNliwGb7QmcfyEeW6qTWofDweLFi9m8eTNXr17FZrMlO37gwIE0Cy67cMYkzqnFW6YfCCFEdte1q43jx/XcvGlk8mQLCTvJd+tmo2RJJwMHenH5MkRHJ39vvUQJJyNHxrFrlydLl0JcnMJ//2nHChRwcuWKltyOGmWiWTPImRPmzjUyZgxA8rFUFc6e1XP2rJ7Vq6FMGS9mzLBSp076vvaU2rWL2wmtFnft2naWLLHg5+dL0l3AhEipVCe1s2bN4ptvvqFbt2589tln9O7dm8uXL7N9+/YsdwNXholJrNTqvGX6gRBCZHcmE8yebSUw0MjNm8nnv9aq5eD4cXjzTRvffmskb15o0CCe117zoHz5GIxG6NQJrlyxs3279mu6SBEnGzbEMmuWD198AbGxCqVLg9OZfLH6fv2gdGkLR47oOXHCg99/1zaSADhxQk+DBl506AB+fh74+ICfH0RFeWAwqLz+OuTJkzGfnwMHdLz2Gq6EtnlzmDPHgsmUMdcX2VOqk9r169fz0UcfUbt2bWbOnEmzZs0oUqQIwcHBHLtz7zoBgJqkUqvzkUqtEEI86XLlgrlzrUyaZKVECV9u3YojIMDDNYfUaIQFCyy8+66ZiAgj48bFkj+/yiefwPbtTs6f1921QsK778YxcaKJ0FA7b7xhJzDQg8uXozl4UM/o0V6cOAF2u8LixZAwRUGjtcePh4EDPRg/Hux2OHZMR2go2GwGPD1ViheHHDm02B/H8eM63njDi5gY7XG9ena++cZAVNTjjStEqpPamzdvEhQUBIC3tzdRt78K69Spw/Tp09M2uuzCkjihX+8rlVohhBCanDmTr4CQlLc3zJqVvNrr7Q1Lllh45x0TFosBg8GBr69Kr14GXnopHkVJXuo0maB6dQeHD8N778Xx2Wce2O33Xk7AbtfW1v3mG7h1y4eoqITzkv7e8sXPT6VhQ/joI/D3T93rvXEDOnXydI1du7adxYstmEy+ktSKx5bqpDZv3rzcuHGDAgUKULhwYX777TeeffZZjh8/joeHx8MHeAIplsRKrd5XbhQTQgjx6EqXdrJ+veX2erna75fAwAfPQ/XwgHffjefNN+OJiPDl0qVYoqIUfH09iYmJ5cgRPTNnmrDb4eJFuHN+blKRkQrffAN//unFN99YCAxMWdw2G7RtC5cuaVn8iy9qCbpZfi2KNJLqpPall15i7969lCtXjo4dO/LOO++wZs0arly5QpcuXdIhxKxPZ02cU2uQSq0QQgg38feHoCAoXtwBQGAg3LzpoFEjB126mOjc2cHvv+sJDHRSvbqDatWMREbGERsL0dEmTp+2c/SonshIhZMn9bRq5cmGDdp0iYetWDlqlIlfftHaefM6WbdOh9TCRFpKdVL79ttvu9pNmjQhf/78/P777xQtWpS6WWVRvAymj0us1BpzSFIrhBAi8ylbFrZtiyUuzhejMQadjttTH7R9fQMDTdy8aeHcOYXWrX24fBn++ktPqVIAvuj1Km++CePG3T32mjUGvvxSy2A9PFQWL7ZQoICsQyvS1mOvUxsSEkJISEhaxJJt6eOTVGr9JKkVQgiROSkKFCzIA5PNkiVVdu2C2rWd/Pdf4oRgh0Nh7lzw9vbg448Tzz9zBoYOTZxjMGWKlQoVZB1akfZSlNTu2LGDmjVrYjQa2bFjxwPPrVevXpoElp0YkiS1xhyy+oEQQoisrUQJ2LgxllmzPLhyxYNbt+zs2aNHVRWmTTNRtiw0aQJWK8mW7uraFdq3t7s5epFdpSip7devH7/99hsBAQEPXItWURROnTqVZsFlF0Z7kqTWT2bECyGEyPry51cZPz6OwEAPbt60MHeu0bWLWo8e8NJLZq5e1ZGw2mdQkIOZM/VYLA8YVIjHkKKk9vTp0/dsi5Qx2hLn1CreXqgPOFcIIYTIinr1snHlipk5c7SVDjZtStyT12xWWbDAire3tyS1It3cZ3W8e7PZbHTu3JkLFy6kUzjZk8meZJtcL5lTK4QQIvtRFJgxA5o0sSXrNxjgk0+sPP20zKMV6StVN4oZjUb++uuv9Iol2/JwJP5ZqpolqRVCCJE9GQywZIkVh8PIjRvR6HRQrJgPsbEyj1akv1RVagFefvll1qxZkx6xZFsmp5bUxuGhfccLIYQQ2ZSiQN68kC+fSp48Kl5yf7TIIKnOsBwOBytWrGDPnj2UKVMGzztWWx4xYkSaBZddmB3a9IM4nVRphRBCCCHSQ6qT2jNnzvDMM88A8M8//yQ7pij331bvSWZWE5JarwdsPCiEEEIIIR5VqpPaZcuWpUcc2ZbDAV7cTmr1XsiCXkIIIYQQaS/Vc2pF6litiUltvEEmFgkhhBBCpIdHumvp+PHjbN68matXr2KzJV+6Y9asWWkSWHZhiVUJRLtRLN4oSa0QQgghRHpIdaV248aNtG3blvPnz7Nt2zbsdjtnz55l3759+Pr6pkeMWZo13Opq2ySpFUIIIYRIF6lOaufOncuIESOYO3cuRqOR9957jx9//JHGjRuTP3/+9IgxS4u7lbjxgsMoqx8IIYQQQqSHVCe1//33H7Vq1QLAw8OD2NhYFEWhS5curF69Os0DzOpsEYlJrd0klVohhBBCiPSQ6qTWz8+PmJgYAPLkycPZs2cBiIyMxCIbOt8lPjxJpdZDklohhBBCiPSQ6hvFKlasyJ49ewgODqZRo0aMHz+effv2sWfPHqpUqZIeMWZpSSu1TrMktUIIIYQQ6SHFSe2ZM2cICgpi9OjRxMXFAdCnTx+MRiNHjhyhQYMG9OnTJ90CzarsUYnVa6enJLVCCCGEEOkhxUntyy+/zHPPPcerr75KkyZNANDpdPTs2TPdgssOHFGJlVrMcqOYEEIIIUR6SPGc2uXLl/PUU08xadIkatSowbvvvsuhQ4fSM7ZsIWlSq3pJpVYIIYQQIj2kOKmtUKECEydOZPfu3YwaNYrLly/ToUMHGjZsyBdffMGNGzfSM84syxmdmNQqktQKIYQQQqSLVK9+4OXlRevWrVm+fDlbtmyhUaNGfP3119SpU4fevXunR4xZmjMmSVLrLUmtEEIIIUR6SHVSm1TRokXp1asXffr0wdvbm19++SWt4so21JjEG8V0PpLUCiGEEEKkh1Qv6ZXg4MGDfPvtt2zZsgWdTkfjxo1p06ZNWsaWPcQmVmp13nKjmBBCCCFEekhVUnv9+nXWrVvHunXr+PfffwkJCWHUqFE0btwYL5kv+v/27j04qvr+//jr7CW72WRJuIpchIbWeJ+fba2CcYAvFq0dasUqg7ZFx9oBrY5V1KJtvyZKta3TmTqiaZlqBamOVatFW1H0hxNtter4Q6RarCiJIiLhEpJsdje75/dH3LMnISGbZD97SZ6PGceTk933+ezZC6+8z+ec7Z0r1HrD7CMAAAATMg61P/jBD/TPf/5To0eP1rnnnqvzzz9fVVVVJsc2LFgd6VDrG0WoBQAAMCHjUOvz+fTb3/5Wc+fOldfrNTmmYcUTIdQCAACYlnGora+vNzmOYcsTTZ8o5q8g1AIAAJgwpKsfoH/eaLpT6x/FiWIAAAAmEGoN88XSoTYwmk4tAACACYRaw3xxQi0AAIBphFrD/K5QGxzN9AMAAAATCLWGlXR2hdqY/AqG/XkeDQAAwPBEqDWspLPr6gcRlYoroQEAAJhBqDUskOjq1EYs5tMCAACYQqg1LJDsCrUdhFoAAABjCLWGldqfh1oPoRYAAMAUQq1Jtq3Q56E26uXKBwAAAKYQak2KRp3FGKEWAADAGEKtQXZb+hq1MR/TDwAAAEwh1BoUPxBxlmN+Qi0AAIAphFqDYvvTndq4n+kHAAAAphBqDeps6XCWEyV0agEAAEwh1BoUc00/6CyhUwsAAGAKodagxMF0qE0ECLUAAACmEGoNcofaZIDpBwAAAKYQag1KtLpCbSmdWgAAAFMItQYlW9NXP7CDhFoAAABTCj7Ufvrpp1q+fLlOPfVUnXTSSVqwYIG2bNmS72Flpi3dqbVLmX4AAABgii/fAzicAwcOaPHixTr11FO1evVqjR49Wjt27FBFRUW+h5aRZFv6kl5WKJjHkQAAAAxvBR1qV69erYkTJ+r222931k2dOnVQtSwrW6PKbDuWJVmR9PQDqyx0yDjct+25bqDL1KAGNczXKPbxU4Ma1KDGUGqYlI3tWLZt20MvY8Y555yjmpoa7dq1S6+99pqOOOIIXXTRRbrwwgvzPbSM/L+zf6L/s+GXkqS/Xf9/dc6v5uR3QAAAAMNUQXdqm5qa9NBDD+nSSy/V0qVLtWXLFt12223y+/0677zzBlSrufmgchHfLUsaOzas5uaDire0OOujXo8zDqnrNnv3HtSYMeFu6wa6TA1qUMN8jWIfPzWoQQ1qDKVGLvPTUBR0qLVtWyeccIKuvfZaSdJxxx2n9957Tw8//PCAQ61tKydPint7nkj6RDFPechZ775NX+sGukwNalDDfI1iHz81qEENagzmfu6fC1lBX/1g/PjxmjFjRrd1VVVV2rlzZ55GNDCeaDrUess5UQwAAMCUgg61X/7yl/XBBx90W/fhhx9q8uTJeRrRwLhDrW8U16kFAAAwpaBD7ZIlS7R582bV19drx44dWr9+vR555BFddNFF+R5aRnzR9NUP/BWEWgAAAFMKek7tSSedpLvvvlu/+c1vtGrVKk2ZMkU33XSTvvWtb+V7aBnxxd2dWr58AQAAwJSCDrWSNHfuXM2dOzffwxgUf7yrUxuXT4Hygt/VAAAARaugpx8UO//nndqIShXkPDEAAABjCLUG+Tu7Qm27QgoE8jwYAACAYYxQa1Ag0TX9oF0hlZYWyUXeAAAAihCh1iB3qKVTCwAAYA6h1hTbVjDZFWojCsnvz/N4AAAAhjFCrSmxmDzqmnLQ4eEatQAAACYRag2xIukvXoh6CbUAAAAmEWoNsSLpL16IevniBQAAAJMItaa0pzu1MR+hFgAAwCRCrSHuTm2cUAsAAGAUodYUV6e208+cWgAAAJMItYZ0tnY4y/ESQi0AAIBJhFpDOg+kO7WJEqYfAAAAmESoNaSzJd2pTQTo1AIAAJhEqDUkcdDVqQ3SqQUAADCJUGtIsjV99QM7EMzjSAAAAIY/Qq0hCdeJYslSOrUAAAAmEWoNsdvS0w9USqcWAADAJEKtIcn2aPqHIKEWAADAJEKtIXYkPf3AW0aoBQAAMIlQa0pHulNrlQbyOBAAAIDhj1BrSgedWgAAgFwh1JoSTXdqPSFCLQAAgEmEWkOsaLpT6w+X5HEkAAAAwx+h1hCPq1PL9AMAAACzCLWGeGLpTq0vTKgFAAAwiVBriNcVagOjuPoBAACASYRaQzzxrlAbk1+hMLsZAADAJNKWIb7PQ22HgiotzfNgAAAAhjlCrSHezq4TxbpCrZ3n0QAAAAxvhFpD/Ak6tQAAALlCqDXEHWpDITq1AAAAJhFqDSlJ0qkFAADIFUKtCbbthNqoFZTXm+fxAAAADHOEWhPicXnUNeUg5qVNCwAAYBqh1oRIxFmMe/k2MQAAANMItSZ0pL9NLOEj1AIAAJhGqDXBFWo7/YRaAAAA0wi1BnS2pkNtklALAABgHKHWgOgB1/SDEkItAACAaYRaAzr2p0OtTagFAAAwjlBrgLtTawcItQAAAKYRag2ItaRDrUoJtQAAAKYRag3oFmqDfPkCAACAaYRaA+IH06HWolMLAABgHKHWgM6D6W8U84QItQAAAKYRag1wX6eWUAsAAGAeodaARFs61PrKCbUAAACmEWoNSLanQ623jFALAABgGqHWAHeo9YUJtQAAAKYRag2wI+lQ62f6AQAAgHGEWgPcobZkFKEWAADANEKtCVFXqK3gyxcAAABMI9QaYLlCbaCCTi0AAIBphFoDPNH0ly8EKwm1AAAAphFqDfDE0p1aQi0AAIB5RRVqf//736u6ulorV67M91AOyxsn1AIAAORS0YTat956Sw8//LCqq6vzPZR+uUNtaAyhFgAAwLSiCLVtbW26/vrrddttt6mioiLfw+mXr9P15QuhkjyOBAAAYGTw5XsAmairq9Ps2bM1a9Ys3XvvvYOqYVlZHtRhtuP/PNRGFFSpZXXbdm/L/f0+k2VqUIMa5msU+/ipQQ1qUGMoNUzKxnYs27btoZcx5+mnn1Z9fb0effRRBQIBfe9739Mxxxyjm2++Od9D69P7/mrN6Nym/ValKpP78j0cAACAYa+gO7WffPKJVq5cqfvuu0+BQGBItZqbDyoX8d2ypJJkV6c25gk625aksWPD3Zb37j2oMWPCff4+k2VqUIMa5msU+/ipQQ1qUGMoNXKVn8aODQ+pRkGH2q1bt6q5uVkLFy501iUSCb322mtat26dtmzZIq/Xm1Et21ZOnhQpHWqjnlJn2+5x9Fzu7/fUoAY1CqNGsY+fGtSgBjUGcz/3z4WsoEPtaaedpvXr13dbt2LFClVVVenyyy/PONDmUiIhlarryxfiXq58AAAAkAsFHWrLy8t19NFHd1sXCoVUWVl5yPpCEYlIo9XVqe30DW3KBAAAADJTFJf0KiaR1qRKFJckdfro1AIAAORCQXdqe7N27dp8D+GwOg5EneUEoRYAACAn6NRmWdQdav2EWgAAgFwg1GZZrMUVakuYUwsAAJALhNosc3dq7SFeWxcAAACZIdRmWfxgh7NsB5h+AAAAkAuE2izrbHV3akvzOBIAAICRg1CbZZ2uTq2CTD8AAADIBUJtlrk7tVYpoRYAACAXCLVZlmhLd2qtEHNqAQAAcoFQm2WJtnSn1huiUwsAAJALhNossyPpTq2HTi0AAEBOEGqzzI64OrVldGoBAABygVCbZe5OrbecTi0AAEAuEGqzrSPdqfWV06kFAADIBUJtllnRdKe2ZBSdWgAAgFwg1GaZ1eEOtXRqAQAAcoFQm2WeWDrU+sN0agEAAHKBUJtl3jhzagEAAHKNUJtlnni6U2sH6NQCAADkAqE2y3zdQi2dWgAAgFwg1GaZrzMdahWkUwsAAJALhNos8yfSc2qZfgAAAJAbhNosSiYlf5LpBwAAALlGqM2iSEQKiukHAAAAuUaozaJIxHJCbaflk3y+PI8IAABgZCDUZlEkIpUqIkmKe+jSAgAA5AqhNovcndq4j1ALAACQK4TaLHLPqe30EmoBAAByhVCbRd3m1Pq58gEAAECuEGqzqL093alN+OnUAgAA5AqhNosmjE86odYbolMLAACQK4TaLDq+OiavkpKkiomEWgAAgFwh1GaRJ5b+4gUrxPQDAACAXCHUZlNH1Fm0A4RaAACAXCHUZpHVEUn/QKgFAADIGUJtFlnR9PQDO8icWgAAgFwh1GaTa/oBnVoAAIDcIdRmUbdObYBOLQAAQK4QarPIirpOFAvSqQUAAMgVQm02daQ7taJTCwAAkDOE2mzyep1Fe1RFHgcCAAAwsvjyPYDhJH7aLMXm/I9KDh5QdOF38j0cAACAEYNQm00lJWr58xMaNy6s5J6D+R4NAADAiMH0AwAAABQ9Qi0AAACKHqEWAAAARY9QCwAAgKJHqAUAAEDRI9QCAACg6BFqAQAAUPQItQAAACh6hFoAAAAUPUItAAAAih6hFgAAAEWPUAsAAICiR6gFAABA0SPUAgAAoOgRagEAAFD0fPkewOH87ne/07PPPqvt27crGAzq5JNP1vLly1VVVZXvoQEAAKCAFHSn9l//+pcuvvhiPfLII7r//vvV2dmpyy67TO3t7fkeGgAAAApIQXdq//CHP3T7+Y477tDMmTO1detWnXLKKQOqZVnZHFn/23Fvr7/lgdyWGtSgRv5qFPv4qUENalBjKDVMysZ2LNu27aGXyY0dO3Zo/vz5Wr9+vY4++uh8DwcAAAAFomhCbTKZ1LJly9TS0qKHHnoo38MBAABAASno6QdutbW1eu+99/SnP/0p30MBAABAgSmKUFtXV6dNmzbpwQcf1MSJE/M9HAAAABSYgg61tm3r1ltv1XPPPae1a9dq6tSp+R4SAAAAClBBh9ra2lo99dRTuueee1RWVqbPPvtMkhQOhxUMBvM8OgAAABSKgj5RrLq6utf1t99+uxYuXJjj0QAAAKBQFXSoBQAAADJR0N8oBgAAAGSCUAsAAICiR6gFAABA0SPU9qG6ulobN250/u9eN5Rl9/9T/2WrJjWoQQ1z2x5MvZ7v90LdP9SgxnB9DxbSPjBZA11G7Ilin332merr6/X888/r008/lWVZSiQSCgQCsixLHR0dKikpUSwWk2VZKi0tVXt7e0bLkuTxeJRMJnvdts/nU2dnp/Pz4WoGAgF1dHQM6LFZlqUR+rQCAIA8sixLZWVl6ujo6JZ1MuH1emXbtqZMmaIrr7xS3/72twd0/xHZqf3oo4+0cOFCNTQ0qL29XVOmTNEPf/hDhUIhJRIJnXHGGZKkUaNGOfcZN25cv8uVlZWSugJtaWmps76srEyS5Pf7nd/31FdN9wviuOOOc5a/+tWvSpICgYCzbsKECZLULdBalqXy8nJn2X0ptNTt3dzX/w2FQs5yb2O2LEtjxow5ZH1/LMtSVVWV87PX6834vj7f4C6t7H4+eo4lpbdrH/f2uHtyjz8cDmd8v76kavTFPWa3k046yVlOvXb7um0m20vd113Dvf/7ul/qdS6l3xNuqdfj4bi3mXqNuV+PAzGQ11dPfb1usiWT56c/g31848ePH/K23UxdO7yvfTSQx+2u4X59mjSUz4CUkpKSLIyksLj3SybPoXsfpJ67bLxvMuEea2+fP5mMYyifP5lyb6OkpOSQcR111FHdfk793n2/nu/fnjXcP/dcTuUQ9/rW1tZDssjEiRPl9Xp1+umna/To0Vq0aJGuu+46eTwe+f1++f1+LVu2TEcddZQqKipUW1urF154IbOd8LkRGWpra2tlWZamTJmiYDCoJ598Ulu3blU4HNYLL7ygaDQqSbrpppskdQWEuXPnSuoKjB9//LGzvH//fmd5586dkqRkMqm2tjZne6nleDwuSYrFYt3GY9u2Ghsbe112h9p///vfzvLrr78uSc5YJWn37t2HPFbbttXa2uosP/7444e9vbsrnOo6px5Tb7X37t17yPr+2Lat7du3Oz8nEomM7zvQv/pSIpFIn2NJ6a0j3le33c09/oMHD2Z8v76kavSlry78W2+95Sy3tLQc9raZbC91X3cN9/7v636p17kk5/3hlno9Ho57m6nXmPv1OBADeX311NfrJluycURlsI8v9WU22TLQI0qZ6msfDeRxu2u4X58mDeUzIKXnvxXDgXu/ZPIcuvdB6rnL1ZFI91h7+/zJZBxD+fzJlHsbsVjskHGlMkVK6vc979fzNhMmTHCacjNmzHD+yE9lI6mrwdbZ2alwOKyamhpJUlVVlcLhsLP/AoGAfD6fWltbdc011+j999/XFVdcoRdffFEej0djxoxRPB7Xeeedp6uuukrf/e53tXv3bi1atEirV68e0L4YcaF2//79amho0MKFC/WPf/xDF198sWKxmBoaGnTxxRcrEAiooaFBUvof8NmzZzt/xVRVVWnp0qWSusJu6sXR119jJSUlzl97ff1V1/Mv+oF0EnL1F2uK+3G6u8QAit9APk/cnwUD7b71Z7Bdzlx0xUx+5maju4vClM/nNpNM4Q7w7u54qnHmPhLobtr5fD4lEgnZtu28//bv36+2tjYnH0WjUcXjcVmWpeeee067du3SqlWrtGvXLk2YMEHNzc0KBoMaO3as9uzZow0bNmj27NkKBALasmXLgP4QHXHvoMbGRtm2rbKyMtm2raqqKmede1lKdzKOOOIInXnmmZKkefPmac6cOZK6Xij9zfeYOXOmc5i2r0OZwWDQecH4/f6MDs+mTJo0qdf1vR22cn8Y9xVI3et7eyO435hf+9rXeq3R35t3oP/w5PorkQc7xSET+fwH3y1Xh2CzabCHm6dOndrrbfrbjyMxYLg7PP0d+nbv4yOPPNJZHjt2bMbb6+s57esf2P7G5O48ZWN6RW8B1mSX0P243fsm182LQlEon1PZmIaUz/NcMgmFHo/HeZ2lura7d+923lPvvvuuc+TqgQcecO63efNmSV1Bd9OmTZLkhFSp67Wbqnvw4EHniGLq8/Wxxx6TZVmKx+O69957dfrpp6usrEwLFy7Uo48+qng8rn379mX8WEfcp3ZvLyz3ur6WX375ZUnSH//4R1144YWSup64tWvXSur7EMOLL76oAwcOSOr78Gl7e7vzRA/0CUxNheipt8NW7sfjnrbg5l7f2xvBvS7V0e6pv8NuAz0cY+qwZl8GO8UhE9k4FJWNw5q5OgSbTYM93NzU1NTrbfrbj9nYz8Wsv0Pf7veJ+3Oot2lNfRno4eeBHI7PxvSKfAYR974ZqSf+FsrnVDamIRX6c5hMJg8Zo/ukc/f0x1SmkdL7puf82VTe6evE9Xnz5kmSXnnlFdm2rSuuuELz5s2T1+vVpk2bdMkllzhNw4E0GEZcqJ02bZosy1JbW5ssy9L27dudde5lKX0i1TvvvKO77rpLUtebbNGiRU691AlbhzOQzgUAAEAuTZs2zVlOzaO9+uqrdeqpp0qSvvGNb6i6ulqSdMcddzi3TZ1vZFmWTj755EPqupsDY8aMcU7EnzlzprP+yCOP1I9+9CPdc8892rx5s+666y51dHRo1KhRKisrG9AJ6SMu1FZWVqqmpkaPP/64Zs6cqXXr1qmkpEQ1NTVat26dotGoM9k5dRj69ddfdw6vWZalG2+80ak3ZcoUZ30qBPc8fN3f4exM/grx+Xz9Hn511+mrpvtQfn/13Id+UrfteRgsG4do+xtHpnORD6dQDmNlMrVhJB72Ru/6OuyZjWksQ62RjUPihzvDeiDbNDEW03rbnokx5PrzpLerpuTKYKeOFcpnbl/jH+xVH1L3mzhxorPc21UcfD6fmpubnZ/j8bh8Pp/+/ve/65NPPpHUNf2gsbFRXq9XL7/8soLBoDwej95++21JXVMh29raFAgE9Ne//lXTp0+Xz+fT4sWLVV5erokTJ6q9vV3vvPOOKioq9OKLLzq5avr06d3GnMpSzz//vObOnTug52dEXqe2qalJixcvVigU0r59+1RZWalvfvObeuCBBxSLxTRv3jxt2LBB48aN0549ew5pn5eVlTkTpbkmLAAAKFSHu27+4e7j9XoPmQLi9XoPmTYUDAYVj8eVTCYVCoUUDoe1a9cuTZ8+XS0tLdq7d6/mzJmjhoYGJRIJnXDCCfrPf/4jr9crr9eraDSqpUuXqry8XOPHj9eqVavU3Nwsy7L02GOPOc3DTIzIUCt1zftKfflCag5YMpns9csXPB6PPB6P0bmWAAAAw0VvYTp14lhFRYVaWlp08803K5lMas2aNWpqapJt2/L5fDrttNN08803d7umfSZGbKgFAADA8FEYE0kAAACAITB3QU706+c//7nWr1+vWCzG1AYAAFDwfD6fSkpKtGDBAtXV1eV7ON0w/SCPmpub1draqn379jnXdGtpaVEkElEoFJJt27IsS+FwWC0tLRkv27atSCSiRCKhSCSi5uZmeTwelZaWKplMyuPxKBgMqrS0VOFweEA1U+MazBipQY3hXCMb2x5MvdbWVnm9XrW2tqq9vd05Uzh10kZ5ebkSiYTC4XDR72NqUKMQ34OFtA9M1kh9kVRZWZkqKytVXl5ecJcsJdQCAACg6DGnFgAAAEWPUAsAAICiR6gFAABA0SPUAgAAoOgRagEgT6qrq7Vx48Z8DwMAhgWuUwsAhnz22Weqr6/Xpk2b9Omnn2rs2LE69thjtWTJEs2cOTPfwwOAYYVQCwAGfPTRR1q8eLFGjRqlG264QUcffbQ6Ozv10ksvqba2Vs8880y+hwgAwwqhFgAMqK2tlWVZ+vOf/6xQKOSs/9KXvqTzzz+/1/v8+te/1saNG7Vr1y6NGzdOCxYs0JVXXim/3y9Jevfdd7Vy5Uq9/fbbsixL06dPV21trU488UR9/PHHuvXWW/XGG28oHo9r8uTJuuGGGzR79mxJ0rZt2/SrX/1Kb7zxhkpLS3X66adrxYoVGjNmjCTpmWee0apVq7Rjxw6Vlpbq2GOP1T333NNt7ABQyAi1AJBl+/fvV0NDg3784x/3GgpHjRrV6/3Kysp0++23a8KECdq2bZt+9rOfqaysTJdffrkkafny5Tr22GN1yy23yOv16p133nECb11dneLxuB588EGFQiH997//dbbd0tKiJUuW6IILLtCKFSsUjUZ155136pprrtGaNWu0e/duXXfddbr++ut15plnqq2tTa+//rr4bh4AxYRQCwBZ1tjYKNu2VVVVNaD7XXHFFc7ylClT9MEHH+jpp592Qu3OnTt12WWXacaMGZKk6dOnO7ffuXOnzjrrLFVXV0uSpk6d6vzuwQcf1HHHHadrr73WWfeLX/xCs2fP1gcffKD29nZ1dnbq61//uiZPnixJTh0AKBaEWgDIssF2OP/2t79pzZo1ampqcoJmeXm58/tLL71UP/3pT/Xkk09q1qxZOvvss3XUUUdJkr7//e/rlltu0UsvvaRZs2Zp/vz5OuaYYyR1TVt49dVXdfLJJx+yzcbGRtXU1GjmzJlasGCBampqVFNTo7POOksVFRWDehwAkA9c0gsAsmzatGmyLEvbt2/P+D5vvvmmli9frtmzZ6u+vl5/+ctftHTpUsXjcec2V111lZ566inNmTNHr7zyis455xw999xzkqQLLrhAGzdu1Lnnnqtt27bpO9/5jtauXStJam9v19y5c/XEE090++/ZZ5/VKaecIq/Xq/vvv1+rV6/WF7/4Ra1du1Znn322mpqasrtjAMAgQi0AZFllZaVqamq0bt06tbe3H/L7lpaWQ9a9+eabmjRpkpYtW6YTTzxR06dP186dOw+53Re+8AVdcskluu+++zR//nw99thjzu+OPPJILV68WHfffbcuvfRSPfLII5Kk448/Xu+9954mT56sadOmdfsvNe/Wsix95Stf0dVXX60nnnhCfr+fa+gCKCqEWgAw4H//93+VTCZ1wQUXaMOGDfrwww/1/vvva82aNVq0aNEht582bZo++eQTPf3002psbNSaNWu6hcqOjg7V1dXp1Vdf1ccff6w33nhDW7ZscebXrly5Ug0NDWpqatLWrVv16quvOr+76KKLdODAAV177bV666231NjYqIaGBq1YsUKJREKbN29WfX29tmzZop07d+rZZ5/V3r17BzwnGADyiTm1AGDA1KlT9fjjj6u+vl6//OUvtXv3bo0ZM0bHH3+8brnllkNuP2/ePC1ZskR1dXWKxWKaM2eOli1bprvvvluS5PF4tH//ft14443as2ePRo8erfnz5+vqq6+WJCWTSdXV1WnXrl0qLy/XGWecoRUrVkiSjjjiCD300EO68847ddlllykWi2nSpEk644wz5PF4VF5ertdee00PPPCAWltbNWnSJP3kJz9xLgcGAMXAsrlmCwAAAIoc0w8AAABQ9Ai1AAAAKHqEWgAAABQ9Qi0AAACKHqEWAAAARY9QCwAAgKJHqAUAAEDRI9QCAACg6BFqAQAAUPQItQAAACh6hFoAAAAUvf8PQC0PGd8paaIAAAAASUVORK5CYII="},"metadata":{}}]}]}