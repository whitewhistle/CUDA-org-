{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3989074,"sourceType":"datasetVersion","datasetId":2367101}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-24T13:28:16.989924Z","iopub.execute_input":"2024-01-24T13:28:16.990373Z","iopub.status.idle":"2024-01-24T13:28:17.349688Z","shell.execute_reply.started":"2024-01-24T13:28:16.990340Z","shell.execute_reply":"2024-01-24T13:28:17.348729Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/smoker-status-prediction-using-biosignals/train_dataset.csv\n/kaggle/input/smoker-status-prediction-using-biosignals/test_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\n\nimport argparse, os, shutil, time, random, math\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.utils.data as data\nimport torch.nn.functional as F\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:17.351912Z","iopub.execute_input":"2024-01-24T13:28:17.352675Z","iopub.status.idle":"2024-01-24T13:28:18.823356Z","shell.execute_reply.started":"2024-01-24T13:28:17.352636Z","shell.execute_reply":"2024-01-24T13:28:18.822239Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"bcl.py","metadata":{}},{"cell_type":"code","source":"\"\"\"\nAuthor: Yonglong Tian (yonglong@mit.edu)\nDate: May 07, 2020\n\"\"\"\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport math\nimport torch.nn.functional as F\nimport numpy as np\n\n\n\nclass BalSCL(nn.Module):\n    def __init__(self, cls_num_list=None, temperature=0.1):\n        super(BalSCL, self).__init__()\n        self.temperature = temperature\n        self.cls_num_list = cls_num_list\n\n    def forward(self, centers1, features, targets, ):\n\n        device = (torch.device('cuda')\n                  if features.is_cuda\n                  else torch.device('cpu'))\n        batch_size = features.shape[0]\n        targets = targets.contiguous().view(-1, 1)\n        targets_centers = torch.arange(len(self.cls_num_list), device=device).view(-1, 1)\n        targets = torch.cat([targets.repeat(2, 1), targets_centers], dim=0)\n        batch_cls_count = torch.eye(len(self.cls_num_list))[targets].sum(dim=0).squeeze()\n\n        mask = torch.eq(targets[:2 * batch_size], targets.T).float().to(device)\n        logits_mask = torch.scatter(\n            torch.ones_like(mask),\n            1,\n            torch.arange(batch_size * 2).view(-1, 1).to(device),\n            0\n        )\n        mask = mask * logits_mask\n        \n        # class-complement\n        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n        features = torch.cat([features, centers1], dim=0)\n        logits = features[:2 * batch_size].mm(features.T)\n        logits = torch.div(logits, self.temperature)\n\n        # For numerical stability\n        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n        logits = logits - logits_max.detach()\n\n        # class-averaging\n        exp_logits = torch.exp(logits) * logits_mask\n        per_ins_weight = torch.tensor([batch_cls_count[i] for i in targets], device=device).view(1, -1).expand(\n            2 * batch_size, 2 * batch_size + len(self.cls_num_list)) - mask\n        exp_logits_sum = exp_logits.div(per_ins_weight).sum(dim=1, keepdim=True)\n        \n        log_prob = logits - torch.log(exp_logits_sum)\n        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n\n        loss = - mean_log_prob_pos\n        loss = loss.view(2, batch_size).mean()\n        return loss\n\n\n\n\nclass LogitAdjust(nn.Module):\n\n    def __init__(self, cls_num_list, tau=1, weight=None):\n        super(LogitAdjust, self).__init__()\n        cls_num_list = torch.cuda.FloatTensor(cls_num_list)\n        cls_p_list = cls_num_list / cls_num_list.sum()\n        m_list = tau * torch.log(cls_p_list)\n        self.m_list = m_list.view(1, -1)\n        self.weight = weight\n\n    def forward(self, x, target):\n        x_m = x + self.m_list\n        return F.cross_entropy(x_m, target, weight=self.weight)\n\n\nclass BCLLoss(nn.Module):\n    def __init__(self, cls_num_list, tau=1, weight=None, temperature = 0.1, alpha=2.0, beta=0.6 ):\n        super(BCLLoss, self).__init__()\n        self.criterion_ce = LogitAdjust(cls_num_list).cuda()\n        self.criterion_scl = BalSCL(cls_num_list, temperature).cuda()\n        self.alpha = alpha\n        self.beta = beta\n        \n    def forward(self, centers,  logits, features, targets):\n        scl_loss = self.criterion_scl(centers, features, targets)\n        ce_loss = self.criterion_ce(logits, targets)\n\n        return self.alpha * ce_loss + self.beta * scl_loss\n\n\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.824559Z","iopub.execute_input":"2024-01-24T13:28:18.824999Z","iopub.status.idle":"2024-01-24T13:28:18.845498Z","shell.execute_reply.started":"2024-01-24T13:28:18.824965Z","shell.execute_reply":"2024-01-24T13:28:18.844207Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"bs.py","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BS(nn.Module):\n    def __init__(self, dist):\n        super().__init__()\n        dist = torch.from_numpy(np.array(dist)).float().cuda()\n        self.prob = dist / sum(dist)\n        self.log_prior = torch.log(self.prob).unsqueeze(0)\n        \n    def forward(self, logits, targets, epoch=None, reduction='mean'):\n        adjusted_logits = logits + self.log_prior\n        return F.cross_entropy(adjusted_logits, targets, reduction = reduction)\n        \n        \n        # targets = F.one_hot(targets, num_classes=logits.size(1))\n        # logits = logits + torch.log(self.prob.view(1, -1).expand(logits.shape[0], -1)).cuda()\n        \n        # if reduction == 'none':\n        #     return -(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n        # else:\n        #     return -torch.mean(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.846745Z","iopub.execute_input":"2024-01-24T13:28:18.847110Z","iopub.status.idle":"2024-01-24T13:28:18.863222Z","shell.execute_reply.started":"2024-01-24T13:28:18.847076Z","shell.execute_reply":"2024-01-24T13:28:18.862284Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"ce drw","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass CE_DRW(nn.Module):\n    \n    def __init__(self, cls_num_list, reweight_epoch=160):\n        super(CE_DRW, self).__init__()\n        self.cls_num_list = cls_num_list\n        self.reweight_epoch= reweight_epoch\n        \n    def drw(self, epoch):\n        idx = epoch // self.reweight_epoch\n        betas = [0, 0.9999]\n        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n        self.weight = per_cls_weights\n\n    def forward(self, x, target, epoch, reduction='mean'):\n        self.drw(epoch)\n        return F.cross_entropy(x, target, weight=self.weight, reduction=reduction)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.866383Z","iopub.execute_input":"2024-01-24T13:28:18.867029Z","iopub.status.idle":"2024-01-24T13:28:18.878781Z","shell.execute_reply.started":"2024-01-24T13:28:18.867002Z","shell.execute_reply":"2024-01-24T13:28:18.877987Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"ce","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CE(nn.Module):\n    def __init__(self, weight=None):\n        super().__init__()\n        self.weight = weight\n    def forward(self, logits, targets, epoch=None, reduction='mean'):\n        # targets = F.one_hot(targets, num_classes=logits.size(1))\n        # if reduction == 'mean':\n        #     return -torch.mean(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n        # else:\n        #     return -(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n\n        return F.cross_entropy(logits, targets, weight = self.weight, reduction = reduction)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.879750Z","iopub.execute_input":"2024-01-24T13:28:18.880038Z","iopub.status.idle":"2024-01-24T13:28:18.890415Z","shell.execute_reply.started":"2024-01-24T13:28:18.880013Z","shell.execute_reply":"2024-01-24T13:28:18.889619Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"ldam drw","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass LDAM_DRW(nn.Module):\n    def __init__(self, cls_num_list, reweight_epoch, max_m=0.5, s=30):\n        super(LDAM_DRW, self).__init__()\n        self.cls_num_list = cls_num_list\n        self.reweight_epoch = reweight_epoch\n        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n        m_list = m_list * (max_m / np.max(m_list))\n        m_list = torch.cuda.FloatTensor(m_list)\n        self.m_list = m_list\n        assert s > 0\n        self.s = s\n      \n    def drw(self, epoch):\n        idx = epoch // self.reweight_epoch\n        betas = [0, 0.9999]\n        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n        self.weight = per_cls_weights\n\n\n    def forward(self, x, target, epoch=None, reduction='mean'):\n        self.drw(epoch)\n        index = torch.zeros_like(x, dtype=torch.uint8)\n        index.scatter_(1, target.data.view(-1, 1), 1)\n        \n        index_float = index.type(torch.cuda.FloatTensor)\n        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n        batch_m = batch_m.view((-1, 1))\n        x_m = x - batch_m\n    \n        output = torch.where(index, x_m, x)\n        return F.cross_entropy(self.s*output, target, weight=self.weight, reduction=reduction)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.891345Z","iopub.execute_input":"2024-01-24T13:28:18.892570Z","iopub.status.idle":"2024-01-24T13:28:18.905119Z","shell.execute_reply.started":"2024-01-24T13:28:18.892543Z","shell.execute_reply":"2024-01-24T13:28:18.904346Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"ncl","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\ndef NBOD(inputs, factor):\n\n    classifier_num = len(inputs)\n    if classifier_num == 1:\n        return 0\n    logits_softmax = []\n    logits_logsoftmax = []\n    for i in range(classifier_num):\n        logits_softmax.append(F.softmax(inputs[i], dim=1))\n        logits_logsoftmax.append(torch.log(logits_softmax[i] + 1e-9))\n\n    loss_mutual = 0\n    for i in range(classifier_num):\n        for j in range(classifier_num):\n            if i == j:\n                continue\n            loss_mutual += factor * F.kl_div(logits_logsoftmax[i], logits_softmax[j],reduction='batchmean')\n    loss_mutual /= (classifier_num - 1)\n    return  loss_mutual\n\nclass NIL_NBOD(nn.Module):\n    def __init__(self, args, num_class_list):\n        super(NIL_NBOD, self).__init__()\n        self.args = args\n        self.num_class_list = num_class_list\n        self.bsce_weight = torch.FloatTensor(self.num_class_list).cuda()\n\n\n        self.multi_classifier_diversity_factor = 0.6\n        self.multi_classifier_diversity_factor_hcm = 0.6\n        self.ce_ratio = 1.0\n        self.hcm_ratio = 1.0\n        if self.args.dataset == 'cifar100':\n            self.hcm_N = 30\n        elif self.args.dataset == 'imgnet':\n            self.hcm_N = 300\n        elif self.args.dataset == 'places':\n            self.hcm_N = 122\n        elif self.args.dataset == 'inat':\n            self.hcm_N = 2442\n\n\n\n    def forward(self, inputs, targets, **kwargs):\n        \"\"\"\n        Args:\n            inputs: prediction matrix (before softmax) with shape (classifier_num, batch_size, num_classes)\n            targets: ground truth labels with shape (classifier_num, batch_size)\n        \"\"\"\n        classifier_num = len(inputs)\n        loss_HCM = 0\n        loss = 0\n        los_ce = 0\n\n        inputs_HCM_balance = []\n        inputs_balance = []\n        class_select = inputs[0].scatter(1, targets[0].unsqueeze(1), 999999)\n        class_select_include_target = class_select.sort(descending=True, dim=1)[1][:, :self.hcm_N]\n        mask = torch.zeros_like(inputs[0]).scatter(1, class_select_include_target, 1)\n        for i in range(classifier_num):\n\n            logits = inputs[i] + self.bsce_weight.unsqueeze(0).expand(inputs[i].shape[0], -1).log()\n            inputs_balance.append(logits)\n            inputs_HCM_balance.append(logits * mask)\n\n            los_ce += F.cross_entropy(logits, targets[0])\n            loss_HCM += F.cross_entropy(inputs_HCM_balance[i], targets[0])\n\n        loss += NBOD(inputs_balance, factor=self.multi_classifier_diversity_factor)\n        loss += NBOD(inputs_HCM_balance, factor=self.multi_classifier_diversity_factor_hcm)\n        loss += los_ce * self.ce_ratio + loss_HCM * self.hcm_ratio\n        return loss\n\n    def update(self, epoch):\n        \"\"\"\n        Args:\n           code can be added for progressive loss.\n        \"\"\"\n        pass\n\n\nif __name__ == '__main__':\n    pass","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.906223Z","iopub.execute_input":"2024-01-24T13:28:18.906543Z","iopub.status.idle":"2024-01-24T13:28:18.924374Z","shell.execute_reply.started":"2024-01-24T13:28:18.906518Z","shell.execute_reply":"2024-01-24T13:28:18.923463Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"ride","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nimport random\n\nclass RIDE(nn.Module):\n    def __init__(self, cls_num_list=None, base_diversity_temperature=1.0, max_m=0.5, s=30, reweight=True, reweight_epoch=-1, \n        base_loss_factor=1.0, additional_diversity_factor=-0.2, reweight_factor=0.05):\n        super().__init__()\n        self.base_loss = F.cross_entropy\n        self.base_loss_factor = base_loss_factor\n        if not reweight:\n            self.reweight_epoch = -1\n        else:\n            self.reweight_epoch = reweight_epoch\n\n        # LDAM is a variant of cross entropy and we handle it with self.m_list.\n        if cls_num_list is None:\n            # No cls_num_list is provided, then we cannot adjust cross entropy with LDAM.\n\n            self.m_list = None\n            self.per_cls_weights_enabled = None\n            self.per_cls_weights_enabled_diversity = None\n        else:\n            # We will use LDAM loss if we provide cls_num_list.\n\n            m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n            m_list = m_list * (max_m / np.max(m_list))\n            m_list = torch.tensor(m_list, dtype=torch.float, requires_grad=False)\n            self.m_list = m_list\n            self.s = s\n            assert s > 0\n            \n            if reweight_epoch != -1:\n                idx = 1 # condition could be put in order to set idx\n                betas = [0, 0.9999]\n                effective_num = 1.0 - np.power(betas[idx], cls_num_list)\n                per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n                per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(cls_num_list)\n                self.per_cls_weights_enabled = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False)\n            else:\n                self.per_cls_weights_enabled = None\n\n            cls_num_list = np.array(cls_num_list) / np.sum(cls_num_list)\n            C = len(cls_num_list)\n            per_cls_weights = C * cls_num_list * reweight_factor + 1 - reweight_factor\n\n            # Experimental normalization: This is for easier hyperparam tuning, the effect can be described in the learning rate so the math formulation keeps the same.\n            # At the same time, the 1 - max trick that was previously used is not required since weights are already adjusted.\n            per_cls_weights = per_cls_weights / np.max(per_cls_weights)\n\n            assert np.all(per_cls_weights > 0), \"reweight factor is too large: out of bounds\"\n            # save diversity per_cls_weights\n            self.per_cls_weights_enabled_diversity = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False).cuda()\n\n        self.base_diversity_temperature = base_diversity_temperature\n        self.additional_diversity_factor = additional_diversity_factor\n\n    def to(self, device):\n        super().to(device)\n        if self.m_list is not None:\n            self.m_list = self.m_list.to(device)\n        \n        if self.per_cls_weights_enabled is not None:\n            self.per_cls_weights_enabled = self.per_cls_weights_enabled.to(device)\n\n        if self.per_cls_weights_enabled_diversity is not None:\n            self.per_cls_weights_enabled_diversity = self.per_cls_weights_enabled_diversity.to(device)\n\n        return self\n\n    def _hook_before_epoch(self, epoch):\n        if self.reweight_epoch != -1:\n            self.epoch = epoch\n\n            if epoch > self.reweight_epoch:\n                self.per_cls_weights_base = self.per_cls_weights_enabled\n                self.per_cls_weights_diversity = self.per_cls_weights_enabled_diversity\n            else:\n                self.per_cls_weights_base = None\n                self.per_cls_weights_diversity = None\n\n    def get_final_output(self, output_logits, target):\n        x = output_logits\n\n        index = torch.zeros_like(x, dtype=torch.uint8, device=x.device)\n        index.scatter_(1, target.data.view(-1, 1), 1)\n        \n        index_float = index.float()\n        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n        \n        batch_m = batch_m.view((-1, 1))\n        x_m = x - batch_m * self.s\n\n        final_output = torch.where(index, x_m, x)\n        return final_output\n\n    def forward(self, output_logits, target, extra_info=None, reduction='mean'):\n        if extra_info is None:\n            return self.base_loss(output_logits, target)\n\n        if reduction == 'none':\n            loss = torch.zeros_like(target).float()\n        else:\n            loss = 0\n\n\n        # Adding RIDE Individual Loss for each expert\n        for logits_item in extra_info['logits']:\n            ride_loss_logits = output_logits if self.additional_diversity_factor == 0 else logits_item\n            if self.m_list is None:\n                loss += self.base_loss_factor * self.base_loss(ride_loss_logits, target, reduction=reduction)\n            else:\n                final_output = self.get_final_output(ride_loss_logits, target)\n                loss += self.base_loss_factor * self.base_loss(final_output, target, weight=self.per_cls_weights_base, reduction=reduction)\n            \n            base_diversity_temperature = self.base_diversity_temperature\n\n            if self.per_cls_weights_diversity is not None:\n                diversity_temperature = base_diversity_temperature * self.per_cls_weights_diversity.view((1, -1))\n                temperature_mean = diversity_temperature.mean().item()\n            else:\n                diversity_temperature = base_diversity_temperature\n                temperature_mean = base_diversity_temperature\n            \n            output_dist = F.log_softmax(logits_item / diversity_temperature, dim=1)\n            with torch.no_grad():\n                # Using the mean takes only linear instead of quadratic time in computing and has only a slight difference so using the mean is preferred here\n                mean_output_dist = F.softmax(output_logits / diversity_temperature, dim=1)\n            \n            loss += self.additional_diversity_factor * temperature_mean * temperature_mean * F.kl_div(output_dist, mean_output_dist, reduction='batchmean')\n        \n        return loss\n\nclass RIDEWithDistill(nn.Module):\n    def __init__(self, cls_num_list=None, additional_distill_loss_factor=1.0, distill_temperature=1.5, ride_loss_factor=1.0, **kwargs):\n        super().__init__()\n        self.ride_loss = RIDE(cls_num_list=cls_num_list, **kwargs)\n        self.distill_temperature = distill_temperature\n\n        self.ride_loss_factor = ride_loss_factor\n        self.additional_distill_loss_factor = additional_distill_loss_factor\n\n    def to(self, device):\n        super().to(device)\n        self.ride_loss = self.ride_loss.to(device)\n        return self\n\n    def _hook_before_epoch(self, epoch):\n        self.ride_loss._hook_before_epoch(epoch)\n\n    def forward(self, student, target=None, teacher=None, extra_info=None):\n        output_logits = student\n        if extra_info is None:\n            return self.ride_loss(output_logits, target)\n\n        loss = 0\n        num_experts = len(extra_info['logits'])\n        for logits_item in extra_info['logits']:\n            loss += self.ride_loss_factor * self.ride_loss(output_logits, target, extra_info)\n            distill_temperature = self.distill_temperature\n\n            student_dist = F.log_softmax(student / distill_temperature, dim=1)\n            with torch.no_grad():\n                teacher_dist = F.softmax(teacher / distill_temperature, dim=1)\n            \n            distill_loss = F.kl_div(student_dist, teacher_dist, reduction='batchmean')\n            distill_loss = distill_temperature * distill_temperature * distill_loss\n            loss += self.additional_distill_loss_factor * distill_loss\n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.925888Z","iopub.execute_input":"2024-01-24T13:28:18.926252Z","iopub.status.idle":"2024-01-24T13:28:18.956925Z","shell.execute_reply.started":"2024-01-24T13:28:18.926225Z","shell.execute_reply":"2024-01-24T13:28:18.956156Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"common.py\n","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\n\nimport argparse, os, shutil, random, math\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\n!pip install progress\n# added on my own\nimport progress \n#end\n\nfrom progress.bar import Bar as Bar\n\ndef make_imb_data(max_num, class_num, gamma):\n    mu = np.power(1/gamma, 1/(class_num - 1))\n    class_num_list = []\n    for i in range(class_num):\n        if i == (class_num - 1):\n            class_num_list.append(int(max_num / gamma))\n        else:\n            class_num_list.append(int(max_num * np.power(mu, i)))\n    print(class_num_list)\n    return list(class_num_list)\n\ndef hms_string(sec_elapsed):\n    h = int(sec_elapsed / (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) / 60)\n    s = sec_elapsed % 60.\n    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n\ndef save_checkpoint(state, epoch, checkpoint='none', filename='checkpoint.pth.tar'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n    \n    if epoch % 100 == 0:\n        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_' + str(epoch) + '.pth.tar'))\n        \ndef linear_rampup(current, rampup_length=0):\n    if rampup_length == 0:\n        return 1.0\n    else:\n        current = np.clip(current / rampup_length, 0.0, 1.0)\n        return float(current)\n    \ndef adjust_learning_rate(optimizer, epoch, scheduler, args):\n    if scheduler == None:\n        if args.epochs == 200:\n            epoch = epoch + 1\n            if epoch <= args.warmup:\n                lr = args.lr * epoch / args.warmup\n            elif epoch > 180:\n                lr = args.lr * args.lr_decay ** 2\n            elif epoch > 160:\n                lr = args.lr * args.lr_decay\n            else:\n                lr = args.lr\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = lr\n            return lr\n\n        elif args.epochs == 400:\n            if args.loss_fn == 'bcl':\n                epoch = epoch + 1\n                if epoch <= args.warmup:\n                    lr = args.lr * epoch / args.warmup\n                elif epoch > 380:\n                    lr = args.lr * args.lr_decay ** 2\n                elif epoch > 360:\n                    lr = args.lr * args.lr_decay\n                else:\n                    lr = args.lr\n\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = lr\n                return lr\n            else:\n                epoch = epoch + 1\n                if epoch <= args.warmup:\n                    lr = args.lr * epoch / args.warmup\n                elif epoch > 360:\n                    lr = args.lr * args.lr_decay ** 2\n                elif epoch > 320:\n                    lr = args.lr * args.lr_decay\n                else:\n                    lr = args.lr\n\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = lr\n                return lr\n        else:\n            return args.lr\n    else:\n        scheduler.step()\n        return optimizer.param_groups[0]['lr']\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:18.958411Z","iopub.execute_input":"2024-01-24T13:28:18.958662Z","iopub.status.idle":"2024-01-24T13:28:30.758751Z","shell.execute_reply.started":"2024-01-24T13:28:18.958632Z","shell.execute_reply":"2024-01-24T13:28:30.757697Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Requirement already satisfied: progress in /opt/conda/lib/python3.10/site-packages (1.6)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"loss.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom bisect import bisect_right\n\n\n\n#from utils.common import adjust_learning_rate\n\nfrom torch.optim import lr_scheduler\n\ndef get_optimizer(args, model):\n    _model = model['model'] if args.loss_fn == 'ncl' else model\n    return optim.SGD(_model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd,\n                     nesterov=args.nesterov)\n\ndef get_scheduler(args, optimizer):\n    if args.scheduler == 'cosine':\n        return lr_scheduler.CosineAnnealingLR(optimizer, args.epochs, eta_min = 0)\n    elif args.scheduler == 'warmup':\n        return None\n\ndef get_loss(args, N_SAMPLES_PER_CLASS):\n    if args.loss_fn == 'ce':\n        train_criterion = CE()\n    elif args.loss_fn == 'ce_drw':\n        train_criterion = CE_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160)\n    elif args.loss_fn == 'bs':\n        train_criterion = BS(N_SAMPLES_PER_CLASS)\n    elif args.loss_fn == 'ldam_drw':\n        train_criterion = LDAM_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160, max_m=0.5, s=30).cuda()\n    elif args.loss_fn == 'ride':\n        if args.num_experts == 3 and args.ride_distill:\n            train_criterion = RIDEWithDistill(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n        else:\n            train_criterion = RIDE(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n        train_criterion = train_criterion.to(torch.device('cuda'))\n    elif args.loss_fn == 'ncl':\n        train_criterion = NIL_NBOD(args, N_SAMPLES_PER_CLASS)\n\n    elif args.loss_fn == 'bcl':\n        train_criterion = BCLLoss(N_SAMPLES_PER_CLASS)\n\n    else:\n        raise NotImplementedError\n        \n\n    return train_criterion\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.760540Z","iopub.execute_input":"2024-01-24T13:28:30.761430Z","iopub.status.idle":"2024-01-24T13:28:30.773964Z","shell.execute_reply.started":"2024-01-24T13:28:30.761389Z","shell.execute_reply":"2024-01-24T13:28:30.772954Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"cuda.py","metadata":{}},{"cell_type":"code","source":"import torch as t\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom torch.utils.data.dataset import Dataset\n\nimport random\nimport PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\nimport numpy as np\nimport torch\nfrom PIL import Image\n\ndef CUDA(img,m,n, rand=True, max_d=30):\n    _augment_list = augment_list()\n    ops = random.choices(_augment_list, k=n)\n    m = float(m) / max_d\n    for op, minval, maxval in ops:\n        val = (float(m)) * float(maxval - minval) + minval\n        img = op(img, val)\n    return img\n\ndef Flip(img, _):\n    return PIL.ImageOps.flip(img)\n\ndef Mirror(img, _):\n    return PIL.ImageOps.mirror(img)\n\ndef EdgeEnhance(img, _):\n    return img.filter(PIL.ImageFilter.EDGE_ENHANCE)\n\ndef Detail(img, _):\n    return img.filter(PIL.ImageFilter.DETAIL)\n\ndef Smooth(img, _):\n    return img.filter(PIL.ImageFilter.SMOOTH)\n    \ndef AutoContrast(img, _):\n    return PIL.ImageOps.autocontrast(img)\n\ndef Equalize(img, _):\n    return PIL.ImageOps.equalize(img)\n\ndef Invert(img, _):\n    return PIL.ImageOps.invert(img)\n\ndef GaussianBlur(img, v):\n    # assert 0 <= v <= 5\n    filter = PIL.ImageFilter.GaussianBlur(v)\n    return img.filter(filter)\n\ndef ResizeCrop(img, v):\n    # assert 1 <= v <= 2\n    width, height = img.size\n    enlarge = img.resize((int(width*v), int(height*v)), Image.ANTIALIAS)\n    left = int(width*v)//2 - width//2\n    right = int(width*v)//2 + width//2\n    top = int(height*v)//2 - height//2\n    bottom = int(height*v)//2 + height//2\n    return enlarge.crop((left, top, right, bottom))\n\ndef Rotate(img, v):  # [-30, 30]\n    # assert -30 <= v <= 30\n    if random.random() > 0.5:\n        v = -v\n    return img.rotate(v)\n\ndef Posterize(img, v):  # [4, 8]\n    v = int(v)\n    v = max(1, v)\n    return PIL.ImageOps.posterize(img, v)\n\ndef Solarize(img, v):  # [0, 256]\n    # assert 0 <= v <= 256\n    return PIL.ImageOps.solarize(img, v)\n\ndef SolarizeAdd(img, addition=0, threshold=128):\n    img_np = np.array(img).astype(int)\n    img_np = img_np + addition\n    img_np = np.clip(img_np, 0, 255)\n    img_np = img_np.astype(np.uint8)\n    img = Image.fromarray(img_np)\n    return PIL.ImageOps.solarize(img, threshold)\n\ndef Color(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Color(img).enhance(v)\n\ndef Contrast(img, v):  # [0.1,1.9]Æ’\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Contrast(img).enhance(v)\n\ndef Brightness(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Brightness(img).enhance(v)\n\ndef Sharpness(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n\ndef ShearX(img, v):  # [-0.3, 0.3]\n    # assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n\ndef ShearY(img, v):  # [-0.3, 0.3]\n    # assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n\ndef TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    # assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\ndef TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    # assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\ndef augment_list():  \n    l = [\n        (Flip, 0, 1),\n        (Mirror, 0, 1),\n        (EdgeEnhance, 0, 1),\n        (Detail, 0, 1),\n        (Smooth, 0, 1),\n        (AutoContrast, 0, 1),\n        (Equalize, 0, 1),\n        (Invert, 0, 1),\n        (GaussianBlur, 0, 2),\n        (ResizeCrop,1, 1.5),\n        (Rotate, 0, 30),\n        (Posterize, 0, 4),\n        (Solarize, 0, 256),\n        (SolarizeAdd, 0, 110),\n        (Color, 0.1, 1.9),\n        (Contrast, 0.1, 1.9),\n        (Brightness, 0.1, 1.9),\n        (Sharpness, 0.1, 1.9),\n        (ShearX, 0., 0.3),\n        (ShearY, 0., 0.3),\n        (TranslateXabs, 0., 100),\n        (TranslateYabs, 0., 100),\n    ]\n\n    \n\n    return l\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.775033Z","iopub.execute_input":"2024-01-24T13:28:30.775319Z","iopub.status.idle":"2024-01-24T13:28:30.803989Z","shell.execute_reply.started":"2024-01-24T13:28:30.775295Z","shell.execute_reply":"2024-01-24T13:28:30.803142Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"autoaug.py\n","metadata":{}},{"cell_type":"code","source":"from PIL import Image, ImageEnhance, ImageOps\nimport numpy as np\nimport random\nimport torch\n\n\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n\nclass ImageNetPolicy(object):\n    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n        Example:\n        >>> policy = ImageNetPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     ImageNetPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment ImageNet Policy\"\n\n\nclass CIFAR10Policy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n        Example:\n        >>> policy = CIFAR10Policy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     CIFAR10Policy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n\n            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n\n            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n\n            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n\n            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment CIFAR10 Policy\"\n\n\nclass SVHNPolicy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on SVHN.\n        Example:\n        >>> policy = SVHNPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     SVHNPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.9, \"shearX\", 4, 0.2, \"invert\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.7, \"invert\", 5, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.6, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 3, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"equalize\", 1, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.8, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.4, \"invert\", 5, fillcolor),\n            SubPolicy(0.9, \"shearY\", 5, 0.2, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 6, 0.8, \"autocontrast\", 1, fillcolor),\n            SubPolicy(0.6, \"equalize\", 3, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.3, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 8, 0.7, \"invert\", 4, fillcolor),\n            SubPolicy(0.9, \"equalize\", 5, 0.6, \"translateY\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 4, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.3, \"contrast\", 3, 0.8, \"rotate\", 4, fillcolor),\n\n            SubPolicy(0.8, \"invert\", 5, 0.0, \"translateY\", 2, fillcolor),\n            SubPolicy(0.7, \"shearY\", 6, 0.4, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 0.8, \"rotate\", 4, fillcolor),\n            SubPolicy(0.3, \"shearY\", 7, 0.9, \"translateX\", 3, fillcolor),\n            SubPolicy(0.1, \"shearX\", 6, 0.6, \"invert\", 5, fillcolor),\n\n            SubPolicy(0.7, \"solarize\", 2, 0.6, \"translateY\", 7, fillcolor),\n            SubPolicy(0.8, \"shearY\", 4, 0.8, \"invert\", 8, fillcolor),\n            SubPolicy(0.7, \"shearX\", 9, 0.8, \"translateY\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 5, 0.7, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.7, \"shearX\", 2, 0.1, \"invert\", 5, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment SVHN Policy\"\n\n\nclass SubPolicy(object):\n    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n        ranges = {\n            \"shearX\": np.linspace(0, 0.3, 10),\n            \"shearY\": np.linspace(0, 0.3, 10),\n            \"translateX\": np.linspace(0, 150 / 331, 10),\n            \"translateY\": np.linspace(0, 150 / 331, 10),\n            \"rotate\": np.linspace(0, 30, 10),\n            \"color\": np.linspace(0.0, 0.9, 10),\n            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n            \"solarize\": np.linspace(256, 0, 10),\n            \"contrast\": np.linspace(0.0, 0.9, 10),\n            \"sharpness\": np.linspace(0.0, 0.9, 10),\n            \"brightness\": np.linspace(0.0, 0.9, 10),\n            \"autocontrast\": [0] * 10,\n            \"equalize\": [0] * 10,\n            \"invert\": [0] * 10\n        }\n\n        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n        def rotate_with_fill(img, magnitude):\n            rot = img.convert(\"RGBA\").rotate(magnitude)\n            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n\n        func = {\n            \"shearX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"shearY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"translateX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n                fillcolor=fillcolor),\n            \"translateY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n                fillcolor=fillcolor),\n            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n        }\n\n        self.p1 = p1\n        self.operation1 = func[operation1]\n        self.magnitude1 = ranges[operation1][magnitude_idx1]\n        self.p2 = p2\n        self.operation2 = func[operation2]\n        self.magnitude2 = ranges[operation2][magnitude_idx2]\n\n\n    def __call__(self, img):\n        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n        return img","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.805451Z","iopub.execute_input":"2024-01-24T13:28:30.805727Z","iopub.status.idle":"2024-01-24T13:28:30.858260Z","shell.execute_reply.started":"2024-01-24T13:28:30.805703Z","shell.execute_reply":"2024-01-24T13:28:30.857407Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"randaug.py\n","metadata":{}},{"cell_type":"code","source":"# code in this file is adpated from rpmcruz/autoaugment\n# https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\nimport random\n\nimport PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\nimport numpy as np\nimport torch\nfrom PIL import Image\n\n\ndef ShearX(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n\n\ndef ShearY(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n\n\ndef TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random.random() > 0.5:\n        v = -v\n    v = v * img.size[0]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random.random() > 0.5:\n        v = -v\n    v = v * img.size[1]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef Rotate(img, v):  # [-30, 30]\n    assert -30 <= v <= 30\n    if random.random() > 0.5:\n        v = -v\n    return img.rotate(v)\n\n\ndef AutoContrast(img, _):\n    return PIL.ImageOps.autocontrast(img)\n\n\ndef Invert(img, _):\n    return PIL.ImageOps.invert(img)\n\n\ndef Equalize(img, _):\n    return PIL.ImageOps.equalize(img)\n\n\ndef Flip(img, _):  # not from the paper\n    return PIL.ImageOps.mirror(img)\n\n\ndef Solarize(img, v):  # [0, 256]\n    assert 0 <= v <= 256\n    return PIL.ImageOps.solarize(img, v)\n\n\ndef SolarizeAdd(img, addition=0, threshold=128):\n    img_np = np.array(img).astype(int)\n    img_np = img_np + addition\n    img_np = np.clip(img_np, 0, 255)\n    img_np = img_np.astype(np.uint8)\n    img = Image.fromarray(img_np)\n    return PIL.ImageOps.solarize(img, threshold)\n\n\ndef Posterize(img, v):  # [4, 8]\n    v = int(v)\n    v = max(1, v)\n    return PIL.ImageOps.posterize(img, v)\n\n\ndef Contrast(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Contrast(img).enhance(v)\n\n\ndef Color(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Color(img).enhance(v)\n\n\ndef Brightness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Brightness(img).enhance(v)\n\n\ndef Sharpness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n\n\n\n\ndef CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n    # assert 0 <= v <= 20\n    if v < 0:\n        return img\n    w, h = img.size\n    x0 = np.random.uniform(w)\n    y0 = np.random.uniform(h)\n\n    x0 = int(max(0, x0 - v / 2.))\n    y0 = int(max(0, y0 - v / 2.))\n    x1 = min(w, x0 + v)\n    y1 = min(h, y0 + v)\n\n    xy = (x0, y0, x1, y1)\n    color = (125, 123, 114)\n    # color = (0, 0, 0)\n    img = img.copy()\n    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n    return img\n\n\ndef SamplePairing(imgs):  # [0, 0.4]\n    def f(img1, v):\n        i = np.random.choice(len(imgs))\n        img2 = PIL.Image.fromarray(imgs[i])\n        return PIL.Image.blend(img1, img2, v)\n\n    return f\n\n\ndef Identity(img, v):\n    return img\n\n\ndef augment_list():  # 16 oeprations and their ranges\n    # https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57\n    # l = [\n    #     (Identity, 0., 1.0),\n    #     (ShearX, 0., 0.3),  # 0\n    #     (ShearY, 0., 0.3),  # 1\n    #     (TranslateX, 0., 0.33),  # 2\n    #     (TranslateY, 0., 0.33),  # 3\n    #     (Rotate, 0, 30),  # 4\n    #     (AutoContrast, 0, 1),  # 5\n    #     (Invert, 0, 1),  # 6\n    #     (Equalize, 0, 1),  # 7\n    #     (Solarize, 0, 110),  # 8\n    #     (Posterize, 4, 8),  # 9\n    #     # (Contrast, 0.1, 1.9),  # 10\n    #     (Color, 0.1, 1.9),  # 11\n    #     (Brightness, 0.1, 1.9),  # 12\n    #     (Sharpness, 0.1, 1.9),  # 13\n    #     # (Cutout, 0, 0.2),  # 14\n    #     # (SamplePairing(imgs), 0, 0.4),  # 15\n    # ]\n\n    # https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505\n    l = [\n        (AutoContrast, 0, 1),\n        (Equalize, 0, 1),\n        (Invert, 0, 1),\n        (Rotate, 0, 30),\n        (Posterize, 0, 4),\n        (Solarize, 0, 256),\n        (SolarizeAdd, 0, 110),\n        (Color, 0.1, 1.9),\n        (Contrast, 0.1, 1.9),\n        (Brightness, 0.1, 1.9),\n        (Sharpness, 0.1, 1.9),\n        (ShearX, 0., 0.3),\n        (ShearY, 0., 0.3),\n        (CutoutAbs, 0, 40),\n        (TranslateXabs, 0., 100),\n        (TranslateYabs, 0., 100),\n    ]\n\n    return l\n\n\nclass Lighting(object):\n    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n\n    def __init__(self, alphastd, eigval, eigvec):\n        self.alphastd = alphastd\n        self.eigval = torch.Tensor(eigval)\n        self.eigvec = torch.Tensor(eigvec)\n\n    def __call__(self, img):\n        if self.alphastd == 0:\n            return img\n\n        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n        rgb = self.eigvec.type_as(img).clone() \\\n            .mul(alpha.view(1, 3).expand(3, 3)) \\\n            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n            .sum(1).squeeze()\n\n        return img.add(rgb.view(3, 1, 1).expand_as(img))\n\n\nclass CutoutDefault(object):\n    \"\"\"\n    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py\n    \"\"\"\n    def __init__(self, length):\n        self.length = length\n\n    def __call__(self, img):\n        h, w = img.size(1), img.size(2)\n        mask = np.ones((h, w), np.float32)\n        y = np.random.randint(h)\n        x = np.random.randint(w)\n\n        y1 = np.clip(y - self.length // 2, 0, h)\n        y2 = np.clip(y + self.length // 2, 0, h)\n        x1 = np.clip(x - self.length // 2, 0, w)\n        x2 = np.clip(x + self.length // 2, 0, w)\n\n        mask[y1: y2, x1: x2] = 0.\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img *= mask\n        return img\n\n\nclass RandAugment:\n    def __init__(self, n, m):\n        self.n = n\n        self.m = m      # [0, 30]\n        self.augment_list = augment_list()\n\n    def __call__(self, img):\n        ops = random.choices(self.augment_list, k=self.n)\n        for op, minval, maxval in ops:\n            val = (float(self.m) / 30) * float(maxval - minval) + minval\n            img = op(img, val)\n\n        return img\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.862885Z","iopub.execute_input":"2024-01-24T13:28:30.863158Z","iopub.status.idle":"2024-01-24T13:28:30.900333Z","shell.execute_reply.started":"2024-01-24T13:28:30.863135Z","shell.execute_reply":"2024-01-24T13:28:30.899400Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"cutout.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.901291Z","iopub.execute_input":"2024-01-24T13:28:30.901565Z","iopub.status.idle":"2024-01-24T13:28:30.914362Z","shell.execute_reply.started":"2024-01-24T13:28:30.901542Z","shell.execute_reply":"2024-01-24T13:28:30.913479Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"transformer.py","metadata":{}},{"cell_type":"code","source":"from torchvision.transforms import transforms\nfrom PIL import ImageFilter\nimport random\n#from aug.cutout import *\n\ncifar10_mean = (0.4914, 0.4822, 0.4465)\ncifar10_std = (0.2023, 0.1994, 0.2010)\n\n\n\nclass GaussianBlur(object):\n    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n\n    def __init__(self, sigma=[.1, 2.]):\n        self.sigma = sigma\n\n    def __call__(self, x):\n        sigma = random.uniform(self.sigma[0], self.sigma[1])\n        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n        return x\n\n\n\ndef get_transform(loss_fn, cutout = False):\n    # Augmentations.\n    if loss_fn in ['ce', 'ldam_drw', 'bs', 'ce_drw', 'ride']:\n        train_before = [\n                transforms.RandomCrop(32, padding=4),\n                transforms.RandomHorizontalFlip(),\n            ]\n        \n        if cutout:\n            train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n\n        transform_train = [[transforms.Compose(train_before), transforms.Compose(train_after)]]\n\n    elif loss_fn in ['ncl']:\n        regular_train_before = [\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),\n            ]\n\n        if cutout:\n            regular_train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            regular_train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n\n\n        sim_cifar_before = [\n            transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n            ]\n        sim_cifar_after = [\n            transforms.ToTensor(),\n            transforms.Normalize(cifar10_mean, cifar10_std),\n            ]\n        transform_train = [\n            [transforms.Compose(regular_train_before), \n            transforms.Compose(regular_train_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)],\n            ]\n\n\n    \n    elif loss_fn in ['bcl']:\n        regular_train_before = [\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),\n            ]\n\n        if cutout:\n            regular_train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            regular_train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        \n        sim_cifar_before = [\n            transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n            ]\n        sim_cifar_after = [\n            transforms.ToTensor(),\n            transforms.Normalize(cifar10_mean, cifar10_std),\n            ]\n\n        transform_train = [\n            [transforms.Compose(regular_train_before), \n            transforms.Compose(regular_train_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)],\n            ]\n\n    transform_val = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(cifar10_mean, cifar10_std)\n    ])\n    \n    return transform_train, transform_val\n    \n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.915533Z","iopub.execute_input":"2024-01-24T13:28:30.915812Z","iopub.status.idle":"2024-01-24T13:28:30.935232Z","shell.execute_reply.started":"2024-01-24T13:28:30.915789Z","shell.execute_reply":"2024-01-24T13:28:30.934415Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"cifar100.py\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport random\n\nimport torchvision\nimport torch\n\nfrom torch.utils.data import Dataset\n\nfrom torchvision.transforms import transforms\n\n\n\n    \ndef get_cifar100(root, args):\n    transform_train, transform_val = get_transform(args.loss_fn, cutout = args.cutout)\n\n    train_dataset = CIFAR100_train(root, args, imb_ratio = args.imb_ratio, train=True, transform = transform_train, aug_prob=args.aug_prob)\n    test_dataset = CIFAR100_val(root, transform=transform_val)\n    print (f\"#Train: {len(train_dataset)}, #Test: {len(test_dataset)}\")\n    return train_dataset, test_dataset\n    \nclass test_CIFAR100(Dataset):\n    def __init__(self, indices, state, cifar_dataset):\n        self.indices = indices\n        self.state = state\n        self.dataset = cifar_dataset\n\n    def __getitem__(self,idx):\n        data, label, _ = self.dataset.get_item(self.indices[idx], self.state[idx], train=False)\n        return data, label, self.indices[idx], self.state[idx]\n    \n    def __len__(self):\n        return len(self.indices)\n\nclass CIFAR100_train(torchvision.datasets.CIFAR100):\n    def __init__(self, root , args, aug_prob, imb_type='exp', imb_ratio=100, train=True, transform=None, target_transform=None, download=True):\n        super(CIFAR100_train,self).__init__(root, train=train, transform=transform, target_transform = target_transform, download= download)\n\n        np.random.seed(0)\n        self.args = args\n        self.cls_num = 100\n        self.img_num_list = self.get_img_num_per_cls(self.cls_num, imb_type, 1./imb_ratio)\n        self.transform_train = transform\n        self.gen_imbalanced_data(self.img_num_list)\n        \n\n        if 'autoaug_cifar' in args.aug_type:\n            print('autoaug_cifar')\n            self.aug_transform = transforms.Compose([CIFAR10Policy()])\n        elif 'autoaug_svhn' in args.aug_type:\n            print('autoaug_svhn')\n            self.aug_transform = transforms.Compose([SVHNPolicy()])\n        elif 'autoaug_imagenet' in args.aug_type:\n            print('autoaug_imagenet')\n            self.aug_transform = transforms.Compose([ImageNetPolicy()])\n        #elif 'dada_cifar' in args.aug_type:\n            print('dada_cifar')\n            self.aug_transform = transforms.Compose([dada_cifar()])\n        #elif 'dada_imagenet' in args.aug_type:\n            print('dada_imagenet')\n            self.aug_transform = transforms.Compose([dada_imagenet()])\n        #elif 'faa_cifar' in args.aug_type:\n            print('faa_cifar')\n            self.aug_transform = transforms.Compose([faa_cifar()])\n        #elif 'faa_imagenet' in args.aug_type:\n            print('faa_imagenet')\n            self.aug_transform = transforms.Compose([faa_imagenet()])\n        elif 'randaug' in args.aug_type:\n            print('randaug')\n            self.aug_transform = transforms.Compose([RandAugment(2, 14)])\n        elif 'none' in args.aug_type:\n            self.aug_transform = transforms.Compose([])\n        else:\n            raise NotImplementedError\n        \n\n\n\n        # max_mag = 10\n        # max_ops = 10\n        max_mag = 10\n        max_ops = 10\n        self.min_state = 0\n        self.max_state = max(max_mag, max_ops) + 1\n        \n        states = torch.arange(self.min_state, self.max_state)\n        if self.max_state == 1:\n            self.ops = torch.tensor([0])\n            self.mag = torch.tensor([0])\n            \n        elif max_mag > max_ops:\n            self.ops = (states * max_ops / max_mag).ceil().int()\n            self.mag = states.int()\n        else:\n            self.mag = (states * max_mag / max_ops).ceil().int()\n            self.ops = states.int()\n        \n        print(f\"Magnitude set = {self.mag}\")\n        print(f\"Operation set = {self.ops}\")\n\n        self.curr_state = torch.zeros(len(self.data))\n        self.score_tmp = torch.zeros((len(self.targets), self.max_state))\n        self.num_test = torch.zeros((len(self.targets), self.max_state))\n        self.aug_prob = aug_prob\n\n\n\n    def get_img_num_per_cls(self, cls_num, imb_type, imb_factor):\n        img_max = len(self.data) / cls_num\n        img_num_per_cls = []\n        if imb_type == 'exp':\n            for cls_idx in range(cls_num):\n                num = img_max * (imb_factor ** (cls_idx / (cls_num - 1.0)))\n                img_num_per_cls.append(int(num))\n        else:\n            img_num_per_cls.extend([int(img_max)] * cls_num)\n        return img_num_per_cls\n\n\n    def gen_imbalanced_data(self, img_num_per_cls):\n        new_data = []\n        new_targets = []\n        #changed from np.int64\n        targets_np = np.array(self.targets, dtype=int)\n        classes = np.unique(targets_np)\n        # np.random.shuffle(classes)\n\n        self.num_per_cls_dict = dict()\n        for the_class, the_img_num in zip(classes, img_num_per_cls):\n            self.num_per_cls_dict[the_class] = the_img_num\n            idx = np.where(targets_np == the_class)[0]\n            np.random.shuffle(idx)\n            selec_idx = idx[:the_img_num]\n            # print(selec_idx)\n            new_data.append(self.data[selec_idx, ...])\n            new_targets.extend([the_class, ] * the_img_num)\n        new_data = np.vstack(new_data)\n        self.data = new_data\n        self.targets = new_targets\n\n    def get_cls_num_list(self):\n        cls_num_list = []\n        for i in range(self.cls_num):\n            cls_num_list.append(self.num_per_cls_dict[i])\n        return cls_num_list\n\n    def sim_aug(self, img, state, type):\n        if type == 'cuda':\n            return  CUDA(img, self.mag[state], self.ops[state], max_d = self.args.max_d)\n        else:\n            return img\n        \n\n    \n    def get_item(self, index, state, train=True):\n        img, target = self.data[index], self.targets[index]\n        img = Image.fromarray(img)\n        \n        if train:\n            if len(self.transform_train) == 1:\n                img = self.transform_train[0][0](img)\n                img = self.aug_transform(img)\n                img = CUDA(img, self.mag[state], self.ops[state])\n                img = self.transform_train[0][1](img)\n                return img, target, index\n\n            elif len(self.transform_train) == 2:\n                img1 = self.transform_train[0][0](img)\n                img1 = self.aug_transform(img1)\n                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n                img1 = self.transform_train[0][1](img1)\n\n                img2 = self.transform_train[1][0](img)\n                img2 = self.sim_aug(img2, state, self.args.sim_type)\n                img2 = self.transform_train[1][1](img2)\n                \n                return (img1, img2), target, index\n                \n            elif len(self.transform_train) == 3:\n                img1 = self.transform_train[0][0](img)\n                img1 = self.aug_transform(img1)\n                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n                img1 = self.transform_train[0][1](img1)\n\n                img2 = self.transform_train[1][0](img)\n                img2 = self.sim_aug(img2, state, self.args.sim_type)\n                img2 = self.transform_train[1][1](img2)\n                \n                img3 = self.transform_train[2][0](img)\n                img3 = self.sim_aug(img3, state, self.args.sim_type)\n                img3 = self.transform_train[2][1](img3)\n                return (img1, img2, img3), target, index\n\n        else:\n            img = self.transform_train[0][0](img)\n            img = self.aug_transform(img)\n            img = CUDA(img, self.mag[state], self.ops[state], rand=False , max_d = self.args.max_d)\n            img = self.transform_train[0][1](img)\n            return img, target, index\n        \n    def __getitem__(self, index):\n        state = self.curr_state[index].int() if torch.rand(1) < self.aug_prob else 0\n        \n        img, target, index = self.get_item(index, state, train=True)\n        return img, target, index\n    \n    def update_scores(self, correct, index, state):\n        for s in np.unique(state):\n            pos = np.where(state == s)\n            score_result = np.bincount(index[pos], correct[pos], len(self.score_tmp))\n            num_test_result = np.bincount(index[pos], np.ones(len(index))[pos], len(self.score_tmp))\n            self.score_tmp[:,s] += score_result\n            self.num_test[:,s] += num_test_result\n            \n\n    def update(self):\n        # Increase\n        pos = torch.where((self.score_tmp == self.num_test) & (self.num_test != 0))\n        self.curr_state[pos] += 1\n        \n        # Decrease\n        pos = torch.where(self.score_tmp != self.num_test)\n        self.curr_state[pos] -= 1\n        \n        \n        self.curr_state = torch.clamp(self.curr_state, self.min_state, self.max_state-1)\n        self.score_tmp *= 0\n        self.num_test *= 0\n        \n    \nclass CIFAR100_val(torchvision.datasets.CIFAR100):\n    def __init__(self, root, transform=None, indexs=None,\n                 target_transform=None, download=True):\n        super(CIFAR100_val, self).__init__(root, train=False, transform=transform, target_transform=target_transform,download=download)\n        \n        if indexs is not None:\n            self.data = self.data[indexs]\n            self.targets = np.array(self.targets)[indexs]\n        self.data = [Image.fromarray(img) for img in self.data]\n        \n    def __getitem__(self, index):\n        img, target = self.data[index], self.targets[index]\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n        return img, target, index","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.936366Z","iopub.execute_input":"2024-01-24T13:28:30.936689Z","iopub.status.idle":"2024-01-24T13:28:30.981841Z","shell.execute_reply.started":"2024-01-24T13:28:30.936663Z","shell.execute_reply":"2024-01-24T13:28:30.981035Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"accuracy.py","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function, absolute_import\n\nimport errno\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\nfrom torch.autograd import Variable\n\n\n__all__ = ['accuracy', 'AverageMeter']\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].reshape(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\n       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.982997Z","iopub.execute_input":"2024-01-24T13:28:30.983322Z","iopub.status.idle":"2024-01-24T13:28:30.997007Z","shell.execute_reply.started":"2024-01-24T13:28:30.983297Z","shell.execute_reply":"2024-01-24T13:28:30.996216Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"cutmix.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ndef rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix(data_f, data_b):\n    lam = np.random.beta(1., 1.)\n    bbx1, bby1, bbx2, bby2 = rand_bbox(data_f.size(), lam)\n    data_b[:, :, bbx1:bbx2, bby1:bby2] = data_f[:, :, bbx1:bbx2, bby1:bby2]\n    lam = 1-((bbx2 - bbx1) * (bby2 - bby1) / (data_f.size()[2] * data_f.size()[3]))\n    \n    return data_b, torch.tensor(lam)\n\n# def cutmix(data_aug, data, label, param, percent=1.0):\n    # data = data_aug\n    # sample_num = int(len(param)*percent)\n    # argsort = torch.argsort(param,descending=True)\n    # param /= torch.max(param)\n    \n    # candidate = argsort[:sample_num]\n    \n    # data_f = data[candidate]\n    # label_f = label[candidate]\n    # param_f = param[candidate]\n    \n    # back_perm = candidate[torch.randperm(len(candidate))]\n    # data_b = data[back_perm]\n    # label_b = label[back_perm]\n    # param_b = param[back_perm]\n    \n    # # lam = torch.exp(param_f) / (torch.exp(param_f)+torch.exp(param_b))\n    # lam = torch.tensor(np.random.beta(1.,1.,(sample_num,)))\n    \n    # size = data.size()\n    # W = size[2]\n    # H = size[3]\n    # cut_rat = torch.sqrt(1. - lam)\n    # cut_w = (cut_rat * W).int()\n    # cut_h = (cut_rat * H).int()\n\n    # # uniform\n    # cx = torch.randint(0,W,(len(candidate),))\n    # cy = torch.randint(0,H,(len(candidate),))\n\n    # bbx1 = torch.clip(cx - cut_w // 2, 0, W)\n    # bby1 = torch.clip(cy - cut_h // 2, 0, H)\n    # bbx2 = torch.clip(cx + cut_w // 2, 0, W)\n    # bby2 = torch.clip(cy + cut_h // 2, 0, H)\n    \n    # for idx in range(len(data_b)):\n    #     data_b[idx, :, bbx1[idx]:bbx2[idx], bby1[idx]:bby2[idx]] = data_f[idx, :, bbx1[idx]:bbx2[idx], bby1[idx]:bby2[idx]]\n    # data_aug[candidate] = data_b\n    \n    # label[candidate] = label_b\n    # label_aug = torch.zeros(len(label),dtype=int)\n    # label_aug[candidate] = label_f.cpu()\n\n    # ret_lbd = torch.ones(len(label))\n    # ret_lbd[candidate] -= ((bbx2 - bbx1) * (bby2 - bby1) / (W*H))\n\n    # return data_aug, label, label_aug, ret_lbd","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:30.998075Z","iopub.execute_input":"2024-01-24T13:28:30.998400Z","iopub.status.idle":"2024-01-24T13:28:31.013600Z","shell.execute_reply.started":"2024-01-24T13:28:30.998367Z","shell.execute_reply":"2024-01-24T13:28:31.012823Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"basetrain","metadata":{}},{"cell_type":"code","source":"\nfrom __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar\n\nimport copy, time\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\n\n\ndef update_score_base(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    curr_state = loader.dataset.curr_state\n    max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        n = num_test\n        pos, state = [], []\n        ''' \n        for s in range(max_state):\n            entire_pos = torch.arange(len(loader.dataset.targets))\n            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n            pos +=  _pos\n            state += [s] * len(_pos)\n        tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n                                                 shuffle=False, num_workers = 8)\n        \n        '''\n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            logit = model(data, output_type = None).cpu()\n\n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n\n    \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    \n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    '''\n    \n\n    all_indices = torch.arange(len(loader.dataset.targets))\n    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n\n    ratio = correct_sum_all_classes / trial_sum_all_classes\n    idx = loader.dataset.curr_state[0].int() + 1\n    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n\n    if condition:\n            loader.dataset.curr_state[all_indices] += 1\n    else:\n            loader.dataset.curr_state[all_indices] -= 1\n    '''\n        \n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n\n    # print(f'Max correct: {int(torch.max(correct_sum_per_class))} Max trial: {int(torch.max(trial_sum_per_class))}')\n    \n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    \n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n# def update_score_base(loader, model, n_samples_per_class, posthoc_la):\n#     model.eval()\n    \n#     if posthoc_la:\n#         dist = torch.tensor(n_samples_per_class)\n#         prob = dist / dist.sum()\n    \n#     # curr_state= loader.dataset.curr_state\n#     # max_state = torch.max(curr_state).int() + 1\n    \n#     with torch.no_grad():\n#         # pos, state = [], []\n            \n#         # for s in range(max_state):\n#         #     _pos = torch.where(curr_state >= s)[0]\n#         #     pos_list = _pos.tolist() * (s+1) \n#         #     pos +=  pos_list\n#         #     state += [s] * len(pos_list)\n#         # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n#         # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n#         #                                         shuffle=False, num_workers = 8)\n        \n#         n = 10\n#         pos, state = [], []\n#         for cidx in range(len(n_samples_per_class)):\n#             class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n#             max_state = loader.dataset.curr_state[class_pos[0]].int() \n#             for s in range(max_state+1):\n#                 _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n#                 pos += _pos \n#                 state += [s] * len(_pos)\n \n#         tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n#         tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n#         for batch_idx, data_tuple in enumerate(tmp_loader):\n#             data = data_tuple[0].cuda()\n#             label = data_tuple[1]\n#             idx = data_tuple[2]\n\n#             logit = model(data, output_type = None).cpu()\n\n#             if posthoc_la:\n#                 logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n#             correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n#             loader.dataset.update_scores(correct,idx)\n#     print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    \n#     # loader.dataset.update()\n#     for cidx in range(len(n_samples_per_class)):\n#         class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n#         correct_sum = torch.sum(loader.dataset.score_tmp[class_pos])\n#         trial_sum = torch.sum(loader.dataset.num_test[class_pos])\n\n#         # if correct_sum == trial_sum:\n#         if float(correct_sum) >= float(trial_sum * 0.8):\n#             loader.dataset.curr_state[class_pos] += 1\n#         else:\n#             loader.dataset.curr_state[class_pos] -= 1\n\n#     loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n#     loader.dataset.score_tmp *= 0\n#     loader.dataset.num_test *= 0\n\n\n\n\n#     model.train()\n    \n#     # Debug\n#     curr_state = loader.dataset.curr_state\n#     label = loader.dataset.targets\n#     print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n#     return curr_state, label\n\n\n\n\n\ndef train_base(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    bar = Bar('Training', max=len(trainloader))\n\n    if args.cmo and 3 < epoch < (args.epochs - 3):\n        inverse_iter = iter(weighted_trainloader)\n\n        \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo and 3 < epoch < (args.epochs - 3):\n            try:\n                data_tuple_f = next(inverse_iter)\n            except:\n                inverse_iter = iter(weighted_trainloader)\n                data_tuple_f = next(inverse_iter)\n\n            inputs_f = data_tuple_f[0]\n            targets_f = data_tuple_f[1]\n            inputs_f = inputs_f[:len(inputs_b)]\n            targets_f = targets_f[:len(targets_b)]\n            inputs_f = inputs_f.cuda(non_blocking=True)\n            targets_f = targets_f.cuda(non_blocking=True)\n\n        inputs_b = inputs_b.cuda(non_blocking=True)\n        targets_b = targets_b.cuda(non_blocking=True)\n\n\n        r = np.random.rand(1)\n        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n            inputs_b, lam = cutmix(inputs_f, inputs_b)\n            outputs = model(inputs_b, None)\n            loss = criterion(outputs, targets_b, epoch) * lam + criterion(outputs, targets_f, epoch) * (1.-lam)\n        else:\n            outputs = model(inputs_b, None)\n            loss = criterion(outputs, targets_b, epoch)\n        \n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.014751Z","iopub.execute_input":"2024-01-24T13:28:31.015037Z","iopub.status.idle":"2024-01-24T13:28:31.047324Z","shell.execute_reply.started":"2024-01-24T13:28:31.015014Z","shell.execute_reply":"2024-01-24T13:28:31.046491Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"bcltrain","metadata":{}},{"cell_type":"code","source":"\n\nfrom __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar\n\nimport copy, time\nimport random\n\n#from datasets.cifar100 import test_CIFAR100\n\n\n\ndef update_score_bcl(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    # curr_state = loader.dataset.curr_state\n    # max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        # pos, state = [], []\n            \n        # for s in range(max_state):\n        #     _pos = torch.where(curr_state >= s)[0]\n        #     pos_list = _pos.tolist() * (s+1) \n        #     pos +=  pos_list\n        #     state += [s] * len(pos_list)\n        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n        #                                         shuffle=False, num_workers = 8)\n        \n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            _, logit, _ = model(data)\n            \n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n            correct = (logit.cpu().max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n\n\n            \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    # print(f'Max correct: {int(torch.max(correct_sum_per_class))} Max trial: {int(torch.max(trial_sum_per_class))}')\n    \n    \n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n\n\n\ndef train_bcl(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    bar = Bar('Training', max=len(trainloader))\n        \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo:\n            raise \"BCL not implemented for CMO...\"\n        else:\n            inputs_b = torch.cat([inputs_b[0], inputs_b[1], inputs_b[2]], dim=0).cuda()\n            batch_size = targets_b.shape[0]\n            targets_b = targets_b.cuda()\n            feat_mlp, logits, centers = model(inputs_b)\n            centers = centers[:args.num_class]\n            _, f2, f3 = torch.split(feat_mlp, [batch_size, batch_size, batch_size], dim=0)\n            features = torch.cat([f2.unsqueeze(1), f3.unsqueeze(1)], dim=1)\n            logits, _, __ = torch.split(logits, [batch_size, batch_size, batch_size], dim=0)\n            loss = criterion(centers, logits, features, targets_b)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.048583Z","iopub.execute_input":"2024-01-24T13:28:31.048889Z","iopub.status.idle":"2024-01-24T13:28:31.074384Z","shell.execute_reply.started":"2024-01-24T13:28:31.048865Z","shell.execute_reply":"2024-01-24T13:28:31.073621Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"ncltrain","metadata":{}},{"cell_type":"code","source":"\n#from utils.accuracy import AverageMeter\nimport torch\nimport time\n#from utils.common import Bar, adjust_learning_rate\n\nimport copy\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\ndef update_score_ncl(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model = model['model']\n    model.eval()\n     \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    \n    # curr_state = loader.dataset.curr_state\n    # max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        # pos, state = [], []\n            \n        # for s in range(max_state):\n        #     _pos = torch.where(curr_state >= s)[0]\n        #     pos_list = _pos.tolist() * (s+1) \n        #     pos +=  pos_list\n        #     state += [s] * len(pos_list)\n        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,   shuffle=False, num_workers = 8, drop_last=True)\n        \n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            data_list = [data for i in range(model.network_num)]\n\n            feature = model((data_list,data_list), label=label, feature_flag=True)\n            output_ce, output, output_MA = model(feature, classifier_flag=True)\n            logit = torch.mean(torch.stack(output_ce), dim=0).cpu()\n\n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1)).cuda()\n\n            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n    \n    \n \n    \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n    \n    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    \n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\ndef train_ncl(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher=None):\n    combiner = model['comb']\n    model = model['model']\n    network_num = 3\n\n    model.train()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n\n    bar = Bar('Training', max=len(trainloader))\n    \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs = data_tuple[0]\n        targets = data_tuple[1]\n        indexs = data_tuple[2]\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets.size(0)\n\n        if args.cmo:\n            raise \"NCL not implemented for CMO...\"\n        else:\n            image_list = [inputs] * network_num\n            label_list = [targets] * network_num\n            indexs_list = [indexs] * network_num\n\n            loss = combiner.forward(model, criterion, image_list, label_list)\n\n            if args.dataset in ['cifar100', 'places']:\n                alpha = 0.999\n                for net_id in range(network_num):\n                    net = ['backbone', 'module']\n                    for name in net:\n                        for ema_param, param in zip(eval('model.' + name + '_MA').parameters(),\n                                                    eval('model.' + name).parameters()):\n                            ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n\n        # record\n        losses.update(loss.data.item(), targets.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.075543Z","iopub.execute_input":"2024-01-24T13:28:31.075786Z","iopub.status.idle":"2024-01-24T13:28:31.102146Z","shell.execute_reply.started":"2024-01-24T13:28:31.075765Z","shell.execute_reply":"2024-01-24T13:28:31.101290Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"ridetrain","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar, adjust_learning_rate\n\nimport copy\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\ndef update_score_ride(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    curr_state = loader.dataset.curr_state\n    max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        n = num_test\n        pos, state = [], []\n            \n\n    \n    with torch.no_grad():\n        pos, state = [], []\n            \n        # for s in range(max_state):\n        #     _pos = torch.where(curr_state >= s)[0]\n        #     pos_list = _pos.tolist() * (s+1) \n        #     pos +=  pos_list\n        #     state += [s] * len(pos_list)\n        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n        #                                         shuffle=False, num_workers = 8)\n        \n        n = num_test\n        pos, state = [], []\n        \n        \n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n        '''\n        \n        for s in range(max_state):\n            entire_pos = torch.arange(len(loader.dataset.targets))\n            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n            pos +=  _pos\n            state += [s] * len(_pos)\n        '''\n\n        \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            # logit = model(data, output_type = None).cpu()\n            # if posthoc_la:\n            #     logit = logit - tau * torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n            # correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n\n            outputs = model(data, output_type='dict')\n            logit = outputs['logits'].cpu()\n\n            for cor_idx in range(logit.size(1)):\n                if cor_idx == 0:\n                    correct = (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n                else:\n                    correct += (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n            \n            correct = torch.floor(correct/logit.size(1))\n            loader.dataset.update_scores(correct,idx, state)\n    '''\n    all_indices = torch.arange(len(loader.dataset.targets))\n    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n\n    ratio = correct_sum_all_classes / trial_sum_all_classes\n    idx = loader.dataset.curr_state[0].int() + 1\n    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n\n    if condition:\n            loader.dataset.curr_state[all_indices] += 1\n    else:\n            loader.dataset.curr_state[all_indices] -= 1 \n    \n    '''\n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        # if correct_sum == trial_sum:\n        # if float(correct_sum) >= float(trial_sum * 0.6):\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n    \n\n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n\ndef ride_loss_wrap(criterion, student, teacher, target, extra_info):\n    if teacher == None:\n        return criterion(output_logits = student['output'], target = target, extra_info = extra_info)\n    else:\n        return criterion(student = student['output'], target = target, teacher = teacher, extra_info = extra_info)\n\ndef train_ride(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher):\n    \"\"\"\n    Training logic for an epoch\n    \n    :param epoch: Integer, current training epoch.\n    :return: A log that contains average loss and metric in this epoch.\n    \"\"\"\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    if hasattr(criterion, \"_hook_before_epoch\"):\n        criterion._hook_before_epoch(epoch)\n        \n    bar = Bar('Training', max=len(trainloader))\n\n\n    if args.cmo and 3 < epoch < (args.epochs-3):\n        inverse_iter = iter(weighted_trainloader)\n\n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n        \n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo and 3 < epoch < (args.epochs-3):\n            try:\n                data_tuple_f = next(inverse_iter)\n            except:\n                inverse_iter = iter(weighted_trainloader)\n                data_tuple_f = next(inverse_iter)\n                \n            inputs_f = data_tuple_f[0]\n            targets_f = data_tuple_f[1]\n            inputs_f = inputs_f[:len(inputs_b)]\n            targets_f = targets_f[:len(targets_b)]\n            inputs_f = inputs_f.cuda(non_blocking=True)\n            targets_f = targets_f.cuda(non_blocking=True)\n\n\n        inputs_b = inputs_b.cuda(non_blocking=True)\n        targets_b = targets_b.cuda(non_blocking=True)\n\n        r = np.random.rand(1)\n        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n            inputs_b, lam = cutmix(inputs_f, inputs_b)\n            outputs =  model(inputs_b)\n            extra_info = {}\n            # logits = outputs[\"logits\"]\n            # extra_info.update({\"logits\" : logits.transpose(0,1)})\n            # loss = criterion(output_logits = outputs['output'], target = targets_b, extra_info = extra_info) * lam + criterion(output_logits = outputs['output'], target = targets_f, extra_info = extra_info) * (1.-lam)\n            if teacher == None:\n                teacher_outputs = None\n            else:\n                teacher_outputs = teacher(inputs_b)['output']\n            \n            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n                \n            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info) * lam + ride_loss_wrap(criterion, outputs, teacher_outputs, targets_f, extra_info) * (1.-lam)\n            \n            \n        else:\n            extra_info = {}\n            outputs = model(inputs_b)\n            # logits = outputs[\"logits\"]\n            # extra_info.update({\"logits\": logits.transpose(0, 1)})\n            # loss = criterion(output_logits=outputs['output'], target=targets_b, extra_info=extra_info)\n            \n            if teacher == None:\n                teacher_outputs = None\n            else:\n                teacher_outputs = teacher(inputs_b)['output']\n            \n            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        \n        bar.next()\n    bar.finish()\n    return losses.avg\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.103296Z","iopub.execute_input":"2024-01-24T13:28:31.103577Z","iopub.status.idle":"2024-01-24T13:28:31.138275Z","shell.execute_reply.started":"2024-01-24T13:28:31.103552Z","shell.execute_reply":"2024-01-24T13:28:31.137477Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"train.py","metadata":{}},{"cell_type":"code","source":"#from train.train_fn.base import train_base, update_score_base\n#from train.train_fn.ride import train_ride, update_score_ride\n#from train.train_fn.ncl import train_ncl, update_score_ncl\n#from train.train_fn.bcl import train_bcl, update_score_bcl\n\ndef get_train_fn(args):\n    if args.loss_fn == 'ride':\n        return train_ride\n    elif args.loss_fn == 'ncl':\n        return train_ncl\n    elif args.loss_fn == 'bcl':\n        return train_bcl\n    else:\n        return train_base\n\n        \n        \ndef get_update_score_fn(args):\n    if args.loss_fn == 'ride':\n        return update_score_ride\n    elif args.loss_fn == 'ncl':\n        return update_score_ncl\n    elif args.loss_fn == 'bcl':\n        return update_score_bcl\n    else:\n        return update_score_base\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.139297Z","iopub.execute_input":"2024-01-24T13:28:31.139552Z","iopub.status.idle":"2024-01-24T13:28:31.154255Z","shell.execute_reply.started":"2024-01-24T13:28:31.139529Z","shell.execute_reply":"2024-01-24T13:28:31.153393Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"validate.py","metadata":{}},{"cell_type":"code","source":"#from utils.accuracy import AverageMeter, accuracy\nfrom scipy import optimize\n#from utils.common import Bar\nimport torch\nimport numpy as np\nimport time\n\ndef get_valid_fn(args):\n    if args.loss_fn == 'ncl':\n        return valid_ncl\n    elif args.loss_fn == 'bcl':\n        return valid_bcl\n    else:\n        return valid_normal\n\n\ndef valid_ncl(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats'):\n    combiner = model['comb']\n    model = model['model']\n    network_num = 3\n    model.eval()\n    network_num = 3\n    cnt_all = 0\n    every_network_result = [0 for _ in range(network_num)]\n\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    \n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            image = data_tuple[0]\n            label = data_tuple[1]\n            indexs = data_tuple[2]\n\n            image, label = image.cuda(), label.cuda()\n            image_list = [image for i in range(network_num)]\n\n            if args.dataset in ['cifar100', 'places']:\n                feature = model((image_list,image_list), label=label, feature_flag=True)\n                output_ce, output, output_MA = model(feature, classifier_flag=True)\n            else:\n                feature = model(image_list, label=label, feature_flag=True)\n                output_ce = model(feature, classifier_flag=True)\n\n\n            \n            for j, logit in enumerate(output_ce):\n                every_network_result[j] += torch.sum(torch.argmax(logit, dim=1).cpu() == label.cpu())\n\n            average_result = torch.mean(torch.stack(output_ce), dim=0)\n            loss = criterion(average_result, label)\n\n            prec1, prec5 = accuracy(average_result.cpu(), label.cpu(), topk=(1,5))\n            losses.update(loss.data.item(), image.size(0))\n            top1.update(prec1.item(), image.size(0))\n            top5.update(prec5.item(), image.size(0))\n\n            # classwise prediction\n            pred_label = average_result.max(1)[1]\n            pred_mask = (label == pred_label).float()\n            for i in range(num_class):\n                class_mask = (label == i).float()\n                classwise_correct[i] += (class_mask * pred_mask).sum().detach().cpu()\n                classwise_num[i] += class_mask.sum().detach().cpu()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        \n    # Major, Neutral, Minor\n    classwise_acc = (classwise_correct / classwise_num)\n    \n    per_class_num = torch.tensor(per_class_num)\n    many_pos = torch.where(per_class_num > 100)\n    med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n    few_pos = torch.where(per_class_num < 20)\n    section_acc[0] = classwise_acc[many_pos].mean()\n    section_acc[1] = classwise_acc[med_pos].mean()\n    section_acc[2] = classwise_acc[few_pos].mean()\n    \n    return (losses.avg, top1.avg,  section_acc)\n\ndef valid_normal(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    \n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    all_preds = np.zeros(len(valloader.dataset))\n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            inputs = data_tuple[0].cuda(non_blocking=True)\n            targets = data_tuple[1].cuda(non_blocking=True)\n            indexs = data_tuple[2]\n            \n            # measure data loading time\n            data_time.update(time.time() - end)\n            \n            # compute output\n            outputs = model(inputs, None)\n            loss = criterion(outputs, targets)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n            losses.update(loss.item(), inputs.size(0))\n            top1.update(prec1.item(), inputs.size(0))\n            top5.update(prec5.item(), inputs.size(0))\n            \n            # classwise prediction\n            pred_label = outputs.max(1)[1]\n            all_preds[indexs] = pred_label.cpu().numpy()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        # Major, Neutral, Minor\n        \n        all_targets = np.array(valloader.dataset.targets)\n        pred_mask = (all_targets == all_preds).astype(float)\n        for i in range(num_class):\n            class_mask = np.where(all_targets == i)[0].reshape(-1)\n            classwise_correct[i] += pred_mask[class_mask].sum()\n            classwise_num[i] += len(class_mask)\n            \n        classwise_acc = (classwise_correct / classwise_num)\n        \n        per_class_num = torch.tensor(per_class_num)\n        many_pos = torch.where(per_class_num > 100)\n        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n        few_pos = torch.where(per_class_num < 20)\n        section_acc[0] = classwise_acc[many_pos].mean()\n        section_acc[1] = classwise_acc[med_pos].mean()\n        section_acc[2] = classwise_acc[few_pos].mean()\n\n    return (losses.avg, top1.avg,  section_acc)\n\n\ndef valid_bcl(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    \n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    all_preds = np.zeros(len(valloader.dataset))\n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            inputs = data_tuple[0].cuda(non_blocking=True)\n            targets = data_tuple[1].cuda(non_blocking=True)\n            indexs = data_tuple[2]\n            \n            # measure data loading time\n            data_time.update(time.time() - end)\n            \n            # compute output\n            _, outputs, _ = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n            losses.update(loss.item(), inputs.size(0))\n            top1.update(prec1.item(), inputs.size(0))\n            top5.update(prec5.item(), inputs.size(0))\n            \n            # classwise prediction\n            pred_label = outputs.max(1)[1]\n            all_preds[indexs] = pred_label.cpu().numpy()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        # Major, Neutral, Minor\n        \n        all_targets = np.array(valloader.dataset.targets)\n        pred_mask = (all_targets == all_preds).astype(float)\n        for i in range(num_class):\n            class_mask = np.where(all_targets == i)[0].reshape(-1)\n            classwise_correct[i] += pred_mask[class_mask].sum()\n            classwise_num[i] += len(class_mask)\n            \n        classwise_acc = (classwise_correct / classwise_num)\n        \n        per_class_num = torch.tensor(per_class_num)\n        many_pos = torch.where(per_class_num > 100)\n        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n        few_pos = torch.where(per_class_num < 20)\n        section_acc[0] = classwise_acc[many_pos].mean()\n        section_acc[1] = classwise_acc[med_pos].mean()\n        section_acc[2] = classwise_acc[few_pos].mean()\n\n    return (losses.avg, top1.avg,  section_acc)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.155641Z","iopub.execute_input":"2024-01-24T13:28:31.155976Z","iopub.status.idle":"2024-01-24T13:28:31.491962Z","shell.execute_reply.started":"2024-01-24T13:28:31.155945Z","shell.execute_reply":"2024-01-24T13:28:31.491197Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"resnetbcl","metadata":{}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n        self.apply(_weights_init)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass LambdaLayer(nn.Module):\n\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='A'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_s(nn.Module):\n\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet_s, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        return out\n\nclass bcl_model(nn.Module):\n    def __init__(self, num_classes=100, use_norm=False):\n        super(bcl_model, self).__init__()\n        self.encoder = ResNet_s(BasicBlock, [5,5,5], num_classes)\n        dim_in = 64 #2048\n        mid_dim = 512 #2048\n        feat_dim = 128 #1024\n        self.use_norm = use_norm\n        self.head = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n        \n        if self.use_norm:\n            self.fc = NormedLinear(dim_in, num_classes)\n        else:\n            self.fc = nn.Linear(dim_in, num_classes)\n        self.head_fc = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n\n        self.apply(_weights_init)\n\n\n    def forward(self, x):\n        feat = self.encoder(x)\n        feat_mlp = F.normalize(self.head(feat), dim=1)\n        logits = self.fc(feat)\n        if self.use_norm:\n            centers_logits = F.normalize(self.head_fc(self.fc.weight.T), dim=1)\n        else:\n            centers_logits = F.normalize(self.head_fc(self.fc.weight), dim=1)\n        return feat_mlp, logits, centers_logits\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.493141Z","iopub.execute_input":"2024-01-24T13:28:31.493458Z","iopub.status.idle":"2024-01-24T13:28:31.520188Z","shell.execute_reply.started":"2024-01-24T13:28:31.493432Z","shell.execute_reply":"2024-01-24T13:28:31.519228Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"resnetncl","metadata":{}},{"cell_type":"code","source":"\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\n\nimport numpy as np\nimport cv2\nimport os\nimport copy\nimport math\nfrom torch.nn.parameter import Parameter\n\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            inplanes, planes, kernel_size=3, padding=1, bias=False, stride=stride\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, padding=1, bias=False, stride=1\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n        # self.downsample = downsample\n        if stride != 1 or self.expansion * planes != inplanes:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(\n                    inplanes,\n                    self.expansion * planes,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n        else:\n            self.downsample = None\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass BottleNeck(nn.Module):\n\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1):\n        super(BottleNeck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu1 = nn.ReLU(True)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.relu2 = nn.ReLU(True)\n        self.conv3 = nn.Conv2d(\n            planes, planes * self.expansion, kernel_size=1, bias=False\n        )\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n        if stride != 1 or self.expansion * planes != inplanes:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(\n                    inplanes,\n                    self.expansion * planes,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n        else:\n            self.downsample = None\n        self.relu = nn.ReLU(True)\n\n    def forward(self, x):\n        out = self.relu1(self.bn1(self.conv1(x)))\n\n        out = self.relu2(self.bn2(self.conv2(out)))\n\n        out = self.bn3(self.conv3(out))\n\n        if self.downsample != None:\n            residual = self.downsample(x)\n        else:\n            residual = x\n        out = out + residual\n        out = self.relu(out)\n        return out\n\n##kaiming init missing!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nclass ResNet(nn.Module):\n    def __init__(\n        self,\n        args,\n        block_type,\n        num_blocks,\n        last_layer_stride=2,\n    ):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.block = block_type\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(True)\n        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(num_blocks[0], 64)\n        self.layer2 = self._make_layer(\n            num_blocks[1], 128, stride=2\n        )\n        self.layer3 = self._make_layer(\n            num_blocks[2], 256, stride=2\n        )\n        self.layer4 = self._make_layer(\n            num_blocks[3],\n            512,\n            stride=last_layer_stride,\n        )\n\n    def load_model(self, pretrain):\n        print(\"Loading Backbone pretrain model from {}......\".format(pretrain))\n        model_dict = self.state_dict()\n        pretrain_dict = torch.load(pretrain)\n        pretrain_dict = pretrain_dict[\"state_dict\"] if \"state_dict\" in pretrain_dict else pretrain_dict\n        from collections import OrderedDict\n\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if k.startswith(\"module\"):\n                k = k[7:]\n            if \"fc\" not in k and \"classifier\" not in k:\n                k = k.replace(\"backbone.\", \"\")\n                new_dict[k] = v\n\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"Backbone model has been loaded......\")\n\n    def _make_layer(self, num_block, planes, stride=1):\n        strides = [stride] + [1] * (num_block - 1)\n        layers = []\n        for now_stride in strides:\n            layers.append(\n                self.block(\n                    self.inplanes, planes, stride=now_stride\n                )\n            )\n            self.inplanes = planes * self.block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x, **kwargs):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.pool(out)\n\n        out = self.layer1(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer1':\n            out = kwargs['coef']*out + (1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer2(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer2':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer3(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer3':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer4(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer4':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        return out\n\ndef res50(args,last_layer_stride=2):\n    return ResNet(args,BottleNeck,[3, 4, 6, 3],last_layer_stride=last_layer_stride)\n    \n\ndef res152(args,last_layer_stride=2):\n    return ResNet(args,BottleNeck,[3, 8, 36, 3],last_layer_stride=last_layer_stride)\n    \n\n\n\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\n\nclass LambdaLayer(nn.Module):\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option=\"A\"):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == \"A\":\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(\n                    lambda x: F.pad(\n                        x[:, :, ::2, ::2],\n                        (0, 0, 0, 0, planes // 4, planes // 4),\n                        \"constant\",\n                        0,\n                    )\n                )\n            elif option == \"B\":\n                self.shortcut = nn.Sequential(\n                    nn.Conv2d(\n                        in_planes,\n                        self.expansion * planes,\n                        kernel_size=1,\n                        stride=stride,\n                        bias=False,\n                    ),\n                    nn.BatchNorm2d(self.expansion * planes),\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_Cifar(nn.Module):\n    def __init__(self, block, num_blocks):\n        super(ResNet_Cifar, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def load_model(self, pretrain):\n        print(\"Loading Backbone pretrain model from {}......\".format(pretrain))\n        model_dict = self.state_dict()\n        pretrain_dict = torch.load(pretrain)\n        pretrain_dict = pretrain_dict[\"state_dict\"] if \"state_dict\" in pretrain_dict else pretrain_dict\n        from collections import OrderedDict\n\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if k.startswith(\"module\"):\n                k = k[7:]\n            if \"last_linear\" not in k and \"classifier\" not in k and \"linear\" not in k and \"fd\" not in k:\n                k = k.replace(\"backbone.\", \"\")\n                k = k.replace(\"fr\", \"layer3.4\")\n                new_dict[k] = v\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"Backbone model has been loaded......\")\n\n    def forward(self, x, **kwargs):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer1':\n            out = kwargs['coef']*out + (1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer2(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer2':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        out = self.layer3(out)\n        if 'layer' in kwargs and kwargs['layer'] == 'layer3':\n            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n        return out\n\ndef res32_cifar(args,last_layer_stride):\n    return ResNet_Cifar(BasicBlock, [5, 5, 5])\n    \n\n\n\ndef ncl_model(args, num_class_list):\n    if args.dataset in ['cifar100', 'places']:\n        model = multi_Network_MOCO(args, mode=\"train\", num_classes=args.num_class).cuda()\n        comb = Combiner(args, num_class_list)\n    else:\n        model = multi_Network(args, mode=\"train\", num_classes=args.num_class).cuda()\n        comb = Combiner(args, num_class_list)\n    return {'comb': comb, 'model': model}\n\nclass Combiner:\n    def __init__(self, args, num_class_list=None):\n        self.args = args\n\n        if self.args.dataset in ['cifar100', 'places']:\n            self.type = 'multi_network_default_CON'\n        else:\n            self.type = 'multi_network_default'\n        \n        self.num_class_list = torch.FloatTensor(num_class_list)\n        self.epoch_number = self.args.epochs\n        self.initilize_all_parameters()\n\n    def initilize_all_parameters(self):\n\n        if self.args.dataset == 'cifar100':\n            self.show_step = 100\n            self.CON_ratio = 1.0    \n            self.distributed = False\n        elif self.args.dataset == 'places':\n            self.show_step = 200\n            self.CON_ratio = 1.0    \n            self.distributed = True\n        elif self.args.dataset == 'imgnet':\n            self.show_step = 200\n            self.CON_ratio = 0.0\n            self.distributed = True\n        elif self.args.dataset == 'inat':\n            self.show_step = 500\n            self.CON_ratio = 0.0\n            self.distributed = True\n\n    def update(self, epoch):\n        self.epoch = epoch\n\n\n    def forward(self, model, criterion, image, label):\n        return eval(\"self.{}\".format(self.type))(model, criterion, image, label)\n\n\n    def multi_network_default(self, model, criterion, image, label):\n\n        for i in range(len(image)):\n            image[i], label[i] = image[i].cuda(), label[i].cuda()\n\n\n        feature = model(image, feature_flag=True, label=label)\n        output = model(feature, classifier_flag=True)\n\n        loss = criterion(output, label)\n\n        average_result = torch.mean(torch.stack(output), dim=0)\n        \n        return loss\n\n    def multi_network_default_CON(self, model, criterion, image, label):\n\n        image_p = []\n        image_k = []\n        for i in range(len(image)):\n            image_p.append(image[i][0].cuda())\n            image_k.append(image[i][1].cuda())\n            label[i] = label[i].cuda()\n\n        # shuffle BN\n        if self.distributed:\n            image_k, idx_unshuffle = shuffle_BN_DDP(image_k)\n            pass\n        else:\n            image_k, idx_unshuffle = shuffle_BN(image_k)\n\n\n        feature = model((image_p, image_k), feature_flag=True, label=label)\n        output_ce, output_p, output_k = model(feature, classifier_flag=True)\n\n        # unshuffle\n        if self.distributed:\n            output_k = unshuffle_BN_DDP(output_k, idx_unshuffle)\n        else:\n            output_k = unshuffle_BN(output_k, idx_unshuffle)\n\n        loss_ce = criterion(output_ce, label, feature=feature, classifier=model.classifier)\n\n        average_result = torch.mean(torch.stack(output_ce), dim=0)\n        \n        # contrastive_loss\n        loss_CON = 0\n        for i, (q, k) in enumerate(zip(output_p, output_k)):\n            q = F.normalize(q, dim=1)\n            k = F.normalize(k, dim=1)\n            # compute logits\n            # Einstein sum is more intuitive\n            # positive logits: Nx1\n            l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n            # negative logits: NxK\n            l_neg = torch.einsum('nc,ck->nk', [q, model.MOCO[i].queue.clone().detach()])\n\n            # logits: Nx(1+K)\n            logits = torch.cat([l_pos, l_neg], dim=1)\n\n            # apply temperature\n            logits /= model.MOCO[i].T\n\n            # labels: positive key indicators\n            labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n\n            # dequeue and enqueue\n            if self.distributed:\n                model.MOCO[i]._dequeue_and_enqueue_DDP(k)\n            else:\n                model.MOCO[i]._dequeue_and_enqueue(k)\n\n\n            loss_CON += F.cross_entropy(logits, labels)\n\n        loss = loss_ce + loss_CON * self.CON_ratio\n\n        return loss\n\n\n\nclass FCNorm(nn.Module):\n    def __init__(self, num_features, num_classes):\n        super(FCNorm, self).__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.linear(F.normalize(x), F.normalize(self.weight))\n        return out\n\n\nclass GAP(nn.Module):\n    \"\"\"Global Average pooling\n        Widely used in ResNet, Inception, DenseNet, etc.\n     \"\"\"\n\n    def __init__(self):\n        super(GAP, self).__init__()\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n    def forward(self, x):\n        x = self.avgpool(x)\n        #         x = x.view(x.shape[0], -1)\n        return x\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n\n    def forward(self, x):\n        return x\n\n\n@torch.no_grad()\ndef concat_all_gather(tensor):\n    \"\"\"\n    Performs all_gather operation on the provided tensors.\n    *** Warning ***: torch.distributed.all_gather has no gradient.\n    \"\"\"\n    #with torch.no_grad():\n    tensors_gather = [torch.ones_like(tensor)\n        for _ in range(torch.distributed.get_world_size())]\n    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n\n    output = torch.cat(tensors_gather, dim=0)\n    return output\n\n@torch.no_grad()\ndef shuffle_BN(image):\n    #with torch.no_grad():\n    batch_size = image[0].shape[0]\n    idx_shuffle = torch.randperm(batch_size).cuda()\n    for i in range(len(image)):\n        image[i] = image[i][idx_shuffle]\n    idx_unshuffle = torch.argsort(idx_shuffle)\n    return image, idx_unshuffle\n\n@torch.no_grad()\ndef shuffle_BN_DDP(x):\n    \"\"\"\n    Batch shuffle, for making use of BatchNorm.\n    *** Only support DistributedDataParallel (DDP) model. ***\n    \"\"\"\n    # gather from all gpus\n\n    #with torch.no_grad():\n    shuffle_list = []\n    idx_shuffle = 0\n    for i in range(len(x)):\n        batch_size_this = x[i].shape[0]\n        x_gather = concat_all_gather(x[i])\n        batch_size_all = x_gather.shape[0]\n\n        num_gpus = batch_size_all // batch_size_this\n\n        # random shuffle index\n        if i == 0:\n            idx_shuffle = torch.randperm(batch_size_all).cuda()\n            # index for restoring\n            idx_unshuffle = torch.argsort(idx_shuffle)\n\n        # broadcast to all gpus\n        torch.distributed.broadcast(idx_shuffle, src=0)\n\n\n\n        # shuffled index for this gpu\n        gpu_idx = torch.distributed.get_rank()\n        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n        shuffle_list.append(x_gather[idx_this])\n\n    return shuffle_list, idx_unshuffle\n\n@torch.no_grad()\ndef unshuffle_BN(x, idx_unshuffle):\n    #with torch.no_grad():\n    for i in range(len(x)):\n        x[i] = x[i][idx_unshuffle]\n    return x\n\n@torch.no_grad()\ndef unshuffle_BN_DDP(x, idx_unshuffle):\n    \"\"\"\n    Undo batch shuffle.\n    *** Only support DistributedDataParallel (DDP) model. ***\n    \"\"\"\n    # gather from all gpus\n   # with torch.no_grad():\n    unshuffle_list = []\n    for i in range(len(x)):\n        batch_size_this = x[i].shape[0]\n        x_gather = concat_all_gather(x[i])\n        batch_size_all = x_gather.shape[0]\n\n        num_gpus = batch_size_all // batch_size_this\n\n        # restored index for this gpu\n        gpu_idx = torch.distributed.get_rank()\n        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n        unshuffle_list.append(x_gather[idx_this])\n\n    return unshuffle_list\n\nclass MoCo(nn.Module):\n    \"\"\"\n    Build a MoCo model with: a query encoder, a key encoder, and a queue\n    https://arxiv.org/abs/1911.05722\n    \"\"\"\n    def __init__(self, dim=128, K=65536, m=0.999, T=0.07):\n        \"\"\"\n        dim: feature dimension (default: 128)\n        K: queue size; number of negative keys (default: 65536)\n        m: moco momentum of updating key encoder (default: 0.999)\n        T: softmax temperature (default: 0.07)\n        \"\"\"\n        super(MoCo, self).__init__()\n\n        self.K = K\n        self.m = m\n        self.T = T\n\n        # create the queue\n        self.register_buffer(\"queue\", torch.randn(dim, K))\n        self.queue = nn.functional.normalize(self.queue, dim=0)\n\n        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n\n\n\n    @torch.no_grad()\n    def _dequeue_and_enqueue_DDP(self, keys):\n        # gather keys before updating queue\n        keys = concat_all_gather(keys)\n\n        batch_size = keys.shape[0]\n\n        ptr = int(self.queue_ptr)\n\n        assert self.K % batch_size == 0  # for simplicity\n\n        # replace the keys at ptr (dequeue and enqueue)\n        self.queue[:, ptr:ptr + batch_size] = keys.T\n        ptr = (ptr + batch_size) % self.K  # move pointer\n\n        self.queue_ptr[0] = ptr\n\n    @torch.no_grad()\n    def _dequeue_and_enqueue(self, keys, **kwargs):\n\n        batch_size = keys.shape[0]\n\n        ptr = int(self.queue_ptr)\n\n        assert self.K % batch_size == 0  # for simplicity\n\n        # replace the keys at ptr (dequeue and enqueue)\n        self.queue[:, ptr:ptr + batch_size] = keys.T\n\n        ptr = (ptr + batch_size) % self.K  # move pointer\n\n        self.queue_ptr[0] = ptr\n\nclass Cos_Classifier(nn.Module):\n    \"\"\" plain cosine classifier \"\"\"\n\n    def __init__(self, num_classes=10, in_dim=640, scale=16, bias=False):\n        super(Cos_Classifier, self).__init__()\n        self.scale = scale\n        self.weight = Parameter(torch.Tensor(num_classes, in_dim).cuda())\n        self.bias = Parameter(torch.Tensor(num_classes).cuda(), requires_grad=bias)\n        self.init_weights()\n\n    def init_weights(self):\n        self.bias.data.fill_(0.)\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n\n    def forward(self, x, **kwargs):\n        ex = x / torch.norm(x.clone(), 2, 1, keepdim=True)\n        ew = self.weight / torch.norm(self.weight, 2, 1, keepdim=True)\n        out = torch.mm(ex, self.scale * ew.t()) + self.bias\n        return out\n\nclass multi_Network(nn.Module):\n    def __init__(self, args, mode=\"train\", num_classes=1000):\n        super(multi_Network, self).__init__()\n        \n        self.num_classes = num_classes\n        self.args = args\n        self.network_num = 3\n        \n        \n        if self.args.dataset == 'cifar100':\n            self.args.net_type = 'res32_cifar'\n            self.args.cf = 'FC'\n            self.args.cos_scale = 16\n        elif self.args.dataset == 'imgnet':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 16\n        elif self.args.dataset == 'inat':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 32\n            \n\n        self.backbone = nn.ModuleList(\n            eval(self.args.net_type)(\n                self.args,\n                last_layer_stride=2,\n            ) for i in range(self.network_num))\n\n        self.module = nn.ModuleList(\n            self._get_module()\n            for i in range(self.network_num))\n\n        \n        self.classifier = nn.ModuleList(\n            self._get_multi_classifer(True, self.cf)\n            for i in range(self.network_num))\n\n    def forward(self, input, **kwargs):\n\n        if \"feature_flag\" in kwargs:\n            return self.extract_feature(input, **kwargs)\n        elif \"classifier_flag\" in kwargs:\n            return self.get_logits(input, **kwargs)\n\n        logits = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i], **kwargs)\n            x = (self.module[i])(x)\n            x = x.view(x.shape[0], -1)\n            self.feat.append(copy.deepcopy(x))\n            x = (self.classifier[i])(x)\n            logits.append(x)\n\n        return logits\n\n    def extract_feature(self, input, **kwargs):\n\n        feature = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i])\n            x = (self.module[i])(x)\n            x = x.view(x.shape[0], -1)\n            feature.append(x)\n\n        return feature\n\n    def get_logits(self, input, **kwargs):\n\n        logits = []\n        for i in range(self.network_num):\n            x = input[i]\n            x = (self.classifier[i])(x)\n            logits.append(x)\n\n        return logits\n\n    def extract_feature_maps(self, x):\n        x = self.backbone(x)\n        return x\n\n    def freeze_multi_backbone(self):\n        print(\"Freezing backbone .......\")\n        for p in self.backbone.parameters():\n            p.requires_grad = False\n\n    def load_backbone_model(self, backbone_path=\"\"):\n        self.backbone.load_model(backbone_path)\n        print(\"Backbone model has been loaded...\")\n\n    def load_model(self, model_path, **kwargs):\n        pretrain_dict = torch.load(\n            model_path, map_location=\"cuda\"\n        )\n        pretrain_dict = pretrain_dict['state_dict'] if 'state_dict' in pretrain_dict else pretrain_dict\n        model_dict = self.state_dict()\n        from collections import OrderedDict\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if 'backbone_only' in kwargs.keys() and 'classifier' in k:\n                continue;\n            if k.startswith(\"module\"):\n                if k[7:] not in model_dict.keys():\n                    print('not load:{}'.format(k))\n                new_dict[k[7:]] = v\n            else:\n                new_dict[k] = v\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"All model has been loaded...\")\n\n    def get_feature_length(self):\n        if \"cifar\" in self.args.net_type:\n            num_features = 64\n        else:\n            num_features = 2048\n        return num_features\n\n    def _get_module(self):\n        module = GAP()\n        return module\n\n    def _get_multi_classifer(self, bias_flag, type):\n\n        num_features = self.get_feature_length()\n        if type == \"FCNorm\":\n            classifier = FCNorm(num_features, self.num_classes)\n        elif type == \"FC\":\n            classifier = nn.Linear(num_features, self.num_classes, bias=bias_flag)\n        elif type == 'cos':\n            classifier = Cos_Classifier(self.num_classes, num_features, scale=self.args.cos_scale, bias=bias_flag)\n        else:\n            raise NotImplementedError\n\n        return classifier\n\nclass multi_Network_MOCO(nn.Module):\n    def __init__(self, args, mode=\"train\", num_classes=1000):\n        super(multi_Network_MOCO, self).__init__()\n        \n        self.args = args\n        self.num_classes = num_classes\n        self.network_num = 3\n        \n        if self.args.dataset == 'cifar100':\n            self.args.net_type = 'res32_cifar'\n            self.args.cf = 'FC'\n            self.args.scf = 'mlp'\n            self.args.cos_scale = 16\n            self.args.moco_dim = 64\n            self.args.mlp_dim = self.args.moco_dim\n            self.args.moco_k = 1024\n            self.args.moco_t = 0.2\n        \n        elif self.args.dataset == 'imgnet':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 16\n\n        elif self.args.dataset == 'inat':\n            self.args.net_type = 'res50'\n            self.args.cf = 'COS'\n            self.args.cos_scale = 32\n\n        self.MOCO = nn.ModuleList(\n            MoCo(dim=self.args.moco_dim, K=self.args.moco_k, T=self.args.moco_t)\n            for i in range(self.network_num))\n\n\n        self.backbone = nn.ModuleList(\n            eval(self.args.net_type)(\n                self.args,\n                last_layer_stride=2,\n            ) for i in range(self.network_num))\n\n\n        self.module = nn.ModuleList(\n            self._get_module()\n            for i in range(self.network_num))\n\n        \n        self.classifier = nn.ModuleList(\n            self._get_multi_classifer(True, self.args.scf)\n            for i in range(self.network_num))\n        self.feat = []\n\n        self.backbone_MA = nn.ModuleList(\n            eval(self.args.net_type)(\n                self.args,\n                last_layer_stride=2,\n            ) for i in range(self.network_num))\n\n        for i in range(self.network_num):\n            for param in self.backbone_MA[i].parameters():\n                param.detach_()\n\n        self.module_MA = nn.ModuleList(\n            self._get_module()\n            for i in range(self.network_num))\n        for i in range(self.network_num):\n            for param in self.module_MA[i].parameters():\n                param.detach_()\n\n        \n        self.classifier_MA = nn.ModuleList(\n            self._get_multi_classifer(True, self.args.scf)\n            for i in range(self.network_num))\n        for i in range(self.network_num):\n            for param in self.classifier_MA[i].parameters():\n                param.detach_()\n        self.feat_MA = []\n\n        if self.args.cf == 'FC':\n            self.classifier_ce = nn.ModuleList(\n                nn.Linear(self.get_feature_length(), self.num_classes, True)\n                for i in range(self.network_num))\n        elif self.args.cf == 'cos':\n            self.classifier_ce = nn.ModuleList(\n                Cos_Classifier(self.num_classes, in_dim=self.get_feature_length(), scale=self.args.cos_scale, bias=True)\n                for i in range(self.network_num))\n\n    def forward(self, input, **kwargs):\n\n\n        if \"feature_flag\" in kwargs:\n            return self.extract_feature(input, **kwargs)\n        elif \"classifier_flag\" in kwargs:\n            return self.get_logits(input, **kwargs)\n\n        logits = []\n        logits_ce = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i], **kwargs)\n            x = (self.module[i])(x)\n            feature = x.view(x.shape[0], -1)\n            self.feat.append(copy.deepcopy(feature))\n            \n            output = (self.classifier[i])(feature)\n            logits.append(output)\n\n            output_ce = (self.classifier_ce[i])(feature)\n            logits_ce.append(output_ce)\n\n        logits_MA = []\n        for i in range(self.network_num):\n            x = (self.backbone_MA[i])(input[i], **kwargs)\n            x = (self.module_MA[i])(x)\n            x = x.view(x.shape[0], -1)\n            self.feat_MA.append(copy.deepcopy(x))\n            x = (self.classifier_MA[i])(x)\n            logits_MA.append(x)\n\n        return logits_ce, logits, logits_MA\n\n    def extract_feature(self, input_all, **kwargs):\n\n        input, input_MA = input_all\n\n        feature = []\n        for i in range(self.network_num):\n            x = (self.backbone[i])(input[i], label=kwargs['label'][i])\n            x = (self.module[i])(x)\n            x = x.view(x.shape[0], -1)\n            feature.append(x)\n\n        feature_MA = []\n        for i in range(self.network_num):\n            x = (self.backbone_MA[i])(input_MA[i], label=kwargs['label'][i])\n            x = (self.module_MA[i])(x)\n            x = x.view(x.shape[0], -1)\n            feature_MA.append(x)\n        return feature, feature_MA\n\n    def get_logits(self, input_all, **kwargs):\n\n        input, input_MA = input_all\n        logits = []\n        logits_ce = []\n        for i in range(self.network_num):\n            feature = input[i]\n            \n            output = (self.classifier[i])(feature)\n            logits.append(output)\n\n            output_ce = (self.classifier_ce[i])(feature)\n            logits_ce.append(output_ce)\n\n        logits_MA = []\n        for i in range(self.network_num):\n            x = input_MA[i]\n            x = (self.classifier_MA[i])(x)\n            logits_MA.append(x)\n\n        return logits_ce, logits, logits_MA\n\n    def extract_feature_maps(self, x):\n        x = self.backbone(x)\n        return x\n\n    def freeze_multi_backbone(self):\n        print(\"Freezing backbone .......\")\n        for p in self.backbone.parameters():\n            p.requires_grad = False\n\n    def load_backbone_model(self, backbone_path=\"\"):\n        self.backbone.load_model(backbone_path)\n        print(\"Backbone model has been loaded...\")\n\n    def load_model(self, model_path, **kwargs):\n        pretrain_dict = torch.load(\n            model_path, map_location=\"cuda\"\n        )\n        pretrain_dict = pretrain_dict['state_dict'] if 'state_dict' in pretrain_dict else pretrain_dict\n        model_dict = self.state_dict()\n        from collections import OrderedDict\n        new_dict = OrderedDict()\n        for k, v in pretrain_dict.items():\n            if 'backbone_only' in kwargs.keys() and 'classifier' in k:\n                continue;\n            if k.startswith(\"module\"):\n                if k[7:] not in model_dict.keys():\n                    print('not load:{}'.format(k))\n                    continue\n                new_dict[k[7:]] = v\n            else:\n                new_dict[k] = v\n        model_dict.update(new_dict)\n        self.load_state_dict(model_dict)\n        print(\"All model has been loaded...\")\n\n    def get_feature_length(self):\n        if \"cifar\" in self.args.net_type:\n            num_features = 64\n        else:\n            num_features = 2048\n        return num_features\n\n    def _get_module(self):\n        module = GAP()\n        return module\n\n    def _get_multi_classifer(self, bias_flag, type):\n\n        num_features = self.get_feature_length()\n        if type == \"FCNorm\":\n            classifier = FCNorm(num_features, self.args.mlp_dim)\n        elif type == \"FC\":\n            classifier = nn.Linear(num_features, self.args.mlp_dim, bias=bias_flag)\n        elif type == \"mlp\":\n            classifier = nn.Sequential(nn.Linear(num_features, num_features, bias=bias_flag), \\\n                                       nn.ReLU(), \\\n                                       nn.Linear(num_features, self.args.mlp_dim, bias=bias_flag))\n        elif type == 'cos':\n            classifier = Cos_Classifier(self.args.mlp_dim, num_features, scale=self.args.cos_scale, bias=bias_flag)\n        else:\n            raise NotImplementedError\n\n        return classifier\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.521979Z","iopub.execute_input":"2024-01-24T13:28:31.522327Z","iopub.status.idle":"2024-01-24T13:28:31.698254Z","shell.execute_reply.started":"2024-01-24T13:28:31.522294Z","shell.execute_reply":"2024-01-24T13:28:31.697462Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"resnetride","metadata":{}},{"cell_type":"code","source":"import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\nimport random\n\n__all__ = ['resnet32_ride']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_planes, planes, stride=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        \n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n            \n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n    \nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n    \nclass ResNet_s(nn.Module):\n    def __init__(self, block, num_blocks, num_experts, num_classes=10, \n                 reduce_dimension=False, layer2_output_dim=None, \n                 layer3_output_dim=None, use_norm=False, use_experts=None, s=30):\n        super(ResNet_s, self).__init__()\n        \n        self.in_planes = 16\n        self.num_experts = num_experts\n        \n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.in_planes = self.next_in_planes\n        \n        if layer2_output_dim is None:\n            if reduce_dimension:\n                layer2_output_dim = 24\n            else:\n                layer2_output_dim = 32\n                \n        if layer3_output_dim is None:\n            if reduce_dimension:\n                layer3_output_dim = 48\n            else:\n                layer3_output_dim = 64\n                \n        self.layer2s = nn.ModuleList([self._make_layer(block, layer2_output_dim, num_blocks[1], stride=2) for _ in range(num_experts)])\n        self.in_planes = self.next_in_planes\n        self.layer3s = nn.ModuleList([self._make_layer(block, layer3_output_dim, num_blocks[2], stride=2) for _ in range(num_experts)])\n        self.in_planes = self.next_in_planes\n        \n        if use_norm:\n            self.linears = nn.ModuleList([NormedLinear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n        else:\n            self.linears = nn.ModuleList([nn.Linear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n            s = 1\n            \n        if use_experts is None:\n            self.use_experts = list(range(num_experts))\n        elif use_experts == \"rand\":\n            self.use_experts = None\n        else:\n            self.use_experts = [int(item) for item in use_experts.split(\",\")]\n            \n        self.s = s\n        self.apply(_weights_init)\n        \n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        self.next_in_planes = self.in_planes\n        for stride in strides:\n            layers.append(block(self.next_in_planes, planes, stride))\n            self.next_in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n    \n    def _hook_before_iter(self):\n        assert self.training, \"_hook_before_iter should be called at training time only, after train() is called\"\n        count = 0\n        for module in self.modules():\n            if isinstance(module, nn.BatchNorm2d):\n                if module.weight.requires_grad == False:\n                    module.eval()\n                    count += 1\n                    \n        if count > 0:\n            print(\"Warning: detected at least one frozen BN, set them to eval state. Count:\", count)\n            \n    def _separate_part(self, x, ind):\n        out = x\n        out = (self.layer2s[ind])(out)\n        out = (self.layer3s[ind])(out)\n        self.feat_before_GAP.append(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        self.feat.append(out)\n        out = (self.linears[ind])(out)\n        out = out * self.s\n        return out\n    \n    def forward(self, x, output_type = 'dict'):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        \n        outs = []\n        self.feat = []\n        self.logits = outs\n        self.feat_before_GAP = []\n        \n        if self.use_experts is None:\n            use_experts = random.sample(range(self.num_experts), self.num_experts - 1)\n        else:\n            use_experts = self.use_experts\n            \n        for ind in use_experts:\n            outs.append(self._separate_part(out, ind))\n        final_out = torch.stack(outs, dim=1).mean(dim=1)\n\n        if output_type == 'dict':\n            return {\"output\": final_out, \"logits\": torch.stack(outs, dim=1)}\n        else:\n            return final_out\n        \ndef resnet32_ride(num_class, use_norm=True, num_experts=3):\n    return ResNet_s(BasicBlock, [5,5,5], num_experts, num_classes=num_class, use_norm=use_norm, reduce_dimension=True)\n\ndef test(net):\n    import numpy as np\n    total_params = 0\n\n    for x in filter(lambda p: p.requires_grad, net.parameters()):\n        total_params += np.prod(x.data.numpy().shape)\n    print(\"Total number of params\", total_params)\n    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n    \nif __name__ == \"__main__\":\n    for net_name in __all__:\n        if net_name.startswith(\"resnet\"):\n            print(net_name)\n            test(globals()[net_name](2))\n            print()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.699670Z","iopub.execute_input":"2024-01-24T13:28:31.699971Z","iopub.status.idle":"2024-01-24T13:28:31.781602Z","shell.execute_reply.started":"2024-01-24T13:28:31.699945Z","shell.execute_reply":"2024-01-24T13:28:31.780763Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"resnet32_ride\nTotal number of params 774784\nTotal layers 80\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"resnet","metadata":{}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\n__all__ = ['resnet32', 'NormedLinear']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass LambdaLayer(nn.Module):\n\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='A'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_s(nn.Module):\n\n    def __init__(self, block, num_blocks, num_classes=10, use_norm=False):\n        super(ResNet_s, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        if use_norm:\n            self.linear = NormedLinear(64, num_classes)\n        else:\n            self.linear = nn.Linear(64, num_classes)\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x, output_type='feat'):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out1 = out.view(out.size(0), -1)\n        out = self.linear(out1)\n        if output_type == 'feat':\n            return out, out1\n        else:\n            return out\n\ndef resnet32(num_class, use_norm):\n    return ResNet_s(BasicBlock, [5,5,5], num_class, use_norm=use_norm)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.782625Z","iopub.execute_input":"2024-01-24T13:28:31.782906Z","iopub.status.idle":"2024-01-24T13:28:31.805401Z","shell.execute_reply.started":"2024-01-24T13:28:31.782880Z","shell.execute_reply":"2024-01-24T13:28:31.804473Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"net.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport shutil\n#from models.resnet import *\n#from models.resnet_ride import *\n#from models.resnet_bcl import *\n#from models.resnet_ncl import *\n\nimport torch.nn as nn\nimport torchvision.models as models\n\ndef get_model(args, num_class_list):\n    if args.loss_fn in ['ride']:\n        model = resnet32_ride(args.num_class, num_experts=args.num_experts).cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    \n    elif args.loss_fn in ['ncl']:\n        model = ncl_model(args, num_class_list)\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model['model'].parameters())/1000000.0))\n\n    elif args.loss_fn in ['bcl']:\n        model = bcl_model(args.num_class, use_norm=args.use_norm).cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    \n    else:\n        model = resnet32(args.num_class, use_norm= args.loss_fn == 'ldam_drw').cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    \n    \n    torch.backends.cudnn.benchmark = True\n    return model   \n    \n\n\ndef load_model(args):\n    if args.loss_fn == 'ride' and args.num_experts == 3 and args.ride_distill:\n        print(\"---- ride teacher load ----\")\n        filepath = os.path.join(args.out, 'checkpoint_teacher.pth.tar')\n        if os.path.isfile(filepath):\n            pass    \n        else:\n            shutil.copy2(os.path.join(args.out, 'checkpoint.pth.tar'), os.path.join(args.out, 'checkpoint_teacher.pth.tar'))\n        checkpoint = torch.load(filepath)\n        teacher = resnet32_ride(args.num_class, num_experts = 6).cuda()\n        teacher.load_state_dict(checkpoint['state_dict'])\n    else:\n        teacher = None\n    return teacher\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.806841Z","iopub.execute_input":"2024-01-24T13:28:31.807759Z","iopub.status.idle":"2024-01-24T13:28:31.821403Z","shell.execute_reply.started":"2024-01-24T13:28:31.807731Z","shell.execute_reply":"2024-01-24T13:28:31.820582Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"config","metadata":{}},{"cell_type":"code","source":"import argparse, torch, os, random\nimport numpy as np\n\ndef parse_args(run_type = 'terminal'):\n    parser = argparse.ArgumentParser(description='Python Training')\n    \n    # Optimization options\n    parser.add_argument('--network', default='resnet32', help='Network: resnet32')\n    parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs to run')\n    parser.add_argument('--batch-size', default=128, type=int, metavar='N', help='train batchsize')\n    parser.add_argument('--update-epoch', default=1, type=int, metavar='N', help='Update epoch')\n    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float, metavar='LR', help='initial learning rate')\n    parser.add_argument('--lr_decay', default=0.01, type=float, help='learnign rate decay')\n    parser.add_argument('--momentum', default=0.9, type=float, help='SGD momentum')\n    parser.add_argument('--wd', default=2e-4, type=float, help='weight decay factor for optimizer')\n    parser.add_argument('--nesterov', action='store_true', help=\"Utilizing Nesterov\")\n    parser.add_argument('--scheduler', default='warmup', type=str, help='LR scheduler')\n    parser.add_argument('--warmup', default=5, type=int, help='Warmup epochs')\n        \n    parser.add_argument('--aug_prob', default=0.5, type=float, help='Augmentation Coin-tossing Probability')\n    parser.add_argument('--cutout', action='store_true', help='Utilizing Cutout')\n    parser.add_argument('--cmo', action='store_true', help='Utilizing CMO')\n    parser.add_argument('--posthoc_la', action='store_true', help='Posthoc LA for state update')\n    parser.add_argument('--cuda', action='store_true', help='Use CUDA')\n    parser.add_argument('--aug_type', default='none')\n    parser.add_argument('--sim_type', default='none')\n    parser.add_argument('--max_d', type=int, default=30, help='max_d')\n\n    parser.add_argument('--num_test', default=10, type=int, help='Curriculum Test')\n    parser.add_argument('--accept_rate', type=float, default=0.6, help='Increasing accept ratio')\n    parser.add_argument('--verbose', action='store_true', help='Debug on/off')\n    parser.add_argument('--use_norm', action='store_true', help='Utilize Normed Linear')\n    \n    # Checkpoints\n    parser.add_argument('--out', default='./results/', help='Directory to output the result')\n    parser.add_argument('--data_dir', default='~/dataset/')\n    \n    # Miscs\n    parser.add_argument('--workers', type=int, default=4, help='# workers')\n    parser.add_argument('--seed', type=str, default='None', help='manual seed')\n    parser.add_argument('--gpu', default=None, type=str, help='id(s) for CUDA_VISIBLE_DEVICES')\n    \n    # Dataset options\n    parser.add_argument('--dataset', default='cifar100', help='Dataset: cifar100')\n    parser.add_argument('--num_max', type=int, default=500, help='Number of samples in the maximal class')\n    parser.add_argument('--imb_ratio', type=int, default=100, help='Imbalance ratio for data')\n    \n    # Method options\n    parser.add_argument('--loss_fn', type=str, default='ce', help='Loss function for training')\n    parser.add_argument('--num_experts', type=int, default=3, help='Number of experts for RIDE')\n    parser.add_argument('--ride_distill', action='store_true', help='Use RIDEWithDistill Loss')\n    \n    if run_type == 'terminal':\n        args = parser.parse_args()\n    elif run_type =='jupyter':\n        args = parser.parse_args(args=[])\n        \n    args.out = f'{args.out}{args.dataset}/{args.loss_fn}@N_{args.num_max}_ir_{args.imb_ratio}/'\n    \n    if args.gpu:\n        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n    return args\n\n\ndef reproducibility(seed):\n    if seed == 'None':\n        return\n    else:\n        seed = int(seed)\n        torch.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        np.random.seed(seed)\n        random.seed(seed)\n\ndef dataset_argument(args):\n    if args.dataset == 'cifar100':\n        args.num_class = 100\n    else:\n        args.num_class = 10\n\n    return args\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.823927Z","iopub.execute_input":"2024-01-24T13:28:31.824221Z","iopub.status.idle":"2024-01-24T13:28:31.843734Z","shell.execute_reply.started":"2024-01-24T13:28:31.824191Z","shell.execute_reply":"2024-01-24T13:28:31.842922Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"logger","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\nfrom datetime import datetime\nimport os\nimport torch as t\n\nimport pandas as pd\n\nclass logger:\n    def __init__(self, args):\n            \n        self.logger = logging.getLogger('Evaluation')\n        self.logger.setLevel(logging.INFO)\n        self.args = args\n        \n        formatter = logging.Formatter('%(message)s')\n        \n        strm_handler = logging.StreamHandler()\n        strm_handler.setFormatter(formatter)\n        \n        now = datetime.now()\n        time = f'{now.hour}:{now.minute}:{now.second}-{now.year}-{now.month}-{now.day}'\n        os.makedirs(f'{args.out}',exist_ok=True)\n        file_handler = logging.FileHandler(f'{args.out}/{time.replace(\":\", \"-\")}.txt')\n\n\n        file_handler.setFormatter(formatter)\n                        \n        self.logger.addHandler(strm_handler)\n        self.logger.addHandler(file_handler)\n\n        message = f'---{args.dataset}---'\n        self(message, level=1)\n        self.arg_logging(args)\n\n    def __call__(self,message, level):\n        if level == 1:\n            prefix = '--->' \n        else:\n            prefix = '  '*level + '>'\n        \n        self.logger.info(f'{prefix} {message}')\n\n\n    def arg_logging(self, argument):\n        self('Argument', level=1)\n        arg_dict = vars(argument)\n        for key in arg_dict.keys():\n            if key == 'logger':\n                pass\n            else:\n                self(f'{key:12s}: {arg_dict[key]}', level=2)\n\n    def map_save(self, map):\n        map_df = pd.DataFrame(map)\n        map_df.to_csv(f'{self.args.out}/curriculum.csv',encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.844799Z","iopub.execute_input":"2024-01-24T13:28:31.845071Z","iopub.status.idle":"2024-01-24T13:28:31.859356Z","shell.execute_reply.started":"2024-01-24T13:28:31.845047Z","shell.execute_reply":"2024-01-24T13:28:31.858621Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"plot","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch as t\nimport numpy as np\nimport os\nimport pandas as pd\n\nsns.set_palette(\"bright\")\nsns.set_style(\"darkgrid\")\n\ndef plot_score_epoch(curr_state, label, epoch, maps, out, name='heat'):\n    label = t.tensor(label)\n    \n    num_samples_per_class = t.sum(t.nn.functional.one_hot(label, num_classes=len(t.unique(label))), dim=0)\n    num_samples_sort = t.argsort(num_samples_per_class)\n    \n    for cidx in t.unique(label):\n        pos = t.where(cidx == label)\n        maps[epoch, cidx] = t.mean(curr_state[pos]).numpy()\n\n    # Transpose the matrix before plotting\n    transposed_maps = np.transpose(maps)\n\n    sns.heatmap(transposed_maps, cmap='YlGnBu', vmin=0, vmax=10)\n    plt.xlabel('Epoch')\n    plt.ylabel('Class index')\n\n    # Flip the graph vertically before saving\n    plt.gca().invert_yaxis()\n\n    os.makedirs(f'{out}/score_epoch_plot/', exist_ok=True)\n    plt.savefig(f'{out}/score_epoch_plot/{name}.png')\n\n    plt.close()\n\n    return maps\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:31.860464Z","iopub.execute_input":"2024-01-24T13:28:31.860805Z","iopub.status.idle":"2024-01-24T13:28:32.126947Z","shell.execute_reply.started":"2024-01-24T13:28:31.860771Z","shell.execute_reply":"2024-01-24T13:28:32.126214Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.__version__)\nprint(f\"CUDA version: {torch.version.cuda}\")\ntorch.has_mps","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:32.127932Z","iopub.execute_input":"2024-01-24T13:28:32.128198Z","iopub.status.idle":"2024-01-24T13:28:32.135346Z","shell.execute_reply.started":"2024-01-24T13:28:32.128158Z","shell.execute_reply":"2024-01-24T13:28:32.134551Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"2.0.0\nCUDA version: 11.8\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import losses\n\n#from datasets.cifar100 import *\n\n#from train.train import *\n#from train.validate import *\n\n#from models.net import *\n\n#from losses.loss import *\n\n#from utils.config import *\n#from utils.plot import *\n#from utils.common import make_imb_data, save_checkpoint, hms_string\n\n#from utils.logger import logger\n\n#args = parse_args()\n\nfrom argparse import Namespace\n\n# Replace the command below with your actual values\nargs=Namespace(network='resnet32', epochs=200, batch_size=128, update_epoch=1,\n               lr=0.1, lr_decay=0.01, momentum=0.9, wd=0.0002, nesterov=False,\n               scheduler='warmup', warmup=5, aug_prob=0.5, cutout=False, cmo=False,\n               posthoc_la=False, cuda=False, aug_type='none', sim_type='none', max_d=30,\n               num_test=10, accept_rate=0.6, verbose=False, use_norm=False,\n               out='/kaggle/working/log3',\n               data_dir='~/dataset/', workers=4, seed='None',\n               gpu='0', dataset='cifar100', num_max=500, imb_ratio=100,\n               loss_fn='ce_drw', num_experts=3, ride_distill=False)\n\nreproducibility(args.seed)\nargs = dataset_argument(args)\nargs.logger = logger(args)\n\nbest_acc = 0 # best test accuracy\ncurr_state_ac=[]\nlabel_ac=[]\nvariance_list=[]\n\ndef main():\n    global best_acc,curr_state_ac,label_ac,variance_list\n\n    try:\n        assert args.num_max <= 50000. / args.num_class\n    except AssertionError:\n        args.num_max = int(50000 / args.num_class)\n    \n    print(f'==> Preparing imbalanced CIFAR-100')\n    # N_SAMPLES_PER_CLASS = make_imb_data(args.num_max, args.num_class, args.imb_ratio)\n    trainset, testset = get_cifar100(os.path.join(args.data_dir, 'cifar100/'), args)\n    N_SAMPLES_PER_CLASS = trainset.img_num_list\n        \n    trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, drop_last= args.loss_fn == 'ncl', pin_memory=True, sampler=None)\n    testloader = data.DataLoader(testset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True) \n    \n    if args.cmo:\n        cls_num_list = N_SAMPLES_PER_CLASS\n        cls_weight = 1.0 / (np.array(cls_num_list))\n        cls_weight = cls_weight / np.sum(cls_weight) * len(cls_num_list)\n        labels = trainloader.dataset.targets\n        samples_weight = np.array([cls_weight[t] for t in labels])\n        samples_weight = torch.from_numpy(samples_weight)\n        samples_weight = samples_weight.double()\n        print(\"samples_weight\", samples_weight)\n        sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(labels), replacement=True)\n        weighted_trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, sampler=sampler)\n    else:\n        weighted_trainloader = None\n    \n\n    # Model\n    print (\"==> creating {}\".format(args.network))\n    model = get_model(args, N_SAMPLES_PER_CLASS)\n    train_criterion = get_loss(args, N_SAMPLES_PER_CLASS)\n    criterion = nn.CrossEntropyLoss() # For test, validation \n    optimizer = get_optimizer(args, model)\n    scheduler = get_scheduler(args,optimizer)\n\n    teacher = load_model(args)\n\n\n    train = get_train_fn(args)\n    validate = get_valid_fn(args)\n    update_score = get_update_score_fn(args)\n    \n    start_time = time.time()\n    \n    test_accs = []\n    for epoch in range(args.epochs):\n        \n        lr = adjust_learning_rate(optimizer, epoch, scheduler, args)\n        if args.cuda:\n            if epoch % args.update_epoch == 0:\n                curr_state_ac, label_ac = update_score(trainloader, model, N_SAMPLES_PER_CLASS, posthoc_la = args.posthoc_la, num_test = args.num_test, accept_rate = args.accept_rate)\n                print(curr_state_ac)\n                \n            if args.verbose:\n                if epoch == 0:\n                    maps = np.zeros((args.epochs,args.num_class))\n                maps = plot_score_epoch(curr_state_ac,label_ac, epoch, maps, args.out)\n        train_loss = train(args, trainloader, model, optimizer,train_criterion, epoch, weighted_trainloader, teacher) \n\n\n        test_loss, test_acc, test_cls = validate(args, testloader, model, criterion, N_SAMPLES_PER_CLASS,  num_class=args.num_class, mode='test Valid')\n\n        if best_acc <= test_acc:\n            best_acc = test_acc\n            many_best = test_cls[0]\n            med_best = test_cls[1]\n            few_best = test_cls[2]\n            # Save models\n            save_checkpoint({\n                'epoch': epoch + 1,\n                'state_dict': model['model'].state_dict() if args.loss_fn == 'ncl' else model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, epoch + 1, args.out)\n        test_accs.append(test_acc)\n        \n        model_weights = model.state_dict()\n        classwise_l1_norms = {}\n        for class_label in range(args.num_class):\n            class_params = {\n            'linear.weight': model_weights['linear.weight'][class_label],\n            'linear.bias': model_weights['linear.bias'][class_label]\n            }\n            class_l1_norm = sum(torch.abs(param).sum() for param in class_params.values())\n            classwise_l1_norms[f'Class_{class_label}'] = class_l1_norm\n        l1_norm_values = [tensor.item() for tensor in classwise_l1_norms.values()]\n        variance_l1_norm = np.var(l1_norm_values)\n        variance_list.append(np.sqrt(variance_l1_norm))\n        print(np.sqrt(variance_l1_norm))\n        \n        args.logger(f'Epoch: [{epoch+1} | {args.epochs}]', level=1)\n        if args.cuda:\n            args.logger(f'Max_state: {int(torch.max(curr_state_ac))}, min_state: {int(torch.min(curr_state_ac))}', level=2)\n        args.logger(f'[Train]\\tLoss:\\t{train_loss:.4f}', level=2)\n        args.logger(f'[Test ]\\tLoss:\\t{test_loss:.4f}\\tAcc:\\t{test_acc:.4f}', level=2)\n        args.logger(f'[Stats]\\tMany:\\t{test_cls[0]:.4f}\\tMedium:\\t{test_cls[1]:.4f}\\tFew:\\t{test_cls[2]:.4f}', level=2)\n        args.logger(f'[Best ]\\tAcc:\\t{np.max(test_accs):.4f}\\tMany:\\t{100*many_best:.4f}\\tMedium:\\t{100*med_best:.4f}\\tFew:\\t{100*few_best:.4f}', level=2)\n        args.logger(f'[Param]\\tLR:\\t{lr:.8f}', level=2)\n    \n    end_time = time.time()\n\n    # Print the final results\n    args.logger(f'Final performance...', level=1)\n    args.logger(f'best bAcc (test):\\t{np.max(test_accs)}', level=2)\n    args.logger(f'best statistics:\\tMany:\\t{many_best}\\tMed:\\t{med_best}\\tFew:\\t{few_best}', level=2)\n    args.logger(f'Training Time: {hms_string(end_time - start_time)}', level=1)\n\n    \n    if args.verbose:\n        args.logger.map_save(maps)\n\nif __name__ == '__main__':\n    main()\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:28:32.136615Z","iopub.execute_input":"2024-01-24T13:28:32.137017Z","iopub.status.idle":"2024-01-24T13:42:34.397690Z","shell.execute_reply.started":"2024-01-24T13:28:32.136992Z","shell.execute_reply":"2024-01-24T13:42:34.396606Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"---> ---cifar100---\n---> Argument\n    > network     : resnet32\n    > epochs      : 200\n    > batch_size  : 128\n    > update_epoch: 1\n    > lr          : 0.1\n    > lr_decay    : 0.01\n    > momentum    : 0.9\n    > wd          : 0.0002\n    > nesterov    : False\n    > scheduler   : warmup\n    > warmup      : 5\n    > aug_prob    : 0.5\n    > cutout      : False\n    > cmo         : False\n    > posthoc_la  : False\n    > cuda        : False\n    > aug_type    : none\n    > sim_type    : none\n    > max_d       : 30\n    > num_test    : 10\n    > accept_rate : 0.6\n    > verbose     : False\n    > use_norm    : False\n    > out         : /kaggle/working/log3\n    > data_dir    : ~/dataset/\n    > workers     : 4\n    > seed        : None\n    > gpu         : 0\n    > dataset     : cifar100\n    > num_max     : 500\n    > imb_ratio   : 100\n    > loss_fn     : ce_drw\n    > num_experts : 3\n    > ride_distill: False\n    > num_class   : 100\n","output_type":"stream"},{"name":"stdout","text":"==> Preparing imbalanced CIFAR-100\nFiles already downloaded and verified\nMagnitude set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nOperation set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nFiles already downloaded and verified\n#Train: 10847, #Test: 10000\n==> creating resnet32\n    Total params: 0.47M\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [1 | 200]\n    > [Train]\tLoss:\t4.0733\n    > [Test ]\tLoss:\t5.3344\tAcc:\t4.5600\n    > [Stats]\tMany:\t0.1277\tMedium:\t0.0026\tFew:\t0.0000\n    > [Best ]\tAcc:\t4.5600\tMany:\t12.7714\tMedium:\t0.2571\tFew:\t0.0000\n    > [Param]\tLR:\t0.02000000\n","output_type":"stream"},{"name":"stdout","text":"0.7331374223447409\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [2 | 200]\n    > [Train]\tLoss:\t3.6156\n    > [Test ]\tLoss:\t5.0759\tAcc:\t6.1900\n    > [Stats]\tMany:\t0.1769\tMedium:\t0.0000\tFew:\t0.0000\n    > [Best ]\tAcc:\t6.1900\tMany:\t17.6857\tMedium:\t0.0000\tFew:\t0.0000\n    > [Param]\tLR:\t0.04000000\n","output_type":"stream"},{"name":"stdout","text":"0.7003908520922258\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [3 | 200]\n    > [Train]\tLoss:\t3.4034\n    > [Test ]\tLoss:\t4.8982\tAcc:\t7.3000\n    > [Stats]\tMany:\t0.1809\tMedium:\t0.0277\tFew:\t0.0000\n    > [Best ]\tAcc:\t7.3000\tMany:\t18.0857\tMedium:\t2.7714\tFew:\t0.0000\n    > [Param]\tLR:\t0.06000000\n","output_type":"stream"},{"name":"stdout","text":"0.7489827843103728\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [4 | 200]\n    > [Train]\tLoss:\t3.2129\n    > [Test ]\tLoss:\t4.9275\tAcc:\t7.5700\n    > [Stats]\tMany:\t0.2091\tMedium:\t0.0071\tFew:\t0.0000\n    > [Best ]\tAcc:\t7.5700\tMany:\t20.9143\tMedium:\t0.7143\tFew:\t0.0000\n    > [Param]\tLR:\t0.08000000\n","output_type":"stream"},{"name":"stdout","text":"0.9013158511162322\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [5 | 200]\n    > [Train]\tLoss:\t3.0865\n    > [Test ]\tLoss:\t4.8473\tAcc:\t9.5300\n    > [Stats]\tMany:\t0.2389\tMedium:\t0.0334\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.5300\tMany:\t23.8857\tMedium:\t3.3429\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.1403339757960271\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [6 | 200]\n    > [Train]\tLoss:\t2.9053\n    > [Test ]\tLoss:\t4.9509\tAcc:\t10.9900\n    > [Stats]\tMany:\t0.2806\tMedium:\t0.0334\tFew:\t0.0000\n    > [Best ]\tAcc:\t10.9900\tMany:\t28.0571\tMedium:\t3.3429\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.3796312073260708\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [7 | 200]\n    > [Train]\tLoss:\t2.7221\n    > [Test ]\tLoss:\t4.7897\tAcc:\t12.1200\n    > [Stats]\tMany:\t0.2803\tMedium:\t0.0660\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.1200\tMany:\t28.0286\tMedium:\t6.6000\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.6077951436317115\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [8 | 200]\n    > [Train]\tLoss:\t2.6129\n    > [Test ]\tLoss:\t4.7789\tAcc:\t12.4500\n    > [Stats]\tMany:\t0.2889\tMedium:\t0.0669\tFew:\t0.0000\n    > [Best ]\tAcc:\t12.4500\tMany:\t28.8857\tMedium:\t6.6857\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.80477040966406\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [9 | 200]\n    > [Train]\tLoss:\t2.4719\n    > [Test ]\tLoss:\t4.6223\tAcc:\t13.9100\n    > [Stats]\tMany:\t0.3406\tMedium:\t0.0566\tFew:\t0.0003\n    > [Best ]\tAcc:\t13.9100\tMany:\t34.0571\tMedium:\t5.6571\tFew:\t0.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.9695476276344863\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [10 | 200]\n    > [Train]\tLoss:\t2.3918\n    > [Test ]\tLoss:\t4.3493\tAcc:\t15.7400\n    > [Stats]\tMany:\t0.3597\tMedium:\t0.0886\tFew:\t0.0017\n    > [Best ]\tAcc:\t15.7400\tMany:\t35.9714\tMedium:\t8.8571\tFew:\t0.1667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.1227972024028774\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [11 | 200]\n    > [Train]\tLoss:\t2.2673\n    > [Test ]\tLoss:\t4.3498\tAcc:\t16.7300\n    > [Stats]\tMany:\t0.3740\tMedium:\t0.1040\tFew:\t0.0000\n    > [Best ]\tAcc:\t16.7300\tMany:\t37.4000\tMedium:\t10.4000\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.269442113367792\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [12 | 200]\n    > [Train]\tLoss:\t2.1767\n    > [Test ]\tLoss:\t4.2915\tAcc:\t17.5200\n    > [Stats]\tMany:\t0.3877\tMedium:\t0.1126\tFew:\t0.0003\n    > [Best ]\tAcc:\t17.5200\tMany:\t38.7714\tMedium:\t11.2571\tFew:\t0.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.403048489284309\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [13 | 200]\n    > [Train]\tLoss:\t2.0678\n    > [Test ]\tLoss:\t4.1130\tAcc:\t19.0700\n    > [Stats]\tMany:\t0.4026\tMedium:\t0.1389\tFew:\t0.0040\n    > [Best ]\tAcc:\t19.0700\tMany:\t40.2571\tMedium:\t13.8857\tFew:\t0.4000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.539726160013663\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [14 | 200]\n    > [Train]\tLoss:\t2.0081\n    > [Test ]\tLoss:\t4.1395\tAcc:\t19.2300\n    > [Stats]\tMany:\t0.4249\tMedium:\t0.1200\tFew:\t0.0053\n    > [Best ]\tAcc:\t19.2300\tMany:\t42.4857\tMedium:\t12.0000\tFew:\t0.5333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6517016425803193\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [15 | 200]\n    > [Train]\tLoss:\t1.9326\n    > [Test ]\tLoss:\t3.9846\tAcc:\t21.4200\n    > [Stats]\tMany:\t0.4483\tMedium:\t0.1574\tFew:\t0.0073\n    > [Best ]\tAcc:\t21.4200\tMany:\t44.8286\tMedium:\t15.7429\tFew:\t0.7333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.750523021513866\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [16 | 200]\n    > [Train]\tLoss:\t1.8538\n    > [Test ]\tLoss:\t4.1863\tAcc:\t20.8500\n    > [Stats]\tMany:\t0.4591\tMedium:\t0.1334\tFew:\t0.0037\n    > [Best ]\tAcc:\t21.4200\tMany:\t44.8286\tMedium:\t15.7429\tFew:\t0.7333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.840059118801284\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [17 | 200]\n    > [Train]\tLoss:\t1.7739\n    > [Test ]\tLoss:\t4.1406\tAcc:\t22.0300\n    > [Stats]\tMany:\t0.4771\tMedium:\t0.1463\tFew:\t0.0070\n    > [Best ]\tAcc:\t22.0300\tMany:\t47.7143\tMedium:\t14.6286\tFew:\t0.7000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.927864755812453\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [18 | 200]\n    > [Train]\tLoss:\t1.7169\n    > [Test ]\tLoss:\t3.9821\tAcc:\t23.1800\n    > [Stats]\tMany:\t0.4766\tMedium:\t0.1820\tFew:\t0.0043\n    > [Best ]\tAcc:\t23.1800\tMany:\t47.6571\tMedium:\t18.2000\tFew:\t0.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.97029454427814\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [19 | 200]\n    > [Train]\tLoss:\t1.6674\n    > [Test ]\tLoss:\t3.8134\tAcc:\t23.6900\n    > [Stats]\tMany:\t0.4746\tMedium:\t0.1963\tFew:\t0.0070\n    > [Best ]\tAcc:\t23.6900\tMany:\t47.4571\tMedium:\t19.6286\tFew:\t0.7000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0375377892522457\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [20 | 200]\n    > [Train]\tLoss:\t1.6145\n    > [Test ]\tLoss:\t3.7205\tAcc:\t24.6700\n    > [Stats]\tMany:\t0.5237\tMedium:\t0.1677\tFew:\t0.0157\n    > [Best ]\tAcc:\t24.6700\tMany:\t52.3714\tMedium:\t16.7714\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.082997394729207\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [21 | 200]\n    > [Train]\tLoss:\t1.5692\n    > [Test ]\tLoss:\t3.7506\tAcc:\t24.1300\n    > [Stats]\tMany:\t0.4891\tMedium:\t0.1923\tFew:\t0.0093\n    > [Best ]\tAcc:\t24.6700\tMany:\t52.3714\tMedium:\t16.7714\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.173181643170272\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [22 | 200]\n    > [Train]\tLoss:\t1.5275\n    > [Test ]\tLoss:\t3.7765\tAcc:\t22.8200\n    > [Stats]\tMany:\t0.4866\tMedium:\t0.1634\tFew:\t0.0023\n    > [Best ]\tAcc:\t24.6700\tMany:\t52.3714\tMedium:\t16.7714\tFew:\t1.5667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1861574976378093\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [23 | 200]\n    > [Train]\tLoss:\t1.4752\n    > [Test ]\tLoss:\t3.4981\tAcc:\t27.9900\n    > [Stats]\tMany:\t0.5403\tMedium:\t0.2471\tFew:\t0.0143\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2328157438928966\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [24 | 200]\n    > [Train]\tLoss:\t1.4331\n    > [Test ]\tLoss:\t4.3408\tAcc:\t23.1400\n    > [Stats]\tMany:\t0.4731\tMedium:\t0.1817\tFew:\t0.0073\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2689806915248347\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [25 | 200]\n    > [Train]\tLoss:\t1.3893\n    > [Test ]\tLoss:\t4.1946\tAcc:\t23.2500\n    > [Stats]\tMany:\t0.4694\tMedium:\t0.1857\tFew:\t0.0107\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3048579210949196\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [26 | 200]\n    > [Train]\tLoss:\t1.3641\n    > [Test ]\tLoss:\t3.7874\tAcc:\t25.9600\n    > [Stats]\tMany:\t0.5420\tMedium:\t0.1911\tFew:\t0.0100\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.349235640899656\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [27 | 200]\n    > [Train]\tLoss:\t1.3285\n    > [Test ]\tLoss:\t4.2672\tAcc:\t22.4000\n    > [Stats]\tMany:\t0.4577\tMedium:\t0.1711\tFew:\t0.0130\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3496990768568113\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [28 | 200]\n    > [Train]\tLoss:\t1.2928\n    > [Test ]\tLoss:\t3.7995\tAcc:\t25.7400\n    > [Stats]\tMany:\t0.5214\tMedium:\t0.2026\tFew:\t0.0133\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.349386087902296\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [29 | 200]\n    > [Train]\tLoss:\t1.2535\n    > [Test ]\tLoss:\t3.7432\tAcc:\t26.0600\n    > [Stats]\tMany:\t0.5266\tMedium:\t0.2020\tFew:\t0.0187\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.395568698454504\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [30 | 200]\n    > [Train]\tLoss:\t1.2396\n    > [Test ]\tLoss:\t3.8736\tAcc:\t26.5500\n    > [Stats]\tMany:\t0.4994\tMedium:\t0.2440\tFew:\t0.0177\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3892482599641003\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [31 | 200]\n    > [Train]\tLoss:\t1.1999\n    > [Test ]\tLoss:\t3.8255\tAcc:\t27.6600\n    > [Stats]\tMany:\t0.5449\tMedium:\t0.2343\tFew:\t0.0130\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4266375015131\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [32 | 200]\n    > [Train]\tLoss:\t1.1508\n    > [Test ]\tLoss:\t3.8985\tAcc:\t25.6600\n    > [Stats]\tMany:\t0.5229\tMedium:\t0.1926\tFew:\t0.0207\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4456498790323216\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [33 | 200]\n    > [Train]\tLoss:\t1.1432\n    > [Test ]\tLoss:\t3.9496\tAcc:\t24.7800\n    > [Stats]\tMany:\t0.4829\tMedium:\t0.2003\tFew:\t0.0290\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.450965605966762\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [34 | 200]\n    > [Train]\tLoss:\t1.1133\n    > [Test ]\tLoss:\t4.0842\tAcc:\t24.0600\n    > [Stats]\tMany:\t0.4571\tMedium:\t0.2131\tFew:\t0.0200\n    > [Best ]\tAcc:\t27.9900\tMany:\t54.0286\tMedium:\t24.7143\tFew:\t1.4333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4375864623414114\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [35 | 200]\n    > [Train]\tLoss:\t1.0742\n    > [Test ]\tLoss:\t3.7957\tAcc:\t28.6400\n    > [Stats]\tMany:\t0.5723\tMedium:\t0.2200\tFew:\t0.0303\n    > [Best ]\tAcc:\t28.6400\tMany:\t57.2286\tMedium:\t22.0000\tFew:\t3.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4532537476330276\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [36 | 200]\n    > [Train]\tLoss:\t1.0458\n    > [Test ]\tLoss:\t4.0145\tAcc:\t26.5200\n    > [Stats]\tMany:\t0.5066\tMedium:\t0.2174\tFew:\t0.0393\n    > [Best ]\tAcc:\t28.6400\tMany:\t57.2286\tMedium:\t22.0000\tFew:\t3.0333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.468006087144156\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [37 | 200]\n    > [Train]\tLoss:\t1.0287\n    > [Test ]\tLoss:\t3.9441\tAcc:\t29.2600\n    > [Stats]\tMany:\t0.5243\tMedium:\t0.2837\tFew:\t0.0327\n    > [Best ]\tAcc:\t29.2600\tMany:\t52.4286\tMedium:\t28.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.471700195499056\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [38 | 200]\n    > [Train]\tLoss:\t1.0078\n    > [Test ]\tLoss:\t4.1798\tAcc:\t26.3700\n    > [Stats]\tMany:\t0.4920\tMedium:\t0.2469\tFew:\t0.0170\n    > [Best ]\tAcc:\t29.2600\tMany:\t52.4286\tMedium:\t28.3714\tFew:\t3.2667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.459409682354228\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [39 | 200]\n    > [Train]\tLoss:\t0.9957\n    > [Test ]\tLoss:\t3.8568\tAcc:\t29.7400\n    > [Stats]\tMany:\t0.5537\tMedium:\t0.2749\tFew:\t0.0247\n    > [Best ]\tAcc:\t29.7400\tMany:\t55.3714\tMedium:\t27.4857\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4668156923634523\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [40 | 200]\n    > [Train]\tLoss:\t0.9746\n    > [Test ]\tLoss:\t4.0782\tAcc:\t27.4000\n    > [Stats]\tMany:\t0.5263\tMedium:\t0.2414\tFew:\t0.0177\n    > [Best ]\tAcc:\t29.7400\tMany:\t55.3714\tMedium:\t27.4857\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.46541493227795\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [41 | 200]\n    > [Train]\tLoss:\t0.9443\n    > [Test ]\tLoss:\t3.7748\tAcc:\t28.7400\n    > [Stats]\tMany:\t0.5294\tMedium:\t0.2740\tFew:\t0.0207\n    > [Best ]\tAcc:\t29.7400\tMany:\t55.3714\tMedium:\t27.4857\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4479275083059155\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [42 | 200]\n    > [Train]\tLoss:\t0.9347\n    > [Test ]\tLoss:\t3.9864\tAcc:\t28.0000\n    > [Stats]\tMany:\t0.5257\tMedium:\t0.2574\tFew:\t0.0197\n    > [Best ]\tAcc:\t29.7400\tMany:\t55.3714\tMedium:\t27.4857\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4559323557440456\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [43 | 200]\n    > [Train]\tLoss:\t0.8849\n    > [Test ]\tLoss:\t4.2102\tAcc:\t27.9000\n    > [Stats]\tMany:\t0.5266\tMedium:\t0.2497\tFew:\t0.0243\n    > [Best ]\tAcc:\t29.7400\tMany:\t55.3714\tMedium:\t27.4857\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.457705092999078\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [44 | 200]\n    > [Train]\tLoss:\t0.8921\n    > [Test ]\tLoss:\t4.5193\tAcc:\t25.5500\n    > [Stats]\tMany:\t0.5111\tMedium:\t0.1809\tFew:\t0.0443\n    > [Best ]\tAcc:\t29.7400\tMany:\t55.3714\tMedium:\t27.4857\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4694953813156033\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [45 | 200]\n    > [Train]\tLoss:\t0.8460\n    > [Test ]\tLoss:\t3.8919\tAcc:\t28.6100\n    > [Stats]\tMany:\t0.5157\tMedium:\t0.2803\tFew:\t0.0250\n    > [Best ]\tAcc:\t29.7400\tMany:\t55.3714\tMedium:\t27.4857\tFew:\t2.4667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4772580643561106\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [46 | 200]\n    > [Train]\tLoss:\t0.8522\n    > [Test ]\tLoss:\t3.8392\tAcc:\t30.5200\n    > [Stats]\tMany:\t0.5749\tMedium:\t0.2646\tFew:\t0.0380\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.48590400274559\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [47 | 200]\n    > [Train]\tLoss:\t0.8404\n    > [Test ]\tLoss:\t3.9367\tAcc:\t29.0100\n    > [Stats]\tMany:\t0.5383\tMedium:\t0.2706\tFew:\t0.0233\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4614739061588167\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [48 | 200]\n    > [Train]\tLoss:\t0.8175\n    > [Test ]\tLoss:\t4.1885\tAcc:\t25.3600\n    > [Stats]\tMany:\t0.4823\tMedium:\t0.2220\tFew:\t0.0237\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.478549772333962\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [49 | 200]\n    > [Train]\tLoss:\t0.8145\n    > [Test ]\tLoss:\t4.1608\tAcc:\t27.6700\n    > [Stats]\tMany:\t0.5154\tMedium:\t0.2283\tFew:\t0.0547\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.45595961891406\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [50 | 200]\n    > [Train]\tLoss:\t0.8106\n    > [Test ]\tLoss:\t4.1347\tAcc:\t27.5700\n    > [Stats]\tMany:\t0.5106\tMedium:\t0.2491\tFew:\t0.0327\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.433351806562258\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [51 | 200]\n    > [Train]\tLoss:\t0.7815\n    > [Test ]\tLoss:\t4.5749\tAcc:\t28.2400\n    > [Stats]\tMany:\t0.5294\tMedium:\t0.2563\tFew:\t0.0247\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4155117117318623\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [52 | 200]\n    > [Train]\tLoss:\t0.7520\n    > [Test ]\tLoss:\t4.4244\tAcc:\t26.6900\n    > [Stats]\tMany:\t0.5094\tMedium:\t0.2217\tFew:\t0.0367\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4057478447422604\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [53 | 200]\n    > [Train]\tLoss:\t0.7177\n    > [Test ]\tLoss:\t4.4990\tAcc:\t28.1100\n    > [Stats]\tMany:\t0.5274\tMedium:\t0.2617\tFew:\t0.0163\n    > [Best ]\tAcc:\t30.5200\tMany:\t57.4857\tMedium:\t26.4571\tFew:\t3.8000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4273988726865863\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [54 | 200]\n    > [Train]\tLoss:\t0.7283\n    > [Test ]\tLoss:\t3.9636\tAcc:\t31.6100\n    > [Stats]\tMany:\t0.5443\tMedium:\t0.3180\tFew:\t0.0477\n    > [Best ]\tAcc:\t31.6100\tMany:\t54.4286\tMedium:\t31.8000\tFew:\t4.7667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4422859579699137\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [55 | 200]\n    > [Train]\tLoss:\t0.7105\n    > [Test ]\tLoss:\t3.7311\tAcc:\t32.0000\n    > [Stats]\tMany:\t0.5594\tMedium:\t0.3006\tFew:\t0.0633\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4209067762516114\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [56 | 200]\n    > [Train]\tLoss:\t0.6922\n    > [Test ]\tLoss:\t4.2551\tAcc:\t28.8100\n    > [Stats]\tMany:\t0.5231\tMedium:\t0.2634\tFew:\t0.0427\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.428240577547114\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [57 | 200]\n    > [Train]\tLoss:\t0.7032\n    > [Test ]\tLoss:\t3.9665\tAcc:\t31.2900\n    > [Stats]\tMany:\t0.5794\tMedium:\t0.2831\tFew:\t0.0367\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.399829782439651\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [58 | 200]\n    > [Train]\tLoss:\t0.6725\n    > [Test ]\tLoss:\t4.3042\tAcc:\t29.4500\n    > [Stats]\tMany:\t0.5614\tMedium:\t0.2531\tFew:\t0.0313\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.418026874946907\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [59 | 200]\n    > [Train]\tLoss:\t0.6825\n    > [Test ]\tLoss:\t4.5333\tAcc:\t28.0600\n    > [Stats]\tMany:\t0.5146\tMedium:\t0.2597\tFew:\t0.0320\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4215663262883216\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [60 | 200]\n    > [Train]\tLoss:\t0.6744\n    > [Test ]\tLoss:\t3.9702\tAcc:\t30.5800\n    > [Stats]\tMany:\t0.5123\tMedium:\t0.3029\tFew:\t0.0683\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.391786887236237\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [61 | 200]\n    > [Train]\tLoss:\t0.6374\n    > [Test ]\tLoss:\t4.3446\tAcc:\t29.2500\n    > [Stats]\tMany:\t0.5771\tMedium:\t0.2171\tFew:\t0.0483\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.407941558669105\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [62 | 200]\n    > [Train]\tLoss:\t0.6395\n    > [Test ]\tLoss:\t4.4163\tAcc:\t27.6500\n    > [Stats]\tMany:\t0.5180\tMedium:\t0.2411\tFew:\t0.0360\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4003226275936496\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [63 | 200]\n    > [Train]\tLoss:\t0.6405\n    > [Test ]\tLoss:\t3.8769\tAcc:\t31.4700\n    > [Stats]\tMany:\t0.5377\tMedium:\t0.2963\tFew:\t0.0760\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3876452089761244\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [64 | 200]\n    > [Train]\tLoss:\t0.6197\n    > [Test ]\tLoss:\t4.2943\tAcc:\t29.6600\n    > [Stats]\tMany:\t0.5286\tMedium:\t0.2823\tFew:\t0.0427\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3972029996637922\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [65 | 200]\n    > [Train]\tLoss:\t0.6106\n    > [Test ]\tLoss:\t4.0314\tAcc:\t30.8700\n    > [Stats]\tMany:\t0.5251\tMedium:\t0.3051\tFew:\t0.0603\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.398519062765417\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [66 | 200]\n    > [Train]\tLoss:\t0.6009\n    > [Test ]\tLoss:\t3.8423\tAcc:\t31.9400\n    > [Stats]\tMany:\t0.5226\tMedium:\t0.3400\tFew:\t0.0583\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.401831830424383\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [67 | 200]\n    > [Train]\tLoss:\t0.6016\n    > [Test ]\tLoss:\t4.4947\tAcc:\t29.1500\n    > [Stats]\tMany:\t0.5529\tMedium:\t0.2509\tFew:\t0.0340\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.394160656665697\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [68 | 200]\n    > [Train]\tLoss:\t0.6009\n    > [Test ]\tLoss:\t3.9890\tAcc:\t31.8500\n    > [Stats]\tMany:\t0.5543\tMedium:\t0.3131\tFew:\t0.0497\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3574833938295714\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [69 | 200]\n    > [Train]\tLoss:\t0.5970\n    > [Test ]\tLoss:\t4.0572\tAcc:\t30.8900\n    > [Stats]\tMany:\t0.5763\tMedium:\t0.2726\tFew:\t0.0393\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.373691610237675\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [70 | 200]\n    > [Train]\tLoss:\t0.5577\n    > [Test ]\tLoss:\t4.3515\tAcc:\t30.0100\n    > [Stats]\tMany:\t0.5186\tMedium:\t0.3023\tFew:\t0.0427\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3748516733023446\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [71 | 200]\n    > [Train]\tLoss:\t0.5643\n    > [Test ]\tLoss:\t4.2809\tAcc:\t31.0600\n    > [Stats]\tMany:\t0.5537\tMedium:\t0.2866\tFew:\t0.0550\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3677924593873843\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [72 | 200]\n    > [Train]\tLoss:\t0.5728\n    > [Test ]\tLoss:\t4.0220\tAcc:\t31.2200\n    > [Stats]\tMany:\t0.5517\tMedium:\t0.2903\tFew:\t0.0583\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3768822721209655\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [73 | 200]\n    > [Train]\tLoss:\t0.5568\n    > [Test ]\tLoss:\t4.2954\tAcc:\t29.9300\n    > [Stats]\tMany:\t0.5363\tMedium:\t0.2726\tFew:\t0.0540\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3838228536447077\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [74 | 200]\n    > [Train]\tLoss:\t0.5554\n    > [Test ]\tLoss:\t4.0634\tAcc:\t30.2200\n    > [Stats]\tMany:\t0.5214\tMedium:\t0.2920\tFew:\t0.0583\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4010870450261828\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [75 | 200]\n    > [Train]\tLoss:\t0.5434\n    > [Test ]\tLoss:\t4.1564\tAcc:\t31.5800\n    > [Stats]\tMany:\t0.5617\tMedium:\t0.2820\tFew:\t0.0683\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3991703828761133\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [76 | 200]\n    > [Train]\tLoss:\t0.5276\n    > [Test ]\tLoss:\t4.3495\tAcc:\t30.9300\n    > [Stats]\tMany:\t0.5903\tMedium:\t0.2420\tFew:\t0.0600\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.4118800518295105\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [77 | 200]\n    > [Train]\tLoss:\t0.5326\n    > [Test ]\tLoss:\t5.1114\tAcc:\t27.6800\n    > [Stats]\tMany:\t0.5351\tMedium:\t0.2071\tFew:\t0.0567\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.401288997502583\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [78 | 200]\n    > [Train]\tLoss:\t0.5027\n    > [Test ]\tLoss:\t4.7386\tAcc:\t27.9200\n    > [Stats]\tMany:\t0.5014\tMedium:\t0.2514\tFew:\t0.0523\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.409663226406207\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [79 | 200]\n    > [Train]\tLoss:\t0.5295\n    > [Test ]\tLoss:\t4.4343\tAcc:\t29.8600\n    > [Stats]\tMany:\t0.5280\tMedium:\t0.2949\tFew:\t0.0353\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.408928734862611\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [80 | 200]\n    > [Train]\tLoss:\t0.5033\n    > [Test ]\tLoss:\t4.5489\tAcc:\t30.0300\n    > [Stats]\tMany:\t0.5434\tMedium:\t0.2700\tFew:\t0.0520\n    > [Best ]\tAcc:\t32.0000\tMany:\t55.9429\tMedium:\t30.0571\tFew:\t6.3333\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.391072742519216\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [81 | 200]\n    > [Train]\tLoss:\t0.4940\n    > [Test ]\tLoss:\t4.2068\tAcc:\t32.1400\n    > [Stats]\tMany:\t0.5703\tMedium:\t0.2891\tFew:\t0.0687\n    > [Best ]\tAcc:\t32.1400\tMany:\t57.0286\tMedium:\t28.9143\tFew:\t6.8667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3882354708743585\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [82 | 200]\n    > [Train]\tLoss:\t0.5268\n    > [Test ]\tLoss:\t4.7281\tAcc:\t29.4100\n    > [Stats]\tMany:\t0.5389\tMedium:\t0.2591\tFew:\t0.0493\n    > [Best ]\tAcc:\t32.1400\tMany:\t57.0286\tMedium:\t28.9143\tFew:\t6.8667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.348438057812476\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [83 | 200]\n    > [Train]\tLoss:\t0.5471\n    > [Test ]\tLoss:\t4.2846\tAcc:\t31.5700\n    > [Stats]\tMany:\t0.5791\tMedium:\t0.2546\tFew:\t0.0797\n    > [Best ]\tAcc:\t32.1400\tMany:\t57.0286\tMedium:\t28.9143\tFew:\t6.8667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3132829515777833\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [84 | 200]\n    > [Train]\tLoss:\t0.4740\n    > [Test ]\tLoss:\t4.8627\tAcc:\t29.1900\n    > [Stats]\tMany:\t0.5231\tMedium:\t0.2563\tFew:\t0.0637\n    > [Best ]\tAcc:\t32.1400\tMany:\t57.0286\tMedium:\t28.9143\tFew:\t6.8667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3247800972308643\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [85 | 200]\n    > [Train]\tLoss:\t0.4578\n    > [Test ]\tLoss:\t4.6798\tAcc:\t29.9000\n    > [Stats]\tMany:\t0.5234\tMedium:\t0.2846\tFew:\t0.0540\n    > [Best ]\tAcc:\t32.1400\tMany:\t57.0286\tMedium:\t28.9143\tFew:\t6.8667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.334049022141243\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [86 | 200]\n    > [Train]\tLoss:\t0.4842\n    > [Test ]\tLoss:\t4.5081\tAcc:\t32.2800\n    > [Stats]\tMany:\t0.5611\tMedium:\t0.3166\tFew:\t0.0520\n    > [Best ]\tAcc:\t32.2800\tMany:\t56.1143\tMedium:\t31.6571\tFew:\t5.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3516149549455965\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [87 | 200]\n    > [Train]\tLoss:\t0.5040\n    > [Test ]\tLoss:\t4.9243\tAcc:\t28.9000\n    > [Stats]\tMany:\t0.5131\tMedium:\t0.2557\tFew:\t0.0663\n    > [Best ]\tAcc:\t32.2800\tMany:\t56.1143\tMedium:\t31.6571\tFew:\t5.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3569220948957312\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [88 | 200]\n    > [Train]\tLoss:\t0.4388\n    > [Test ]\tLoss:\t4.4772\tAcc:\t29.6900\n    > [Stats]\tMany:\t0.4986\tMedium:\t0.2983\tFew:\t0.0600\n    > [Best ]\tAcc:\t32.2800\tMany:\t56.1143\tMedium:\t31.6571\tFew:\t5.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3464211568936717\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [89 | 200]\n    > [Train]\tLoss:\t0.4521\n    > [Test ]\tLoss:\t4.6575\tAcc:\t30.6600\n    > [Stats]\tMany:\t0.5503\tMedium:\t0.2740\tFew:\t0.0603\n    > [Best ]\tAcc:\t32.2800\tMany:\t56.1143\tMedium:\t31.6571\tFew:\t5.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.352525947480279\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [90 | 200]\n    > [Train]\tLoss:\t0.4616\n    > [Test ]\tLoss:\t4.8895\tAcc:\t30.9200\n    > [Stats]\tMany:\t0.5426\tMedium:\t0.3031\tFew:\t0.0440\n    > [Best ]\tAcc:\t32.2800\tMany:\t56.1143\tMedium:\t31.6571\tFew:\t5.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.347754070189346\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [91 | 200]\n    > [Train]\tLoss:\t0.4348\n    > [Test ]\tLoss:\t4.3329\tAcc:\t30.1200\n    > [Stats]\tMany:\t0.5580\tMedium:\t0.2589\tFew:\t0.0510\n    > [Best ]\tAcc:\t32.2800\tMany:\t56.1143\tMedium:\t31.6571\tFew:\t5.2000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.348805182599323\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [92 | 200]\n    > [Train]\tLoss:\t0.4751\n    > [Test ]\tLoss:\t4.3837\tAcc:\t32.7500\n    > [Stats]\tMany:\t0.5514\tMedium:\t0.3357\tFew:\t0.0567\n    > [Best ]\tAcc:\t32.7500\tMany:\t55.1429\tMedium:\t33.5714\tFew:\t5.6667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3394240985035455\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [93 | 200]\n    > [Train]\tLoss:\t0.4560\n    > [Test ]\tLoss:\t4.7483\tAcc:\t29.6500\n    > [Stats]\tMany:\t0.5409\tMedium:\t0.2769\tFew:\t0.0343\n    > [Best ]\tAcc:\t32.7500\tMany:\t55.1429\tMedium:\t33.5714\tFew:\t5.6667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.338325606377638\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [94 | 200]\n    > [Train]\tLoss:\t0.4865\n    > [Test ]\tLoss:\t4.5452\tAcc:\t29.1400\n    > [Stats]\tMany:\t0.5331\tMedium:\t0.2546\tFew:\t0.0523\n    > [Best ]\tAcc:\t32.7500\tMany:\t55.1429\tMedium:\t33.5714\tFew:\t5.6667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3027198989959756\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [95 | 200]\n    > [Train]\tLoss:\t0.4657\n    > [Test ]\tLoss:\t4.3615\tAcc:\t30.1500\n    > [Stats]\tMany:\t0.5266\tMedium:\t0.2989\tFew:\t0.0420\n    > [Best ]\tAcc:\t32.7500\tMany:\t55.1429\tMedium:\t33.5714\tFew:\t5.6667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3284785807236967\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [96 | 200]\n    > [Train]\tLoss:\t0.4458\n    > [Test ]\tLoss:\t4.2598\tAcc:\t32.9800\n    > [Stats]\tMany:\t0.5734\tMedium:\t0.3063\tFew:\t0.0730\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2976485828020965\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [97 | 200]\n    > [Train]\tLoss:\t0.4082\n    > [Test ]\tLoss:\t4.4570\tAcc:\t31.4500\n    > [Stats]\tMany:\t0.5463\tMedium:\t0.2971\tFew:\t0.0643\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.333311192110682\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [98 | 200]\n    > [Train]\tLoss:\t0.4162\n    > [Test ]\tLoss:\t4.8748\tAcc:\t28.6500\n    > [Stats]\tMany:\t0.5249\tMedium:\t0.2631\tFew:\t0.0357\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.371098504005593\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [99 | 200]\n    > [Train]\tLoss:\t0.4650\n    > [Test ]\tLoss:\t4.6411\tAcc:\t31.3300\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2886\tFew:\t0.0563\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3570075525977687\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [100 | 200]\n    > [Train]\tLoss:\t0.4098\n    > [Test ]\tLoss:\t4.4116\tAcc:\t31.1700\n    > [Stats]\tMany:\t0.5437\tMedium:\t0.3023\tFew:\t0.0520\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.341702699775641\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [101 | 200]\n    > [Train]\tLoss:\t0.4028\n    > [Test ]\tLoss:\t4.4190\tAcc:\t31.2700\n    > [Stats]\tMany:\t0.5466\tMedium:\t0.2971\tFew:\t0.0580\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.335174017098048\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [102 | 200]\n    > [Train]\tLoss:\t0.4056\n    > [Test ]\tLoss:\t4.4117\tAcc:\t30.5700\n    > [Stats]\tMany:\t0.5483\tMedium:\t0.2826\tFew:\t0.0497\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3530787669579043\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [103 | 200]\n    > [Train]\tLoss:\t0.4407\n    > [Test ]\tLoss:\t4.6824\tAcc:\t29.8700\n    > [Stats]\tMany:\t0.5591\tMedium:\t0.2343\tFew:\t0.0700\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3136382785018417\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [104 | 200]\n    > [Train]\tLoss:\t0.4107\n    > [Test ]\tLoss:\t4.9558\tAcc:\t28.2800\n    > [Stats]\tMany:\t0.5546\tMedium:\t0.2089\tFew:\t0.0520\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2995267877905\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [105 | 200]\n    > [Train]\tLoss:\t0.4450\n    > [Test ]\tLoss:\t4.6726\tAcc:\t30.6800\n    > [Stats]\tMany:\t0.5246\tMedium:\t0.3106\tFew:\t0.0483\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2974524736431\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [106 | 200]\n    > [Train]\tLoss:\t0.4047\n    > [Test ]\tLoss:\t4.2916\tAcc:\t32.2500\n    > [Stats]\tMany:\t0.5357\tMedium:\t0.3277\tFew:\t0.0677\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.281743576064684\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [107 | 200]\n    > [Train]\tLoss:\t0.4000\n    > [Test ]\tLoss:\t5.2869\tAcc:\t29.1800\n    > [Stats]\tMany:\t0.5443\tMedium:\t0.2480\tFew:\t0.0483\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.301574873376416\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [108 | 200]\n    > [Train]\tLoss:\t0.3913\n    > [Test ]\tLoss:\t4.6057\tAcc:\t31.9000\n    > [Stats]\tMany:\t0.5754\tMedium:\t0.2874\tFew:\t0.0567\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.3017700940306542\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [109 | 200]\n    > [Train]\tLoss:\t0.3473\n    > [Test ]\tLoss:\t5.4850\tAcc:\t28.3900\n    > [Stats]\tMany:\t0.5157\tMedium:\t0.2360\tFew:\t0.0693\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.315180742641839\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [110 | 200]\n    > [Train]\tLoss:\t0.3698\n    > [Test ]\tLoss:\t4.4991\tAcc:\t31.0800\n    > [Stats]\tMany:\t0.5980\tMedium:\t0.2529\tFew:\t0.0433\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.317113497295427\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [111 | 200]\n    > [Train]\tLoss:\t0.4234\n    > [Test ]\tLoss:\t4.7660\tAcc:\t31.6400\n    > [Stats]\tMany:\t0.5629\tMedium:\t0.3040\tFew:\t0.0433\n    > [Best ]\tAcc:\t32.9800\tMany:\t57.3429\tMedium:\t30.6286\tFew:\t7.3000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2893117313040747\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [112 | 200]\n    > [Train]\tLoss:\t0.4210\n    > [Test ]\tLoss:\t4.0191\tAcc:\t33.2100\n    > [Stats]\tMany:\t0.5686\tMedium:\t0.3117\tFew:\t0.0800\n    > [Best ]\tAcc:\t33.2100\tMany:\t56.8571\tMedium:\t31.1714\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2767865921615345\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [113 | 200]\n    > [Train]\tLoss:\t0.3856\n    > [Test ]\tLoss:\t5.0180\tAcc:\t29.5800\n    > [Stats]\tMany:\t0.5683\tMedium:\t0.2429\tFew:\t0.0397\n    > [Best ]\tAcc:\t33.2100\tMany:\t56.8571\tMedium:\t31.1714\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2807584162271404\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [114 | 200]\n    > [Train]\tLoss:\t0.3787\n    > [Test ]\tLoss:\t4.5760\tAcc:\t30.3000\n    > [Stats]\tMany:\t0.5637\tMedium:\t0.2671\tFew:\t0.0407\n    > [Best ]\tAcc:\t33.2100\tMany:\t56.8571\tMedium:\t31.1714\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.257478909706294\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [115 | 200]\n    > [Train]\tLoss:\t0.3526\n    > [Test ]\tLoss:\t4.4629\tAcc:\t33.8600\n    > [Stats]\tMany:\t0.6060\tMedium:\t0.3189\tFew:\t0.0497\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2570893160646657\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [116 | 200]\n    > [Train]\tLoss:\t0.3705\n    > [Test ]\tLoss:\t4.9113\tAcc:\t31.8400\n    > [Stats]\tMany:\t0.5491\tMedium:\t0.3140\tFew:\t0.0543\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2657829850474855\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [117 | 200]\n    > [Train]\tLoss:\t0.3938\n    > [Test ]\tLoss:\t4.6523\tAcc:\t30.9400\n    > [Stats]\tMany:\t0.5497\tMedium:\t0.2863\tFew:\t0.0560\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.229013981950875\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [118 | 200]\n    > [Train]\tLoss:\t0.3825\n    > [Test ]\tLoss:\t4.5245\tAcc:\t32.3100\n    > [Stats]\tMany:\t0.5554\tMedium:\t0.3229\tFew:\t0.0523\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2248568218862323\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [119 | 200]\n    > [Train]\tLoss:\t0.3781\n    > [Test ]\tLoss:\t5.3812\tAcc:\t27.4700\n    > [Stats]\tMany:\t0.5237\tMedium:\t0.2231\tFew:\t0.0443\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.21262098690259\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [120 | 200]\n    > [Train]\tLoss:\t0.4009\n    > [Test ]\tLoss:\t4.2855\tAcc:\t33.4800\n    > [Stats]\tMany:\t0.6094\tMedium:\t0.2906\tFew:\t0.0660\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2129940874037253\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [121 | 200]\n    > [Train]\tLoss:\t0.3607\n    > [Test ]\tLoss:\t4.5066\tAcc:\t31.6400\n    > [Stats]\tMany:\t0.5331\tMedium:\t0.3143\tFew:\t0.0660\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.222842560712368\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [122 | 200]\n    > [Train]\tLoss:\t0.4021\n    > [Test ]\tLoss:\t4.3947\tAcc:\t30.6200\n    > [Stats]\tMany:\t0.5651\tMedium:\t0.2526\tFew:\t0.0667\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1964342993038533\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [123 | 200]\n    > [Train]\tLoss:\t0.3845\n    > [Test ]\tLoss:\t4.5425\tAcc:\t31.3800\n    > [Stats]\tMany:\t0.5323\tMedium:\t0.2900\tFew:\t0.0867\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1983877811932615\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [124 | 200]\n    > [Train]\tLoss:\t0.3630\n    > [Test ]\tLoss:\t5.0510\tAcc:\t29.4500\n    > [Stats]\tMany:\t0.5100\tMedium:\t0.2694\tFew:\t0.0723\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.185393589760113\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [125 | 200]\n    > [Train]\tLoss:\t0.3520\n    > [Test ]\tLoss:\t4.6270\tAcc:\t30.3000\n    > [Stats]\tMany:\t0.5477\tMedium:\t0.2831\tFew:\t0.0407\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2375422373005565\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [126 | 200]\n    > [Train]\tLoss:\t0.3756\n    > [Test ]\tLoss:\t4.6586\tAcc:\t30.2000\n    > [Stats]\tMany:\t0.5386\tMedium:\t0.2683\tFew:\t0.0653\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2280048030632176\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [127 | 200]\n    > [Train]\tLoss:\t0.3546\n    > [Test ]\tLoss:\t5.2130\tAcc:\t28.3000\n    > [Stats]\tMany:\t0.5203\tMedium:\t0.2489\tFew:\t0.0460\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.225378134375522\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [128 | 200]\n    > [Train]\tLoss:\t0.3730\n    > [Test ]\tLoss:\t4.6539\tAcc:\t32.6400\n    > [Stats]\tMany:\t0.5674\tMedium:\t0.2960\tFew:\t0.0807\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2421447946523108\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [129 | 200]\n    > [Train]\tLoss:\t0.3558\n    > [Test ]\tLoss:\t4.7839\tAcc:\t30.8800\n    > [Stats]\tMany:\t0.5643\tMedium:\t0.2711\tFew:\t0.0547\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2419774206785448\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [130 | 200]\n    > [Train]\tLoss:\t0.3701\n    > [Test ]\tLoss:\t4.8907\tAcc:\t30.2700\n    > [Stats]\tMany:\t0.5734\tMedium:\t0.2314\tFew:\t0.0700\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2144330739980345\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [131 | 200]\n    > [Train]\tLoss:\t0.3426\n    > [Test ]\tLoss:\t4.4300\tAcc:\t32.5100\n    > [Stats]\tMany:\t0.5526\tMedium:\t0.3040\tFew:\t0.0843\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2290183480012833\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [132 | 200]\n    > [Train]\tLoss:\t0.3838\n    > [Test ]\tLoss:\t5.4222\tAcc:\t28.5900\n    > [Stats]\tMany:\t0.5406\tMedium:\t0.2291\tFew:\t0.0550\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.242642930923766\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [133 | 200]\n    > [Train]\tLoss:\t0.3528\n    > [Test ]\tLoss:\t5.0732\tAcc:\t30.0200\n    > [Stats]\tMany:\t0.5486\tMedium:\t0.2606\tFew:\t0.0567\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2486281574803733\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [134 | 200]\n    > [Train]\tLoss:\t0.3223\n    > [Test ]\tLoss:\t4.8380\tAcc:\t30.4500\n    > [Stats]\tMany:\t0.5537\tMedium:\t0.2740\tFew:\t0.0493\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2363823480672194\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [135 | 200]\n    > [Train]\tLoss:\t0.3676\n    > [Test ]\tLoss:\t4.4121\tAcc:\t32.7300\n    > [Stats]\tMany:\t0.5474\tMedium:\t0.3229\tFew:\t0.0757\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.230576895824903\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [136 | 200]\n    > [Train]\tLoss:\t0.3606\n    > [Test ]\tLoss:\t4.9740\tAcc:\t30.9400\n    > [Stats]\tMany:\t0.5380\tMedium:\t0.2966\tFew:\t0.0577\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2330741808338823\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [137 | 200]\n    > [Train]\tLoss:\t0.3534\n    > [Test ]\tLoss:\t4.4565\tAcc:\t32.4800\n    > [Stats]\tMany:\t0.5517\tMedium:\t0.3266\tFew:\t0.0580\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2521903812318165\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [138 | 200]\n    > [Train]\tLoss:\t0.3664\n    > [Test ]\tLoss:\t4.8701\tAcc:\t32.2800\n    > [Stats]\tMany:\t0.5554\tMedium:\t0.3189\tFew:\t0.0560\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2558531406578153\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [139 | 200]\n    > [Train]\tLoss:\t0.3471\n    > [Test ]\tLoss:\t4.3718\tAcc:\t31.0700\n    > [Stats]\tMany:\t0.5463\tMedium:\t0.2889\tFew:\t0.0613\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2506096526042865\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [140 | 200]\n    > [Train]\tLoss:\t0.3718\n    > [Test ]\tLoss:\t5.0209\tAcc:\t29.7600\n    > [Stats]\tMany:\t0.5137\tMedium:\t0.2880\tFew:\t0.0567\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.230331429744747\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [141 | 200]\n    > [Train]\tLoss:\t0.3669\n    > [Test ]\tLoss:\t4.4857\tAcc:\t31.6200\n    > [Stats]\tMany:\t0.5460\tMedium:\t0.3057\tFew:\t0.0603\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.236780858876415\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [142 | 200]\n    > [Train]\tLoss:\t0.3378\n    > [Test ]\tLoss:\t5.2738\tAcc:\t28.2000\n    > [Stats]\tMany:\t0.5209\tMedium:\t0.2466\tFew:\t0.0447\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.229549573871274\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [143 | 200]\n    > [Train]\tLoss:\t0.3291\n    > [Test ]\tLoss:\t4.5669\tAcc:\t32.3800\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2980\tFew:\t0.0803\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.212764729163234\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [144 | 200]\n    > [Train]\tLoss:\t0.3194\n    > [Test ]\tLoss:\t4.7663\tAcc:\t30.9800\n    > [Stats]\tMany:\t0.5546\tMedium:\t0.2774\tFew:\t0.0620\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.212756656763099\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [145 | 200]\n    > [Train]\tLoss:\t0.3188\n    > [Test ]\tLoss:\t4.4152\tAcc:\t33.6200\n    > [Stats]\tMany:\t0.5689\tMedium:\t0.3354\tFew:\t0.0657\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.209197019714194\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [146 | 200]\n    > [Train]\tLoss:\t0.3122\n    > [Test ]\tLoss:\t4.9240\tAcc:\t32.1600\n    > [Stats]\tMany:\t0.5577\tMedium:\t0.3226\tFew:\t0.0450\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.200852532728768\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [147 | 200]\n    > [Train]\tLoss:\t0.3106\n    > [Test ]\tLoss:\t4.9045\tAcc:\t30.7100\n    > [Stats]\tMany:\t0.5483\tMedium:\t0.2783\tFew:\t0.0593\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.207818921098175\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [148 | 200]\n    > [Train]\tLoss:\t0.3462\n    > [Test ]\tLoss:\t5.6034\tAcc:\t28.6600\n    > [Stats]\tMany:\t0.5629\tMedium:\t0.2143\tFew:\t0.0487\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.202602315137729\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [149 | 200]\n    > [Train]\tLoss:\t0.3841\n    > [Test ]\tLoss:\t5.1014\tAcc:\t29.8100\n    > [Stats]\tMany:\t0.5100\tMedium:\t0.2960\tFew:\t0.0533\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1852838242154338\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [150 | 200]\n    > [Train]\tLoss:\t0.3680\n    > [Test ]\tLoss:\t4.7045\tAcc:\t32.4500\n    > [Stats]\tMany:\t0.5817\tMedium:\t0.2874\tFew:\t0.0677\n    > [Best ]\tAcc:\t33.8600\tMany:\t60.6000\tMedium:\t31.8857\tFew:\t4.9667\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1641925679255976\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [151 | 200]\n    > [Train]\tLoss:\t0.3451\n    > [Test ]\tLoss:\t4.3032\tAcc:\t34.2800\n    > [Stats]\tMany:\t0.5846\tMedium:\t0.3263\tFew:\t0.0800\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1752484424760135\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [152 | 200]\n    > [Train]\tLoss:\t0.3348\n    > [Test ]\tLoss:\t4.5079\tAcc:\t31.9700\n    > [Stats]\tMany:\t0.5589\tMedium:\t0.2986\tFew:\t0.0653\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.193570962592976\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [153 | 200]\n    > [Train]\tLoss:\t0.3426\n    > [Test ]\tLoss:\t4.6913\tAcc:\t32.1600\n    > [Stats]\tMany:\t0.5594\tMedium:\t0.3077\tFew:\t0.0603\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1839995590162347\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [154 | 200]\n    > [Train]\tLoss:\t0.3225\n    > [Test ]\tLoss:\t4.9613\tAcc:\t29.7300\n    > [Stats]\tMany:\t0.5143\tMedium:\t0.3000\tFew:\t0.0410\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2080726310776146\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [155 | 200]\n    > [Train]\tLoss:\t0.2893\n    > [Test ]\tLoss:\t5.0612\tAcc:\t29.7900\n    > [Stats]\tMany:\t0.5554\tMedium:\t0.2549\tFew:\t0.0477\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.2094267342303744\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [156 | 200]\n    > [Train]\tLoss:\t0.3496\n    > [Test ]\tLoss:\t4.6703\tAcc:\t32.3500\n    > [Stats]\tMany:\t0.5611\tMedium:\t0.3071\tFew:\t0.0653\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1869437583621893\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [157 | 200]\n    > [Train]\tLoss:\t0.3767\n    > [Test ]\tLoss:\t5.0755\tAcc:\t29.8700\n    > [Stats]\tMany:\t0.5397\tMedium:\t0.2637\tFew:\t0.0583\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1768052341327935\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [158 | 200]\n    > [Train]\tLoss:\t0.3645\n    > [Test ]\tLoss:\t4.2866\tAcc:\t33.7800\n    > [Stats]\tMany:\t0.5811\tMedium:\t0.3289\tFew:\t0.0643\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.137403794768447\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [159 | 200]\n    > [Train]\tLoss:\t0.3360\n    > [Test ]\tLoss:\t5.0281\tAcc:\t30.2300\n    > [Stats]\tMany:\t0.5531\tMedium:\t0.2674\tFew:\t0.0503\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1611625776695496\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [160 | 200]\n    > [Train]\tLoss:\t0.2928\n    > [Test ]\tLoss:\t4.4394\tAcc:\t33.9900\n    > [Stats]\tMany:\t0.6157\tMedium:\t0.3049\tFew:\t0.0590\n    > [Best ]\tAcc:\t34.2800\tMany:\t58.4571\tMedium:\t32.6286\tFew:\t8.0000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.164437041049788\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [161 | 200]\n    > [Train]\tLoss:\t0.3598\n    > [Test ]\tLoss:\t3.6940\tAcc:\t38.2100\n    > [Stats]\tMany:\t0.6277\tMedium:\t0.3803\tFew:\t0.0977\n    > [Best ]\tAcc:\t38.2100\tMany:\t62.7714\tMedium:\t38.0286\tFew:\t9.7667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.1410906552102285\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [162 | 200]\n    > [Train]\tLoss:\t0.2231\n    > [Test ]\tLoss:\t3.5675\tAcc:\t39.2300\n    > [Stats]\tMany:\t0.6311\tMedium:\t0.3911\tFew:\t0.1150\n    > [Best ]\tAcc:\t39.2300\tMany:\t63.1143\tMedium:\t39.1143\tFew:\t11.5000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.1271077755634935\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [163 | 200]\n    > [Train]\tLoss:\t0.1837\n    > [Test ]\tLoss:\t3.4987\tAcc:\t39.7200\n    > [Stats]\tMany:\t0.6303\tMedium:\t0.3991\tFew:\t0.1230\n    > [Best ]\tAcc:\t39.7200\tMany:\t63.0286\tMedium:\t39.9143\tFew:\t12.3000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.1182569988403506\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [164 | 200]\n    > [Train]\tLoss:\t0.1556\n    > [Test ]\tLoss:\t3.4541\tAcc:\t40.2100\n    > [Stats]\tMany:\t0.6309\tMedium:\t0.4063\tFew:\t0.1303\n    > [Best ]\tAcc:\t40.2100\tMany:\t63.0857\tMedium:\t40.6286\tFew:\t13.0333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.1109427473885325\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [165 | 200]\n    > [Train]\tLoss:\t0.1380\n    > [Test ]\tLoss:\t3.4295\tAcc:\t40.4800\n    > [Stats]\tMany:\t0.6303\tMedium:\t0.4109\tFew:\t0.1347\n    > [Best ]\tAcc:\t40.4800\tMany:\t63.0286\tMedium:\t41.0857\tFew:\t13.4667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.105598721702296\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [166 | 200]\n    > [Train]\tLoss:\t0.1256\n    > [Test ]\tLoss:\t3.4067\tAcc:\t40.8300\n    > [Stats]\tMany:\t0.6297\tMedium:\t0.4180\tFew:\t0.1387\n    > [Best ]\tAcc:\t40.8300\tMany:\t62.9714\tMedium:\t41.8000\tFew:\t13.8667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.1017206301575926\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [167 | 200]\n    > [Train]\tLoss:\t0.1284\n    > [Test ]\tLoss:\t3.4072\tAcc:\t40.7200\n    > [Stats]\tMany:\t0.6306\tMedium:\t0.4143\tFew:\t0.1383\n    > [Best ]\tAcc:\t40.8300\tMany:\t62.9714\tMedium:\t41.8000\tFew:\t13.8667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0982652272912756\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [168 | 200]\n    > [Train]\tLoss:\t0.1122\n    > [Test ]\tLoss:\t3.3753\tAcc:\t41.1400\n    > [Stats]\tMany:\t0.6331\tMedium:\t0.4174\tFew:\t0.1457\n    > [Best ]\tAcc:\t41.1400\tMany:\t63.3143\tMedium:\t41.7429\tFew:\t14.5667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0949169995610797\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [169 | 200]\n    > [Train]\tLoss:\t0.1141\n    > [Test ]\tLoss:\t3.3878\tAcc:\t41.0000\n    > [Stats]\tMany:\t0.6274\tMedium:\t0.4191\tFew:\t0.1457\n    > [Best ]\tAcc:\t41.1400\tMany:\t63.3143\tMedium:\t41.7429\tFew:\t14.5667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0918003334946675\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [170 | 200]\n    > [Train]\tLoss:\t0.1107\n    > [Test ]\tLoss:\t3.3764\tAcc:\t41.2600\n    > [Stats]\tMany:\t0.6311\tMedium:\t0.4226\tFew:\t0.1460\n    > [Best ]\tAcc:\t41.2600\tMany:\t63.1143\tMedium:\t42.2571\tFew:\t14.6000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.089155982134262\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [171 | 200]\n    > [Train]\tLoss:\t0.1021\n    > [Test ]\tLoss:\t3.3663\tAcc:\t41.2800\n    > [Stats]\tMany:\t0.6329\tMedium:\t0.4211\tFew:\t0.1463\n    > [Best ]\tAcc:\t41.2800\tMany:\t63.2857\tMedium:\t42.1143\tFew:\t14.6333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0867033825757897\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [172 | 200]\n    > [Train]\tLoss:\t0.0954\n    > [Test ]\tLoss:\t3.3742\tAcc:\t41.3300\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.4203\tFew:\t0.1467\n    > [Best ]\tAcc:\t41.3300\tMany:\t63.4857\tMedium:\t42.0286\tFew:\t14.6667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0852659421326396\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [173 | 200]\n    > [Train]\tLoss:\t0.0950\n    > [Test ]\tLoss:\t3.3679\tAcc:\t41.3200\n    > [Stats]\tMany:\t0.6326\tMedium:\t0.4229\tFew:\t0.1460\n    > [Best ]\tAcc:\t41.3300\tMany:\t63.4857\tMedium:\t42.0286\tFew:\t14.6667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.083462105713543\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [174 | 200]\n    > [Train]\tLoss:\t0.0943\n    > [Test ]\tLoss:\t3.3460\tAcc:\t41.3400\n    > [Stats]\tMany:\t0.6317\tMedium:\t0.4189\tFew:\t0.1523\n    > [Best ]\tAcc:\t41.3400\tMany:\t63.1714\tMedium:\t41.8857\tFew:\t15.2333\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.081250565182292\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [175 | 200]\n    > [Train]\tLoss:\t0.0901\n    > [Test ]\tLoss:\t3.3669\tAcc:\t41.5200\n    > [Stats]\tMany:\t0.6311\tMedium:\t0.4240\tFew:\t0.1530\n    > [Best ]\tAcc:\t41.5200\tMany:\t63.1143\tMedium:\t42.4000\tFew:\t15.3000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0800722971700174\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [176 | 200]\n    > [Train]\tLoss:\t0.0888\n    > [Test ]\tLoss:\t3.3405\tAcc:\t41.5900\n    > [Stats]\tMany:\t0.6354\tMedium:\t0.4229\tFew:\t0.1517\n    > [Best ]\tAcc:\t41.5900\tMany:\t63.5429\tMedium:\t42.2857\tFew:\t15.1667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0780879708655218\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [177 | 200]\n    > [Train]\tLoss:\t0.0863\n    > [Test ]\tLoss:\t3.3366\tAcc:\t41.6800\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.4260\tFew:\t0.1517\n    > [Best ]\tAcc:\t41.6800\tMany:\t63.4857\tMedium:\t42.6000\tFew:\t15.1667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0763305932940863\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [178 | 200]\n    > [Train]\tLoss:\t0.0799\n    > [Test ]\tLoss:\t3.3581\tAcc:\t41.6000\n    > [Stats]\tMany:\t0.6323\tMedium:\t0.4251\tFew:\t0.1530\n    > [Best ]\tAcc:\t41.6800\tMany:\t63.4857\tMedium:\t42.6000\tFew:\t15.1667\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.0746822520385337\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [179 | 200]\n    > [Train]\tLoss:\t0.0788\n    > [Test ]\tLoss:\t3.3682\tAcc:\t41.8400\n    > [Stats]\tMany:\t0.6391\tMedium:\t0.4243\tFew:\t0.1540\n    > [Best ]\tAcc:\t41.8400\tMany:\t63.9143\tMedium:\t42.4286\tFew:\t15.4000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.07372468565152\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [180 | 200]\n    > [Train]\tLoss:\t0.0817\n    > [Test ]\tLoss:\t3.3526\tAcc:\t41.8300\n    > [Stats]\tMany:\t0.6306\tMedium:\t0.4291\tFew:\t0.1580\n    > [Best ]\tAcc:\t41.8400\tMany:\t63.9143\tMedium:\t42.4286\tFew:\t15.4000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"3.072458170896146\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [181 | 200]\n    > [Train]\tLoss:\t0.0785\n    > [Test ]\tLoss:\t3.3598\tAcc:\t41.4600\n    > [Stats]\tMany:\t0.6303\tMedium:\t0.4251\tFew:\t0.1507\n    > [Best ]\tAcc:\t41.8400\tMany:\t63.9143\tMedium:\t42.4286\tFew:\t15.4000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.072442888942511\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [182 | 200]\n    > [Train]\tLoss:\t0.0754\n    > [Test ]\tLoss:\t3.3519\tAcc:\t41.7000\n    > [Stats]\tMany:\t0.6340\tMedium:\t0.4274\tFew:\t0.1517\n    > [Best ]\tAcc:\t41.8400\tMany:\t63.9143\tMedium:\t42.4286\tFew:\t15.4000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.07243040594956\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [183 | 200]\n    > [Train]\tLoss:\t0.0847\n    > [Test ]\tLoss:\t3.3547\tAcc:\t41.7700\n    > [Stats]\tMany:\t0.6371\tMedium:\t0.4260\tFew:\t0.1520\n    > [Best ]\tAcc:\t41.8400\tMany:\t63.9143\tMedium:\t42.4286\tFew:\t15.4000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.072408935631994\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [184 | 200]\n    > [Train]\tLoss:\t0.0775\n    > [Test ]\tLoss:\t3.3576\tAcc:\t41.6600\n    > [Stats]\tMany:\t0.6346\tMedium:\t0.4234\tFew:\t0.1543\n    > [Best ]\tAcc:\t41.8400\tMany:\t63.9143\tMedium:\t42.4286\tFew:\t15.4000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.072401983498957\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [185 | 200]\n    > [Train]\tLoss:\t0.0783\n    > [Test ]\tLoss:\t3.3539\tAcc:\t41.6500\n    > [Stats]\tMany:\t0.6357\tMedium:\t0.4243\tFew:\t0.1517\n    > [Best ]\tAcc:\t41.8400\tMany:\t63.9143\tMedium:\t42.4286\tFew:\t15.4000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0723870059803478\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [186 | 200]\n    > [Train]\tLoss:\t0.0769\n    > [Test ]\tLoss:\t3.3565\tAcc:\t41.8500\n    > [Stats]\tMany:\t0.6354\tMedium:\t0.4286\tFew:\t0.1537\n    > [Best ]\tAcc:\t41.8500\tMany:\t63.5429\tMedium:\t42.8571\tFew:\t15.3667\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0723764294469755\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [187 | 200]\n    > [Train]\tLoss:\t0.0766\n    > [Test ]\tLoss:\t3.3517\tAcc:\t41.9200\n    > [Stats]\tMany:\t0.6371\tMedium:\t0.4277\tFew:\t0.1550\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0723657423403403\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [188 | 200]\n    > [Train]\tLoss:\t0.0765\n    > [Test ]\tLoss:\t3.3507\tAcc:\t41.7500\n    > [Stats]\tMany:\t0.6366\tMedium:\t0.4260\tFew:\t0.1520\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.072350022776053\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [189 | 200]\n    > [Train]\tLoss:\t0.0747\n    > [Test ]\tLoss:\t3.3557\tAcc:\t41.8800\n    > [Stats]\tMany:\t0.6360\tMedium:\t0.4280\tFew:\t0.1547\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.072338610961913\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [190 | 200]\n    > [Train]\tLoss:\t0.0802\n    > [Test ]\tLoss:\t3.3520\tAcc:\t41.7800\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.4286\tFew:\t0.1520\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.072320416659496\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [191 | 200]\n    > [Train]\tLoss:\t0.0784\n    > [Test ]\tLoss:\t3.3549\tAcc:\t41.7000\n    > [Stats]\tMany:\t0.6340\tMedium:\t0.4226\tFew:\t0.1573\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0723081493334194\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [192 | 200]\n    > [Train]\tLoss:\t0.0753\n    > [Test ]\tLoss:\t3.3503\tAcc:\t41.7400\n    > [Stats]\tMany:\t0.6300\tMedium:\t0.4306\tFew:\t0.1540\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.072291010675533\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [193 | 200]\n    > [Train]\tLoss:\t0.0765\n    > [Test ]\tLoss:\t3.3454\tAcc:\t41.8600\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.4294\tFew:\t0.1537\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0722784501170697\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [194 | 200]\n    > [Train]\tLoss:\t0.0796\n    > [Test ]\tLoss:\t3.3513\tAcc:\t41.7400\n    > [Stats]\tMany:\t0.6337\tMedium:\t0.4266\tFew:\t0.1543\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0722667670307517\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [195 | 200]\n    > [Train]\tLoss:\t0.0750\n    > [Test ]\tLoss:\t3.3568\tAcc:\t41.8800\n    > [Stats]\tMany:\t0.6369\tMedium:\t0.4280\tFew:\t0.1537\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0722536890183925\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [196 | 200]\n    > [Train]\tLoss:\t0.0795\n    > [Test ]\tLoss:\t3.3534\tAcc:\t41.7000\n    > [Stats]\tMany:\t0.6337\tMedium:\t0.4263\tFew:\t0.1533\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0722418072319755\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [197 | 200]\n    > [Train]\tLoss:\t0.0808\n    > [Test ]\tLoss:\t3.3549\tAcc:\t41.5700\n    > [Stats]\tMany:\t0.6343\tMedium:\t0.4220\tFew:\t0.1533\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0722244434666206\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [198 | 200]\n    > [Train]\tLoss:\t0.0791\n    > [Test ]\tLoss:\t3.3631\tAcc:\t41.8700\n    > [Stats]\tMany:\t0.6349\tMedium:\t0.4289\tFew:\t0.1547\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0722162971632114\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [199 | 200]\n    > [Train]\tLoss:\t0.0755\n    > [Test ]\tLoss:\t3.3574\tAcc:\t41.7200\n    > [Stats]\tMany:\t0.6311\tMedium:\t0.4300\tFew:\t0.1527\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"3.0722078828401385\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [200 | 200]\n    > [Train]\tLoss:\t0.0769\n    > [Test ]\tLoss:\t3.3516\tAcc:\t41.6900\n    > [Stats]\tMany:\t0.6340\tMedium:\t0.4266\tFew:\t0.1523\n    > [Best ]\tAcc:\t41.9200\tMany:\t63.7143\tMedium:\t42.7714\tFew:\t15.5000\n    > [Param]\tLR:\t0.00001000\n---> Final performance...\n    > best bAcc (test):\t41.92\n    > best statistics:\tMany:\t0.6371428370475769\tMed:\t0.4277142882347107\tFew:\t0.1550000011920929\n---> Training Time: 0:13:59.68\n","output_type":"stream"},{"name":"stdout","text":"3.0721999142418515\n","output_type":"stream"}]},{"cell_type":"code","source":"variance_list","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:42:34.399597Z","iopub.execute_input":"2024-01-24T13:42:34.399982Z","iopub.status.idle":"2024-01-24T13:42:34.410252Z","shell.execute_reply.started":"2024-01-24T13:42:34.399945Z","shell.execute_reply":"2024-01-24T13:42:34.409241Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[0.7331374223447409,\n 0.7003908520922258,\n 0.7489827843103728,\n 0.9013158511162322,\n 1.1403339757960271,\n 1.3796312073260708,\n 1.6077951436317115,\n 1.80477040966406,\n 1.9695476276344863,\n 2.1227972024028774,\n 2.269442113367792,\n 2.403048489284309,\n 2.539726160013663,\n 2.6517016425803193,\n 2.750523021513866,\n 2.840059118801284,\n 2.927864755812453,\n 2.97029454427814,\n 3.0375377892522457,\n 3.082997394729207,\n 3.173181643170272,\n 3.1861574976378093,\n 3.2328157438928966,\n 3.2689806915248347,\n 3.3048579210949196,\n 3.349235640899656,\n 3.3496990768568113,\n 3.349386087902296,\n 3.395568698454504,\n 3.3892482599641003,\n 3.4266375015131,\n 3.4456498790323216,\n 3.450965605966762,\n 3.4375864623414114,\n 3.4532537476330276,\n 3.468006087144156,\n 3.471700195499056,\n 3.459409682354228,\n 3.4668156923634523,\n 3.46541493227795,\n 3.4479275083059155,\n 3.4559323557440456,\n 3.457705092999078,\n 3.4694953813156033,\n 3.4772580643561106,\n 3.48590400274559,\n 3.4614739061588167,\n 3.478549772333962,\n 3.45595961891406,\n 3.433351806562258,\n 3.4155117117318623,\n 3.4057478447422604,\n 3.4273988726865863,\n 3.4422859579699137,\n 3.4209067762516114,\n 3.428240577547114,\n 3.399829782439651,\n 3.418026874946907,\n 3.4215663262883216,\n 3.391786887236237,\n 3.407941558669105,\n 3.4003226275936496,\n 3.3876452089761244,\n 3.3972029996637922,\n 3.398519062765417,\n 3.401831830424383,\n 3.394160656665697,\n 3.3574833938295714,\n 3.373691610237675,\n 3.3748516733023446,\n 3.3677924593873843,\n 3.3768822721209655,\n 3.3838228536447077,\n 3.4010870450261828,\n 3.3991703828761133,\n 3.4118800518295105,\n 3.401288997502583,\n 3.409663226406207,\n 3.408928734862611,\n 3.391072742519216,\n 3.3882354708743585,\n 3.348438057812476,\n 3.3132829515777833,\n 3.3247800972308643,\n 3.334049022141243,\n 3.3516149549455965,\n 3.3569220948957312,\n 3.3464211568936717,\n 3.352525947480279,\n 3.347754070189346,\n 3.348805182599323,\n 3.3394240985035455,\n 3.338325606377638,\n 3.3027198989959756,\n 3.3284785807236967,\n 3.2976485828020965,\n 3.333311192110682,\n 3.371098504005593,\n 3.3570075525977687,\n 3.341702699775641,\n 3.335174017098048,\n 3.3530787669579043,\n 3.3136382785018417,\n 3.2995267877905,\n 3.2974524736431,\n 3.281743576064684,\n 3.301574873376416,\n 3.3017700940306542,\n 3.315180742641839,\n 3.317113497295427,\n 3.2893117313040747,\n 3.2767865921615345,\n 3.2807584162271404,\n 3.257478909706294,\n 3.2570893160646657,\n 3.2657829850474855,\n 3.229013981950875,\n 3.2248568218862323,\n 3.21262098690259,\n 3.2129940874037253,\n 3.222842560712368,\n 3.1964342993038533,\n 3.1983877811932615,\n 3.185393589760113,\n 3.2375422373005565,\n 3.2280048030632176,\n 3.225378134375522,\n 3.2421447946523108,\n 3.2419774206785448,\n 3.2144330739980345,\n 3.2290183480012833,\n 3.242642930923766,\n 3.2486281574803733,\n 3.2363823480672194,\n 3.230576895824903,\n 3.2330741808338823,\n 3.2521903812318165,\n 3.2558531406578153,\n 3.2506096526042865,\n 3.230331429744747,\n 3.236780858876415,\n 3.229549573871274,\n 3.212764729163234,\n 3.212756656763099,\n 3.209197019714194,\n 3.200852532728768,\n 3.207818921098175,\n 3.202602315137729,\n 3.1852838242154338,\n 3.1641925679255976,\n 3.1752484424760135,\n 3.193570962592976,\n 3.1839995590162347,\n 3.2080726310776146,\n 3.2094267342303744,\n 3.1869437583621893,\n 3.1768052341327935,\n 3.137403794768447,\n 3.1611625776695496,\n 3.164437041049788,\n 3.1410906552102285,\n 3.1271077755634935,\n 3.1182569988403506,\n 3.1109427473885325,\n 3.105598721702296,\n 3.1017206301575926,\n 3.0982652272912756,\n 3.0949169995610797,\n 3.0918003334946675,\n 3.089155982134262,\n 3.0867033825757897,\n 3.0852659421326396,\n 3.083462105713543,\n 3.081250565182292,\n 3.0800722971700174,\n 3.0780879708655218,\n 3.0763305932940863,\n 3.0746822520385337,\n 3.07372468565152,\n 3.072458170896146,\n 3.072442888942511,\n 3.07243040594956,\n 3.072408935631994,\n 3.072401983498957,\n 3.0723870059803478,\n 3.0723764294469755,\n 3.0723657423403403,\n 3.072350022776053,\n 3.072338610961913,\n 3.072320416659496,\n 3.0723081493334194,\n 3.072291010675533,\n 3.0722784501170697,\n 3.0722667670307517,\n 3.0722536890183925,\n 3.0722418072319755,\n 3.0722244434666206,\n 3.0722162971632114,\n 3.0722078828401385,\n 3.0721999142418515]"},"metadata":{}}]},{"cell_type":"code","source":"'''\nimport matplotlib.pyplot as plt\n\n# Assuming variance_l1_norm is the calculated variance # If you have multiple variances, create a list\n\nplt.figure(figsize=(8, 6))\nplt.plot(range(len(variance_list)), variance_list, color='blue', linestyle='-', linewidth=2)\nplt.xlabel('Classes')\nplt.ylabel('Variance of L1-norm')\nplt.title('Variance of L1-norm Among Classes')\nplt.xticks(range(len(variance_list)), [f'Class_{i}' for i in range(len(variance_list))])\nplt.grid(True)\nplt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:42:34.411626Z","iopub.execute_input":"2024-01-24T13:42:34.412356Z","iopub.status.idle":"2024-01-24T13:42:34.424475Z","shell.execute_reply.started":"2024-01-24T13:42:34.412322Z","shell.execute_reply":"2024-01-24T13:42:34.423595Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"\"\\nimport matplotlib.pyplot as plt\\n\\n# Assuming variance_l1_norm is the calculated variance # If you have multiple variances, create a list\\n\\nplt.figure(figsize=(8, 6))\\nplt.plot(range(len(variance_list)), variance_list, color='blue', linestyle='-', linewidth=2)\\nplt.xlabel('Classes')\\nplt.ylabel('Variance of L1-norm')\\nplt.title('Variance of L1-norm Among Classes')\\nplt.xticks(range(len(variance_list)), [f'Class_{i}' for i in range(len(variance_list))])\\nplt.grid(True)\\nplt.show()\\n\""},"metadata":{}}]},{"cell_type":"code","source":"#import losses\n\n#from datasets.cifar100 import *\n\n#from train.train import *\n#from train.validate import *\n\n#from models.net import *\n\n#from losses.loss import *\n\n#from utils.config import *\n#from utils.plot import *\n#from utils.common import make_imb_data, save_checkpoint, hms_string\n\n#from utils.logger import logger\n\n#args = parse_args()\n\nfrom argparse import Namespace\n\n# Replace the command below with your actual values\nargs=Namespace(network='resnet32', epochs=200, batch_size=128, update_epoch=1,\n               lr=0.1, lr_decay=0.01, momentum=0.9, wd=0.0002, nesterov=False,\n               scheduler='warmup', warmup=5, aug_prob=0.5, cutout=False, cmo=False,\n               posthoc_la=False, cuda=True, aug_type='none', sim_type='none', max_d=30,\n               num_test=10, accept_rate=0.6, verbose=False, use_norm=False,\n               out='/kaggle/working/log3',\n               data_dir='~/dataset/', workers=4, seed='None',\n               gpu='0', dataset='cifar100', num_max=500, imb_ratio=100,\n               loss_fn='ce_drw', num_experts=3, ride_distill=False)\n\nreproducibility(args.seed)\nargs = dataset_argument(args)\nargs.logger = logger(args)\n\nbest_acc = 0 # best test accuracy\ncurr_state_ac=[]\nlabel_ac=[]\nvariance_list1=[]\n\ndef main():\n    global best_acc,curr_state_ac,label_ac,variance_list1\n\n    try:\n        assert args.num_max <= 50000. / args.num_class\n    except AssertionError:\n        args.num_max = int(50000 / args.num_class)\n    \n    print(f'==> Preparing imbalanced CIFAR-100')\n    # N_SAMPLES_PER_CLASS = make_imb_data(args.num_max, args.num_class, args.imb_ratio)\n    trainset, testset = get_cifar100(os.path.join(args.data_dir, 'cifar100/'), args)\n    N_SAMPLES_PER_CLASS = trainset.img_num_list\n        \n    trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, drop_last= args.loss_fn == 'ncl', pin_memory=True, sampler=None)\n    testloader = data.DataLoader(testset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True) \n    \n    if args.cmo:\n        cls_num_list = N_SAMPLES_PER_CLASS\n        cls_weight = 1.0 / (np.array(cls_num_list))\n        cls_weight = cls_weight / np.sum(cls_weight) * len(cls_num_list)\n        labels = trainloader.dataset.targets\n        samples_weight = np.array([cls_weight[t] for t in labels])\n        samples_weight = torch.from_numpy(samples_weight)\n        samples_weight = samples_weight.double()\n        print(\"samples_weight\", samples_weight)\n        sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(labels), replacement=True)\n        weighted_trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, sampler=sampler)\n    else:\n        weighted_trainloader = None\n    \n\n    # Model\n    print (\"==> creating {}\".format(args.network))\n    model = get_model(args, N_SAMPLES_PER_CLASS)\n    train_criterion = get_loss(args, N_SAMPLES_PER_CLASS)\n    criterion = nn.CrossEntropyLoss() # For test, validation \n    optimizer = get_optimizer(args, model)\n    scheduler = get_scheduler(args,optimizer)\n\n    teacher = load_model(args)\n\n\n    train = get_train_fn(args)\n    validate = get_valid_fn(args)\n    update_score = get_update_score_fn(args)\n    \n    start_time = time.time()\n    \n    test_accs = []\n    for epoch in range(args.epochs):\n        \n        lr = adjust_learning_rate(optimizer, epoch, scheduler, args)\n        if args.cuda:\n            if epoch % args.update_epoch == 0:\n                curr_state_ac, label_ac = update_score(trainloader, model, N_SAMPLES_PER_CLASS, posthoc_la = args.posthoc_la, num_test = args.num_test, accept_rate = args.accept_rate)\n                print(curr_state_ac)\n                \n            if args.verbose:\n                if epoch == 0:\n                    maps = np.zeros((args.epochs,args.num_class))\n                maps = plot_score_epoch(curr_state_ac,label_ac, epoch, maps, args.out)\n        train_loss = train(args, trainloader, model, optimizer,train_criterion, epoch, weighted_trainloader, teacher) \n\n\n        test_loss, test_acc, test_cls = validate(args, testloader, model, criterion, N_SAMPLES_PER_CLASS,  num_class=args.num_class, mode='test Valid')\n\n        if best_acc <= test_acc:\n            best_acc = test_acc\n            many_best = test_cls[0]\n            med_best = test_cls[1]\n            few_best = test_cls[2]\n            # Save models\n            save_checkpoint({\n                'epoch': epoch + 1,\n                'state_dict': model['model'].state_dict() if args.loss_fn == 'ncl' else model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, epoch + 1, args.out)\n        test_accs.append(test_acc)\n        \n        model_weights = model.state_dict()\n        classwise_l1_norms = {}\n        for class_label in range(args.num_class):\n            class_params = {\n            'linear.weight': model_weights['linear.weight'][class_label],\n            'linear.bias': model_weights['linear.bias'][class_label]\n            }\n            class_l1_norm = sum(torch.abs(param).sum() for param in class_params.values())\n            classwise_l1_norms[f'Class_{class_label}'] = class_l1_norm\n        l1_norm_values = [tensor.item() for tensor in classwise_l1_norms.values()]\n        variance_l1_norm = np.var(l1_norm_values)\n        variance_list1.append(np.sqrt(variance_l1_norm))\n        print(np.sqrt(variance_l1_norm))\n        \n        args.logger(f'Epoch: [{epoch+1} | {args.epochs}]', level=1)\n        if args.cuda:\n            args.logger(f'Max_state: {int(torch.max(curr_state_ac))}, min_state: {int(torch.min(curr_state_ac))}', level=2)\n        args.logger(f'[Train]\\tLoss:\\t{train_loss:.4f}', level=2)\n        args.logger(f'[Test ]\\tLoss:\\t{test_loss:.4f}\\tAcc:\\t{test_acc:.4f}', level=2)\n        args.logger(f'[Stats]\\tMany:\\t{test_cls[0]:.4f}\\tMedium:\\t{test_cls[1]:.4f}\\tFew:\\t{test_cls[2]:.4f}', level=2)\n        args.logger(f'[Best ]\\tAcc:\\t{np.max(test_accs):.4f}\\tMany:\\t{100*many_best:.4f}\\tMedium:\\t{100*med_best:.4f}\\tFew:\\t{100*few_best:.4f}', level=2)\n        args.logger(f'[Param]\\tLR:\\t{lr:.8f}', level=2)\n    \n    end_time = time.time()\n\n    # Print the final results\n    args.logger(f'Final performance...', level=1)\n    args.logger(f'best bAcc (test):\\t{np.max(test_accs)}', level=2)\n    args.logger(f'best statistics:\\tMany:\\t{many_best}\\tMed:\\t{med_best}\\tFew:\\t{few_best}', level=2)\n    args.logger(f'Training Time: {hms_string(end_time - start_time)}', level=1)\n\n    \n    if args.verbose:\n        args.logger.map_save(maps)\n\nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-24T13:42:34.426188Z","iopub.execute_input":"2024-01-24T13:42:34.426571Z","iopub.status.idle":"2024-01-24T14:06:36.393002Z","shell.execute_reply.started":"2024-01-24T13:42:34.426538Z","shell.execute_reply":"2024-01-24T14:06:36.392127Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"---> ---cifar100---\n---> ---cifar100---\n---> Argument\n---> Argument\n    > network     : resnet32\n    > network     : resnet32\n    > epochs      : 200\n    > epochs      : 200\n    > batch_size  : 128\n    > batch_size  : 128\n    > update_epoch: 1\n    > update_epoch: 1\n    > lr          : 0.1\n    > lr          : 0.1\n    > lr_decay    : 0.01\n    > lr_decay    : 0.01\n    > momentum    : 0.9\n    > momentum    : 0.9\n    > wd          : 0.0002\n    > wd          : 0.0002\n    > nesterov    : False\n    > nesterov    : False\n    > scheduler   : warmup\n    > scheduler   : warmup\n    > warmup      : 5\n    > warmup      : 5\n    > aug_prob    : 0.5\n    > aug_prob    : 0.5\n    > cutout      : False\n    > cutout      : False\n    > cmo         : False\n    > cmo         : False\n    > posthoc_la  : False\n    > posthoc_la  : False\n    > cuda        : True\n    > cuda        : True\n    > aug_type    : none\n    > aug_type    : none\n    > sim_type    : none\n    > sim_type    : none\n    > max_d       : 30\n    > max_d       : 30\n    > num_test    : 10\n    > num_test    : 10\n    > accept_rate : 0.6\n    > accept_rate : 0.6\n    > verbose     : False\n    > verbose     : False\n    > use_norm    : False\n    > use_norm    : False\n    > out         : /kaggle/working/log3\n    > out         : /kaggle/working/log3\n    > data_dir    : ~/dataset/\n    > data_dir    : ~/dataset/\n    > workers     : 4\n    > workers     : 4\n    > seed        : None\n    > seed        : None\n    > gpu         : 0\n    > gpu         : 0\n    > dataset     : cifar100\n    > dataset     : cifar100\n    > num_max     : 500\n    > num_max     : 500\n    > imb_ratio   : 100\n    > imb_ratio   : 100\n    > loss_fn     : ce_drw\n    > loss_fn     : ce_drw\n    > num_experts : 3\n    > num_experts : 3\n    > ride_distill: False\n    > ride_distill: False\n    > num_class   : 100\n    > num_class   : 100\n","output_type":"stream"},{"name":"stdout","text":"==> Preparing imbalanced CIFAR-100\nFiles already downloaded and verified\nMagnitude set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nOperation set = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)\nFiles already downloaded and verified\n#Train: 10847, #Test: 10000\n==> creating resnet32\n    Total params: 0.47M\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"Max state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [1 | 200]\n---> Epoch: [1 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t4.1062\n    > [Train]\tLoss:\t4.1062\n    > [Test ]\tLoss:\t5.2413\tAcc:\t4.9800\n    > [Test ]\tLoss:\t5.2413\tAcc:\t4.9800\n    > [Stats]\tMany:\t0.1423\tMedium:\t0.0000\tFew:\t0.0000\n    > [Stats]\tMany:\t0.1423\tMedium:\t0.0000\tFew:\t0.0000\n    > [Best ]\tAcc:\t4.9800\tMany:\t14.2286\tMedium:\t0.0000\tFew:\t0.0000\n    > [Best ]\tAcc:\t4.9800\tMany:\t14.2286\tMedium:\t0.0000\tFew:\t0.0000\n    > [Param]\tLR:\t0.02000000\n    > [Param]\tLR:\t0.02000000\n","output_type":"stream"},{"name":"stdout","text":"0.8923784099248029\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [2 | 200]\n---> Epoch: [2 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t3.5668\n    > [Train]\tLoss:\t3.5668\n    > [Test ]\tLoss:\t5.0978\tAcc:\t7.0100\n    > [Test ]\tLoss:\t5.0978\tAcc:\t7.0100\n    > [Stats]\tMany:\t0.2000\tMedium:\t0.0003\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2000\tMedium:\t0.0003\tFew:\t0.0000\n    > [Best ]\tAcc:\t7.0100\tMany:\t20.0000\tMedium:\t0.0286\tFew:\t0.0000\n    > [Best ]\tAcc:\t7.0100\tMany:\t20.0000\tMedium:\t0.0286\tFew:\t0.0000\n    > [Param]\tLR:\t0.04000000\n    > [Param]\tLR:\t0.04000000\n","output_type":"stream"},{"name":"stdout","text":"0.8817247144871591\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [3 | 200]\n---> Epoch: [3 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t3.4193\n    > [Train]\tLoss:\t3.4193\n    > [Test ]\tLoss:\t4.9819\tAcc:\t8.0500\n    > [Test ]\tLoss:\t4.9819\tAcc:\t8.0500\n    > [Stats]\tMany:\t0.1991\tMedium:\t0.0309\tFew:\t0.0000\n    > [Stats]\tMany:\t0.1991\tMedium:\t0.0309\tFew:\t0.0000\n    > [Best ]\tAcc:\t8.0500\tMany:\t19.9143\tMedium:\t3.0857\tFew:\t0.0000\n    > [Best ]\tAcc:\t8.0500\tMany:\t19.9143\tMedium:\t3.0857\tFew:\t0.0000\n    > [Param]\tLR:\t0.06000000\n    > [Param]\tLR:\t0.06000000\n","output_type":"stream"},{"name":"stdout","text":"0.9028855097774603\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [4 | 200]\n---> Epoch: [4 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t3.1903\n    > [Train]\tLoss:\t3.1903\n    > [Test ]\tLoss:\t4.8020\tAcc:\t9.5700\n    > [Test ]\tLoss:\t4.8020\tAcc:\t9.5700\n    > [Stats]\tMany:\t0.2674\tMedium:\t0.0060\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2674\tMedium:\t0.0060\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.5700\tMany:\t26.7429\tMedium:\t0.6000\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.5700\tMany:\t26.7429\tMedium:\t0.6000\tFew:\t0.0000\n    > [Param]\tLR:\t0.08000000\n    > [Param]\tLR:\t0.08000000\n","output_type":"stream"},{"name":"stdout","text":"0.9765670179234432\nMax state: 1 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [5 | 200]\n---> Epoch: [5 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t3.0276\n    > [Train]\tLoss:\t3.0276\n    > [Test ]\tLoss:\t4.8259\tAcc:\t9.8400\n    > [Test ]\tLoss:\t4.8259\tAcc:\t9.8400\n    > [Stats]\tMany:\t0.2563\tMedium:\t0.0249\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2563\tMedium:\t0.0249\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8400\tMany:\t25.6286\tMedium:\t2.4857\tFew:\t0.0000\n    > [Best ]\tAcc:\t9.8400\tMany:\t25.6286\tMedium:\t2.4857\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.1367367399896227\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [6 | 200]\n---> Epoch: [6 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t2.8467\n    > [Train]\tLoss:\t2.8467\n    > [Test ]\tLoss:\t4.3533\tAcc:\t13.1000\n    > [Test ]\tLoss:\t4.3533\tAcc:\t13.1000\n    > [Stats]\tMany:\t0.3026\tMedium:\t0.0717\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3026\tMedium:\t0.0717\tFew:\t0.0000\n    > [Best ]\tAcc:\t13.1000\tMany:\t30.2571\tMedium:\t7.1714\tFew:\t0.0000\n    > [Best ]\tAcc:\t13.1000\tMany:\t30.2571\tMedium:\t7.1714\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.3441821466663746\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [7 | 200]\n---> Epoch: [7 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t2.7059\n    > [Train]\tLoss:\t2.7059\n    > [Test ]\tLoss:\t4.6219\tAcc:\t12.0700\n    > [Test ]\tLoss:\t4.6219\tAcc:\t12.0700\n    > [Stats]\tMany:\t0.2940\tMedium:\t0.0509\tFew:\t0.0000\n    > [Stats]\tMany:\t0.2940\tMedium:\t0.0509\tFew:\t0.0000\n    > [Best ]\tAcc:\t13.1000\tMany:\t30.2571\tMedium:\t7.1714\tFew:\t0.0000\n    > [Best ]\tAcc:\t13.1000\tMany:\t30.2571\tMedium:\t7.1714\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.5635868629386331\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [8 | 200]\n---> Epoch: [8 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t2.5611\n    > [Train]\tLoss:\t2.5611\n    > [Test ]\tLoss:\t4.5969\tAcc:\t12.2000\n    > [Test ]\tLoss:\t4.5969\tAcc:\t12.2000\n    > [Stats]\tMany:\t0.2814\tMedium:\t0.0669\tFew:\t0.0003\n    > [Stats]\tMany:\t0.2814\tMedium:\t0.0669\tFew:\t0.0003\n    > [Best ]\tAcc:\t13.1000\tMany:\t30.2571\tMedium:\t7.1714\tFew:\t0.0000\n    > [Best ]\tAcc:\t13.1000\tMany:\t30.2571\tMedium:\t7.1714\tFew:\t0.0000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.7813106168966852\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [9 | 200]\n---> Epoch: [9 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t2.4441\n    > [Train]\tLoss:\t2.4441\n    > [Test ]\tLoss:\t4.3620\tAcc:\t15.4400\n    > [Test ]\tLoss:\t4.3620\tAcc:\t15.4400\n    > [Stats]\tMany:\t0.3566\tMedium:\t0.0814\tFew:\t0.0037\n    > [Stats]\tMany:\t0.3566\tMedium:\t0.0814\tFew:\t0.0037\n    > [Best ]\tAcc:\t15.4400\tMany:\t35.6571\tMedium:\t8.1429\tFew:\t0.3667\n    > [Best ]\tAcc:\t15.4400\tMany:\t35.6571\tMedium:\t8.1429\tFew:\t0.3667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"1.9177482650882303\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [10 | 200]\n---> Epoch: [10 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t2.3048\n    > [Train]\tLoss:\t2.3048\n    > [Test ]\tLoss:\t4.2598\tAcc:\t15.2200\n    > [Test ]\tLoss:\t4.2598\tAcc:\t15.2200\n    > [Stats]\tMany:\t0.3357\tMedium:\t0.0983\tFew:\t0.0010\n    > [Stats]\tMany:\t0.3357\tMedium:\t0.0983\tFew:\t0.0010\n    > [Best ]\tAcc:\t15.4400\tMany:\t35.6571\tMedium:\t8.1429\tFew:\t0.3667\n    > [Best ]\tAcc:\t15.4400\tMany:\t35.6571\tMedium:\t8.1429\tFew:\t0.3667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.10410427436533\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [11 | 200]\n---> Epoch: [11 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t2.2613\n    > [Train]\tLoss:\t2.2613\n    > [Test ]\tLoss:\t4.0787\tAcc:\t17.5200\n    > [Test ]\tLoss:\t4.0787\tAcc:\t17.5200\n    > [Stats]\tMany:\t0.4063\tMedium:\t0.0914\tFew:\t0.0033\n    > [Stats]\tMany:\t0.4063\tMedium:\t0.0914\tFew:\t0.0033\n    > [Best ]\tAcc:\t17.5200\tMany:\t40.6286\tMedium:\t9.1429\tFew:\t0.3333\n    > [Best ]\tAcc:\t17.5200\tMany:\t40.6286\tMedium:\t9.1429\tFew:\t0.3333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.1860082671941723\nMax state: 2 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [12 | 200]\n---> Epoch: [12 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t2.1452\n    > [Train]\tLoss:\t2.1452\n    > [Test ]\tLoss:\t4.2029\tAcc:\t16.7000\n    > [Test ]\tLoss:\t4.2029\tAcc:\t16.7000\n    > [Stats]\tMany:\t0.3566\tMedium:\t0.1206\tFew:\t0.0000\n    > [Stats]\tMany:\t0.3566\tMedium:\t0.1206\tFew:\t0.0000\n    > [Best ]\tAcc:\t17.5200\tMany:\t40.6286\tMedium:\t9.1429\tFew:\t0.3333\n    > [Best ]\tAcc:\t17.5200\tMany:\t40.6286\tMedium:\t9.1429\tFew:\t0.3333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.315435180849101\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [13 | 200]\n---> Epoch: [13 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t2.0939\n    > [Train]\tLoss:\t2.0939\n    > [Test ]\tLoss:\t4.1004\tAcc:\t19.3400\n    > [Test ]\tLoss:\t4.1004\tAcc:\t19.3400\n    > [Stats]\tMany:\t0.4106\tMedium:\t0.1406\tFew:\t0.0017\n    > [Stats]\tMany:\t0.4106\tMedium:\t0.1406\tFew:\t0.0017\n    > [Best ]\tAcc:\t19.3400\tMany:\t41.0571\tMedium:\t14.0571\tFew:\t0.1667\n    > [Best ]\tAcc:\t19.3400\tMany:\t41.0571\tMedium:\t14.0571\tFew:\t0.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.389441395379383\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [14 | 200]\n---> Epoch: [14 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t2.0417\n    > [Train]\tLoss:\t2.0417\n    > [Test ]\tLoss:\t3.9703\tAcc:\t19.6100\n    > [Test ]\tLoss:\t3.9703\tAcc:\t19.6100\n    > [Stats]\tMany:\t0.4246\tMedium:\t0.1331\tFew:\t0.0030\n    > [Stats]\tMany:\t0.4246\tMedium:\t0.1331\tFew:\t0.0030\n    > [Best ]\tAcc:\t19.6100\tMany:\t42.4571\tMedium:\t13.3143\tFew:\t0.3000\n    > [Best ]\tAcc:\t19.6100\tMany:\t42.4571\tMedium:\t13.3143\tFew:\t0.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4766554162600576\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [15 | 200]\n---> Epoch: [15 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.9607\n    > [Train]\tLoss:\t1.9607\n    > [Test ]\tLoss:\t4.7381\tAcc:\t17.1700\n    > [Test ]\tLoss:\t4.7381\tAcc:\t17.1700\n    > [Stats]\tMany:\t0.3749\tMedium:\t0.1134\tFew:\t0.0027\n    > [Stats]\tMany:\t0.3749\tMedium:\t0.1134\tFew:\t0.0027\n    > [Best ]\tAcc:\t19.6100\tMany:\t42.4571\tMedium:\t13.3143\tFew:\t0.3000\n    > [Best ]\tAcc:\t19.6100\tMany:\t42.4571\tMedium:\t13.3143\tFew:\t0.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.578655488957003\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [16 | 200]\n---> Epoch: [16 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t1.9035\n    > [Train]\tLoss:\t1.9035\n    > [Test ]\tLoss:\t3.8232\tAcc:\t20.5200\n    > [Test ]\tLoss:\t3.8232\tAcc:\t20.5200\n    > [Stats]\tMany:\t0.4349\tMedium:\t0.1480\tFew:\t0.0040\n    > [Stats]\tMany:\t0.4349\tMedium:\t0.1480\tFew:\t0.0040\n    > [Best ]\tAcc:\t20.5200\tMany:\t43.4857\tMedium:\t14.8000\tFew:\t0.4000\n    > [Best ]\tAcc:\t20.5200\tMany:\t43.4857\tMedium:\t14.8000\tFew:\t0.4000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6118321790271475\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [17 | 200]\n---> Epoch: [17 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.8642\n    > [Train]\tLoss:\t1.8642\n    > [Test ]\tLoss:\t3.9841\tAcc:\t21.7900\n    > [Test ]\tLoss:\t3.9841\tAcc:\t21.7900\n    > [Stats]\tMany:\t0.4826\tMedium:\t0.1380\tFew:\t0.0023\n    > [Stats]\tMany:\t0.4826\tMedium:\t0.1380\tFew:\t0.0023\n    > [Best ]\tAcc:\t21.7900\tMany:\t48.2571\tMedium:\t13.8000\tFew:\t0.2333\n    > [Best ]\tAcc:\t21.7900\tMany:\t48.2571\tMedium:\t13.8000\tFew:\t0.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6723682893055027\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [18 | 200]\n---> Epoch: [18 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.8464\n    > [Train]\tLoss:\t1.8464\n    > [Test ]\tLoss:\t3.7433\tAcc:\t22.1300\n    > [Test ]\tLoss:\t3.7433\tAcc:\t22.1300\n    > [Stats]\tMany:\t0.4666\tMedium:\t0.1620\tFew:\t0.0043\n    > [Stats]\tMany:\t0.4666\tMedium:\t0.1620\tFew:\t0.0043\n    > [Best ]\tAcc:\t22.1300\tMany:\t46.6571\tMedium:\t16.2000\tFew:\t0.4333\n    > [Best ]\tAcc:\t22.1300\tMany:\t46.6571\tMedium:\t16.2000\tFew:\t0.4333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.7101721380406727\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [19 | 200]\n---> Epoch: [19 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.7455\n    > [Train]\tLoss:\t1.7455\n    > [Test ]\tLoss:\t4.4503\tAcc:\t18.6100\n    > [Test ]\tLoss:\t4.4503\tAcc:\t18.6100\n    > [Stats]\tMany:\t0.3854\tMedium:\t0.1446\tFew:\t0.0020\n    > [Stats]\tMany:\t0.3854\tMedium:\t0.1446\tFew:\t0.0020\n    > [Best ]\tAcc:\t22.1300\tMany:\t46.6571\tMedium:\t16.2000\tFew:\t0.4333\n    > [Best ]\tAcc:\t22.1300\tMany:\t46.6571\tMedium:\t16.2000\tFew:\t0.4333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.786327271239974\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [20 | 200]\n---> Epoch: [20 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.6998\n    > [Train]\tLoss:\t1.6998\n    > [Test ]\tLoss:\t3.5513\tAcc:\t25.1800\n    > [Test ]\tLoss:\t3.5513\tAcc:\t25.1800\n    > [Stats]\tMany:\t0.4886\tMedium:\t0.2260\tFew:\t0.0057\n    > [Stats]\tMany:\t0.4886\tMedium:\t0.2260\tFew:\t0.0057\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.830528860196607\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [21 | 200]\n---> Epoch: [21 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t1.6851\n    > [Train]\tLoss:\t1.6851\n    > [Test ]\tLoss:\t3.9526\tAcc:\t22.3700\n    > [Test ]\tLoss:\t3.9526\tAcc:\t22.3700\n    > [Stats]\tMany:\t0.4306\tMedium:\t0.2000\tFew:\t0.0100\n    > [Stats]\tMany:\t0.4306\tMedium:\t0.2000\tFew:\t0.0100\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.8606370510791725\nMax state: 1 // Min state: 0\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [22 | 200]\n---> Epoch: [22 | 200]\n    > Max_state: 1, min_state: 0\n    > Max_state: 1, min_state: 0\n    > [Train]\tLoss:\t1.5899\n    > [Train]\tLoss:\t1.5899\n    > [Test ]\tLoss:\t3.7032\tAcc:\t24.8800\n    > [Test ]\tLoss:\t3.7032\tAcc:\t24.8800\n    > [Stats]\tMany:\t0.4934\tMedium:\t0.1980\tFew:\t0.0227\n    > [Stats]\tMany:\t0.4934\tMedium:\t0.1980\tFew:\t0.0227\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.9209154897947096\nMax state: 2 // Min state: 0\ntensor([1., 1., 1.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [23 | 200]\n---> Epoch: [23 | 200]\n    > Max_state: 2, min_state: 0\n    > Max_state: 2, min_state: 0\n    > [Train]\tLoss:\t1.6399\n    > [Train]\tLoss:\t1.6399\n    > [Test ]\tLoss:\t3.7900\tAcc:\t25.0900\n    > [Test ]\tLoss:\t3.7900\tAcc:\t25.0900\n    > [Stats]\tMany:\t0.4814\tMedium:\t0.2269\tFew:\t0.0100\n    > [Stats]\tMany:\t0.4814\tMedium:\t0.2269\tFew:\t0.0100\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Best ]\tAcc:\t25.1800\tMany:\t48.8571\tMedium:\t22.6000\tFew:\t0.5667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.9481347197469434\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [24 | 200]\n---> Epoch: [24 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.6166\n    > [Train]\tLoss:\t1.6166\n    > [Test ]\tLoss:\t3.5557\tAcc:\t26.5800\n    > [Test ]\tLoss:\t3.5557\tAcc:\t26.5800\n    > [Stats]\tMany:\t0.5157\tMedium:\t0.2326\tFew:\t0.0130\n    > [Stats]\tMany:\t0.5157\tMedium:\t0.2326\tFew:\t0.0130\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.94164288577201\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [25 | 200]\n---> Epoch: [25 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.5582\n    > [Train]\tLoss:\t1.5582\n    > [Test ]\tLoss:\t4.1447\tAcc:\t21.4300\n    > [Test ]\tLoss:\t4.1447\tAcc:\t21.4300\n    > [Stats]\tMany:\t0.4754\tMedium:\t0.1334\tFew:\t0.0040\n    > [Stats]\tMany:\t0.4754\tMedium:\t0.1334\tFew:\t0.0040\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.998507508617708\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [26 | 200]\n---> Epoch: [26 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t1.5015\n    > [Train]\tLoss:\t1.5015\n    > [Test ]\tLoss:\t3.9430\tAcc:\t24.8600\n    > [Test ]\tLoss:\t3.9430\tAcc:\t24.8600\n    > [Stats]\tMany:\t0.5286\tMedium:\t0.1766\tFew:\t0.0060\n    > [Stats]\tMany:\t0.5286\tMedium:\t0.1766\tFew:\t0.0060\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.021649630510138\nMax state: 4 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [27 | 200]\n---> Epoch: [27 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t1.5265\n    > [Train]\tLoss:\t1.5265\n    > [Test ]\tLoss:\t3.7279\tAcc:\t23.9800\n    > [Test ]\tLoss:\t3.7279\tAcc:\t23.9800\n    > [Stats]\tMany:\t0.4831\tMedium:\t0.1940\tFew:\t0.0093\n    > [Stats]\tMany:\t0.4831\tMedium:\t0.1940\tFew:\t0.0093\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0439578085009398\nMax state: 5 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [28 | 200]\n---> Epoch: [28 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.4707\n    > [Train]\tLoss:\t1.4707\n    > [Test ]\tLoss:\t3.8258\tAcc:\t25.9200\n    > [Test ]\tLoss:\t3.8258\tAcc:\t25.9200\n    > [Stats]\tMany:\t0.4874\tMedium:\t0.2286\tFew:\t0.0287\n    > [Stats]\tMany:\t0.4874\tMedium:\t0.2286\tFew:\t0.0287\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.091652436761625\nMax state: 4 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [29 | 200]\n---> Epoch: [29 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t1.4499\n    > [Train]\tLoss:\t1.4499\n    > [Test ]\tLoss:\t3.7344\tAcc:\t25.2600\n    > [Test ]\tLoss:\t3.7344\tAcc:\t25.2600\n    > [Stats]\tMany:\t0.5080\tMedium:\t0.1997\tFew:\t0.0163\n    > [Stats]\tMany:\t0.5080\tMedium:\t0.1997\tFew:\t0.0163\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0853047611280906\nMax state: 3 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [30 | 200]\n---> Epoch: [30 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.4640\n    > [Train]\tLoss:\t1.4640\n    > [Test ]\tLoss:\t3.9437\tAcc:\t25.4900\n    > [Test ]\tLoss:\t3.9437\tAcc:\t25.4900\n    > [Stats]\tMany:\t0.5203\tMedium:\t0.2046\tFew:\t0.0040\n    > [Stats]\tMany:\t0.5203\tMedium:\t0.2046\tFew:\t0.0040\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Best ]\tAcc:\t26.5800\tMany:\t51.5714\tMedium:\t23.2571\tFew:\t1.3000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0777886047513667\nMax state: 3 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [31 | 200]\n---> Epoch: [31 | 200]\n    > Max_state: 3, min_state: 0\n    > Max_state: 3, min_state: 0\n    > [Train]\tLoss:\t1.4445\n    > [Train]\tLoss:\t1.4445\n    > [Test ]\tLoss:\t3.6920\tAcc:\t27.9600\n    > [Test ]\tLoss:\t3.6920\tAcc:\t27.9600\n    > [Stats]\tMany:\t0.5563\tMedium:\t0.2326\tFew:\t0.0117\n    > [Stats]\tMany:\t0.5563\tMedium:\t0.2326\tFew:\t0.0117\n    > [Best ]\tAcc:\t27.9600\tMany:\t55.6286\tMedium:\t23.2571\tFew:\t1.1667\n    > [Best ]\tAcc:\t27.9600\tMany:\t55.6286\tMedium:\t23.2571\tFew:\t1.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.087343950323977\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [32 | 200]\n---> Epoch: [32 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t1.3573\n    > [Train]\tLoss:\t1.3573\n    > [Test ]\tLoss:\t3.5035\tAcc:\t29.0500\n    > [Test ]\tLoss:\t3.5035\tAcc:\t29.0500\n    > [Stats]\tMany:\t0.5440\tMedium:\t0.2671\tFew:\t0.0220\n    > [Stats]\tMany:\t0.5440\tMedium:\t0.2671\tFew:\t0.0220\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1293932854545305\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [33 | 200]\n---> Epoch: [33 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.3877\n    > [Train]\tLoss:\t1.3877\n    > [Test ]\tLoss:\t3.5798\tAcc:\t27.2900\n    > [Test ]\tLoss:\t3.5798\tAcc:\t27.2900\n    > [Stats]\tMany:\t0.5309\tMedium:\t0.2297\tFew:\t0.0223\n    > [Stats]\tMany:\t0.5309\tMedium:\t0.2297\tFew:\t0.0223\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1331303645507367\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [34 | 200]\n---> Epoch: [34 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.3543\n    > [Train]\tLoss:\t1.3543\n    > [Test ]\tLoss:\t4.0797\tAcc:\t23.7000\n    > [Test ]\tLoss:\t4.0797\tAcc:\t23.7000\n    > [Stats]\tMany:\t0.4806\tMedium:\t0.1863\tFew:\t0.0120\n    > [Stats]\tMany:\t0.4806\tMedium:\t0.1863\tFew:\t0.0120\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1016922129153723\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [35 | 200]\n---> Epoch: [35 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.3221\n    > [Train]\tLoss:\t1.3221\n    > [Test ]\tLoss:\t3.7656\tAcc:\t26.7500\n    > [Test ]\tLoss:\t3.7656\tAcc:\t26.7500\n    > [Stats]\tMany:\t0.5331\tMedium:\t0.2117\tFew:\t0.0227\n    > [Stats]\tMany:\t0.5331\tMedium:\t0.2117\tFew:\t0.0227\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1242217506638945\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [36 | 200]\n---> Epoch: [36 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.3403\n    > [Train]\tLoss:\t1.3403\n    > [Test ]\tLoss:\t3.6944\tAcc:\t25.5200\n    > [Test ]\tLoss:\t3.6944\tAcc:\t25.5200\n    > [Stats]\tMany:\t0.5343\tMedium:\t0.1751\tFew:\t0.0230\n    > [Stats]\tMany:\t0.5343\tMedium:\t0.1751\tFew:\t0.0230\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Best ]\tAcc:\t29.0500\tMany:\t54.4000\tMedium:\t26.7143\tFew:\t2.2000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1014695587993204\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [37 | 200]\n---> Epoch: [37 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.2574\n    > [Train]\tLoss:\t1.2574\n    > [Test ]\tLoss:\t3.5689\tAcc:\t29.4100\n    > [Test ]\tLoss:\t3.5689\tAcc:\t29.4100\n    > [Stats]\tMany:\t0.5217\tMedium:\t0.3000\tFew:\t0.0217\n    > [Stats]\tMany:\t0.5217\tMedium:\t0.3000\tFew:\t0.0217\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1184982307667948\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [38 | 200]\n---> Epoch: [38 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t1.3956\n    > [Train]\tLoss:\t1.3956\n    > [Test ]\tLoss:\t4.1323\tAcc:\t26.7100\n    > [Test ]\tLoss:\t4.1323\tAcc:\t26.7100\n    > [Stats]\tMany:\t0.4526\tMedium:\t0.2937\tFew:\t0.0197\n    > [Stats]\tMany:\t0.4526\tMedium:\t0.2937\tFew:\t0.0197\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0560249711976155\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [39 | 200]\n---> Epoch: [39 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.2007\n    > [Train]\tLoss:\t1.2007\n    > [Test ]\tLoss:\t3.9977\tAcc:\t26.3400\n    > [Test ]\tLoss:\t3.9977\tAcc:\t26.3400\n    > [Stats]\tMany:\t0.5183\tMedium:\t0.2157\tFew:\t0.0217\n    > [Stats]\tMany:\t0.5183\tMedium:\t0.2157\tFew:\t0.0217\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1116899269399076\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [40 | 200]\n---> Epoch: [40 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.2320\n    > [Train]\tLoss:\t1.2320\n    > [Test ]\tLoss:\t3.8302\tAcc:\t26.5900\n    > [Test ]\tLoss:\t3.8302\tAcc:\t26.5900\n    > [Stats]\tMany:\t0.5151\tMedium:\t0.2254\tFew:\t0.0223\n    > [Stats]\tMany:\t0.5151\tMedium:\t0.2254\tFew:\t0.0223\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.107933389742803\nMax state: 6 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [41 | 200]\n---> Epoch: [41 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.2326\n    > [Train]\tLoss:\t1.2326\n    > [Test ]\tLoss:\t3.8000\tAcc:\t27.8500\n    > [Test ]\tLoss:\t3.8000\tAcc:\t27.8500\n    > [Stats]\tMany:\t0.5369\tMedium:\t0.2460\tFew:\t0.0150\n    > [Stats]\tMany:\t0.5369\tMedium:\t0.2460\tFew:\t0.0150\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Best ]\tAcc:\t29.4100\tMany:\t52.1714\tMedium:\t30.0000\tFew:\t2.1667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.101648773778194\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [42 | 200]\n---> Epoch: [42 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.1927\n    > [Train]\tLoss:\t1.1927\n    > [Test ]\tLoss:\t3.5024\tAcc:\t31.7400\n    > [Test ]\tLoss:\t3.5024\tAcc:\t31.7400\n    > [Stats]\tMany:\t0.5743\tMedium:\t0.3049\tFew:\t0.0323\n    > [Stats]\tMany:\t0.5743\tMedium:\t0.3049\tFew:\t0.0323\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.1212161765741695\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [43 | 200]\n---> Epoch: [43 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.2715\n    > [Train]\tLoss:\t1.2715\n    > [Test ]\tLoss:\t4.7808\tAcc:\t22.0400\n    > [Test ]\tLoss:\t4.7808\tAcc:\t22.0400\n    > [Stats]\tMany:\t0.4497\tMedium:\t0.1580\tFew:\t0.0257\n    > [Stats]\tMany:\t0.4497\tMedium:\t0.1580\tFew:\t0.0257\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0756947042050067\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [44 | 200]\n---> Epoch: [44 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.1364\n    > [Train]\tLoss:\t1.1364\n    > [Test ]\tLoss:\t3.9417\tAcc:\t27.4700\n    > [Test ]\tLoss:\t3.9417\tAcc:\t27.4700\n    > [Stats]\tMany:\t0.5389\tMedium:\t0.2326\tFew:\t0.0157\n    > [Stats]\tMany:\t0.5389\tMedium:\t0.2326\tFew:\t0.0157\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.101274546982778\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [45 | 200]\n---> Epoch: [45 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.2745\n    > [Train]\tLoss:\t1.2745\n    > [Test ]\tLoss:\t3.7384\tAcc:\t29.4200\n    > [Test ]\tLoss:\t3.7384\tAcc:\t29.4200\n    > [Stats]\tMany:\t0.5617\tMedium:\t0.2483\tFew:\t0.0357\n    > [Stats]\tMany:\t0.5617\tMedium:\t0.2483\tFew:\t0.0357\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0465043047680034\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [46 | 200]\n---> Epoch: [46 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t1.1616\n    > [Train]\tLoss:\t1.1616\n    > [Test ]\tLoss:\t3.7655\tAcc:\t29.5500\n    > [Test ]\tLoss:\t3.7655\tAcc:\t29.5500\n    > [Stats]\tMany:\t0.5126\tMedium:\t0.3043\tFew:\t0.0320\n    > [Stats]\tMany:\t0.5126\tMedium:\t0.3043\tFew:\t0.0320\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.084677997934947\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [47 | 200]\n---> Epoch: [47 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.2471\n    > [Train]\tLoss:\t1.2471\n    > [Test ]\tLoss:\t3.5948\tAcc:\t27.7600\n    > [Test ]\tLoss:\t3.5948\tAcc:\t27.7600\n    > [Stats]\tMany:\t0.5540\tMedium:\t0.2229\tFew:\t0.0190\n    > [Stats]\tMany:\t0.5540\tMedium:\t0.2229\tFew:\t0.0190\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0272218044514263\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [48 | 200]\n---> Epoch: [48 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.0546\n    > [Train]\tLoss:\t1.0546\n    > [Test ]\tLoss:\t4.1023\tAcc:\t26.4500\n    > [Test ]\tLoss:\t4.1023\tAcc:\t26.4500\n    > [Stats]\tMany:\t0.4871\tMedium:\t0.2360\tFew:\t0.0380\n    > [Stats]\tMany:\t0.4871\tMedium:\t0.2360\tFew:\t0.0380\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.062118966446829\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [49 | 200]\n---> Epoch: [49 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.0782\n    > [Train]\tLoss:\t1.0782\n    > [Test ]\tLoss:\t3.8504\tAcc:\t28.1200\n    > [Test ]\tLoss:\t3.8504\tAcc:\t28.1200\n    > [Stats]\tMany:\t0.5403\tMedium:\t0.2486\tFew:\t0.0170\n    > [Stats]\tMany:\t0.5403\tMedium:\t0.2486\tFew:\t0.0170\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0665959386113517\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [50 | 200]\n---> Epoch: [50 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t1.1729\n    > [Train]\tLoss:\t1.1729\n    > [Test ]\tLoss:\t4.1410\tAcc:\t25.8800\n    > [Test ]\tLoss:\t4.1410\tAcc:\t25.8800\n    > [Stats]\tMany:\t0.4946\tMedium:\t0.2266\tFew:\t0.0213\n    > [Stats]\tMany:\t0.4946\tMedium:\t0.2266\tFew:\t0.0213\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Best ]\tAcc:\t31.7400\tMany:\t57.4286\tMedium:\t30.4857\tFew:\t3.2333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.019127640762976\nMax state: 9 // Min state: 0\ntensor([9., 9., 9.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [51 | 200]\n---> Epoch: [51 | 200]\n    > Max_state: 9, min_state: 0\n    > Max_state: 9, min_state: 0\n    > [Train]\tLoss:\t1.1089\n    > [Train]\tLoss:\t1.1089\n    > [Test ]\tLoss:\t3.6561\tAcc:\t32.2900\n    > [Test ]\tLoss:\t3.6561\tAcc:\t32.2900\n    > [Stats]\tMany:\t0.5829\tMedium:\t0.3043\tFew:\t0.0413\n    > [Stats]\tMany:\t0.5829\tMedium:\t0.3043\tFew:\t0.0413\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0242020134673013\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [52 | 200]\n---> Epoch: [52 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t1.0767\n    > [Train]\tLoss:\t1.0767\n    > [Test ]\tLoss:\t3.5955\tAcc:\t29.6300\n    > [Test ]\tLoss:\t3.5955\tAcc:\t29.6300\n    > [Stats]\tMany:\t0.5563\tMedium:\t0.2643\tFew:\t0.0303\n    > [Stats]\tMany:\t0.5563\tMedium:\t0.2643\tFew:\t0.0303\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.050433970088704\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [53 | 200]\n---> Epoch: [53 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.1329\n    > [Train]\tLoss:\t1.1329\n    > [Test ]\tLoss:\t3.7636\tAcc:\t30.2000\n    > [Test ]\tLoss:\t3.7636\tAcc:\t30.2000\n    > [Stats]\tMany:\t0.5611\tMedium:\t0.2743\tFew:\t0.0320\n    > [Stats]\tMany:\t0.5611\tMedium:\t0.2743\tFew:\t0.0320\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.001331346616277\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [54 | 200]\n---> Epoch: [54 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t1.1347\n    > [Train]\tLoss:\t1.1347\n    > [Test ]\tLoss:\t3.9564\tAcc:\t28.9000\n    > [Test ]\tLoss:\t3.9564\tAcc:\t28.9000\n    > [Stats]\tMany:\t0.5603\tMedium:\t0.2434\tFew:\t0.0257\n    > [Stats]\tMany:\t0.5603\tMedium:\t0.2434\tFew:\t0.0257\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0055177791196845\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [55 | 200]\n---> Epoch: [55 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.1375\n    > [Train]\tLoss:\t1.1375\n    > [Test ]\tLoss:\t3.8026\tAcc:\t28.8700\n    > [Test ]\tLoss:\t3.8026\tAcc:\t28.8700\n    > [Stats]\tMany:\t0.5423\tMedium:\t0.2509\tFew:\t0.0370\n    > [Stats]\tMany:\t0.5423\tMedium:\t0.2509\tFew:\t0.0370\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.9613217665549447\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [56 | 200]\n---> Epoch: [56 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.0926\n    > [Train]\tLoss:\t1.0926\n    > [Test ]\tLoss:\t3.8431\tAcc:\t30.7400\n    > [Test ]\tLoss:\t3.8431\tAcc:\t30.7400\n    > [Stats]\tMany:\t0.5623\tMedium:\t0.2786\tFew:\t0.0437\n    > [Stats]\tMany:\t0.5623\tMedium:\t0.2786\tFew:\t0.0437\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"3.0041102204758907\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [57 | 200]\n---> Epoch: [57 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.1650\n    > [Train]\tLoss:\t1.1650\n    > [Test ]\tLoss:\t3.7387\tAcc:\t30.3500\n    > [Test ]\tLoss:\t3.7387\tAcc:\t30.3500\n    > [Stats]\tMany:\t0.5534\tMedium:\t0.2877\tFew:\t0.0303\n    > [Stats]\tMany:\t0.5534\tMedium:\t0.2877\tFew:\t0.0303\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.97927543851459\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [58 | 200]\n---> Epoch: [58 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t1.0409\n    > [Train]\tLoss:\t1.0409\n    > [Test ]\tLoss:\t3.8564\tAcc:\t29.4700\n    > [Test ]\tLoss:\t3.8564\tAcc:\t29.4700\n    > [Stats]\tMany:\t0.5857\tMedium:\t0.2360\tFew:\t0.0237\n    > [Stats]\tMany:\t0.5857\tMedium:\t0.2360\tFew:\t0.0237\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.992254818989348\nMax state: 9 // Min state: 0\ntensor([9., 9., 9.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [59 | 200]\n---> Epoch: [59 | 200]\n    > Max_state: 9, min_state: 0\n    > Max_state: 9, min_state: 0\n    > [Train]\tLoss:\t1.1105\n    > [Train]\tLoss:\t1.1105\n    > [Test ]\tLoss:\t4.0452\tAcc:\t28.8100\n    > [Test ]\tLoss:\t4.0452\tAcc:\t28.8100\n    > [Stats]\tMany:\t0.4997\tMedium:\t0.2871\tFew:\t0.0423\n    > [Stats]\tMany:\t0.4997\tMedium:\t0.2871\tFew:\t0.0423\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.972628572043158\nMax state: 10 // Min state: 0\ntensor([10., 10., 10.,  ...,  0.,  0.,  0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [60 | 200]\n---> Epoch: [60 | 200]\n    > Max_state: 10, min_state: 0\n    > Max_state: 10, min_state: 0\n    > [Train]\tLoss:\t1.0843\n    > [Train]\tLoss:\t1.0843\n    > [Test ]\tLoss:\t3.6106\tAcc:\t31.3700\n    > [Test ]\tLoss:\t3.6106\tAcc:\t31.3700\n    > [Stats]\tMany:\t0.5720\tMedium:\t0.2826\tFew:\t0.0487\n    > [Stats]\tMany:\t0.5720\tMedium:\t0.2826\tFew:\t0.0487\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.9941848744458284\nMax state: 9 // Min state: 0\ntensor([9., 9., 9.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [61 | 200]\n---> Epoch: [61 | 200]\n    > Max_state: 9, min_state: 0\n    > Max_state: 9, min_state: 0\n    > [Train]\tLoss:\t1.1006\n    > [Train]\tLoss:\t1.1006\n    > [Test ]\tLoss:\t4.2189\tAcc:\t26.5500\n    > [Test ]\tLoss:\t4.2189\tAcc:\t26.5500\n    > [Stats]\tMany:\t0.5360\tMedium:\t0.2034\tFew:\t0.0223\n    > [Stats]\tMany:\t0.5360\tMedium:\t0.2034\tFew:\t0.0223\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.9602450658774604\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [62 | 200]\n---> Epoch: [62 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t1.0192\n    > [Train]\tLoss:\t1.0192\n    > [Test ]\tLoss:\t3.7510\tAcc:\t31.6500\n    > [Test ]\tLoss:\t3.7510\tAcc:\t31.6500\n    > [Stats]\tMany:\t0.5454\tMedium:\t0.3120\tFew:\t0.0547\n    > [Stats]\tMany:\t0.5454\tMedium:\t0.3120\tFew:\t0.0547\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.9723113888724755\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [63 | 200]\n---> Epoch: [63 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.0700\n    > [Train]\tLoss:\t1.0700\n    > [Test ]\tLoss:\t4.1608\tAcc:\t27.0900\n    > [Test ]\tLoss:\t4.1608\tAcc:\t27.0900\n    > [Stats]\tMany:\t0.5300\tMedium:\t0.2311\tFew:\t0.0150\n    > [Stats]\tMany:\t0.5300\tMedium:\t0.2311\tFew:\t0.0150\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.942667811410663\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [64 | 200]\n---> Epoch: [64 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.0212\n    > [Train]\tLoss:\t1.0212\n    > [Test ]\tLoss:\t3.9024\tAcc:\t28.9500\n    > [Test ]\tLoss:\t3.9024\tAcc:\t28.9500\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.2634\tFew:\t0.0283\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.2634\tFew:\t0.0283\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.934212607281971\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [65 | 200]\n---> Epoch: [65 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t1.0164\n    > [Train]\tLoss:\t1.0164\n    > [Test ]\tLoss:\t3.5631\tAcc:\t31.2300\n    > [Test ]\tLoss:\t3.5631\tAcc:\t31.2300\n    > [Stats]\tMany:\t0.5831\tMedium:\t0.2637\tFew:\t0.0530\n    > [Stats]\tMany:\t0.5831\tMedium:\t0.2637\tFew:\t0.0530\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.922610423871128\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [66 | 200]\n---> Epoch: [66 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t1.0713\n    > [Train]\tLoss:\t1.0713\n    > [Test ]\tLoss:\t3.5604\tAcc:\t31.3700\n    > [Test ]\tLoss:\t3.5604\tAcc:\t31.3700\n    > [Stats]\tMany:\t0.5746\tMedium:\t0.2683\tFew:\t0.0623\n    > [Stats]\tMany:\t0.5746\tMedium:\t0.2683\tFew:\t0.0623\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.8637243459737665\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [67 | 200]\n---> Epoch: [67 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.0625\n    > [Train]\tLoss:\t1.0625\n    > [Test ]\tLoss:\t3.7396\tAcc:\t30.3900\n    > [Test ]\tLoss:\t3.7396\tAcc:\t30.3900\n    > [Stats]\tMany:\t0.5680\tMedium:\t0.2577\tFew:\t0.0497\n    > [Stats]\tMany:\t0.5680\tMedium:\t0.2577\tFew:\t0.0497\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.8288932819308767\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [68 | 200]\n---> Epoch: [68 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9554\n    > [Train]\tLoss:\t0.9554\n    > [Test ]\tLoss:\t3.6246\tAcc:\t32.0800\n    > [Test ]\tLoss:\t3.6246\tAcc:\t32.0800\n    > [Stats]\tMany:\t0.5751\tMedium:\t0.3037\tFew:\t0.0440\n    > [Stats]\tMany:\t0.5751\tMedium:\t0.3037\tFew:\t0.0440\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.9132065869520853\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [69 | 200]\n---> Epoch: [69 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.1087\n    > [Train]\tLoss:\t1.1087\n    > [Test ]\tLoss:\t3.6531\tAcc:\t31.9500\n    > [Test ]\tLoss:\t3.6531\tAcc:\t31.9500\n    > [Stats]\tMany:\t0.6049\tMedium:\t0.2657\tFew:\t0.0493\n    > [Stats]\tMany:\t0.6049\tMedium:\t0.2657\tFew:\t0.0493\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.836410523443099\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [70 | 200]\n---> Epoch: [70 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9701\n    > [Train]\tLoss:\t0.9701\n    > [Test ]\tLoss:\t4.6731\tAcc:\t24.6500\n    > [Test ]\tLoss:\t4.6731\tAcc:\t24.6500\n    > [Stats]\tMany:\t0.4317\tMedium:\t0.2357\tFew:\t0.0430\n    > [Stats]\tMany:\t0.4317\tMedium:\t0.2357\tFew:\t0.0430\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.831762625012917\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [71 | 200]\n---> Epoch: [71 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8886\n    > [Train]\tLoss:\t0.8886\n    > [Test ]\tLoss:\t3.6066\tAcc:\t29.9600\n    > [Test ]\tLoss:\t3.6066\tAcc:\t29.9600\n    > [Stats]\tMany:\t0.5686\tMedium:\t0.2634\tFew:\t0.0280\n    > [Stats]\tMany:\t0.5686\tMedium:\t0.2634\tFew:\t0.0280\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.846753458230321\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [72 | 200]\n---> Epoch: [72 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.9805\n    > [Train]\tLoss:\t0.9805\n    > [Test ]\tLoss:\t3.6928\tAcc:\t31.5400\n    > [Test ]\tLoss:\t3.6928\tAcc:\t31.5400\n    > [Stats]\tMany:\t0.5831\tMedium:\t0.2851\tFew:\t0.0383\n    > [Stats]\tMany:\t0.5831\tMedium:\t0.2851\tFew:\t0.0383\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.797898665023011\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [73 | 200]\n---> Epoch: [73 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t1.0467\n    > [Train]\tLoss:\t1.0467\n    > [Test ]\tLoss:\t3.8950\tAcc:\t30.4400\n    > [Test ]\tLoss:\t3.8950\tAcc:\t30.4400\n    > [Stats]\tMany:\t0.5409\tMedium:\t0.3031\tFew:\t0.0300\n    > [Stats]\tMany:\t0.5409\tMedium:\t0.3031\tFew:\t0.0300\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.780297582005274\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [74 | 200]\n---> Epoch: [74 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9351\n    > [Train]\tLoss:\t0.9351\n    > [Test ]\tLoss:\t3.8270\tAcc:\t31.2100\n    > [Test ]\tLoss:\t3.8270\tAcc:\t31.2100\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2940\tFew:\t0.0460\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2940\tFew:\t0.0460\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.784359769825801\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [75 | 200]\n---> Epoch: [75 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9815\n    > [Train]\tLoss:\t0.9815\n    > [Test ]\tLoss:\t3.6300\tAcc:\t31.3600\n    > [Test ]\tLoss:\t3.6300\tAcc:\t31.3600\n    > [Stats]\tMany:\t0.5629\tMedium:\t0.2857\tFew:\t0.0553\n    > [Stats]\tMany:\t0.5629\tMedium:\t0.2857\tFew:\t0.0553\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.7531185293447926\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [76 | 200]\n---> Epoch: [76 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9716\n    > [Train]\tLoss:\t0.9716\n    > [Test ]\tLoss:\t3.7696\tAcc:\t29.8600\n    > [Test ]\tLoss:\t3.7696\tAcc:\t29.8600\n    > [Stats]\tMany:\t0.5449\tMedium:\t0.2791\tFew:\t0.0340\n    > [Stats]\tMany:\t0.5449\tMedium:\t0.2791\tFew:\t0.0340\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.7499457760390453\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [77 | 200]\n---> Epoch: [77 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9479\n    > [Train]\tLoss:\t0.9479\n    > [Test ]\tLoss:\t3.9273\tAcc:\t30.2900\n    > [Test ]\tLoss:\t3.9273\tAcc:\t30.2900\n    > [Stats]\tMany:\t0.5654\tMedium:\t0.2674\tFew:\t0.0380\n    > [Stats]\tMany:\t0.5654\tMedium:\t0.2674\tFew:\t0.0380\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.7341322806594017\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [78 | 200]\n---> Epoch: [78 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9973\n    > [Train]\tLoss:\t0.9973\n    > [Test ]\tLoss:\t4.2334\tAcc:\t27.9600\n    > [Test ]\tLoss:\t4.2334\tAcc:\t27.9600\n    > [Stats]\tMany:\t0.5486\tMedium:\t0.2194\tFew:\t0.0360\n    > [Stats]\tMany:\t0.5486\tMedium:\t0.2194\tFew:\t0.0360\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.722816690334103\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [79 | 200]\n---> Epoch: [79 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9564\n    > [Train]\tLoss:\t0.9564\n    > [Test ]\tLoss:\t4.1513\tAcc:\t28.4400\n    > [Test ]\tLoss:\t4.1513\tAcc:\t28.4400\n    > [Stats]\tMany:\t0.5097\tMedium:\t0.2794\tFew:\t0.0273\n    > [Stats]\tMany:\t0.5097\tMedium:\t0.2794\tFew:\t0.0273\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6811328591282937\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [80 | 200]\n---> Epoch: [80 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8791\n    > [Train]\tLoss:\t0.8791\n    > [Test ]\tLoss:\t3.8901\tAcc:\t29.8000\n    > [Test ]\tLoss:\t3.8901\tAcc:\t29.8000\n    > [Stats]\tMany:\t0.5634\tMedium:\t0.2680\tFew:\t0.0233\n    > [Stats]\tMany:\t0.5634\tMedium:\t0.2680\tFew:\t0.0233\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.7381362561405997\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [81 | 200]\n---> Epoch: [81 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9425\n    > [Train]\tLoss:\t0.9425\n    > [Test ]\tLoss:\t4.1439\tAcc:\t27.8700\n    > [Test ]\tLoss:\t4.1439\tAcc:\t27.8700\n    > [Stats]\tMany:\t0.5423\tMedium:\t0.2346\tFew:\t0.0227\n    > [Stats]\tMany:\t0.5423\tMedium:\t0.2346\tFew:\t0.0227\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6895804932962863\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [82 | 200]\n---> Epoch: [82 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.9952\n    > [Train]\tLoss:\t0.9952\n    > [Test ]\tLoss:\t3.6749\tAcc:\t31.3600\n    > [Test ]\tLoss:\t3.6749\tAcc:\t31.3600\n    > [Stats]\tMany:\t0.5643\tMedium:\t0.3003\tFew:\t0.0367\n    > [Stats]\tMany:\t0.5643\tMedium:\t0.3003\tFew:\t0.0367\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6537487888184748\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [83 | 200]\n---> Epoch: [83 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9253\n    > [Train]\tLoss:\t0.9253\n    > [Test ]\tLoss:\t4.2453\tAcc:\t29.9700\n    > [Test ]\tLoss:\t4.2453\tAcc:\t29.9700\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.2740\tFew:\t0.0500\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.2740\tFew:\t0.0500\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6843028627614287\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [84 | 200]\n---> Epoch: [84 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8866\n    > [Train]\tLoss:\t0.8866\n    > [Test ]\tLoss:\t3.9198\tAcc:\t30.5300\n    > [Test ]\tLoss:\t3.9198\tAcc:\t30.5300\n    > [Stats]\tMany:\t0.5431\tMedium:\t0.2943\tFew:\t0.0407\n    > [Stats]\tMany:\t0.5431\tMedium:\t0.2943\tFew:\t0.0407\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Best ]\tAcc:\t32.2900\tMany:\t58.2857\tMedium:\t30.4286\tFew:\t4.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.697750285052858\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [85 | 200]\n---> Epoch: [85 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9299\n    > [Train]\tLoss:\t0.9299\n    > [Test ]\tLoss:\t3.7912\tAcc:\t33.1700\n    > [Test ]\tLoss:\t3.7912\tAcc:\t33.1700\n    > [Stats]\tMany:\t0.5986\tMedium:\t0.2900\tFew:\t0.0690\n    > [Stats]\tMany:\t0.5986\tMedium:\t0.2900\tFew:\t0.0690\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.665841862270796\nMax state: 6 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [86 | 200]\n---> Epoch: [86 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9502\n    > [Train]\tLoss:\t0.9502\n    > [Test ]\tLoss:\t4.4589\tAcc:\t27.8900\n    > [Test ]\tLoss:\t4.4589\tAcc:\t27.8900\n    > [Stats]\tMany:\t0.5243\tMedium:\t0.2220\tFew:\t0.0590\n    > [Stats]\tMany:\t0.5243\tMedium:\t0.2220\tFew:\t0.0590\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.648382522508097\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [87 | 200]\n---> Epoch: [87 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8316\n    > [Train]\tLoss:\t0.8316\n    > [Test ]\tLoss:\t3.8921\tAcc:\t31.5200\n    > [Test ]\tLoss:\t3.8921\tAcc:\t31.5200\n    > [Stats]\tMany:\t0.5729\tMedium:\t0.2771\tFew:\t0.0590\n    > [Stats]\tMany:\t0.5729\tMedium:\t0.2771\tFew:\t0.0590\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6987517557139173\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [88 | 200]\n---> Epoch: [88 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8878\n    > [Train]\tLoss:\t0.8878\n    > [Test ]\tLoss:\t4.2785\tAcc:\t29.5800\n    > [Test ]\tLoss:\t4.2785\tAcc:\t29.5800\n    > [Stats]\tMany:\t0.5471\tMedium:\t0.2494\tFew:\t0.0567\n    > [Stats]\tMany:\t0.5471\tMedium:\t0.2494\tFew:\t0.0567\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Best ]\tAcc:\t33.1700\tMany:\t59.8571\tMedium:\t29.0000\tFew:\t6.9000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.7096984014208867\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [89 | 200]\n---> Epoch: [89 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9223\n    > [Train]\tLoss:\t0.9223\n    > [Test ]\tLoss:\t3.6867\tAcc:\t33.4200\n    > [Test ]\tLoss:\t3.6867\tAcc:\t33.4200\n    > [Stats]\tMany:\t0.5743\tMedium:\t0.3166\tFew:\t0.0747\n    > [Stats]\tMany:\t0.5743\tMedium:\t0.3166\tFew:\t0.0747\n    > [Best ]\tAcc:\t33.4200\tMany:\t57.4286\tMedium:\t31.6571\tFew:\t7.4667\n    > [Best ]\tAcc:\t33.4200\tMany:\t57.4286\tMedium:\t31.6571\tFew:\t7.4667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6744807135556554\nMax state: 6 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [90 | 200]\n---> Epoch: [90 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9602\n    > [Train]\tLoss:\t0.9602\n    > [Test ]\tLoss:\t4.2838\tAcc:\t29.0900\n    > [Test ]\tLoss:\t4.2838\tAcc:\t29.0900\n    > [Stats]\tMany:\t0.5326\tMedium:\t0.2663\tFew:\t0.0377\n    > [Stats]\tMany:\t0.5326\tMedium:\t0.2663\tFew:\t0.0377\n    > [Best ]\tAcc:\t33.4200\tMany:\t57.4286\tMedium:\t31.6571\tFew:\t7.4667\n    > [Best ]\tAcc:\t33.4200\tMany:\t57.4286\tMedium:\t31.6571\tFew:\t7.4667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.657583401325475\nMax state: 7 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [91 | 200]\n---> Epoch: [91 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9007\n    > [Train]\tLoss:\t0.9007\n    > [Test ]\tLoss:\t3.5944\tAcc:\t33.9200\n    > [Test ]\tLoss:\t3.5944\tAcc:\t33.9200\n    > [Stats]\tMany:\t0.6100\tMedium:\t0.3111\tFew:\t0.0560\n    > [Stats]\tMany:\t0.6100\tMedium:\t0.3111\tFew:\t0.0560\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6377454340640845\nMax state: 6 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [92 | 200]\n---> Epoch: [92 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9768\n    > [Train]\tLoss:\t0.9768\n    > [Test ]\tLoss:\t3.8386\tAcc:\t32.3300\n    > [Test ]\tLoss:\t3.8386\tAcc:\t32.3300\n    > [Stats]\tMany:\t0.5817\tMedium:\t0.2963\tFew:\t0.0533\n    > [Stats]\tMany:\t0.5817\tMedium:\t0.2963\tFew:\t0.0533\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6213113226673768\nMax state: 7 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [93 | 200]\n---> Epoch: [93 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9580\n    > [Train]\tLoss:\t0.9580\n    > [Test ]\tLoss:\t3.9881\tAcc:\t28.9800\n    > [Test ]\tLoss:\t3.9881\tAcc:\t28.9800\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2357\tFew:\t0.0397\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2357\tFew:\t0.0397\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6215827899293767\nMax state: 8 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [94 | 200]\n---> Epoch: [94 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.9380\n    > [Train]\tLoss:\t0.9380\n    > [Test ]\tLoss:\t3.6735\tAcc:\t31.2700\n    > [Test ]\tLoss:\t3.6735\tAcc:\t31.2700\n    > [Stats]\tMany:\t0.5611\tMedium:\t0.2737\tFew:\t0.0683\n    > [Stats]\tMany:\t0.5611\tMedium:\t0.2737\tFew:\t0.0683\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6130670828448537\nMax state: 7 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [95 | 200]\n---> Epoch: [95 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9683\n    > [Train]\tLoss:\t0.9683\n    > [Test ]\tLoss:\t3.8585\tAcc:\t31.4900\n    > [Test ]\tLoss:\t3.8585\tAcc:\t31.4900\n    > [Stats]\tMany:\t0.5600\tMedium:\t0.2943\tFew:\t0.0530\n    > [Stats]\tMany:\t0.5600\tMedium:\t0.2943\tFew:\t0.0530\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5792952681383534\nMax state: 8 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [96 | 200]\n---> Epoch: [96 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.9376\n    > [Train]\tLoss:\t0.9376\n    > [Test ]\tLoss:\t4.0011\tAcc:\t29.9500\n    > [Test ]\tLoss:\t4.0011\tAcc:\t29.9500\n    > [Stats]\tMany:\t0.6040\tMedium:\t0.2314\tFew:\t0.0237\n    > [Stats]\tMany:\t0.6040\tMedium:\t0.2314\tFew:\t0.0237\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.605407738519385\nMax state: 7 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [97 | 200]\n---> Epoch: [97 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9521\n    > [Train]\tLoss:\t0.9521\n    > [Test ]\tLoss:\t3.9364\tAcc:\t32.2800\n    > [Test ]\tLoss:\t3.9364\tAcc:\t32.2800\n    > [Stats]\tMany:\t0.5486\tMedium:\t0.3200\tFew:\t0.0627\n    > [Stats]\tMany:\t0.5486\tMedium:\t0.3200\tFew:\t0.0627\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.6034739453729294\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [98 | 200]\n---> Epoch: [98 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9198\n    > [Train]\tLoss:\t0.9198\n    > [Test ]\tLoss:\t3.6610\tAcc:\t32.9000\n    > [Test ]\tLoss:\t3.6610\tAcc:\t32.9000\n    > [Stats]\tMany:\t0.5720\tMedium:\t0.3269\tFew:\t0.0480\n    > [Stats]\tMany:\t0.5720\tMedium:\t0.3269\tFew:\t0.0480\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.615406050786803\nMax state: 7 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [99 | 200]\n---> Epoch: [99 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9371\n    > [Train]\tLoss:\t0.9371\n    > [Test ]\tLoss:\t3.8672\tAcc:\t31.4300\n    > [Test ]\tLoss:\t3.8672\tAcc:\t31.4300\n    > [Stats]\tMany:\t0.6029\tMedium:\t0.2709\tFew:\t0.0283\n    > [Stats]\tMany:\t0.6029\tMedium:\t0.2709\tFew:\t0.0283\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.585885984734795\nMax state: 8 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [100 | 200]\n---> Epoch: [100 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.9713\n    > [Train]\tLoss:\t0.9713\n    > [Test ]\tLoss:\t3.9541\tAcc:\t31.6000\n    > [Test ]\tLoss:\t3.9541\tAcc:\t31.6000\n    > [Stats]\tMany:\t0.5551\tMedium:\t0.3054\tFew:\t0.0493\n    > [Stats]\tMany:\t0.5551\tMedium:\t0.3054\tFew:\t0.0493\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.560195481286558\nMax state: 9 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [101 | 200]\n---> Epoch: [101 | 200]\n    > Max_state: 9, min_state: 0\n    > Max_state: 9, min_state: 0\n    > [Train]\tLoss:\t0.9894\n    > [Train]\tLoss:\t0.9894\n    > [Test ]\tLoss:\t3.9866\tAcc:\t30.6800\n    > [Test ]\tLoss:\t3.9866\tAcc:\t30.6800\n    > [Stats]\tMany:\t0.5803\tMedium:\t0.2694\tFew:\t0.0313\n    > [Stats]\tMany:\t0.5803\tMedium:\t0.2694\tFew:\t0.0313\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5407223297219783\nMax state: 8 // Min state: 0\ntensor([6., 6., 6.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [102 | 200]\n---> Epoch: [102 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.9537\n    > [Train]\tLoss:\t0.9537\n    > [Test ]\tLoss:\t3.8995\tAcc:\t33.2600\n    > [Test ]\tLoss:\t3.8995\tAcc:\t33.2600\n    > [Stats]\tMany:\t0.5629\tMedium:\t0.3271\tFew:\t0.0703\n    > [Stats]\tMany:\t0.5629\tMedium:\t0.3271\tFew:\t0.0703\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5436612978655395\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [103 | 200]\n---> Epoch: [103 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8884\n    > [Train]\tLoss:\t0.8884\n    > [Test ]\tLoss:\t3.9777\tAcc:\t33.6900\n    > [Test ]\tLoss:\t3.9777\tAcc:\t33.6900\n    > [Stats]\tMany:\t0.5983\tMedium:\t0.3183\tFew:\t0.0537\n    > [Stats]\tMany:\t0.5983\tMedium:\t0.3183\tFew:\t0.0537\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5547240322103426\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [104 | 200]\n---> Epoch: [104 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9358\n    > [Train]\tLoss:\t0.9358\n    > [Test ]\tLoss:\t4.2000\tAcc:\t30.5200\n    > [Test ]\tLoss:\t4.2000\tAcc:\t30.5200\n    > [Stats]\tMany:\t0.5571\tMedium:\t0.2583\tFew:\t0.0660\n    > [Stats]\tMany:\t0.5571\tMedium:\t0.2583\tFew:\t0.0660\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5117990009347375\nMax state: 7 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [105 | 200]\n---> Epoch: [105 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8648\n    > [Train]\tLoss:\t0.8648\n    > [Test ]\tLoss:\t3.8763\tAcc:\t31.7000\n    > [Test ]\tLoss:\t3.8763\tAcc:\t31.7000\n    > [Stats]\tMany:\t0.5649\tMedium:\t0.2923\tFew:\t0.0567\n    > [Stats]\tMany:\t0.5649\tMedium:\t0.2923\tFew:\t0.0567\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5477203455949997\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [106 | 200]\n---> Epoch: [106 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8870\n    > [Train]\tLoss:\t0.8870\n    > [Test ]\tLoss:\t3.8384\tAcc:\t32.7300\n    > [Test ]\tLoss:\t3.8384\tAcc:\t32.7300\n    > [Stats]\tMany:\t0.5737\tMedium:\t0.3277\tFew:\t0.0393\n    > [Stats]\tMany:\t0.5737\tMedium:\t0.3277\tFew:\t0.0393\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.56740619128232\nMax state: 7 // Min state: 0\ntensor([5., 5., 5.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [107 | 200]\n---> Epoch: [107 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9956\n    > [Train]\tLoss:\t0.9956\n    > [Test ]\tLoss:\t4.0440\tAcc:\t31.3600\n    > [Test ]\tLoss:\t4.0440\tAcc:\t31.3600\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.3020\tFew:\t0.0637\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.3020\tFew:\t0.0637\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.500389486116466\nMax state: 6 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [108 | 200]\n---> Epoch: [108 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8459\n    > [Train]\tLoss:\t0.8459\n    > [Test ]\tLoss:\t4.0055\tAcc:\t31.3900\n    > [Test ]\tLoss:\t4.0055\tAcc:\t31.3900\n    > [Stats]\tMany:\t0.5794\tMedium:\t0.2811\tFew:\t0.0423\n    > [Stats]\tMany:\t0.5794\tMedium:\t0.2811\tFew:\t0.0423\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.565565440506021\nMax state: 6 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [109 | 200]\n---> Epoch: [109 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9222\n    > [Train]\tLoss:\t0.9222\n    > [Test ]\tLoss:\t4.4745\tAcc:\t27.4500\n    > [Test ]\tLoss:\t4.4745\tAcc:\t27.4500\n    > [Stats]\tMany:\t0.5143\tMedium:\t0.2391\tFew:\t0.0360\n    > [Stats]\tMany:\t0.5143\tMedium:\t0.2391\tFew:\t0.0360\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5614458465237226\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [110 | 200]\n---> Epoch: [110 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8299\n    > [Train]\tLoss:\t0.8299\n    > [Test ]\tLoss:\t4.0256\tAcc:\t30.1700\n    > [Test ]\tLoss:\t4.0256\tAcc:\t30.1700\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.2911\tFew:\t0.0367\n    > [Stats]\tMany:\t0.5394\tMedium:\t0.2911\tFew:\t0.0367\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5782215569549782\nMax state: 6 // Min state: 0\ntensor([5., 5., 5.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [111 | 200]\n---> Epoch: [111 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8729\n    > [Train]\tLoss:\t0.8729\n    > [Test ]\tLoss:\t4.6803\tAcc:\t29.9200\n    > [Test ]\tLoss:\t4.6803\tAcc:\t29.9200\n    > [Stats]\tMany:\t0.5857\tMedium:\t0.2454\tFew:\t0.0277\n    > [Stats]\tMany:\t0.5857\tMedium:\t0.2454\tFew:\t0.0277\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5637542627363574\nMax state: 6 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [112 | 200]\n---> Epoch: [112 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8822\n    > [Train]\tLoss:\t0.8822\n    > [Test ]\tLoss:\t4.5186\tAcc:\t30.1100\n    > [Test ]\tLoss:\t4.5186\tAcc:\t30.1100\n    > [Stats]\tMany:\t0.5540\tMedium:\t0.2700\tFew:\t0.0423\n    > [Stats]\tMany:\t0.5540\tMedium:\t0.2700\tFew:\t0.0423\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.537282398614247\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [113 | 200]\n---> Epoch: [113 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8476\n    > [Train]\tLoss:\t0.8476\n    > [Test ]\tLoss:\t4.2846\tAcc:\t30.9700\n    > [Test ]\tLoss:\t4.2846\tAcc:\t30.9700\n    > [Stats]\tMany:\t0.5657\tMedium:\t0.2580\tFew:\t0.0713\n    > [Stats]\tMany:\t0.5657\tMedium:\t0.2580\tFew:\t0.0713\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.54824947408583\nMax state: 6 // Min state: 0\ntensor([2., 2., 2.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [114 | 200]\n---> Epoch: [114 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8639\n    > [Train]\tLoss:\t0.8639\n    > [Test ]\tLoss:\t4.0185\tAcc:\t30.1200\n    > [Test ]\tLoss:\t4.0185\tAcc:\t30.1200\n    > [Stats]\tMany:\t0.5306\tMedium:\t0.2654\tFew:\t0.0753\n    > [Stats]\tMany:\t0.5306\tMedium:\t0.2654\tFew:\t0.0753\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5271069400234456\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [115 | 200]\n---> Epoch: [115 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8913\n    > [Train]\tLoss:\t0.8913\n    > [Test ]\tLoss:\t4.2066\tAcc:\t30.9200\n    > [Test ]\tLoss:\t4.2066\tAcc:\t30.9200\n    > [Stats]\tMany:\t0.5694\tMedium:\t0.2786\tFew:\t0.0413\n    > [Stats]\tMany:\t0.5694\tMedium:\t0.2786\tFew:\t0.0413\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4856449477848153\nMax state: 6 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [116 | 200]\n---> Epoch: [116 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.7753\n    > [Train]\tLoss:\t0.7753\n    > [Test ]\tLoss:\t4.0564\tAcc:\t33.4100\n    > [Test ]\tLoss:\t4.0564\tAcc:\t33.4100\n    > [Stats]\tMany:\t0.5729\tMedium:\t0.3406\tFew:\t0.0480\n    > [Stats]\tMany:\t0.5729\tMedium:\t0.3406\tFew:\t0.0480\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5244707168614764\nMax state: 7 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [117 | 200]\n---> Epoch: [117 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8999\n    > [Train]\tLoss:\t0.8999\n    > [Test ]\tLoss:\t3.9769\tAcc:\t31.4600\n    > [Test ]\tLoss:\t3.9769\tAcc:\t31.4600\n    > [Stats]\tMany:\t0.5817\tMedium:\t0.2774\tFew:\t0.0463\n    > [Stats]\tMany:\t0.5817\tMedium:\t0.2774\tFew:\t0.0463\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4633755691776114\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [118 | 200]\n---> Epoch: [118 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8859\n    > [Train]\tLoss:\t0.8859\n    > [Test ]\tLoss:\t4.4178\tAcc:\t29.0400\n    > [Test ]\tLoss:\t4.4178\tAcc:\t29.0400\n    > [Stats]\tMany:\t0.5406\tMedium:\t0.2434\tFew:\t0.0533\n    > [Stats]\tMany:\t0.5406\tMedium:\t0.2434\tFew:\t0.0533\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4488026237934655\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [119 | 200]\n---> Epoch: [119 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8946\n    > [Train]\tLoss:\t0.8946\n    > [Test ]\tLoss:\t3.8501\tAcc:\t33.3200\n    > [Test ]\tLoss:\t3.8501\tAcc:\t33.3200\n    > [Stats]\tMany:\t0.5789\tMedium:\t0.3260\tFew:\t0.0550\n    > [Stats]\tMany:\t0.5789\tMedium:\t0.3260\tFew:\t0.0550\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.432038300177251\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [120 | 200]\n---> Epoch: [120 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8810\n    > [Train]\tLoss:\t0.8810\n    > [Test ]\tLoss:\t4.8283\tAcc:\t28.8800\n    > [Test ]\tLoss:\t4.8283\tAcc:\t28.8800\n    > [Stats]\tMany:\t0.5497\tMedium:\t0.2314\tFew:\t0.0513\n    > [Stats]\tMany:\t0.5497\tMedium:\t0.2314\tFew:\t0.0513\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.480044939201156\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [121 | 200]\n---> Epoch: [121 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.7698\n    > [Train]\tLoss:\t0.7698\n    > [Test ]\tLoss:\t3.7989\tAcc:\t32.1700\n    > [Test ]\tLoss:\t3.7989\tAcc:\t32.1700\n    > [Stats]\tMany:\t0.5717\tMedium:\t0.2894\tFew:\t0.0677\n    > [Stats]\tMany:\t0.5717\tMedium:\t0.2894\tFew:\t0.0677\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.456839327968781\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [122 | 200]\n---> Epoch: [122 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8726\n    > [Train]\tLoss:\t0.8726\n    > [Test ]\tLoss:\t4.8865\tAcc:\t29.4000\n    > [Test ]\tLoss:\t4.8865\tAcc:\t29.4000\n    > [Stats]\tMany:\t0.5131\tMedium:\t0.2831\tFew:\t0.0510\n    > [Stats]\tMany:\t0.5131\tMedium:\t0.2831\tFew:\t0.0510\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4638313750708503\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [123 | 200]\n---> Epoch: [123 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.7959\n    > [Train]\tLoss:\t0.7959\n    > [Test ]\tLoss:\t4.2239\tAcc:\t29.7500\n    > [Test ]\tLoss:\t4.2239\tAcc:\t29.7500\n    > [Stats]\tMany:\t0.5529\tMedium:\t0.2666\tFew:\t0.0357\n    > [Stats]\tMany:\t0.5529\tMedium:\t0.2666\tFew:\t0.0357\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.492022502334731\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [124 | 200]\n---> Epoch: [124 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8837\n    > [Train]\tLoss:\t0.8837\n    > [Test ]\tLoss:\t3.9714\tAcc:\t32.7700\n    > [Test ]\tLoss:\t3.9714\tAcc:\t32.7700\n    > [Stats]\tMany:\t0.5851\tMedium:\t0.2989\tFew:\t0.0610\n    > [Stats]\tMany:\t0.5851\tMedium:\t0.2989\tFew:\t0.0610\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.444710469980436\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [125 | 200]\n---> Epoch: [125 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9293\n    > [Train]\tLoss:\t0.9293\n    > [Test ]\tLoss:\t4.4702\tAcc:\t30.0600\n    > [Test ]\tLoss:\t4.4702\tAcc:\t30.0600\n    > [Stats]\tMany:\t0.5729\tMedium:\t0.2589\tFew:\t0.0317\n    > [Stats]\tMany:\t0.5729\tMedium:\t0.2589\tFew:\t0.0317\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Best ]\tAcc:\t33.9200\tMany:\t61.0000\tMedium:\t31.1143\tFew:\t5.6000\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4398483043233408\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [126 | 200]\n---> Epoch: [126 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8014\n    > [Train]\tLoss:\t0.8014\n    > [Test ]\tLoss:\t3.7905\tAcc:\t34.0100\n    > [Test ]\tLoss:\t3.7905\tAcc:\t34.0100\n    > [Stats]\tMany:\t0.6031\tMedium:\t0.3160\tFew:\t0.0613\n    > [Stats]\tMany:\t0.6031\tMedium:\t0.3160\tFew:\t0.0613\n    > [Best ]\tAcc:\t34.0100\tMany:\t60.3143\tMedium:\t31.6000\tFew:\t6.1333\n    > [Best ]\tAcc:\t34.0100\tMany:\t60.3143\tMedium:\t31.6000\tFew:\t6.1333\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.456326002808103\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [127 | 200]\n---> Epoch: [127 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9152\n    > [Train]\tLoss:\t0.9152\n    > [Test ]\tLoss:\t3.6946\tAcc:\t34.3400\n    > [Test ]\tLoss:\t3.6946\tAcc:\t34.3400\n    > [Stats]\tMany:\t0.5591\tMedium:\t0.3451\tFew:\t0.0897\n    > [Stats]\tMany:\t0.5591\tMedium:\t0.3451\tFew:\t0.0897\n    > [Best ]\tAcc:\t34.3400\tMany:\t55.9143\tMedium:\t34.5143\tFew:\t8.9667\n    > [Best ]\tAcc:\t34.3400\tMany:\t55.9143\tMedium:\t34.5143\tFew:\t8.9667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4332768840819377\nMax state: 6 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [128 | 200]\n---> Epoch: [128 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8780\n    > [Train]\tLoss:\t0.8780\n    > [Test ]\tLoss:\t3.9528\tAcc:\t33.0800\n    > [Test ]\tLoss:\t3.9528\tAcc:\t33.0800\n    > [Stats]\tMany:\t0.5814\tMedium:\t0.3240\tFew:\t0.0463\n    > [Stats]\tMany:\t0.5814\tMedium:\t0.3240\tFew:\t0.0463\n    > [Best ]\tAcc:\t34.3400\tMany:\t55.9143\tMedium:\t34.5143\tFew:\t8.9667\n    > [Best ]\tAcc:\t34.3400\tMany:\t55.9143\tMedium:\t34.5143\tFew:\t8.9667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4303031524154486\nMax state: 7 // Min state: 0\ntensor([3., 3., 3.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [129 | 200]\n---> Epoch: [129 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8811\n    > [Train]\tLoss:\t0.8811\n    > [Test ]\tLoss:\t3.6885\tAcc:\t32.8800\n    > [Test ]\tLoss:\t3.6885\tAcc:\t32.8800\n    > [Stats]\tMany:\t0.5760\tMedium:\t0.3163\tFew:\t0.0550\n    > [Stats]\tMany:\t0.5760\tMedium:\t0.3163\tFew:\t0.0550\n    > [Best ]\tAcc:\t34.3400\tMany:\t55.9143\tMedium:\t34.5143\tFew:\t8.9667\n    > [Best ]\tAcc:\t34.3400\tMany:\t55.9143\tMedium:\t34.5143\tFew:\t8.9667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.407119545518666\nMax state: 8 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [130 | 200]\n---> Epoch: [130 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.7728\n    > [Train]\tLoss:\t0.7728\n    > [Test ]\tLoss:\t3.6756\tAcc:\t34.8800\n    > [Test ]\tLoss:\t3.6756\tAcc:\t34.8800\n    > [Stats]\tMany:\t0.6014\tMedium:\t0.3380\tFew:\t0.0667\n    > [Stats]\tMany:\t0.6014\tMedium:\t0.3380\tFew:\t0.0667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.466866524525136\nMax state: 7 // Min state: 0\ntensor([3., 3., 3.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [131 | 200]\n---> Epoch: [131 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8757\n    > [Train]\tLoss:\t0.8757\n    > [Test ]\tLoss:\t4.2647\tAcc:\t29.4700\n    > [Test ]\tLoss:\t4.2647\tAcc:\t29.4700\n    > [Stats]\tMany:\t0.5646\tMedium:\t0.2374\tFew:\t0.0467\n    > [Stats]\tMany:\t0.5646\tMedium:\t0.2374\tFew:\t0.0467\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4541723206166854\nMax state: 7 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [132 | 200]\n---> Epoch: [132 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8932\n    > [Train]\tLoss:\t0.8932\n    > [Test ]\tLoss:\t4.9941\tAcc:\t25.3600\n    > [Test ]\tLoss:\t4.9941\tAcc:\t25.3600\n    > [Stats]\tMany:\t0.4686\tMedium:\t0.2354\tFew:\t0.0240\n    > [Stats]\tMany:\t0.4686\tMedium:\t0.2354\tFew:\t0.0240\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4258486553722793\nMax state: 8 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [133 | 200]\n---> Epoch: [133 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.8025\n    > [Train]\tLoss:\t0.8025\n    > [Test ]\tLoss:\t4.0108\tAcc:\t32.5300\n    > [Test ]\tLoss:\t4.0108\tAcc:\t32.5300\n    > [Stats]\tMany:\t0.6077\tMedium:\t0.2886\tFew:\t0.0387\n    > [Stats]\tMany:\t0.6077\tMedium:\t0.2886\tFew:\t0.0387\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4758259875259627\nMax state: 7 // Min state: 0\ntensor([6., 6., 6.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [134 | 200]\n---> Epoch: [134 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8386\n    > [Train]\tLoss:\t0.8386\n    > [Test ]\tLoss:\t4.1240\tAcc:\t32.6900\n    > [Test ]\tLoss:\t4.1240\tAcc:\t32.6900\n    > [Stats]\tMany:\t0.5700\tMedium:\t0.2983\tFew:\t0.0767\n    > [Stats]\tMany:\t0.5700\tMedium:\t0.2983\tFew:\t0.0767\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4734840756947563\nMax state: 6 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [135 | 200]\n---> Epoch: [135 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9242\n    > [Train]\tLoss:\t0.9242\n    > [Test ]\tLoss:\t3.9446\tAcc:\t31.9500\n    > [Test ]\tLoss:\t3.9446\tAcc:\t31.9500\n    > [Stats]\tMany:\t0.5694\tMedium:\t0.3109\tFew:\t0.0380\n    > [Stats]\tMany:\t0.5694\tMedium:\t0.3109\tFew:\t0.0380\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.461742050975585\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [136 | 200]\n---> Epoch: [136 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8455\n    > [Train]\tLoss:\t0.8455\n    > [Test ]\tLoss:\t4.0283\tAcc:\t33.4400\n    > [Test ]\tLoss:\t4.0283\tAcc:\t33.4400\n    > [Stats]\tMany:\t0.6060\tMedium:\t0.2926\tFew:\t0.0663\n    > [Stats]\tMany:\t0.6060\tMedium:\t0.2926\tFew:\t0.0663\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4807026829634236\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [137 | 200]\n---> Epoch: [137 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8747\n    > [Train]\tLoss:\t0.8747\n    > [Test ]\tLoss:\t3.8790\tAcc:\t33.5800\n    > [Test ]\tLoss:\t3.8790\tAcc:\t33.5800\n    > [Stats]\tMany:\t0.6134\tMedium:\t0.3017\tFew:\t0.0517\n    > [Stats]\tMany:\t0.6134\tMedium:\t0.3017\tFew:\t0.0517\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4645420147263812\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [138 | 200]\n---> Epoch: [138 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8913\n    > [Train]\tLoss:\t0.8913\n    > [Test ]\tLoss:\t4.3577\tAcc:\t30.0200\n    > [Test ]\tLoss:\t4.3577\tAcc:\t30.0200\n    > [Stats]\tMany:\t0.5357\tMedium:\t0.2946\tFew:\t0.0320\n    > [Stats]\tMany:\t0.5357\tMedium:\t0.2946\tFew:\t0.0320\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.458504879838506\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [139 | 200]\n---> Epoch: [139 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.7598\n    > [Train]\tLoss:\t0.7598\n    > [Test ]\tLoss:\t4.0133\tAcc:\t33.0600\n    > [Test ]\tLoss:\t4.0133\tAcc:\t33.0600\n    > [Stats]\tMany:\t0.5957\tMedium:\t0.2969\tFew:\t0.0607\n    > [Stats]\tMany:\t0.5957\tMedium:\t0.2969\tFew:\t0.0607\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4847652576812727\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [140 | 200]\n---> Epoch: [140 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8047\n    > [Train]\tLoss:\t0.8047\n    > [Test ]\tLoss:\t3.9156\tAcc:\t33.9300\n    > [Test ]\tLoss:\t3.9156\tAcc:\t33.9300\n    > [Stats]\tMany:\t0.5689\tMedium:\t0.3260\tFew:\t0.0870\n    > [Stats]\tMany:\t0.5689\tMedium:\t0.3260\tFew:\t0.0870\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5092714382479633\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [141 | 200]\n---> Epoch: [141 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8488\n    > [Train]\tLoss:\t0.8488\n    > [Test ]\tLoss:\t4.0003\tAcc:\t31.6700\n    > [Test ]\tLoss:\t4.0003\tAcc:\t31.6700\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2989\tFew:\t0.0557\n    > [Stats]\tMany:\t0.5583\tMedium:\t0.2989\tFew:\t0.0557\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4859818374825196\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [142 | 200]\n---> Epoch: [142 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.7784\n    > [Train]\tLoss:\t0.7784\n    > [Test ]\tLoss:\t4.0856\tAcc:\t31.7700\n    > [Test ]\tLoss:\t4.0856\tAcc:\t31.7700\n    > [Stats]\tMany:\t0.5757\tMedium:\t0.2997\tFew:\t0.0377\n    > [Stats]\tMany:\t0.5757\tMedium:\t0.2997\tFew:\t0.0377\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.5181564915937313\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [143 | 200]\n---> Epoch: [143 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8862\n    > [Train]\tLoss:\t0.8862\n    > [Test ]\tLoss:\t4.1786\tAcc:\t29.8900\n    > [Test ]\tLoss:\t4.1786\tAcc:\t29.8900\n    > [Stats]\tMany:\t0.5249\tMedium:\t0.2709\tFew:\t0.0680\n    > [Stats]\tMany:\t0.5249\tMedium:\t0.2709\tFew:\t0.0680\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4582329640868834\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [144 | 200]\n---> Epoch: [144 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8347\n    > [Train]\tLoss:\t0.8347\n    > [Test ]\tLoss:\t3.9195\tAcc:\t32.9100\n    > [Test ]\tLoss:\t3.9195\tAcc:\t32.9100\n    > [Stats]\tMany:\t0.5803\tMedium:\t0.3060\tFew:\t0.0630\n    > [Stats]\tMany:\t0.5803\tMedium:\t0.3060\tFew:\t0.0630\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4604649153596996\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [145 | 200]\n---> Epoch: [145 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8413\n    > [Train]\tLoss:\t0.8413\n    > [Test ]\tLoss:\t3.8609\tAcc:\t33.5000\n    > [Test ]\tLoss:\t3.8609\tAcc:\t33.5000\n    > [Stats]\tMany:\t0.5734\tMedium:\t0.3089\tFew:\t0.0873\n    > [Stats]\tMany:\t0.5734\tMedium:\t0.3089\tFew:\t0.0873\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4319521238917963\nMax state: 4 // Min state: 0\ntensor([2., 2., 2.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [146 | 200]\n---> Epoch: [146 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8639\n    > [Train]\tLoss:\t0.8639\n    > [Test ]\tLoss:\t3.9863\tAcc:\t32.4300\n    > [Test ]\tLoss:\t3.9863\tAcc:\t32.4300\n    > [Stats]\tMany:\t0.6143\tMedium:\t0.2789\tFew:\t0.0390\n    > [Stats]\tMany:\t0.6143\tMedium:\t0.2789\tFew:\t0.0390\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4257161097026794\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [147 | 200]\n---> Epoch: [147 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8096\n    > [Train]\tLoss:\t0.8096\n    > [Test ]\tLoss:\t3.8892\tAcc:\t33.2500\n    > [Test ]\tLoss:\t3.8892\tAcc:\t33.2500\n    > [Stats]\tMany:\t0.5926\tMedium:\t0.3057\tFew:\t0.0603\n    > [Stats]\tMany:\t0.5926\tMedium:\t0.3057\tFew:\t0.0603\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.3993233798908893\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [148 | 200]\n---> Epoch: [148 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8319\n    > [Train]\tLoss:\t0.8319\n    > [Test ]\tLoss:\t4.2665\tAcc:\t31.5500\n    > [Test ]\tLoss:\t4.2665\tAcc:\t31.5500\n    > [Stats]\tMany:\t0.5697\tMedium:\t0.2769\tFew:\t0.0640\n    > [Stats]\tMany:\t0.5697\tMedium:\t0.2769\tFew:\t0.0640\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.3833172972652457\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [149 | 200]\n---> Epoch: [149 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8042\n    > [Train]\tLoss:\t0.8042\n    > [Test ]\tLoss:\t4.4558\tAcc:\t30.2700\n    > [Test ]\tLoss:\t4.4558\tAcc:\t30.2700\n    > [Stats]\tMany:\t0.5766\tMedium:\t0.2520\tFew:\t0.0423\n    > [Stats]\tMany:\t0.5766\tMedium:\t0.2520\tFew:\t0.0423\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4168205290218037\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [150 | 200]\n---> Epoch: [150 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8788\n    > [Train]\tLoss:\t0.8788\n    > [Test ]\tLoss:\t4.1903\tAcc:\t31.2900\n    > [Test ]\tLoss:\t4.1903\tAcc:\t31.2900\n    > [Stats]\tMany:\t0.5794\tMedium:\t0.2554\tFew:\t0.0690\n    > [Stats]\tMany:\t0.5794\tMedium:\t0.2554\tFew:\t0.0690\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4001017258985673\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [151 | 200]\n---> Epoch: [151 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8196\n    > [Train]\tLoss:\t0.8196\n    > [Test ]\tLoss:\t4.2420\tAcc:\t30.6600\n    > [Test ]\tLoss:\t4.2420\tAcc:\t30.6600\n    > [Stats]\tMany:\t0.5620\tMedium:\t0.2686\tFew:\t0.0530\n    > [Stats]\tMany:\t0.5620\tMedium:\t0.2686\tFew:\t0.0530\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4116362796719875\nMax state: 4 // Min state: 0\ntensor([4., 4., 4.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [152 | 200]\n---> Epoch: [152 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.7780\n    > [Train]\tLoss:\t0.7780\n    > [Test ]\tLoss:\t4.2328\tAcc:\t32.3700\n    > [Test ]\tLoss:\t4.2328\tAcc:\t32.3700\n    > [Stats]\tMany:\t0.5649\tMedium:\t0.3091\tFew:\t0.0593\n    > [Stats]\tMany:\t0.5649\tMedium:\t0.3091\tFew:\t0.0593\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.402365478792858\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [153 | 200]\n---> Epoch: [153 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8325\n    > [Train]\tLoss:\t0.8325\n    > [Test ]\tLoss:\t4.2465\tAcc:\t30.6400\n    > [Test ]\tLoss:\t4.2465\tAcc:\t30.6400\n    > [Stats]\tMany:\t0.5840\tMedium:\t0.2537\tFew:\t0.0440\n    > [Stats]\tMany:\t0.5840\tMedium:\t0.2537\tFew:\t0.0440\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.3793459906284546\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [154 | 200]\n---> Epoch: [154 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.7996\n    > [Train]\tLoss:\t0.7996\n    > [Test ]\tLoss:\t4.5073\tAcc:\t30.9900\n    > [Test ]\tLoss:\t4.5073\tAcc:\t30.9900\n    > [Stats]\tMany:\t0.5434\tMedium:\t0.2989\tFew:\t0.0503\n    > [Stats]\tMany:\t0.5434\tMedium:\t0.2989\tFew:\t0.0503\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.420005322134003\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [155 | 200]\n---> Epoch: [155 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.8052\n    > [Train]\tLoss:\t0.8052\n    > [Test ]\tLoss:\t4.1306\tAcc:\t33.4600\n    > [Test ]\tLoss:\t4.1306\tAcc:\t33.4600\n    > [Stats]\tMany:\t0.5726\tMedium:\t0.3449\tFew:\t0.0450\n    > [Stats]\tMany:\t0.5726\tMedium:\t0.3449\tFew:\t0.0450\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.43419746004283\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 0., 0., 0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [156 | 200]\n---> Epoch: [156 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.8373\n    > [Train]\tLoss:\t0.8373\n    > [Test ]\tLoss:\t3.7314\tAcc:\t33.0500\n    > [Test ]\tLoss:\t3.7314\tAcc:\t33.0500\n    > [Stats]\tMany:\t0.5966\tMedium:\t0.2914\tFew:\t0.0657\n    > [Stats]\tMany:\t0.5966\tMedium:\t0.2914\tFew:\t0.0657\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.441455756818165\nMax state: 9 // Min state: 0\ntensor([9., 9., 9.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [157 | 200]\n---> Epoch: [157 | 200]\n    > Max_state: 9, min_state: 0\n    > Max_state: 9, min_state: 0\n    > [Train]\tLoss:\t0.8862\n    > [Train]\tLoss:\t0.8862\n    > [Test ]\tLoss:\t4.3369\tAcc:\t29.1400\n    > [Test ]\tLoss:\t4.3369\tAcc:\t29.1400\n    > [Stats]\tMany:\t0.5403\tMedium:\t0.2397\tFew:\t0.0613\n    > [Stats]\tMany:\t0.5403\tMedium:\t0.2397\tFew:\t0.0613\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.412130329176037\nMax state: 10 // Min state: 0\ntensor([10., 10., 10.,  ...,  0.,  0.,  0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [158 | 200]\n---> Epoch: [158 | 200]\n    > Max_state: 10, min_state: 0\n    > Max_state: 10, min_state: 0\n    > [Train]\tLoss:\t0.7857\n    > [Train]\tLoss:\t0.7857\n    > [Test ]\tLoss:\t4.8019\tAcc:\t28.5300\n    > [Test ]\tLoss:\t4.8019\tAcc:\t28.5300\n    > [Stats]\tMany:\t0.5017\tMedium:\t0.2749\tFew:\t0.0450\n    > [Stats]\tMany:\t0.5017\tMedium:\t0.2749\tFew:\t0.0450\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.433956690075999\nMax state: 9 // Min state: 0\ntensor([9., 9., 9.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [159 | 200]\n---> Epoch: [159 | 200]\n    > Max_state: 9, min_state: 0\n    > Max_state: 9, min_state: 0\n    > [Train]\tLoss:\t0.7513\n    > [Train]\tLoss:\t0.7513\n    > [Test ]\tLoss:\t3.9562\tAcc:\t31.2800\n    > [Test ]\tLoss:\t3.9562\tAcc:\t31.2800\n    > [Stats]\tMany:\t0.5800\tMedium:\t0.2743\tFew:\t0.0460\n    > [Stats]\tMany:\t0.5800\tMedium:\t0.2743\tFew:\t0.0460\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.4383163532439815\nMax state: 10 // Min state: 0\ntensor([10., 10., 10.,  ...,  0.,  0.,  0.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [160 | 200]\n---> Epoch: [160 | 200]\n    > Max_state: 10, min_state: 0\n    > Max_state: 10, min_state: 0\n    > [Train]\tLoss:\t0.8824\n    > [Train]\tLoss:\t0.8824\n    > [Test ]\tLoss:\t4.0396\tAcc:\t32.3600\n    > [Test ]\tLoss:\t4.0396\tAcc:\t32.3600\n    > [Stats]\tMany:\t0.5937\tMedium:\t0.2789\tFew:\t0.0607\n    > [Stats]\tMany:\t0.5937\tMedium:\t0.2789\tFew:\t0.0607\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Best ]\tAcc:\t34.8800\tMany:\t60.1429\tMedium:\t33.8000\tFew:\t6.6667\n    > [Param]\tLR:\t0.10000000\n    > [Param]\tLR:\t0.10000000\n","output_type":"stream"},{"name":"stdout","text":"2.437338952512515\nMax state: 9 // Min state: 0\ntensor([9., 9., 9.,  ..., 1., 1., 1.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [161 | 200]\n---> Epoch: [161 | 200]\n    > Max_state: 9, min_state: 0\n    > Max_state: 9, min_state: 0\n    > [Train]\tLoss:\t0.9206\n    > [Train]\tLoss:\t0.9206\n    > [Test ]\tLoss:\t3.1338\tAcc:\t39.5300\n    > [Test ]\tLoss:\t3.1338\tAcc:\t39.5300\n    > [Stats]\tMany:\t0.6446\tMedium:\t0.3900\tFew:\t0.1107\n    > [Stats]\tMany:\t0.6446\tMedium:\t0.3900\tFew:\t0.1107\n    > [Best ]\tAcc:\t39.5300\tMany:\t64.4571\tMedium:\t39.0000\tFew:\t11.0667\n    > [Best ]\tAcc:\t39.5300\tMany:\t64.4571\tMedium:\t39.0000\tFew:\t11.0667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.416398320491676\nMax state: 8 // Min state: 0\ntensor([8., 8., 8.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [162 | 200]\n---> Epoch: [162 | 200]\n    > Max_state: 8, min_state: 0\n    > Max_state: 8, min_state: 0\n    > [Train]\tLoss:\t0.9346\n    > [Train]\tLoss:\t0.9346\n    > [Test ]\tLoss:\t2.9533\tAcc:\t41.3100\n    > [Test ]\tLoss:\t2.9533\tAcc:\t41.3100\n    > [Stats]\tMany:\t0.6374\tMedium:\t0.4154\tFew:\t0.1487\n    > [Stats]\tMany:\t0.6374\tMedium:\t0.4154\tFew:\t0.1487\n    > [Best ]\tAcc:\t41.3100\tMany:\t63.7429\tMedium:\t41.5429\tFew:\t14.8667\n    > [Best ]\tAcc:\t41.3100\tMany:\t63.7429\tMedium:\t41.5429\tFew:\t14.8667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.403251466634937\nMax state: 7 // Min state: 0\ntensor([7., 7., 7.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [163 | 200]\n---> Epoch: [163 | 200]\n    > Max_state: 7, min_state: 0\n    > Max_state: 7, min_state: 0\n    > [Train]\tLoss:\t0.9080\n    > [Train]\tLoss:\t0.9080\n    > [Test ]\tLoss:\t2.8564\tAcc:\t41.6400\n    > [Test ]\tLoss:\t2.8564\tAcc:\t41.6400\n    > [Stats]\tMany:\t0.6323\tMedium:\t0.4257\tFew:\t0.1537\n    > [Stats]\tMany:\t0.6323\tMedium:\t0.4257\tFew:\t0.1537\n    > [Best ]\tAcc:\t41.6400\tMany:\t63.2286\tMedium:\t42.5714\tFew:\t15.3667\n    > [Best ]\tAcc:\t41.6400\tMany:\t63.2286\tMedium:\t42.5714\tFew:\t15.3667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3924128107388047\nMax state: 6 // Min state: 0\ntensor([6., 6., 6.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [164 | 200]\n---> Epoch: [164 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8888\n    > [Train]\tLoss:\t0.8888\n    > [Test ]\tLoss:\t2.8110\tAcc:\t42.1600\n    > [Test ]\tLoss:\t2.8110\tAcc:\t42.1600\n    > [Stats]\tMany:\t0.6220\tMedium:\t0.4369\tFew:\t0.1700\n    > [Stats]\tMany:\t0.6220\tMedium:\t0.4369\tFew:\t0.1700\n    > [Best ]\tAcc:\t42.1600\tMany:\t62.2000\tMedium:\t43.6857\tFew:\t17.0000\n    > [Best ]\tAcc:\t42.1600\tMany:\t62.2000\tMedium:\t43.6857\tFew:\t17.0000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.386451829222154\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [165 | 200]\n---> Epoch: [165 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8693\n    > [Train]\tLoss:\t0.8693\n    > [Test ]\tLoss:\t2.7773\tAcc:\t42.7700\n    > [Test ]\tLoss:\t2.7773\tAcc:\t42.7700\n    > [Stats]\tMany:\t0.6277\tMedium:\t0.4460\tFew:\t0.1730\n    > [Stats]\tMany:\t0.6277\tMedium:\t0.4460\tFew:\t0.1730\n    > [Best ]\tAcc:\t42.7700\tMany:\t62.7714\tMedium:\t44.6000\tFew:\t17.3000\n    > [Best ]\tAcc:\t42.7700\tMany:\t62.7714\tMedium:\t44.6000\tFew:\t17.3000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3817780850244312\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [166 | 200]\n---> Epoch: [166 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8715\n    > [Train]\tLoss:\t0.8715\n    > [Test ]\tLoss:\t2.7561\tAcc:\t42.8500\n    > [Test ]\tLoss:\t2.7561\tAcc:\t42.8500\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4460\tFew:\t0.1783\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4460\tFew:\t0.1783\n    > [Best ]\tAcc:\t42.8500\tMany:\t62.5429\tMedium:\t44.6000\tFew:\t17.8333\n    > [Best ]\tAcc:\t42.8500\tMany:\t62.5429\tMedium:\t44.6000\tFew:\t17.8333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.376253654120197\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [167 | 200]\n---> Epoch: [167 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8827\n    > [Train]\tLoss:\t0.8827\n    > [Test ]\tLoss:\t2.7136\tAcc:\t43.2100\n    > [Test ]\tLoss:\t2.7136\tAcc:\t43.2100\n    > [Stats]\tMany:\t0.6229\tMedium:\t0.4523\tFew:\t0.1860\n    > [Stats]\tMany:\t0.6229\tMedium:\t0.4523\tFew:\t0.1860\n    > [Best ]\tAcc:\t43.2100\tMany:\t62.2857\tMedium:\t45.2286\tFew:\t18.6000\n    > [Best ]\tAcc:\t43.2100\tMany:\t62.2857\tMedium:\t45.2286\tFew:\t18.6000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3716937471024977\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [168 | 200]\n---> Epoch: [168 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8225\n    > [Train]\tLoss:\t0.8225\n    > [Test ]\tLoss:\t2.7055\tAcc:\t43.3600\n    > [Test ]\tLoss:\t2.7055\tAcc:\t43.3600\n    > [Stats]\tMany:\t0.6223\tMedium:\t0.4540\tFew:\t0.1897\n    > [Stats]\tMany:\t0.6223\tMedium:\t0.4540\tFew:\t0.1897\n    > [Best ]\tAcc:\t43.3600\tMany:\t62.2286\tMedium:\t45.4000\tFew:\t18.9667\n    > [Best ]\tAcc:\t43.3600\tMany:\t62.2286\tMedium:\t45.4000\tFew:\t18.9667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3677151493464117\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [169 | 200]\n---> Epoch: [169 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8609\n    > [Train]\tLoss:\t0.8609\n    > [Test ]\tLoss:\t2.7110\tAcc:\t43.4900\n    > [Test ]\tLoss:\t2.7110\tAcc:\t43.4900\n    > [Stats]\tMany:\t0.6217\tMedium:\t0.4554\tFew:\t0.1930\n    > [Stats]\tMany:\t0.6217\tMedium:\t0.4554\tFew:\t0.1930\n    > [Best ]\tAcc:\t43.4900\tMany:\t62.1714\tMedium:\t45.5429\tFew:\t19.3000\n    > [Best ]\tAcc:\t43.4900\tMany:\t62.1714\tMedium:\t45.5429\tFew:\t19.3000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.364373099845376\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [170 | 200]\n---> Epoch: [170 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.7791\n    > [Train]\tLoss:\t0.7791\n    > [Test ]\tLoss:\t2.6988\tAcc:\t43.6100\n    > [Test ]\tLoss:\t2.6988\tAcc:\t43.6100\n    > [Stats]\tMany:\t0.6271\tMedium:\t0.4560\tFew:\t0.1900\n    > [Stats]\tMany:\t0.6271\tMedium:\t0.4560\tFew:\t0.1900\n    > [Best ]\tAcc:\t43.6100\tMany:\t62.7143\tMedium:\t45.6000\tFew:\t19.0000\n    > [Best ]\tAcc:\t43.6100\tMany:\t62.7143\tMedium:\t45.6000\tFew:\t19.0000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3605399606961033\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [171 | 200]\n---> Epoch: [171 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8277\n    > [Train]\tLoss:\t0.8277\n    > [Test ]\tLoss:\t2.6872\tAcc:\t43.6500\n    > [Test ]\tLoss:\t2.6872\tAcc:\t43.6500\n    > [Stats]\tMany:\t0.6249\tMedium:\t0.4531\tFew:\t0.1973\n    > [Stats]\tMany:\t0.6249\tMedium:\t0.4531\tFew:\t0.1973\n    > [Best ]\tAcc:\t43.6500\tMany:\t62.4857\tMedium:\t45.3143\tFew:\t19.7333\n    > [Best ]\tAcc:\t43.6500\tMany:\t62.4857\tMedium:\t45.3143\tFew:\t19.7333\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3589059029761255\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [172 | 200]\n---> Epoch: [172 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.7876\n    > [Train]\tLoss:\t0.7876\n    > [Test ]\tLoss:\t2.6696\tAcc:\t43.8100\n    > [Test ]\tLoss:\t2.6696\tAcc:\t43.8100\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4557\tFew:\t0.1990\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4557\tFew:\t0.1990\n    > [Best ]\tAcc:\t43.8100\tMany:\t62.5429\tMedium:\t45.5714\tFew:\t19.9000\n    > [Best ]\tAcc:\t43.8100\tMany:\t62.5429\tMedium:\t45.5714\tFew:\t19.9000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.355135822505883\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [173 | 200]\n---> Epoch: [173 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8312\n    > [Train]\tLoss:\t0.8312\n    > [Test ]\tLoss:\t2.6607\tAcc:\t44.3500\n    > [Test ]\tLoss:\t2.6607\tAcc:\t44.3500\n    > [Stats]\tMany:\t0.6229\tMedium:\t0.4663\tFew:\t0.2077\n    > [Stats]\tMany:\t0.6229\tMedium:\t0.4663\tFew:\t0.2077\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.352960909524201\nMax state: 5 // Min state: 0\ntensor([2., 2., 2.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [174 | 200]\n---> Epoch: [174 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8982\n    > [Train]\tLoss:\t0.8982\n    > [Test ]\tLoss:\t2.6820\tAcc:\t44.0600\n    > [Test ]\tLoss:\t2.6820\tAcc:\t44.0600\n    > [Stats]\tMany:\t0.6223\tMedium:\t0.4600\tFew:\t0.2060\n    > [Stats]\tMany:\t0.6223\tMedium:\t0.4600\tFew:\t0.2060\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3496252604950087\nMax state: 5 // Min state: 0\ntensor([1., 1., 1.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [175 | 200]\n---> Epoch: [175 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9231\n    > [Train]\tLoss:\t0.9231\n    > [Test ]\tLoss:\t2.6664\tAcc:\t44.2000\n    > [Test ]\tLoss:\t2.6664\tAcc:\t44.2000\n    > [Stats]\tMany:\t0.6251\tMedium:\t0.4594\tFew:\t0.2080\n    > [Stats]\tMany:\t0.6251\tMedium:\t0.4594\tFew:\t0.2080\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3476036022731304\nMax state: 4 // Min state: 0\ntensor([2., 2., 2.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [176 | 200]\n---> Epoch: [176 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8479\n    > [Train]\tLoss:\t0.8479\n    > [Test ]\tLoss:\t2.6702\tAcc:\t44.1100\n    > [Test ]\tLoss:\t2.6702\tAcc:\t44.1100\n    > [Stats]\tMany:\t0.6269\tMedium:\t0.4569\tFew:\t0.2060\n    > [Stats]\tMany:\t0.6269\tMedium:\t0.4569\tFew:\t0.2060\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.346433074947021\nMax state: 4 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [177 | 200]\n---> Epoch: [177 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8406\n    > [Train]\tLoss:\t0.8406\n    > [Test ]\tLoss:\t2.6711\tAcc:\t44.1300\n    > [Test ]\tLoss:\t2.6711\tAcc:\t44.1300\n    > [Stats]\tMany:\t0.6231\tMedium:\t0.4597\tFew:\t0.2077\n    > [Stats]\tMany:\t0.6231\tMedium:\t0.4597\tFew:\t0.2077\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Best ]\tAcc:\t44.3500\tMany:\t62.2857\tMedium:\t46.6286\tFew:\t20.7667\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3433514651795333\nMax state: 5 // Min state: 0\ntensor([2., 2., 2.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [178 | 200]\n---> Epoch: [178 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8460\n    > [Train]\tLoss:\t0.8460\n    > [Test ]\tLoss:\t2.6546\tAcc:\t44.4000\n    > [Test ]\tLoss:\t2.6546\tAcc:\t44.4000\n    > [Stats]\tMany:\t0.6303\tMedium:\t0.4557\tFew:\t0.2130\n    > [Stats]\tMany:\t0.6303\tMedium:\t0.4557\tFew:\t0.2130\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3417693788350458\nMax state: 6 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [179 | 200]\n---> Epoch: [179 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.7946\n    > [Train]\tLoss:\t0.7946\n    > [Test ]\tLoss:\t2.6744\tAcc:\t44.2000\n    > [Test ]\tLoss:\t2.6744\tAcc:\t44.2000\n    > [Stats]\tMany:\t0.6263\tMedium:\t0.4566\tFew:\t0.2100\n    > [Stats]\tMany:\t0.6263\tMedium:\t0.4566\tFew:\t0.2100\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.341147885592692\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [180 | 200]\n---> Epoch: [180 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8807\n    > [Train]\tLoss:\t0.8807\n    > [Test ]\tLoss:\t2.6717\tAcc:\t44.3600\n    > [Test ]\tLoss:\t2.6717\tAcc:\t44.3600\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4631\tFew:\t0.2087\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4631\tFew:\t0.2087\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Param]\tLR:\t0.00100000\n    > [Param]\tLR:\t0.00100000\n","output_type":"stream"},{"name":"stdout","text":"2.3399177552037784\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [181 | 200]\n---> Epoch: [181 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8693\n    > [Train]\tLoss:\t0.8693\n    > [Test ]\tLoss:\t2.6766\tAcc:\t44.2400\n    > [Test ]\tLoss:\t2.6766\tAcc:\t44.2400\n    > [Stats]\tMany:\t0.6257\tMedium:\t0.4600\tFew:\t0.2080\n    > [Stats]\tMany:\t0.6257\tMedium:\t0.4600\tFew:\t0.2080\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Best ]\tAcc:\t44.4000\tMany:\t63.0286\tMedium:\t45.5714\tFew:\t21.3000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339907532732132\nMax state: 5 // Min state: 0\ntensor([2., 2., 2.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [182 | 200]\n---> Epoch: [182 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8480\n    > [Train]\tLoss:\t0.8480\n    > [Test ]\tLoss:\t2.6531\tAcc:\t44.4000\n    > [Test ]\tLoss:\t2.6531\tAcc:\t44.4000\n    > [Stats]\tMany:\t0.6260\tMedium:\t0.4631\tFew:\t0.2093\n    > [Stats]\tMany:\t0.6260\tMedium:\t0.4631\tFew:\t0.2093\n    > [Best ]\tAcc:\t44.4000\tMany:\t62.6000\tMedium:\t46.3143\tFew:\t20.9333\n    > [Best ]\tAcc:\t44.4000\tMany:\t62.6000\tMedium:\t46.3143\tFew:\t20.9333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339896664795799\nMax state: 5 // Min state: 0\ntensor([1., 1., 1.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [183 | 200]\n---> Epoch: [183 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8128\n    > [Train]\tLoss:\t0.8128\n    > [Test ]\tLoss:\t2.6584\tAcc:\t44.2600\n    > [Test ]\tLoss:\t2.6584\tAcc:\t44.2600\n    > [Stats]\tMany:\t0.6269\tMedium:\t0.4609\tFew:\t0.2063\n    > [Stats]\tMany:\t0.6269\tMedium:\t0.4609\tFew:\t0.2063\n    > [Best ]\tAcc:\t44.4000\tMany:\t62.6000\tMedium:\t46.3143\tFew:\t20.9333\n    > [Best ]\tAcc:\t44.4000\tMany:\t62.6000\tMedium:\t46.3143\tFew:\t20.9333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.3398793161680973\nMax state: 5 // Min state: 0\ntensor([0., 0., 0.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [184 | 200]\n---> Epoch: [184 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.7822\n    > [Train]\tLoss:\t0.7822\n    > [Test ]\tLoss:\t2.6552\tAcc:\t44.3400\n    > [Test ]\tLoss:\t2.6552\tAcc:\t44.3400\n    > [Stats]\tMany:\t0.6257\tMedium:\t0.4611\tFew:\t0.2100\n    > [Stats]\tMany:\t0.6257\tMedium:\t0.4611\tFew:\t0.2100\n    > [Best ]\tAcc:\t44.4000\tMany:\t62.6000\tMedium:\t46.3143\tFew:\t20.9333\n    > [Best ]\tAcc:\t44.4000\tMany:\t62.6000\tMedium:\t46.3143\tFew:\t20.9333\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339858823634058\nMax state: 4 // Min state: 0\ntensor([1., 1., 1.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [185 | 200]\n---> Epoch: [185 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.7971\n    > [Train]\tLoss:\t0.7971\n    > [Test ]\tLoss:\t2.6625\tAcc:\t44.4700\n    > [Test ]\tLoss:\t2.6625\tAcc:\t44.4700\n    > [Stats]\tMany:\t0.6286\tMedium:\t0.4620\tFew:\t0.2100\n    > [Stats]\tMany:\t0.6286\tMedium:\t0.4620\tFew:\t0.2100\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339845397510761\nMax state: 4 // Min state: 0\ntensor([2., 2., 2.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [186 | 200]\n---> Epoch: [186 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8493\n    > [Train]\tLoss:\t0.8493\n    > [Test ]\tLoss:\t2.6682\tAcc:\t44.2200\n    > [Test ]\tLoss:\t2.6682\tAcc:\t44.2200\n    > [Stats]\tMany:\t0.6217\tMedium:\t0.4640\tFew:\t0.2073\n    > [Stats]\tMany:\t0.6217\tMedium:\t0.4640\tFew:\t0.2073\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339815828248691\nMax state: 4 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [187 | 200]\n---> Epoch: [187 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8487\n    > [Train]\tLoss:\t0.8487\n    > [Test ]\tLoss:\t2.6755\tAcc:\t44.1400\n    > [Test ]\tLoss:\t2.6755\tAcc:\t44.1400\n    > [Stats]\tMany:\t0.6231\tMedium:\t0.4614\tFew:\t0.2060\n    > [Stats]\tMany:\t0.6231\tMedium:\t0.4614\tFew:\t0.2060\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339778358484092\nMax state: 5 // Min state: 0\ntensor([2., 2., 2.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [188 | 200]\n---> Epoch: [188 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8733\n    > [Train]\tLoss:\t0.8733\n    > [Test ]\tLoss:\t2.6730\tAcc:\t44.3300\n    > [Test ]\tLoss:\t2.6730\tAcc:\t44.3300\n    > [Stats]\tMany:\t0.6240\tMedium:\t0.4609\tFew:\t0.2120\n    > [Stats]\tMany:\t0.6240\tMedium:\t0.4609\tFew:\t0.2120\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.3397549987245494\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [189 | 200]\n---> Epoch: [189 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9502\n    > [Train]\tLoss:\t0.9502\n    > [Test ]\tLoss:\t2.6679\tAcc:\t44.3700\n    > [Test ]\tLoss:\t2.6679\tAcc:\t44.3700\n    > [Stats]\tMany:\t0.6246\tMedium:\t0.4609\tFew:\t0.2127\n    > [Stats]\tMany:\t0.6246\tMedium:\t0.4609\tFew:\t0.2127\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339733500339645\nMax state: 6 // Min state: 0\ntensor([4., 4., 4.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [190 | 200]\n---> Epoch: [190 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.8355\n    > [Train]\tLoss:\t0.8355\n    > [Test ]\tLoss:\t2.6597\tAcc:\t44.4400\n    > [Test ]\tLoss:\t2.6597\tAcc:\t44.4400\n    > [Stats]\tMany:\t0.6234\tMedium:\t0.4654\tFew:\t0.2110\n    > [Stats]\tMany:\t0.6234\tMedium:\t0.4654\tFew:\t0.2110\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Best ]\tAcc:\t44.4700\tMany:\t62.8572\tMedium:\t46.2000\tFew:\t21.0000\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339708975943722\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [191 | 200]\n---> Epoch: [191 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8656\n    > [Train]\tLoss:\t0.8656\n    > [Test ]\tLoss:\t2.6541\tAcc:\t44.5700\n    > [Test ]\tLoss:\t2.6541\tAcc:\t44.5700\n    > [Stats]\tMany:\t0.6280\tMedium:\t0.4631\tFew:\t0.2127\n    > [Stats]\tMany:\t0.6280\tMedium:\t0.4631\tFew:\t0.2127\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339679472614242\nMax state: 5 // Min state: 0\ntensor([2., 2., 2.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [192 | 200]\n---> Epoch: [192 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8603\n    > [Train]\tLoss:\t0.8603\n    > [Test ]\tLoss:\t2.6798\tAcc:\t44.2100\n    > [Test ]\tLoss:\t2.6798\tAcc:\t44.2100\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.4603\tFew:\t0.2083\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.4603\tFew:\t0.2083\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339660456446881\nMax state: 6 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [193 | 200]\n---> Epoch: [193 | 200]\n    > Max_state: 6, min_state: 0\n    > Max_state: 6, min_state: 0\n    > [Train]\tLoss:\t0.9081\n    > [Train]\tLoss:\t0.9081\n    > [Test ]\tLoss:\t2.6802\tAcc:\t44.4400\n    > [Test ]\tLoss:\t2.6802\tAcc:\t44.4400\n    > [Stats]\tMany:\t0.6229\tMedium:\t0.4663\tFew:\t0.2107\n    > [Stats]\tMany:\t0.6229\tMedium:\t0.4663\tFew:\t0.2107\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.3396390616542013\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [194 | 200]\n---> Epoch: [194 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.9425\n    > [Train]\tLoss:\t0.9425\n    > [Test ]\tLoss:\t2.6828\tAcc:\t44.2500\n    > [Test ]\tLoss:\t2.6828\tAcc:\t44.2500\n    > [Stats]\tMany:\t0.6209\tMedium:\t0.4614\tFew:\t0.2123\n    > [Stats]\tMany:\t0.6209\tMedium:\t0.4614\tFew:\t0.2123\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.3396096383335734\nMax state: 5 // Min state: 0\ntensor([5., 5., 5.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [195 | 200]\n---> Epoch: [195 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8997\n    > [Train]\tLoss:\t0.8997\n    > [Test ]\tLoss:\t2.6487\tAcc:\t44.3800\n    > [Test ]\tLoss:\t2.6487\tAcc:\t44.3800\n    > [Stats]\tMany:\t0.6257\tMedium:\t0.4623\tFew:\t0.2100\n    > [Stats]\tMany:\t0.6257\tMedium:\t0.4623\tFew:\t0.2100\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339582805703971\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [196 | 200]\n---> Epoch: [196 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8870\n    > [Train]\tLoss:\t0.8870\n    > [Test ]\tLoss:\t2.6879\tAcc:\t44.3700\n    > [Test ]\tLoss:\t2.6879\tAcc:\t44.3700\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.4631\tFew:\t0.2103\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.4631\tFew:\t0.2103\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.3395617722889837\nMax state: 5 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [197 | 200]\n---> Epoch: [197 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8554\n    > [Train]\tLoss:\t0.8554\n    > [Test ]\tLoss:\t2.6583\tAcc:\t44.5000\n    > [Test ]\tLoss:\t2.6583\tAcc:\t44.5000\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.4654\tFew:\t0.2120\n    > [Stats]\tMany:\t0.6243\tMedium:\t0.4654\tFew:\t0.2120\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.3395499198365175\nMax state: 5 // Min state: 0\ntensor([4., 4., 4.,  ..., 4., 4., 4.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [198 | 200]\n---> Epoch: [198 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8576\n    > [Train]\tLoss:\t0.8576\n    > [Test ]\tLoss:\t2.6849\tAcc:\t44.3800\n    > [Test ]\tLoss:\t2.6849\tAcc:\t44.3800\n    > [Stats]\tMany:\t0.6246\tMedium:\t0.4600\tFew:\t0.2140\n    > [Stats]\tMany:\t0.6246\tMedium:\t0.4600\tFew:\t0.2140\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.3395286507410598\nMax state: 4 // Min state: 0\ntensor([3., 3., 3.,  ..., 3., 3., 3.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [199 | 200]\n---> Epoch: [199 | 200]\n    > Max_state: 4, min_state: 0\n    > Max_state: 4, min_state: 0\n    > [Train]\tLoss:\t0.8307\n    > [Train]\tLoss:\t0.8307\n    > [Test ]\tLoss:\t2.6638\tAcc:\t44.4000\n    > [Test ]\tLoss:\t2.6638\tAcc:\t44.4000\n    > [Stats]\tMany:\t0.6271\tMedium:\t0.4611\tFew:\t0.2103\n    > [Stats]\tMany:\t0.6271\tMedium:\t0.4611\tFew:\t0.2103\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n","output_type":"stream"},{"name":"stdout","text":"2.339513499706046\nMax state: 5 // Min state: 0\ntensor([2., 2., 2.,  ..., 2., 2., 2.])\n","output_type":"stream"},{"name":"stderr","text":"---> Epoch: [200 | 200]\n---> Epoch: [200 | 200]\n    > Max_state: 5, min_state: 0\n    > Max_state: 5, min_state: 0\n    > [Train]\tLoss:\t0.8699\n    > [Train]\tLoss:\t0.8699\n    > [Test ]\tLoss:\t2.6827\tAcc:\t44.4700\n    > [Test ]\tLoss:\t2.6827\tAcc:\t44.4700\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4626\tFew:\t0.2130\n    > [Stats]\tMany:\t0.6254\tMedium:\t0.4626\tFew:\t0.2130\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Best ]\tAcc:\t44.5700\tMany:\t62.8000\tMedium:\t46.3143\tFew:\t21.2667\n    > [Param]\tLR:\t0.00001000\n    > [Param]\tLR:\t0.00001000\n---> Final performance...\n---> Final performance...\n    > best bAcc (test):\t44.57\n    > best bAcc (test):\t44.57\n    > best statistics:\tMany:\t0.6279999613761902\tMed:\t0.46314284205436707\tFew:\t0.21266667544841766\n    > best statistics:\tMany:\t0.6279999613761902\tMed:\t0.46314284205436707\tFew:\t0.21266667544841766\n---> Training Time: 0:23:59.59\n---> Training Time: 0:23:59.59\n","output_type":"stream"},{"name":"stdout","text":"2.3394950385176614\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming variance_l1_norm is the calculated variance # If you have multiple variances, create a list\n\nplt.figure(figsize=(8, 6))\nplt.plot(range(len(variance_list1)), variance_list1, color='blue', linestyle='-', linewidth=2)\nplt.plot(range(len(variance_list)), variance_list, color='red', linestyle='-', linewidth=2)\nplt.xlabel('Classes')\nplt.ylabel('Variance of L1-norm')\nplt.title('Variance of L1-norm Among Classes')\nplt.xticks(range(len(variance_list1)), [f'Class_{i}' for i in range(len(variance_list1))])\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T14:06:36.394804Z","iopub.execute_input":"2024-01-24T14:06:36.395103Z","iopub.status.idle":"2024-01-24T14:06:38.782804Z","shell.execute_reply.started":"2024-01-24T14:06:36.395071Z","shell.execute_reply":"2024-01-24T14:06:38.781906Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}}]}]}