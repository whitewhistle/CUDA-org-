{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","\n","import argparse, os, shutil, time, random, math\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["bcl.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\"\"\"\n","Author: Yonglong Tian (yonglong@mit.edu)\n","Date: May 07, 2020\n","\"\"\"\n","from __future__ import print_function\n","\n","import torch\n","import torch.nn as nn\n","import math\n","import torch.nn.functional as F\n","import numpy as np\n","\n","\n","\n","class BalSCL(nn.Module):\n","    def __init__(self, cls_num_list=None, temperature=0.1):\n","        super(BalSCL, self).__init__()\n","        self.temperature = temperature\n","        self.cls_num_list = cls_num_list\n","\n","    def forward(self, centers1, features, targets, ):\n","\n","        device = (torch.device('cuda')\n","                  if features.is_cuda\n","                  else torch.device('cpu'))\n","        batch_size = features.shape[0]\n","        targets = targets.contiguous().view(-1, 1)\n","        targets_centers = torch.arange(len(self.cls_num_list), device=device).view(-1, 1)\n","        targets = torch.cat([targets.repeat(2, 1), targets_centers], dim=0)\n","        batch_cls_count = torch.eye(len(self.cls_num_list))[targets].sum(dim=0).squeeze()\n","\n","        mask = torch.eq(targets[:2 * batch_size], targets.T).float().to(device)\n","        logits_mask = torch.scatter(\n","            torch.ones_like(mask),\n","            1,\n","            torch.arange(batch_size * 2).view(-1, 1).to(device),\n","            0\n","        )\n","        mask = mask * logits_mask\n","        \n","        # class-complement\n","        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n","        features = torch.cat([features, centers1], dim=0)\n","        logits = features[:2 * batch_size].mm(features.T)\n","        logits = torch.div(logits, self.temperature)\n","\n","        # For numerical stability\n","        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n","        logits = logits - logits_max.detach()\n","\n","        # class-averaging\n","        exp_logits = torch.exp(logits) * logits_mask\n","        per_ins_weight = torch.tensor([batch_cls_count[i] for i in targets], device=device).view(1, -1).expand(\n","            2 * batch_size, 2 * batch_size + len(self.cls_num_list)) - mask\n","        exp_logits_sum = exp_logits.div(per_ins_weight).sum(dim=1, keepdim=True)\n","        \n","        log_prob = logits - torch.log(exp_logits_sum)\n","        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n","\n","        loss = - mean_log_prob_pos\n","        loss = loss.view(2, batch_size).mean()\n","        return loss\n","\n","\n","\n","\n","class LogitAdjust(nn.Module):\n","\n","    def __init__(self, cls_num_list, tau=1, weight=None):\n","        super(LogitAdjust, self).__init__()\n","        cls_num_list = torch.cuda.FloatTensor(cls_num_list)\n","        cls_p_list = cls_num_list / cls_num_list.sum()\n","        m_list = tau * torch.log(cls_p_list)\n","        self.m_list = m_list.view(1, -1)\n","        self.weight = weight\n","\n","    def forward(self, x, target):\n","        x_m = x + self.m_list\n","        return F.cross_entropy(x_m, target, weight=self.weight)\n","\n","\n","class BCLLoss(nn.Module):\n","    def __init__(self, cls_num_list, tau=1, weight=None, temperature = 0.1, alpha=2.0, beta=0.6 ):\n","        super(BCLLoss, self).__init__()\n","        self.criterion_ce = LogitAdjust(cls_num_list).cuda()\n","        self.criterion_scl = BalSCL(cls_num_list, temperature).cuda()\n","        self.alpha = alpha\n","        self.beta = beta\n","        \n","    def forward(self, centers,  logits, features, targets):\n","        scl_loss = self.criterion_scl(centers, features, targets)\n","        ce_loss = self.criterion_ce(logits, targets)\n","\n","        return self.alpha * ce_loss + self.beta * scl_loss\n","\n","\n","        \n"]},{"cell_type":"markdown","metadata":{},"source":["bs.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BS(nn.Module):\n","    def __init__(self, dist):\n","        super().__init__()\n","        dist = torch.from_numpy(np.array(dist)).float().cuda()\n","        self.prob = dist / sum(dist)\n","        self.log_prior = torch.log(self.prob).unsqueeze(0)\n","        \n","    def forward(self, logits, targets, epoch=None, reduction='mean'):\n","        adjusted_logits = logits + self.log_prior\n","        return F.cross_entropy(adjusted_logits, targets, reduction = reduction)\n","        \n","        \n","        # targets = F.one_hot(targets, num_classes=logits.size(1))\n","        # logits = logits + torch.log(self.prob.view(1, -1).expand(logits.shape[0], -1)).cuda()\n","        \n","        # if reduction == 'none':\n","        #     return -(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n","        # else:\n","        #     return -torch.mean(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))"]},{"cell_type":"markdown","metadata":{},"source":["ce drw"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","class CE_DRW(nn.Module):\n","    \n","    def __init__(self, cls_num_list, reweight_epoch=160):\n","        super(CE_DRW, self).__init__()\n","        self.cls_num_list = cls_num_list\n","        self.reweight_epoch= reweight_epoch\n","        \n","    def drw(self, epoch):\n","        idx = epoch // self.reweight_epoch\n","        betas = [0, 0.9999]\n","        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n","        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n","        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n","        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n","        self.weight = per_cls_weights\n","\n","    def forward(self, x, target, epoch, reduction='mean'):\n","        self.drw(epoch)\n","        return F.cross_entropy(x, target, weight=self.weight, reduction=reduction)"]},{"cell_type":"markdown","metadata":{},"source":["ce"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CE(nn.Module):\n","    def __init__(self, weight=None):\n","        super().__init__()\n","        self.weight = weight\n","    def forward(self, logits, targets, epoch=None, reduction='mean'):\n","        # targets = F.one_hot(targets, num_classes=logits.size(1))\n","        # if reduction == 'mean':\n","        #     return -torch.mean(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n","        # else:\n","        #     return -(torch.sum(F.log_softmax(logits, dim=1) * targets, dim=1))\n","\n","        return F.cross_entropy(logits, targets, weight = self.weight, reduction = reduction)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["ldam drw"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","class LDAM_DRW(nn.Module):\n","    def __init__(self, cls_num_list, reweight_epoch, max_m=0.5, s=30):\n","        super(LDAM_DRW, self).__init__()\n","        self.cls_num_list = cls_num_list\n","        self.reweight_epoch = reweight_epoch\n","        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n","        m_list = m_list * (max_m / np.max(m_list))\n","        m_list = torch.cuda.FloatTensor(m_list)\n","        self.m_list = m_list\n","        assert s > 0\n","        self.s = s\n","      \n","    def drw(self, epoch):\n","        idx = epoch // self.reweight_epoch\n","        betas = [0, 0.9999]\n","        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n","        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n","        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n","        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n","        self.weight = per_cls_weights\n","\n","\n","    def forward(self, x, target, epoch=None, reduction='mean'):\n","        self.drw(epoch)\n","        index = torch.zeros_like(x, dtype=torch.uint8)\n","        index.scatter_(1, target.data.view(-1, 1), 1)\n","        \n","        index_float = index.type(torch.cuda.FloatTensor)\n","        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n","        batch_m = batch_m.view((-1, 1))\n","        x_m = x - batch_m\n","    \n","        output = torch.where(index, x_m, x)\n","        return F.cross_entropy(self.s*output, target, weight=self.weight, reduction=reduction)"]},{"cell_type":"markdown","metadata":{},"source":["ncl"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","def NBOD(inputs, factor):\n","\n","    classifier_num = len(inputs)\n","    if classifier_num == 1:\n","        return 0\n","    logits_softmax = []\n","    logits_logsoftmax = []\n","    for i in range(classifier_num):\n","        logits_softmax.append(F.softmax(inputs[i], dim=1))\n","        logits_logsoftmax.append(torch.log(logits_softmax[i] + 1e-9))\n","\n","    loss_mutual = 0\n","    for i in range(classifier_num):\n","        for j in range(classifier_num):\n","            if i == j:\n","                continue\n","            loss_mutual += factor * F.kl_div(logits_logsoftmax[i], logits_softmax[j],reduction='batchmean')\n","    loss_mutual /= (classifier_num - 1)\n","    return  loss_mutual\n","\n","class NIL_NBOD(nn.Module):\n","    def __init__(self, args, num_class_list):\n","        super(NIL_NBOD, self).__init__()\n","        self.args = args\n","        self.num_class_list = num_class_list\n","        self.bsce_weight = torch.FloatTensor(self.num_class_list).cuda()\n","\n","\n","        self.multi_classifier_diversity_factor = 0.6\n","        self.multi_classifier_diversity_factor_hcm = 0.6\n","        self.ce_ratio = 1.0\n","        self.hcm_ratio = 1.0\n","        if self.args.dataset == 'cifar100':\n","            self.hcm_N = 30\n","        elif self.args.dataset == 'imgnet':\n","            self.hcm_N = 300\n","        elif self.args.dataset == 'places':\n","            self.hcm_N = 122\n","        elif self.args.dataset == 'inat':\n","            self.hcm_N = 2442\n","\n","\n","\n","    def forward(self, inputs, targets, **kwargs):\n","        \"\"\"\n","        Args:\n","            inputs: prediction matrix (before softmax) with shape (classifier_num, batch_size, num_classes)\n","            targets: ground truth labels with shape (classifier_num, batch_size)\n","        \"\"\"\n","        classifier_num = len(inputs)\n","        loss_HCM = 0\n","        loss = 0\n","        los_ce = 0\n","\n","        inputs_HCM_balance = []\n","        inputs_balance = []\n","        class_select = inputs[0].scatter(1, targets[0].unsqueeze(1), 999999)\n","        class_select_include_target = class_select.sort(descending=True, dim=1)[1][:, :self.hcm_N]\n","        mask = torch.zeros_like(inputs[0]).scatter(1, class_select_include_target, 1)\n","        for i in range(classifier_num):\n","\n","            logits = inputs[i] + self.bsce_weight.unsqueeze(0).expand(inputs[i].shape[0], -1).log()\n","            inputs_balance.append(logits)\n","            inputs_HCM_balance.append(logits * mask)\n","\n","            los_ce += F.cross_entropy(logits, targets[0])\n","            loss_HCM += F.cross_entropy(inputs_HCM_balance[i], targets[0])\n","\n","        loss += NBOD(inputs_balance, factor=self.multi_classifier_diversity_factor)\n","        loss += NBOD(inputs_HCM_balance, factor=self.multi_classifier_diversity_factor_hcm)\n","        loss += los_ce * self.ce_ratio + loss_HCM * self.hcm_ratio\n","        return loss\n","\n","    def update(self, epoch):\n","        \"\"\"\n","        Args:\n","           code can be added for progressive loss.\n","        \"\"\"\n","        pass\n","\n","\n","if __name__ == '__main__':\n","    pass"]},{"cell_type":"markdown","metadata":{},"source":["ride"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","import random\n","\n","class RIDE(nn.Module):\n","    def __init__(self, cls_num_list=None, base_diversity_temperature=1.0, max_m=0.5, s=30, reweight=True, reweight_epoch=-1, \n","        base_loss_factor=1.0, additional_diversity_factor=-0.2, reweight_factor=0.05):\n","        super().__init__()\n","        self.base_loss = F.cross_entropy\n","        self.base_loss_factor = base_loss_factor\n","        if not reweight:\n","            self.reweight_epoch = -1\n","        else:\n","            self.reweight_epoch = reweight_epoch\n","\n","        # LDAM is a variant of cross entropy and we handle it with self.m_list.\n","        if cls_num_list is None:\n","            # No cls_num_list is provided, then we cannot adjust cross entropy with LDAM.\n","\n","            self.m_list = None\n","            self.per_cls_weights_enabled = None\n","            self.per_cls_weights_enabled_diversity = None\n","        else:\n","            # We will use LDAM loss if we provide cls_num_list.\n","\n","            m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n","            m_list = m_list * (max_m / np.max(m_list))\n","            m_list = torch.tensor(m_list, dtype=torch.float, requires_grad=False)\n","            self.m_list = m_list\n","            self.s = s\n","            assert s > 0\n","            \n","            if reweight_epoch != -1:\n","                idx = 1 # condition could be put in order to set idx\n","                betas = [0, 0.9999]\n","                effective_num = 1.0 - np.power(betas[idx], cls_num_list)\n","                per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n","                per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(cls_num_list)\n","                self.per_cls_weights_enabled = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False)\n","            else:\n","                self.per_cls_weights_enabled = None\n","\n","            cls_num_list = np.array(cls_num_list) / np.sum(cls_num_list)\n","            C = len(cls_num_list)\n","            per_cls_weights = C * cls_num_list * reweight_factor + 1 - reweight_factor\n","\n","            # Experimental normalization: This is for easier hyperparam tuning, the effect can be described in the learning rate so the math formulation keeps the same.\n","            # At the same time, the 1 - max trick that was previously used is not required since weights are already adjusted.\n","            per_cls_weights = per_cls_weights / np.max(per_cls_weights)\n","\n","            assert np.all(per_cls_weights > 0), \"reweight factor is too large: out of bounds\"\n","            # save diversity per_cls_weights\n","            self.per_cls_weights_enabled_diversity = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False).cuda()\n","\n","        self.base_diversity_temperature = base_diversity_temperature\n","        self.additional_diversity_factor = additional_diversity_factor\n","\n","    def to(self, device):\n","        super().to(device)\n","        if self.m_list is not None:\n","            self.m_list = self.m_list.to(device)\n","        \n","        if self.per_cls_weights_enabled is not None:\n","            self.per_cls_weights_enabled = self.per_cls_weights_enabled.to(device)\n","\n","        if self.per_cls_weights_enabled_diversity is not None:\n","            self.per_cls_weights_enabled_diversity = self.per_cls_weights_enabled_diversity.to(device)\n","\n","        return self\n","\n","    def _hook_before_epoch(self, epoch):\n","        if self.reweight_epoch != -1:\n","            self.epoch = epoch\n","\n","            if epoch > self.reweight_epoch:\n","                self.per_cls_weights_base = self.per_cls_weights_enabled\n","                self.per_cls_weights_diversity = self.per_cls_weights_enabled_diversity\n","            else:\n","                self.per_cls_weights_base = None\n","                self.per_cls_weights_diversity = None\n","\n","    def get_final_output(self, output_logits, target):\n","        x = output_logits\n","\n","        index = torch.zeros_like(x, dtype=torch.uint8, device=x.device)\n","        index.scatter_(1, target.data.view(-1, 1), 1)\n","        \n","        index_float = index.float()\n","        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n","        \n","        batch_m = batch_m.view((-1, 1))\n","        x_m = x - batch_m * self.s\n","\n","        final_output = torch.where(index, x_m, x)\n","        return final_output\n","\n","    def forward(self, output_logits, target, extra_info=None, reduction='mean'):\n","        if extra_info is None:\n","            return self.base_loss(output_logits, target)\n","\n","        if reduction == 'none':\n","            loss = torch.zeros_like(target).float()\n","        else:\n","            loss = 0\n","\n","\n","        # Adding RIDE Individual Loss for each expert\n","        for logits_item in extra_info['logits']:\n","            ride_loss_logits = output_logits if self.additional_diversity_factor == 0 else logits_item\n","            if self.m_list is None:\n","                loss += self.base_loss_factor * self.base_loss(ride_loss_logits, target, reduction=reduction)\n","            else:\n","                final_output = self.get_final_output(ride_loss_logits, target)\n","                loss += self.base_loss_factor * self.base_loss(final_output, target, weight=self.per_cls_weights_base, reduction=reduction)\n","            \n","            base_diversity_temperature = self.base_diversity_temperature\n","\n","            if self.per_cls_weights_diversity is not None:\n","                diversity_temperature = base_diversity_temperature * self.per_cls_weights_diversity.view((1, -1))\n","                temperature_mean = diversity_temperature.mean().item()\n","            else:\n","                diversity_temperature = base_diversity_temperature\n","                temperature_mean = base_diversity_temperature\n","            \n","            output_dist = F.log_softmax(logits_item / diversity_temperature, dim=1)\n","            with torch.no_grad():\n","                # Using the mean takes only linear instead of quadratic time in computing and has only a slight difference so using the mean is preferred here\n","                mean_output_dist = F.softmax(output_logits / diversity_temperature, dim=1)\n","            \n","            loss += self.additional_diversity_factor * temperature_mean * temperature_mean * F.kl_div(output_dist, mean_output_dist, reduction='batchmean')\n","        \n","        return loss\n","\n","class RIDEWithDistill(nn.Module):\n","    def __init__(self, cls_num_list=None, additional_distill_loss_factor=1.0, distill_temperature=1.5, ride_loss_factor=1.0, **kwargs):\n","        super().__init__()\n","        self.ride_loss = RIDE(cls_num_list=cls_num_list, **kwargs)\n","        self.distill_temperature = distill_temperature\n","\n","        self.ride_loss_factor = ride_loss_factor\n","        self.additional_distill_loss_factor = additional_distill_loss_factor\n","\n","    def to(self, device):\n","        super().to(device)\n","        self.ride_loss = self.ride_loss.to(device)\n","        return self\n","\n","    def _hook_before_epoch(self, epoch):\n","        self.ride_loss._hook_before_epoch(epoch)\n","\n","    def forward(self, student, target=None, teacher=None, extra_info=None):\n","        output_logits = student\n","        if extra_info is None:\n","            return self.ride_loss(output_logits, target)\n","\n","        loss = 0\n","        num_experts = len(extra_info['logits'])\n","        for logits_item in extra_info['logits']:\n","            loss += self.ride_loss_factor * self.ride_loss(output_logits, target, extra_info)\n","            distill_temperature = self.distill_temperature\n","\n","            student_dist = F.log_softmax(student / distill_temperature, dim=1)\n","            with torch.no_grad():\n","                teacher_dist = F.softmax(teacher / distill_temperature, dim=1)\n","            \n","            distill_loss = F.kl_div(student_dist, teacher_dist, reduction='batchmean')\n","            distill_loss = distill_temperature * distill_temperature * distill_loss\n","            loss += self.additional_distill_loss_factor * distill_loss\n","        return loss"]},{"cell_type":"markdown","metadata":{},"source":["common.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","\n","import argparse, os, shutil, random, math\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","\n","!pip install progress\n","# added on my own\n","import progress \n","#end\n","\n","from progress.bar import Bar as Bar\n","\n","def make_imb_data(max_num, class_num, gamma):\n","    mu = np.power(1/gamma, 1/(class_num - 1))\n","    class_num_list = []\n","    for i in range(class_num):\n","        if i == (class_num - 1):\n","            class_num_list.append(int(max_num / gamma))\n","        else:\n","            class_num_list.append(int(max_num * np.power(mu, i)))\n","    print(class_num_list)\n","    return list(class_num_list)\n","\n","def hms_string(sec_elapsed):\n","    h = int(sec_elapsed / (60 * 60))\n","    m = int((sec_elapsed % (60 * 60)) / 60)\n","    s = sec_elapsed % 60.\n","    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n","\n","def save_checkpoint(state, epoch, checkpoint='none', filename='checkpoint.pth.tar'):\n","    filepath = os.path.join(checkpoint, filename)\n","    torch.save(state, filepath)\n","    \n","    if epoch % 100 == 0:\n","        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_' + str(epoch) + '.pth.tar'))\n","        \n","def linear_rampup(current, rampup_length=0):\n","    if rampup_length == 0:\n","        return 1.0\n","    else:\n","        current = np.clip(current / rampup_length, 0.0, 1.0)\n","        return float(current)\n","    \n","def adjust_learning_rate(optimizer, epoch, scheduler, args):\n","    if scheduler == None:\n","        if args.epochs == 200:\n","            epoch = epoch + 1\n","            if epoch <= args.warmup:\n","                lr = args.lr * epoch / args.warmup\n","            elif epoch > 180:\n","                lr = args.lr * args.lr_decay ** 2\n","            elif epoch > 160:\n","                lr = args.lr * args.lr_decay\n","            else:\n","                lr = args.lr\n","\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr\n","            return lr\n","\n","        elif args.epochs == 400:\n","            if args.loss_fn == 'bcl':\n","                epoch = epoch + 1\n","                if epoch <= args.warmup:\n","                    lr = args.lr * epoch / args.warmup\n","                elif epoch > 380:\n","                    lr = args.lr * args.lr_decay ** 2\n","                elif epoch > 360:\n","                    lr = args.lr * args.lr_decay\n","                else:\n","                    lr = args.lr\n","\n","                for param_group in optimizer.param_groups:\n","                    param_group['lr'] = lr\n","                return lr\n","            else:\n","                epoch = epoch + 1\n","                if epoch <= args.warmup:\n","                    lr = args.lr * epoch / args.warmup\n","                elif epoch > 360:\n","                    lr = args.lr * args.lr_decay ** 2\n","                elif epoch > 320:\n","                    lr = args.lr * args.lr_decay\n","                else:\n","                    lr = args.lr\n","\n","                for param_group in optimizer.param_groups:\n","                    param_group['lr'] = lr\n","                return lr\n","        else:\n","            return args.lr\n","    else:\n","        scheduler.step()\n","        return optimizer.param_groups[0]['lr']\n","    "]},{"cell_type":"markdown","metadata":{},"source":["loss.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","from bisect import bisect_right\n","\n","\n","\n","#from utils.common import adjust_learning_rate\n","\n","from torch.optim import lr_scheduler\n","\n","def get_optimizer(args, model):\n","    _model = model['model'] if args.loss_fn == 'ncl' else model\n","    return optim.SGD(_model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd,\n","                     nesterov=args.nesterov)\n","\n","def get_scheduler(args, optimizer):\n","    if args.scheduler == 'cosine':\n","        return lr_scheduler.CosineAnnealingLR(optimizer, args.epochs, eta_min = 0)\n","    elif args.scheduler == 'warmup':\n","        return None\n","\n","def get_loss(args, N_SAMPLES_PER_CLASS):\n","    if args.loss_fn == 'ce':\n","        train_criterion = CE()\n","    elif args.loss_fn == 'ce_drw':\n","        train_criterion = CE_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160)\n","    elif args.loss_fn == 'bs':\n","        train_criterion = BS(N_SAMPLES_PER_CLASS)\n","    elif args.loss_fn == 'ldam_drw':\n","        train_criterion = LDAM_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160, max_m=0.5, s=30).cuda()\n","    elif args.loss_fn == 'ride':\n","        if args.num_experts == 3 and args.ride_distill:\n","            train_criterion = RIDEWithDistill(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n","        else:\n","            train_criterion = RIDE(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n","        train_criterion = train_criterion.to(torch.device('cuda'))\n","    elif args.loss_fn == 'ncl':\n","        train_criterion = NIL_NBOD(args, N_SAMPLES_PER_CLASS)\n","\n","    elif args.loss_fn == 'bcl':\n","        train_criterion = BCLLoss(N_SAMPLES_PER_CLASS)\n","\n","    else:\n","        raise NotImplementedError\n","        \n","\n","    return train_criterion\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["cuda.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch as t\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","from torch.utils.data.dataset import Dataset\n","\n","import random\n","import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n","import numpy as np\n","import torch\n","from PIL import Image\n","\n","def CUDA(img,m,n, rand=True, max_d=30):\n","    _augment_list = augment_list()\n","    ops = random.choices(_augment_list, k=n)\n","    m = float(m) / max_d\n","    for op, minval, maxval in ops:\n","        val = (float(m)) * float(maxval - minval) + minval\n","        img = op(img, val)\n","    return img\n","\n","def Flip(img, _):\n","    return PIL.ImageOps.flip(img)\n","\n","def Mirror(img, _):\n","    return PIL.ImageOps.mirror(img)\n","\n","def EdgeEnhance(img, _):\n","    return img.filter(PIL.ImageFilter.EDGE_ENHANCE)\n","\n","def Detail(img, _):\n","    return img.filter(PIL.ImageFilter.DETAIL)\n","\n","def Smooth(img, _):\n","    return img.filter(PIL.ImageFilter.SMOOTH)\n","    \n","def AutoContrast(img, _):\n","    return PIL.ImageOps.autocontrast(img)\n","\n","def Equalize(img, _):\n","    return PIL.ImageOps.equalize(img)\n","\n","def Invert(img, _):\n","    return PIL.ImageOps.invert(img)\n","\n","def GaussianBlur(img, v):\n","    # assert 0 <= v <= 5\n","    filter = PIL.ImageFilter.GaussianBlur(v)\n","    return img.filter(filter)\n","\n","def ResizeCrop(img, v):\n","    # assert 1 <= v <= 2\n","    width, height = img.size\n","    enlarge = img.resize((int(width*v), int(height*v)), Image.ANTIALIAS)\n","    left = int(width*v)//2 - width//2\n","    right = int(width*v)//2 + width//2\n","    top = int(height*v)//2 - height//2\n","    bottom = int(height*v)//2 + height//2\n","    return enlarge.crop((left, top, right, bottom))\n","\n","def Rotate(img, v):  # [-30, 30]\n","    # assert -30 <= v <= 30\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.rotate(v)\n","\n","def Posterize(img, v):  # [4, 8]\n","    v = int(v)\n","    v = max(1, v)\n","    return PIL.ImageOps.posterize(img, v)\n","\n","def Solarize(img, v):  # [0, 256]\n","    # assert 0 <= v <= 256\n","    return PIL.ImageOps.solarize(img, v)\n","\n","def SolarizeAdd(img, addition=0, threshold=128):\n","    img_np = np.array(img).astype(int)\n","    img_np = img_np + addition\n","    img_np = np.clip(img_np, 0, 255)\n","    img_np = img_np.astype(np.uint8)\n","    img = Image.fromarray(img_np)\n","    return PIL.ImageOps.solarize(img, threshold)\n","\n","def Color(img, v):  # [0.1,1.9]\n","    # assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Color(img).enhance(v)\n","\n","def Contrast(img, v):  # [0.1,1.9]Æ’\n","    # assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Contrast(img).enhance(v)\n","\n","def Brightness(img, v):  # [0.1,1.9]\n","    # assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Brightness(img).enhance(v)\n","\n","def Sharpness(img, v):  # [0.1,1.9]\n","    # assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n","\n","def ShearX(img, v):  # [-0.3, 0.3]\n","    # assert -0.3 <= v <= 0.3\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n","\n","def ShearY(img, v):  # [-0.3, 0.3]\n","    # assert -0.3 <= v <= 0.3\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n","\n","def TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    # assert 0 <= v\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n","\n","def TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    # assert 0 <= v\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n","\n","def augment_list():  \n","    l = [\n","        (Flip, 0, 1),\n","        (Mirror, 0, 1),\n","        (EdgeEnhance, 0, 1),\n","        (Detail, 0, 1),\n","        (Smooth, 0, 1),\n","        (AutoContrast, 0, 1),\n","        (Equalize, 0, 1),\n","        (Invert, 0, 1),\n","        (GaussianBlur, 0, 2),\n","        (ResizeCrop,1, 1.5),\n","        (Rotate, 0, 30),\n","        (Posterize, 0, 4),\n","        (Solarize, 0, 256),\n","        (SolarizeAdd, 0, 110),\n","        (Color, 0.1, 1.9),\n","        (Contrast, 0.1, 1.9),\n","        (Brightness, 0.1, 1.9),\n","        (Sharpness, 0.1, 1.9),\n","        (ShearX, 0., 0.3),\n","        (ShearY, 0., 0.3),\n","        (TranslateXabs, 0., 100),\n","        (TranslateYabs, 0., 100),\n","    ]\n","\n","    \n","\n","    return l\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["autoaug.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from PIL import Image, ImageEnhance, ImageOps\n","import numpy as np\n","import random\n","import torch\n","\n","\n","\n","class Cutout(object):\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img\n","\n","class ImageNetPolicy(object):\n","    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n","        Example:\n","        >>> policy = ImageNetPolicy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     ImageNetPolicy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n","            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n","            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n","            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n","\n","            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n","            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n","            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n","            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n","\n","            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n","            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n","            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n","            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n","            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n","\n","            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n","            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n","            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n","            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n","            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n","\n","            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n","            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n","            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n","            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment ImageNet Policy\"\n","\n","\n","class CIFAR10Policy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n","        Example:\n","        >>> policy = CIFAR10Policy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     CIFAR10Policy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n","            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n","            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n","            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n","\n","            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n","            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n","            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n","            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n","            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n","            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n","            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n","            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n","\n","            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n","            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n","            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n","            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n","\n","            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n","            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment CIFAR10 Policy\"\n","\n","\n","class SVHNPolicy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on SVHN.\n","        Example:\n","        >>> policy = SVHNPolicy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     SVHNPolicy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.9, \"shearX\", 4, 0.2, \"invert\", 3, fillcolor),\n","            SubPolicy(0.9, \"shearY\", 8, 0.7, \"invert\", 5, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.6, \"solarize\", 6, fillcolor),\n","            SubPolicy(0.9, \"invert\", 3, 0.6, \"equalize\", 3, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 1, 0.9, \"rotate\", 3, fillcolor),\n","\n","            SubPolicy(0.9, \"shearX\", 4, 0.8, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"shearY\", 8, 0.4, \"invert\", 5, fillcolor),\n","            SubPolicy(0.9, \"shearY\", 5, 0.2, \"solarize\", 6, fillcolor),\n","            SubPolicy(0.9, \"invert\", 6, 0.8, \"autocontrast\", 1, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 3, 0.9, \"rotate\", 3, fillcolor),\n","\n","            SubPolicy(0.9, \"shearX\", 4, 0.3, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"shearY\", 8, 0.7, \"invert\", 4, fillcolor),\n","            SubPolicy(0.9, \"equalize\", 5, 0.6, \"translateY\", 6, fillcolor),\n","            SubPolicy(0.9, \"invert\", 4, 0.6, \"equalize\", 7, fillcolor),\n","            SubPolicy(0.3, \"contrast\", 3, 0.8, \"rotate\", 4, fillcolor),\n","\n","            SubPolicy(0.8, \"invert\", 5, 0.0, \"translateY\", 2, fillcolor),\n","            SubPolicy(0.7, \"shearY\", 6, 0.4, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.6, \"invert\", 4, 0.8, \"rotate\", 4, fillcolor),\n","            SubPolicy(0.3, \"shearY\", 7, 0.9, \"translateX\", 3, fillcolor),\n","            SubPolicy(0.1, \"shearX\", 6, 0.6, \"invert\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"solarize\", 2, 0.6, \"translateY\", 7, fillcolor),\n","            SubPolicy(0.8, \"shearY\", 4, 0.8, \"invert\", 8, fillcolor),\n","            SubPolicy(0.7, \"shearX\", 9, 0.8, \"translateY\", 3, fillcolor),\n","            SubPolicy(0.8, \"shearY\", 5, 0.7, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.7, \"shearX\", 2, 0.1, \"invert\", 5, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment SVHN Policy\"\n","\n","\n","class SubPolicy(object):\n","    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n","        ranges = {\n","            \"shearX\": np.linspace(0, 0.3, 10),\n","            \"shearY\": np.linspace(0, 0.3, 10),\n","            \"translateX\": np.linspace(0, 150 / 331, 10),\n","            \"translateY\": np.linspace(0, 150 / 331, 10),\n","            \"rotate\": np.linspace(0, 30, 10),\n","            \"color\": np.linspace(0.0, 0.9, 10),\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n","            \"solarize\": np.linspace(256, 0, 10),\n","            \"contrast\": np.linspace(0.0, 0.9, 10),\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\n","            \"brightness\": np.linspace(0.0, 0.9, 10),\n","            \"autocontrast\": [0] * 10,\n","            \"equalize\": [0] * 10,\n","            \"invert\": [0] * 10\n","        }\n","\n","        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n","        def rotate_with_fill(img, magnitude):\n","            rot = img.convert(\"RGBA\").rotate(magnitude)\n","            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n","\n","        func = {\n","            \"shearX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"shearY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"translateX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n","                fillcolor=fillcolor),\n","            \"translateY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n","                fillcolor=fillcolor),\n","            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n","            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n","        }\n","\n","        self.p1 = p1\n","        self.operation1 = func[operation1]\n","        self.magnitude1 = ranges[operation1][magnitude_idx1]\n","        self.p2 = p2\n","        self.operation2 = func[operation2]\n","        self.magnitude2 = ranges[operation2][magnitude_idx2]\n","\n","\n","    def __call__(self, img):\n","        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n","        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n","        return img"]},{"cell_type":"markdown","metadata":{},"source":["randaug.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# code in this file is adpated from rpmcruz/autoaugment\n","# https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\n","import random\n","\n","import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n","import numpy as np\n","import torch\n","from PIL import Image\n","\n","\n","def ShearX(img, v):  # [-0.3, 0.3]\n","    assert -0.3 <= v <= 0.3\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n","\n","\n","def ShearY(img, v):  # [-0.3, 0.3]\n","    assert -0.3 <= v <= 0.3\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n","\n","\n","def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    assert -0.45 <= v <= 0.45\n","    if random.random() > 0.5:\n","        v = -v\n","    v = v * img.size[0]\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n","\n","\n","def TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    assert 0 <= v\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n","\n","\n","def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    assert -0.45 <= v <= 0.45\n","    if random.random() > 0.5:\n","        v = -v\n","    v = v * img.size[1]\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n","\n","\n","def TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n","    assert 0 <= v\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n","\n","\n","def Rotate(img, v):  # [-30, 30]\n","    assert -30 <= v <= 30\n","    if random.random() > 0.5:\n","        v = -v\n","    return img.rotate(v)\n","\n","\n","def AutoContrast(img, _):\n","    return PIL.ImageOps.autocontrast(img)\n","\n","\n","def Invert(img, _):\n","    return PIL.ImageOps.invert(img)\n","\n","\n","def Equalize(img, _):\n","    return PIL.ImageOps.equalize(img)\n","\n","\n","def Flip(img, _):  # not from the paper\n","    return PIL.ImageOps.mirror(img)\n","\n","\n","def Solarize(img, v):  # [0, 256]\n","    assert 0 <= v <= 256\n","    return PIL.ImageOps.solarize(img, v)\n","\n","\n","def SolarizeAdd(img, addition=0, threshold=128):\n","    img_np = np.array(img).astype(int)\n","    img_np = img_np + addition\n","    img_np = np.clip(img_np, 0, 255)\n","    img_np = img_np.astype(np.uint8)\n","    img = Image.fromarray(img_np)\n","    return PIL.ImageOps.solarize(img, threshold)\n","\n","\n","def Posterize(img, v):  # [4, 8]\n","    v = int(v)\n","    v = max(1, v)\n","    return PIL.ImageOps.posterize(img, v)\n","\n","\n","def Contrast(img, v):  # [0.1,1.9]\n","    assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Contrast(img).enhance(v)\n","\n","\n","def Color(img, v):  # [0.1,1.9]\n","    assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Color(img).enhance(v)\n","\n","\n","def Brightness(img, v):  # [0.1,1.9]\n","    assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Brightness(img).enhance(v)\n","\n","\n","def Sharpness(img, v):  # [0.1,1.9]\n","    assert 0.1 <= v <= 1.9\n","    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n","\n","\n","\n","\n","def CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n","    # assert 0 <= v <= 20\n","    if v < 0:\n","        return img\n","    w, h = img.size\n","    x0 = np.random.uniform(w)\n","    y0 = np.random.uniform(h)\n","\n","    x0 = int(max(0, x0 - v / 2.))\n","    y0 = int(max(0, y0 - v / 2.))\n","    x1 = min(w, x0 + v)\n","    y1 = min(h, y0 + v)\n","\n","    xy = (x0, y0, x1, y1)\n","    color = (125, 123, 114)\n","    # color = (0, 0, 0)\n","    img = img.copy()\n","    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n","    return img\n","\n","\n","def SamplePairing(imgs):  # [0, 0.4]\n","    def f(img1, v):\n","        i = np.random.choice(len(imgs))\n","        img2 = PIL.Image.fromarray(imgs[i])\n","        return PIL.Image.blend(img1, img2, v)\n","\n","    return f\n","\n","\n","def Identity(img, v):\n","    return img\n","\n","\n","def augment_list():  # 16 oeprations and their ranges\n","    # https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57\n","    # l = [\n","    #     (Identity, 0., 1.0),\n","    #     (ShearX, 0., 0.3),  # 0\n","    #     (ShearY, 0., 0.3),  # 1\n","    #     (TranslateX, 0., 0.33),  # 2\n","    #     (TranslateY, 0., 0.33),  # 3\n","    #     (Rotate, 0, 30),  # 4\n","    #     (AutoContrast, 0, 1),  # 5\n","    #     (Invert, 0, 1),  # 6\n","    #     (Equalize, 0, 1),  # 7\n","    #     (Solarize, 0, 110),  # 8\n","    #     (Posterize, 4, 8),  # 9\n","    #     # (Contrast, 0.1, 1.9),  # 10\n","    #     (Color, 0.1, 1.9),  # 11\n","    #     (Brightness, 0.1, 1.9),  # 12\n","    #     (Sharpness, 0.1, 1.9),  # 13\n","    #     # (Cutout, 0, 0.2),  # 14\n","    #     # (SamplePairing(imgs), 0, 0.4),  # 15\n","    # ]\n","\n","    # https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505\n","    l = [\n","        (AutoContrast, 0, 1),\n","        (Equalize, 0, 1),\n","        (Invert, 0, 1),\n","        (Rotate, 0, 30),\n","        (Posterize, 0, 4),\n","        (Solarize, 0, 256),\n","        (SolarizeAdd, 0, 110),\n","        (Color, 0.1, 1.9),\n","        (Contrast, 0.1, 1.9),\n","        (Brightness, 0.1, 1.9),\n","        (Sharpness, 0.1, 1.9),\n","        (ShearX, 0., 0.3),\n","        (ShearY, 0., 0.3),\n","        (CutoutAbs, 0, 40),\n","        (TranslateXabs, 0., 100),\n","        (TranslateYabs, 0., 100),\n","    ]\n","\n","    return l\n","\n","\n","class Lighting(object):\n","    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n","\n","    def __init__(self, alphastd, eigval, eigvec):\n","        self.alphastd = alphastd\n","        self.eigval = torch.Tensor(eigval)\n","        self.eigvec = torch.Tensor(eigvec)\n","\n","    def __call__(self, img):\n","        if self.alphastd == 0:\n","            return img\n","\n","        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n","        rgb = self.eigvec.type_as(img).clone() \\\n","            .mul(alpha.view(1, 3).expand(3, 3)) \\\n","            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n","            .sum(1).squeeze()\n","\n","        return img.add(rgb.view(3, 1, 1).expand_as(img))\n","\n","\n","class CutoutDefault(object):\n","    \"\"\"\n","    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py\n","    \"\"\"\n","    def __init__(self, length):\n","        self.length = length\n","\n","    def __call__(self, img):\n","        h, w = img.size(1), img.size(2)\n","        mask = np.ones((h, w), np.float32)\n","        y = np.random.randint(h)\n","        x = np.random.randint(w)\n","\n","        y1 = np.clip(y - self.length // 2, 0, h)\n","        y2 = np.clip(y + self.length // 2, 0, h)\n","        x1 = np.clip(x - self.length // 2, 0, w)\n","        x2 = np.clip(x + self.length // 2, 0, w)\n","\n","        mask[y1: y2, x1: x2] = 0.\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img *= mask\n","        return img\n","\n","\n","class RandAugment:\n","    def __init__(self, n, m):\n","        self.n = n\n","        self.m = m      # [0, 30]\n","        self.augment_list = augment_list()\n","\n","    def __call__(self, img):\n","        ops = random.choices(self.augment_list, k=self.n)\n","        for op, minval, maxval in ops:\n","            val = (float(self.m) / 30) * float(maxval - minval) + minval\n","            img = op(img, val)\n","\n","        return img\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["cutout.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","\n","\n","class Cutout(object):\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img\n","    "]},{"cell_type":"markdown","metadata":{},"source":["transformer.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torchvision.transforms import transforms\n","from PIL import ImageFilter\n","import random\n","#from aug.cutout import *\n","\n","cifar10_mean = (0.4914, 0.4822, 0.4465)\n","cifar10_std = (0.2023, 0.1994, 0.2010)\n","\n","\n","\n","class GaussianBlur(object):\n","    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n","\n","    def __init__(self, sigma=[.1, 2.]):\n","        self.sigma = sigma\n","\n","    def __call__(self, x):\n","        sigma = random.uniform(self.sigma[0], self.sigma[1])\n","        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n","        return x\n","\n","\n","\n","def get_transform(loss_fn, cutout = False):\n","    # Augmentations.\n","    if loss_fn in ['ce', 'ldam_drw', 'bs', 'ce_drw', 'ride']:\n","        train_before = [\n","                transforms.RandomCrop(32, padding=4),\n","                transforms.RandomHorizontalFlip(),\n","            ]\n","        \n","        if cutout:\n","            train_after = [\n","                transforms.ToTensor(),\n","                Cutout(n_holes = 1, length = 16),\n","                transforms.Normalize(cifar10_mean, cifar10_std),\n","                ]\n","        else:\n","            train_after = [\n","                transforms.ToTensor(),\n","                transforms.Normalize(cifar10_mean, cifar10_std),\n","                ]\n","\n","        transform_train = [[transforms.Compose(train_before), transforms.Compose(train_after)]]\n","\n","    elif loss_fn in ['ncl']:\n","        regular_train_before = [\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),\n","            ]\n","\n","        if cutout:\n","            regular_train_after = [\n","                transforms.ToTensor(),\n","                Cutout(n_holes = 1, length = 16),\n","                transforms.Normalize(cifar10_mean, cifar10_std),\n","                ]\n","        else:\n","            regular_train_after = [\n","                transforms.ToTensor(),\n","                transforms.Normalize(cifar10_mean, cifar10_std),\n","                ]\n","\n","\n","        sim_cifar_before = [\n","            transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomApply([\n","                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n","            ], p=0.8),\n","            transforms.RandomGrayscale(p=0.2),\n","            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n","            ]\n","        sim_cifar_after = [\n","            transforms.ToTensor(),\n","            transforms.Normalize(cifar10_mean, cifar10_std),\n","            ]\n","        transform_train = [\n","            [transforms.Compose(regular_train_before), \n","            transforms.Compose(regular_train_after)], \n","            [transforms.Compose(sim_cifar_before), \n","            transforms.Compose(sim_cifar_after)],\n","            ]\n","\n","\n","    \n","    elif loss_fn in ['bcl']:\n","        regular_train_before = [\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),\n","            ]\n","\n","        if cutout:\n","            regular_train_after = [\n","                transforms.ToTensor(),\n","                Cutout(n_holes = 1, length = 16),\n","                transforms.Normalize(cifar10_mean, cifar10_std),\n","                ]\n","        else:\n","            regular_train_after = [\n","                transforms.ToTensor(),\n","                transforms.Normalize(cifar10_mean, cifar10_std),\n","                ]\n","        \n","        sim_cifar_before = [\n","            transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomApply([\n","                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n","            ], p=0.8),\n","            transforms.RandomGrayscale(p=0.2),\n","            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n","            ]\n","        sim_cifar_after = [\n","            transforms.ToTensor(),\n","            transforms.Normalize(cifar10_mean, cifar10_std),\n","            ]\n","\n","        transform_train = [\n","            [transforms.Compose(regular_train_before), \n","            transforms.Compose(regular_train_after)], \n","            [transforms.Compose(sim_cifar_before), \n","            transforms.Compose(sim_cifar_after)], \n","            [transforms.Compose(sim_cifar_before), \n","            transforms.Compose(sim_cifar_after)],\n","            ]\n","\n","    transform_val = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(cifar10_mean, cifar10_std)\n","    ])\n","    \n","    return transform_train, transform_val\n","    \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["cifar100.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import random\n","\n","import torchvision\n","import torch\n","\n","from torch.utils.data import Dataset\n","\n","from torchvision.transforms import transforms\n","\n","\n","\n","    \n","def get_cifar100(root, args):\n","    transform_train, transform_val = get_transform(args.loss_fn, cutout = args.cutout)\n","\n","    train_dataset = CIFAR100_train(root, args, imb_ratio = args.imb_ratio, train=True, transform = transform_train, aug_prob=args.aug_prob)\n","    test_dataset = CIFAR100_val(root, transform=transform_val)\n","    print (f\"#Train: {len(train_dataset)}, #Test: {len(test_dataset)}\")\n","    return train_dataset, test_dataset\n","    \n","class test_CIFAR100(Dataset):\n","    def __init__(self, indices, state, cifar_dataset):\n","        self.indices = indices\n","        self.state = state\n","        self.dataset = cifar_dataset\n","\n","    def __getitem__(self,idx):\n","        data, label, _ = self.dataset.get_item(self.indices[idx], self.state[idx], train=False)\n","        return data, label, self.indices[idx], self.state[idx]\n","    \n","    def __len__(self):\n","        return len(self.indices)\n","\n","class CIFAR100_train(torchvision.datasets.CIFAR100):\n","    def __init__(self, root , args, aug_prob, imb_type='exp', imb_ratio=100, train=True, transform=None, target_transform=None, download=True):\n","        super(CIFAR100_train,self).__init__(root, train=train, transform=transform, target_transform = target_transform, download= download)\n","\n","        np.random.seed(0)\n","        self.args = args\n","        self.cls_num = 100\n","        self.img_num_list = self.get_img_num_per_cls(self.cls_num, imb_type, 1./imb_ratio)\n","        self.transform_train = transform\n","        self.gen_imbalanced_data(self.img_num_list)\n","        \n","\n","        if 'autoaug_cifar' in args.aug_type:\n","            print('autoaug_cifar')\n","            self.aug_transform = transforms.Compose([CIFAR10Policy()])\n","        elif 'autoaug_svhn' in args.aug_type:\n","            print('autoaug_svhn')\n","            self.aug_transform = transforms.Compose([SVHNPolicy()])\n","        elif 'autoaug_imagenet' in args.aug_type:\n","            print('autoaug_imagenet')\n","            self.aug_transform = transforms.Compose([ImageNetPolicy()])\n","        #elif 'dada_cifar' in args.aug_type:\n","            print('dada_cifar')\n","            self.aug_transform = transforms.Compose([dada_cifar()])\n","        #elif 'dada_imagenet' in args.aug_type:\n","            print('dada_imagenet')\n","            self.aug_transform = transforms.Compose([dada_imagenet()])\n","        #elif 'faa_cifar' in args.aug_type:\n","            print('faa_cifar')\n","            self.aug_transform = transforms.Compose([faa_cifar()])\n","        #elif 'faa_imagenet' in args.aug_type:\n","            print('faa_imagenet')\n","            self.aug_transform = transforms.Compose([faa_imagenet()])\n","        elif 'randaug' in args.aug_type:\n","            print('randaug')\n","            self.aug_transform = transforms.Compose([RandAugment(2, 14)])\n","        elif 'none' in args.aug_type:\n","            self.aug_transform = transforms.Compose([])\n","        else:\n","            raise NotImplementedError\n","        \n","\n","\n","\n","        # max_mag = 10\n","        # max_ops = 10\n","        max_mag = 10\n","        max_ops = 10\n","        self.min_state = 0\n","        self.max_state = max(max_mag, max_ops) + 1\n","        \n","        states = torch.arange(self.min_state, self.max_state)\n","        if self.max_state == 1:\n","            self.ops = torch.tensor([0])\n","            self.mag = torch.tensor([0])\n","            \n","        elif max_mag > max_ops:\n","            self.ops = (states * max_ops / max_mag).ceil().int()\n","            self.mag = states.int()\n","        else:\n","            self.mag = (states * max_mag / max_ops).ceil().int()\n","            self.ops = states.int()\n","        \n","        print(f\"Magnitude set = {self.mag}\")\n","        print(f\"Operation set = {self.ops}\")\n","\n","        self.curr_state = torch.zeros(len(self.data))\n","        self.score_tmp = torch.zeros((len(self.targets), self.max_state))\n","        self.num_test = torch.zeros((len(self.targets), self.max_state))\n","        self.aug_prob = aug_prob\n","\n","\n","\n","    def get_img_num_per_cls(self, cls_num, imb_type, imb_factor):\n","        img_max = len(self.data) / cls_num\n","        img_num_per_cls = []\n","        if imb_type == 'exp':\n","            for cls_idx in range(cls_num):\n","                num = img_max * (imb_factor ** (cls_idx / (cls_num - 1.0)))\n","                img_num_per_cls.append(int(num))\n","        else:\n","            img_num_per_cls.extend([int(img_max)] * cls_num)\n","        return img_num_per_cls\n","\n","\n","    def gen_imbalanced_data(self, img_num_per_cls):\n","        new_data = []\n","        new_targets = []\n","        #changed from np.int64\n","        targets_np = np.array(self.targets, dtype=int)\n","        classes = np.unique(targets_np)\n","        # np.random.shuffle(classes)\n","\n","        self.num_per_cls_dict = dict()\n","        for the_class, the_img_num in zip(classes, img_num_per_cls):\n","            self.num_per_cls_dict[the_class] = the_img_num\n","            idx = np.where(targets_np == the_class)[0]\n","            np.random.shuffle(idx)\n","            selec_idx = idx[:the_img_num]\n","            # print(selec_idx)\n","            new_data.append(self.data[selec_idx, ...])\n","            new_targets.extend([the_class, ] * the_img_num)\n","        new_data = np.vstack(new_data)\n","        self.data = new_data\n","        self.targets = new_targets\n","\n","    def get_cls_num_list(self):\n","        cls_num_list = []\n","        for i in range(self.cls_num):\n","            cls_num_list.append(self.num_per_cls_dict[i])\n","        return cls_num_list\n","\n","    def sim_aug(self, img, state, type):\n","        if type == 'cuda':\n","            return  CUDA(img, self.mag[state], self.ops[state], max_d = self.args.max_d)\n","        else:\n","            return img\n","        \n","\n","    \n","    def get_item(self, index, state, train=True):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","        \n","        if train:\n","            if len(self.transform_train) == 1:\n","                img = self.transform_train[0][0](img)\n","                img = self.aug_transform(img)\n","                img = CUDA(img, self.mag[state], self.ops[state])\n","                img = self.transform_train[0][1](img)\n","                return img, target, index\n","\n","            elif len(self.transform_train) == 2:\n","                img1 = self.transform_train[0][0](img)\n","                img1 = self.aug_transform(img1)\n","                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n","                img1 = self.transform_train[0][1](img1)\n","\n","                img2 = self.transform_train[1][0](img)\n","                img2 = self.sim_aug(img2, state, self.args.sim_type)\n","                img2 = self.transform_train[1][1](img2)\n","                \n","                return (img1, img2), target, index\n","                \n","            elif len(self.transform_train) == 3:\n","                img1 = self.transform_train[0][0](img)\n","                img1 = self.aug_transform(img1)\n","                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n","                img1 = self.transform_train[0][1](img1)\n","\n","                img2 = self.transform_train[1][0](img)\n","                img2 = self.sim_aug(img2, state, self.args.sim_type)\n","                img2 = self.transform_train[1][1](img2)\n","                \n","                img3 = self.transform_train[2][0](img)\n","                img3 = self.sim_aug(img3, state, self.args.sim_type)\n","                img3 = self.transform_train[2][1](img3)\n","                return (img1, img2, img3), target, index\n","\n","        else:\n","            img = self.transform_train[0][0](img)\n","            img = self.aug_transform(img)\n","            img = CUDA(img, self.mag[state], self.ops[state], rand=False , max_d = self.args.max_d)\n","            img = self.transform_train[0][1](img)\n","            return img, target, index\n","        \n","    def __getitem__(self, index):\n","        state = self.curr_state[index].int() if torch.rand(1) < self.aug_prob else 0\n","        \n","        img, target, index = self.get_item(index, state, train=True)\n","        return img, target, index\n","    \n","    def update_scores(self, correct, index, state):\n","        for s in np.unique(state):\n","            pos = np.where(state == s)\n","            score_result = np.bincount(index[pos], correct[pos], len(self.score_tmp))\n","            num_test_result = np.bincount(index[pos], np.ones(len(index))[pos], len(self.score_tmp))\n","            self.score_tmp[:,s] += score_result\n","            self.num_test[:,s] += num_test_result\n","            \n","\n","    def update(self):\n","        # Increase\n","        pos = torch.where((self.score_tmp == self.num_test) & (self.num_test != 0))\n","        self.curr_state[pos] += 1\n","        \n","        # Decrease\n","        pos = torch.where(self.score_tmp != self.num_test)\n","        self.curr_state[pos] -= 1\n","        \n","        \n","        self.curr_state = torch.clamp(self.curr_state, self.min_state, self.max_state-1)\n","        self.score_tmp *= 0\n","        self.num_test *= 0\n","        \n","    \n","class CIFAR100_val(torchvision.datasets.CIFAR100):\n","    def __init__(self, root, transform=None, indexs=None,\n","                 target_transform=None, download=True):\n","        super(CIFAR100_val, self).__init__(root, train=False, transform=transform, target_transform=target_transform,download=download)\n","        \n","        if indexs is not None:\n","            self.data = self.data[indexs]\n","            self.targets = np.array(self.targets)[indexs]\n","        self.data = [Image.fromarray(img) for img in self.data]\n","        \n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","        return img, target, index"]},{"cell_type":"markdown","metadata":{},"source":["accuracy.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from __future__ import print_function, absolute_import\n","\n","import errno\n","import os\n","import sys\n","import time\n","import math\n","\n","import torch.nn as nn\n","import torch.nn.init as init\n","from torch.autograd import Variable\n","\n","\n","__all__ = ['accuracy', 'AverageMeter']\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].reshape(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\n","       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n","    \"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{},"source":["cutmix.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","def rand_bbox(size, lam):\n","    W = size[2]\n","    H = size[3]\n","    cut_rat = np.sqrt(1. - lam)\n","    cut_w = int(W * cut_rat)\n","    cut_h = int(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W)\n","    cy = np.random.randint(H)\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","\n","    return bbx1, bby1, bbx2, bby2\n","\n","def cutmix(data_f, data_b):\n","    lam = np.random.beta(1., 1.)\n","    bbx1, bby1, bbx2, bby2 = rand_bbox(data_f.size(), lam)\n","    data_b[:, :, bbx1:bbx2, bby1:bby2] = data_f[:, :, bbx1:bbx2, bby1:bby2]\n","    lam = 1-((bbx2 - bbx1) * (bby2 - bby1) / (data_f.size()[2] * data_f.size()[3]))\n","    \n","    return data_b, torch.tensor(lam)\n","\n","# def cutmix(data_aug, data, label, param, percent=1.0):\n","    # data = data_aug\n","    # sample_num = int(len(param)*percent)\n","    # argsort = torch.argsort(param,descending=True)\n","    # param /= torch.max(param)\n","    \n","    # candidate = argsort[:sample_num]\n","    \n","    # data_f = data[candidate]\n","    # label_f = label[candidate]\n","    # param_f = param[candidate]\n","    \n","    # back_perm = candidate[torch.randperm(len(candidate))]\n","    # data_b = data[back_perm]\n","    # label_b = label[back_perm]\n","    # param_b = param[back_perm]\n","    \n","    # # lam = torch.exp(param_f) / (torch.exp(param_f)+torch.exp(param_b))\n","    # lam = torch.tensor(np.random.beta(1.,1.,(sample_num,)))\n","    \n","    # size = data.size()\n","    # W = size[2]\n","    # H = size[3]\n","    # cut_rat = torch.sqrt(1. - lam)\n","    # cut_w = (cut_rat * W).int()\n","    # cut_h = (cut_rat * H).int()\n","\n","    # # uniform\n","    # cx = torch.randint(0,W,(len(candidate),))\n","    # cy = torch.randint(0,H,(len(candidate),))\n","\n","    # bbx1 = torch.clip(cx - cut_w // 2, 0, W)\n","    # bby1 = torch.clip(cy - cut_h // 2, 0, H)\n","    # bbx2 = torch.clip(cx + cut_w // 2, 0, W)\n","    # bby2 = torch.clip(cy + cut_h // 2, 0, H)\n","    \n","    # for idx in range(len(data_b)):\n","    #     data_b[idx, :, bbx1[idx]:bbx2[idx], bby1[idx]:bby2[idx]] = data_f[idx, :, bbx1[idx]:bbx2[idx], bby1[idx]:bby2[idx]]\n","    # data_aug[candidate] = data_b\n","    \n","    # label[candidate] = label_b\n","    # label_aug = torch.zeros(len(label),dtype=int)\n","    # label_aug[candidate] = label_f.cpu()\n","\n","    # ret_lbd = torch.ones(len(label))\n","    # ret_lbd[candidate] -= ((bbx2 - bbx1) * (bby2 - bby1) / (W*H))\n","\n","    # return data_aug, label, label_aug, ret_lbd"]},{"cell_type":"markdown","metadata":{},"source":["basetrain"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","from __future__ import print_function\n","\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","#from aug.cutmix import *\n","\n","#from utils.accuracy import AverageMeter\n","#from utils.common import Bar\n","\n","import copy, time\n","\n","#from datasets.cifar100 import test_CIFAR100\n","import random\n","\n","\n","\n","def update_score_base(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n","    model.eval()\n","    \n","    if posthoc_la:\n","        dist = torch.tensor(n_samples_per_class)\n","        prob = dist / dist.sum()\n","    \n","    curr_state = loader.dataset.curr_state\n","    max_state = torch.max(curr_state).int() + 1\n","    \n","    with torch.no_grad():\n","        n = num_test\n","        pos, state = [], []\n","            \n","        for s in range(max_state):\n","            entire_pos = torch.arange(len(loader.dataset.targets))\n","            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n","            pos +=  _pos\n","            state += [s] * len(_pos)\n","        tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n","        tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n","                                                 shuffle=False, num_workers = 8)\n","        \n","        '''\n","        n = num_test\n","        pos, state = [], []\n","        for cidx in range(len(n_samples_per_class)):\n","            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","            max_state = loader.dataset.curr_state[class_pos[0]].int() \n","            for s in range(max_state+1):\n","                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n","                pos += _pos \n","                state += [s] * len(_pos)\n"," \n","        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n","        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n","        '''\n","\n","        for batch_idx, data_tuple in enumerate(tmp_loader):\n","            data = data_tuple[0].cuda()\n","            label = data_tuple[1]\n","            idx = data_tuple[2]\n","            state = data_tuple[3]\n","\n","            logit = model(data, output_type = None).cpu()\n","\n","            if posthoc_la:\n","                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n","\n","            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n","            loader.dataset.update_scores(correct,idx, state)\n","\n","    \n","    '''\n","    # loader.dataset.update()\n","    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    \n","    for cidx in range(len(n_samples_per_class)):\n","        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","        \n","        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n","        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n","\n","\n","        ratio = correct_sum_row / trial_sum_row \n","        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n","        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n","        \n","        # if correct_sum == trial_sum:\n","        # if float(correct_sum) >= float(trial_sum * 0.6):\n","        if condition:\n","            loader.dataset.curr_state[class_pos] += 1\n","        else:\n","            loader.dataset.curr_state[class_pos] -= 1\n","    '''\n","    \n","\n","    all_indices = torch.arange(len(loader.dataset.targets))\n","    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n","    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n","\n","    ratio = correct_sum_all_classes / trial_sum_all_classes\n","    idx = loader.dataset.curr_state[0].int() + 1\n","    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n","\n","    if condition:\n","            loader.dataset.curr_state[all_indices] += 1\n","    else:\n","            loader.dataset.curr_state[all_indices] -= 1\n","\n","        \n","    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n","    loader.dataset.score_tmp *= 0\n","    loader.dataset.num_test *= 0\n","\n","\n","    # print(f'Max correct: {int(torch.max(correct_sum_per_class))} Max trial: {int(torch.max(trial_sum_per_class))}')\n","    \n","    # loader.dataset.update()\n","    model.train()\n","    \n","    # Debug\n","    curr_state = loader.dataset.curr_state\n","    \n","    label = loader.dataset.targets\n","    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n","\n","    return curr_state, label\n","\n","\n","# def update_score_base(loader, model, n_samples_per_class, posthoc_la):\n","#     model.eval()\n","    \n","#     if posthoc_la:\n","#         dist = torch.tensor(n_samples_per_class)\n","#         prob = dist / dist.sum()\n","    \n","#     # curr_state= loader.dataset.curr_state\n","#     # max_state = torch.max(curr_state).int() + 1\n","    \n","#     with torch.no_grad():\n","#         # pos, state = [], []\n","            \n","#         # for s in range(max_state):\n","#         #     _pos = torch.where(curr_state >= s)[0]\n","#         #     pos_list = _pos.tolist() * (s+1) \n","#         #     pos +=  pos_list\n","#         #     state += [s] * len(pos_list)\n","#         # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n","#         # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n","#         #                                         shuffle=False, num_workers = 8)\n","        \n","#         n = 10\n","#         pos, state = [], []\n","#         for cidx in range(len(n_samples_per_class)):\n","#             class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","#             max_state = loader.dataset.curr_state[class_pos[0]].int() \n","#             for s in range(max_state+1):\n","#                 _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n","#                 pos += _pos \n","#                 state += [s] * len(_pos)\n"," \n","#         tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n","#         tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n","        \n","\n","#         for batch_idx, data_tuple in enumerate(tmp_loader):\n","#             data = data_tuple[0].cuda()\n","#             label = data_tuple[1]\n","#             idx = data_tuple[2]\n","\n","#             logit = model(data, output_type = None).cpu()\n","\n","#             if posthoc_la:\n","#                 logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n","\n","#             correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n","#             loader.dataset.update_scores(correct,idx)\n","#     print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n","    \n","#     # loader.dataset.update()\n","#     for cidx in range(len(n_samples_per_class)):\n","#         class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","        \n","#         correct_sum = torch.sum(loader.dataset.score_tmp[class_pos])\n","#         trial_sum = torch.sum(loader.dataset.num_test[class_pos])\n","\n","#         # if correct_sum == trial_sum:\n","#         if float(correct_sum) >= float(trial_sum * 0.8):\n","#             loader.dataset.curr_state[class_pos] += 1\n","#         else:\n","#             loader.dataset.curr_state[class_pos] -= 1\n","\n","#     loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n","#     loader.dataset.score_tmp *= 0\n","#     loader.dataset.num_test *= 0\n","\n","\n","\n","\n","#     model.train()\n","    \n","#     # Debug\n","#     curr_state = loader.dataset.curr_state\n","#     label = loader.dataset.targets\n","#     print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n","\n","#     return curr_state, label\n","\n","\n","\n","\n","\n","def train_base(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n","    model.train()\n","    \n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    end = time.time()\n","    \n","    bar = Bar('Training', max=len(trainloader))\n","\n","    if args.cmo and 3 < epoch < (args.epochs - 3):\n","        inverse_iter = iter(weighted_trainloader)\n","\n","        \n","    for batch_idx, data_tuple in enumerate(trainloader):\n","        inputs_b = data_tuple[0]\n","        targets_b = data_tuple[1]\n","        indexs = data_tuple[2]\n","\n","\n","        # Measure data loading\n","        data_time.update(time.time() - end)\n","        batch_size = targets_b.size(0)\n","        \n","        if args.cmo and 3 < epoch < (args.epochs - 3):\n","            try:\n","                data_tuple_f = next(inverse_iter)\n","            except:\n","                inverse_iter = iter(weighted_trainloader)\n","                data_tuple_f = next(inverse_iter)\n","\n","            inputs_f = data_tuple_f[0]\n","            targets_f = data_tuple_f[1]\n","            inputs_f = inputs_f[:len(inputs_b)]\n","            targets_f = targets_f[:len(targets_b)]\n","            inputs_f = inputs_f.cuda(non_blocking=True)\n","            targets_f = targets_f.cuda(non_blocking=True)\n","\n","        inputs_b = inputs_b.cuda(non_blocking=True)\n","        targets_b = targets_b.cuda(non_blocking=True)\n","\n","\n","        r = np.random.rand(1)\n","        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n","            inputs_b, lam = cutmix(inputs_f, inputs_b)\n","            outputs = model(inputs_b, None)\n","            loss = criterion(outputs, targets_b, epoch) * lam + criterion(outputs, targets_f, epoch) * (1.-lam)\n","        else:\n","            outputs = model(inputs_b, None)\n","            loss = criterion(outputs, targets_b, epoch)\n","        \n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # record\n","        losses.update(loss.item(), targets_b.size(0))\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        \n","        # plot\n","        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n","                      'Loss: {loss:.4f}'.format(\n","                    batch=batch_idx + 1,\n","                    size=len(trainloader),\n","                    data=data_time.avg,\n","                    bt=batch_time.avg,\n","                    total=bar.elapsed_td,\n","                    eta=bar.eta_td,\n","                    loss=losses.avg,\n","                    )\n","        bar.next()\n","    bar.finish()\n","    return losses.avg\n"]},{"cell_type":"markdown","metadata":{},"source":["bcltrain"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","from __future__ import print_function\n","\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","#from aug.cutmix import *\n","\n","#from utils.accuracy import AverageMeter\n","#from utils.common import Bar\n","\n","import copy, time\n","import random\n","\n","#from datasets.cifar100 import test_CIFAR100\n","\n","\n","\n","def update_score_bcl(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n","    model.eval()\n","    \n","    if posthoc_la:\n","        dist = torch.tensor(n_samples_per_class)\n","        prob = dist / dist.sum()\n","    \n","    # curr_state = loader.dataset.curr_state\n","    # max_state = torch.max(curr_state).int() + 1\n","    \n","    with torch.no_grad():\n","        # pos, state = [], []\n","            \n","        # for s in range(max_state):\n","        #     _pos = torch.where(curr_state >= s)[0]\n","        #     pos_list = _pos.tolist() * (s+1) \n","        #     pos +=  pos_list\n","        #     state += [s] * len(pos_list)\n","        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n","        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n","        #                                         shuffle=False, num_workers = 8)\n","        \n","        n = num_test\n","        pos, state = [], []\n","        for cidx in range(len(n_samples_per_class)):\n","            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","            max_state = loader.dataset.curr_state[class_pos[0]].int() \n","            for s in range(max_state+1):\n","                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n","                pos += _pos \n","                state += [s] * len(_pos)\n"," \n","        \n","        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n","        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n","\n","        for batch_idx, data_tuple in enumerate(tmp_loader):\n","            data = data_tuple[0].cuda()\n","            label = data_tuple[1]\n","            idx = data_tuple[2]\n","            state = data_tuple[3]\n","\n","            _, logit, _ = model(data)\n","            \n","            if posthoc_la:\n","                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n","\n","            correct = (logit.cpu().max(dim=1)[1] == label).int().detach().cpu()\n","            loader.dataset.update_scores(correct,idx, state)\n","\n","\n","            \n","    \n","    # loader.dataset.update()\n","    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    for cidx in range(len(n_samples_per_class)):\n","        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","        \n","        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n","        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n","\n","        ratio = correct_sum_row / trial_sum_row \n","        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n","        condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n","        \n","        # if correct_sum == trial_sum:\n","        # if float(correct_sum) >= float(trial_sum * 0.6):\n","        if condition:\n","            loader.dataset.curr_state[class_pos] += 1\n","        else:\n","            loader.dataset.curr_state[class_pos] -= 1\n","    \n","        \n","\n","    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n","    loader.dataset.score_tmp *= 0\n","    loader.dataset.num_test *= 0\n","\n","    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n","    # print(f'Max correct: {int(torch.max(correct_sum_per_class))} Max trial: {int(torch.max(trial_sum_per_class))}')\n","    \n","    \n","    # loader.dataset.update()\n","    model.train()\n","    \n","    # Debug\n","    curr_state = loader.dataset.curr_state\n","    label = loader.dataset.targets\n","    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n","\n","    return curr_state, label\n","\n","\n","\n","\n","\n","def train_bcl(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n","    model.train()\n","    \n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    end = time.time()\n","    \n","    bar = Bar('Training', max=len(trainloader))\n","        \n","    for batch_idx, data_tuple in enumerate(trainloader):\n","        inputs_b = data_tuple[0]\n","        targets_b = data_tuple[1]\n","        indexs = data_tuple[2]\n","\n","        # Measure data loading\n","        data_time.update(time.time() - end)\n","        batch_size = targets_b.size(0)\n","        \n","        if args.cmo:\n","            raise \"BCL not implemented for CMO...\"\n","        else:\n","            inputs_b = torch.cat([inputs_b[0], inputs_b[1], inputs_b[2]], dim=0).cuda()\n","            batch_size = targets_b.shape[0]\n","            targets_b = targets_b.cuda()\n","            feat_mlp, logits, centers = model(inputs_b)\n","            centers = centers[:args.num_class]\n","            _, f2, f3 = torch.split(feat_mlp, [batch_size, batch_size, batch_size], dim=0)\n","            features = torch.cat([f2.unsqueeze(1), f3.unsqueeze(1)], dim=1)\n","            logits, _, __ = torch.split(logits, [batch_size, batch_size, batch_size], dim=0)\n","            loss = criterion(centers, logits, features, targets_b)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # record\n","        losses.update(loss.item(), targets_b.size(0))\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        \n","        # plot\n","        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n","                      'Loss: {loss:.4f}'.format(\n","                    batch=batch_idx + 1,\n","                    size=len(trainloader),\n","                    data=data_time.avg,\n","                    bt=batch_time.avg,\n","                    total=bar.elapsed_td,\n","                    eta=bar.eta_td,\n","                    loss=losses.avg,\n","                    )\n","        bar.next()\n","    bar.finish()\n","    return losses.avg\n"]},{"cell_type":"markdown","metadata":{},"source":["ncltrain"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","#from utils.accuracy import AverageMeter\n","import torch\n","import time\n","#from utils.common import Bar, adjust_learning_rate\n","\n","import copy\n","\n","#from datasets.cifar100 import test_CIFAR100\n","import random\n","\n","def update_score_ncl(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n","    model = model['model']\n","    model.eval()\n","     \n","    if posthoc_la:\n","        dist = torch.tensor(n_samples_per_class)\n","        prob = dist / dist.sum()\n","    \n","    \n","    # curr_state = loader.dataset.curr_state\n","    # max_state = torch.max(curr_state).int() + 1\n","    \n","    with torch.no_grad():\n","        # pos, state = [], []\n","            \n","        # for s in range(max_state):\n","        #     _pos = torch.where(curr_state >= s)[0]\n","        #     pos_list = _pos.tolist() * (s+1) \n","        #     pos +=  pos_list\n","        #     state += [s] * len(pos_list)\n","        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n","        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,   shuffle=False, num_workers = 8, drop_last=True)\n","        \n","        n = num_test\n","        pos, state = [], []\n","        for cidx in range(len(n_samples_per_class)):\n","            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","            max_state = loader.dataset.curr_state[class_pos[0]].int() \n","            for s in range(max_state+1):\n","                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n","                pos += _pos \n","                state += [s] * len(_pos)\n"," \n","        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n","        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n","        \n","\n","        for batch_idx, data_tuple in enumerate(tmp_loader):\n","            data = data_tuple[0].cuda()\n","            label = data_tuple[1]\n","            idx = data_tuple[2]\n","            state = data_tuple[3]\n","\n","            data_list = [data for i in range(model.network_num)]\n","\n","            feature = model((data_list,data_list), label=label, feature_flag=True)\n","            output_ce, output, output_MA = model(feature, classifier_flag=True)\n","            logit = torch.mean(torch.stack(output_ce), dim=0).cpu()\n","\n","            if posthoc_la:\n","                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1)).cuda()\n","\n","            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n","            loader.dataset.update_scores(correct,idx, state)\n","    \n","    \n"," \n","    \n","    \n","    # loader.dataset.update()\n","    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    for cidx in range(len(n_samples_per_class)):\n","        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","        \n","        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n","        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n","\n","\n","        ratio = correct_sum_row / trial_sum_row \n","        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n","        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n","        \n","        # if correct_sum == trial_sum:\n","        # if float(correct_sum) >= float(trial_sum * 0.6):\n","        if condition:\n","            loader.dataset.curr_state[class_pos] += 1\n","        else:\n","            loader.dataset.curr_state[class_pos] -= 1\n","    \n","        \n","\n","    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n","    loader.dataset.score_tmp *= 0\n","    loader.dataset.num_test *= 0\n","\n","    \n","    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n","    \n","    # loader.dataset.update()\n","    model.train()\n","    \n","    # Debug\n","    curr_state = loader.dataset.curr_state\n","    label = loader.dataset.targets\n","    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n","\n","    return curr_state, label\n","\n","\n","def train_ncl(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher=None):\n","    combiner = model['comb']\n","    model = model['model']\n","    network_num = 3\n","\n","    model.train()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    end = time.time()\n","\n","    bar = Bar('Training', max=len(trainloader))\n","    \n","    for batch_idx, data_tuple in enumerate(trainloader):\n","        inputs = data_tuple[0]\n","        targets = data_tuple[1]\n","        indexs = data_tuple[2]\n","\n","        # Measure data loading\n","        data_time.update(time.time() - end)\n","        batch_size = targets.size(0)\n","\n","        if args.cmo:\n","            raise \"NCL not implemented for CMO...\"\n","        else:\n","            image_list = [inputs] * network_num\n","            label_list = [targets] * network_num\n","            indexs_list = [indexs] * network_num\n","\n","            loss = combiner.forward(model, criterion, image_list, label_list)\n","\n","            if args.dataset in ['cifar100', 'places']:\n","                alpha = 0.999\n","                for net_id in range(network_num):\n","                    net = ['backbone', 'module']\n","                    for name in net:\n","                        for ema_param, param in zip(eval('model.' + name + '_MA').parameters(),\n","                                                    eval('model.' + name).parameters()):\n","                            ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n","\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","\n","        # record\n","        losses.update(loss.data.item(), targets.size(0))\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        \n","        # plot\n","        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n","                      'Loss: {loss:.4f}'.format(\n","                    batch=batch_idx + 1,\n","                    size=len(trainloader),\n","                    data=data_time.avg,\n","                    bt=batch_time.avg,\n","                    total=bar.elapsed_td,\n","                    eta=bar.eta_td,\n","                    loss=losses.avg,\n","                    )\n","        bar.next()\n","    bar.finish()\n","    return losses.avg\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["ridetrain"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","#from aug.cutmix import *\n","\n","#from utils.accuracy import AverageMeter\n","#from utils.common import Bar, adjust_learning_rate\n","\n","import copy\n","\n","#from datasets.cifar100 import test_CIFAR100\n","import random\n","\n","def update_score_ride(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n","    model.eval()\n","    \n","    if posthoc_la:\n","        dist = torch.tensor(n_samples_per_class)\n","        prob = dist / dist.sum()\n","    \n","    curr_state = loader.dataset.curr_state\n","    max_state = torch.max(curr_state).int() + 1\n","    \n","    with torch.no_grad():\n","        n = num_test\n","        pos, state = [], []\n","            \n","\n","    \n","    with torch.no_grad():\n","        pos, state = [], []\n","            \n","        # for s in range(max_state):\n","        #     _pos = torch.where(curr_state >= s)[0]\n","        #     pos_list = _pos.tolist() * (s+1) \n","        #     pos +=  pos_list\n","        #     state += [s] * len(pos_list)\n","        # tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n","        # tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n","        #                                         shuffle=False, num_workers = 8)\n","        \n","        n = num_test\n","        pos, state = [], []\n","        \n","        '''\n","        for cidx in range(len(n_samples_per_class)):\n","            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","            max_state = loader.dataset.curr_state[class_pos[0]].int() \n","            for s in range(max_state+1):\n","                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n","                pos += _pos \n","                state += [s] * len(_pos)\n","        '''\n","        \n","        for s in range(max_state):\n","            entire_pos = torch.arange(len(loader.dataset.targets))\n","            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n","            pos +=  _pos\n","            state += [s] * len(_pos)\n","        \n","\n","        \n","        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n","        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n","        \n","\n","        for batch_idx, data_tuple in enumerate(tmp_loader):\n","            data = data_tuple[0].cuda()\n","            label = data_tuple[1]\n","            idx = data_tuple[2]\n","            state = data_tuple[3]\n","\n","            # logit = model(data, output_type = None).cpu()\n","            # if posthoc_la:\n","            #     logit = logit - tau * torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n","            # correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n","\n","            outputs = model(data, output_type='dict')\n","            logit = outputs['logits'].cpu()\n","\n","            for cor_idx in range(logit.size(1)):\n","                if cor_idx == 0:\n","                    correct = (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n","                else:\n","                    correct += (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n","            \n","            correct = torch.floor(correct/logit.size(1))\n","            loader.dataset.update_scores(correct,idx, state)\n","\n","    all_indices = torch.arange(len(loader.dataset.targets))\n","    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n","    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n","\n","    ratio = correct_sum_all_classes / trial_sum_all_classes\n","    idx = loader.dataset.curr_state[0].int() + 1\n","    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n","\n","    if condition:\n","            loader.dataset.curr_state[all_indices] += 1\n","    else:\n","            loader.dataset.curr_state[all_indices] -= 1 \n","    \n","    '''\n","    # loader.dataset.update()\n","    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n","    for cidx in range(len(n_samples_per_class)):\n","        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n","        \n","        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n","        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n","\n","\n","        ratio = correct_sum_row / trial_sum_row \n","        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n","        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n","        \n","        # if correct_sum == trial_sum:\n","        # if float(correct_sum) >= float(trial_sum * 0.6):\n","        if condition:\n","            loader.dataset.curr_state[class_pos] += 1\n","        else:\n","            loader.dataset.curr_state[class_pos] -= 1\n","    '''\n","        \n","\n","    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n","    loader.dataset.score_tmp *= 0\n","    loader.dataset.num_test *= 0\n","\n","    # print(f'Max correct: {int(torch.max(loader.dataset.score_tmp))} Max trial: {int(torch.max(loader.dataset.num_test))}')\n","    \n","\n","    # loader.dataset.update()\n","    model.train()\n","    \n","    # Debug\n","    curr_state = loader.dataset.curr_state\n","    label = loader.dataset.targets\n","    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n","\n","    return curr_state, label\n","\n","\n","\n","def ride_loss_wrap(criterion, student, teacher, target, extra_info):\n","    if teacher == None:\n","        return criterion(output_logits = student['output'], target = target, extra_info = extra_info)\n","    else:\n","        return criterion(student = student['output'], target = target, teacher = teacher, extra_info = extra_info)\n","\n","def train_ride(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher):\n","    \"\"\"\n","    Training logic for an epoch\n","    \n","    :param epoch: Integer, current training epoch.\n","    :return: A log that contains average loss and metric in this epoch.\n","    \"\"\"\n","    model.train()\n","    \n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    end = time.time()\n","    \n","    if hasattr(criterion, \"_hook_before_epoch\"):\n","        criterion._hook_before_epoch(epoch)\n","        \n","    bar = Bar('Training', max=len(trainloader))\n","\n","\n","    if args.cmo and 3 < epoch < (args.epochs-3):\n","        inverse_iter = iter(weighted_trainloader)\n","\n","    for batch_idx, data_tuple in enumerate(trainloader):\n","        inputs_b = data_tuple[0]\n","        targets_b = data_tuple[1]\n","        indexs = data_tuple[2]\n","        \n","        # Measure data loading\n","        data_time.update(time.time() - end)\n","        batch_size = targets_b.size(0)\n","        \n","        if args.cmo and 3 < epoch < (args.epochs-3):\n","            try:\n","                data_tuple_f = next(inverse_iter)\n","            except:\n","                inverse_iter = iter(weighted_trainloader)\n","                data_tuple_f = next(inverse_iter)\n","                \n","            inputs_f = data_tuple_f[0]\n","            targets_f = data_tuple_f[1]\n","            inputs_f = inputs_f[:len(inputs_b)]\n","            targets_f = targets_f[:len(targets_b)]\n","            inputs_f = inputs_f.cuda(non_blocking=True)\n","            targets_f = targets_f.cuda(non_blocking=True)\n","\n","\n","        inputs_b = inputs_b.cuda(non_blocking=True)\n","        targets_b = targets_b.cuda(non_blocking=True)\n","\n","        r = np.random.rand(1)\n","        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n","            inputs_b, lam = cutmix(inputs_f, inputs_b)\n","            outputs =  model(inputs_b)\n","            extra_info = {}\n","            # logits = outputs[\"logits\"]\n","            # extra_info.update({\"logits\" : logits.transpose(0,1)})\n","            # loss = criterion(output_logits = outputs['output'], target = targets_b, extra_info = extra_info) * lam + criterion(output_logits = outputs['output'], target = targets_f, extra_info = extra_info) * (1.-lam)\n","            if teacher == None:\n","                teacher_outputs = None\n","            else:\n","                teacher_outputs = teacher(inputs_b)['output']\n","            \n","            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n","                \n","            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info) * lam + ride_loss_wrap(criterion, outputs, teacher_outputs, targets_f, extra_info) * (1.-lam)\n","            \n","            \n","        else:\n","            extra_info = {}\n","            outputs = model(inputs_b)\n","            # logits = outputs[\"logits\"]\n","            # extra_info.update({\"logits\": logits.transpose(0, 1)})\n","            # loss = criterion(output_logits=outputs['output'], target=targets_b, extra_info=extra_info)\n","            \n","            if teacher == None:\n","                teacher_outputs = None\n","            else:\n","                teacher_outputs = teacher(inputs_b)['output']\n","            \n","            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n","            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # record\n","        losses.update(loss.item(), targets_b.size(0))\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        \n","        # plot\n","        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n","                      'Loss: {loss:.4f}'.format(\n","                    batch=batch_idx + 1,\n","                    size=len(trainloader),\n","                    data=data_time.avg,\n","                    bt=batch_time.avg,\n","                    total=bar.elapsed_td,\n","                    eta=bar.eta_td,\n","                    loss=losses.avg,\n","                    )\n","        \n","        bar.next()\n","    bar.finish()\n","    return losses.avg\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["train.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#from train.train_fn.base import train_base, update_score_base\n","#from train.train_fn.ride import train_ride, update_score_ride\n","#from train.train_fn.ncl import train_ncl, update_score_ncl\n","#from train.train_fn.bcl import train_bcl, update_score_bcl\n","\n","def get_train_fn(args):\n","    if args.loss_fn == 'ride':\n","        return train_ride\n","    elif args.loss_fn == 'ncl':\n","        return train_ncl\n","    elif args.loss_fn == 'bcl':\n","        return train_bcl\n","    else:\n","        return train_base\n","\n","        \n","        \n","def get_update_score_fn(args):\n","    if args.loss_fn == 'ride':\n","        return update_score_ride\n","    elif args.loss_fn == 'ncl':\n","        return update_score_ncl\n","    elif args.loss_fn == 'bcl':\n","        return update_score_bcl\n","    else:\n","        return update_score_base\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["validate.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#from utils.accuracy import AverageMeter, accuracy\n","from scipy import optimize\n","#from utils.common import Bar\n","import torch\n","import numpy as np\n","import time\n","\n","def get_valid_fn(args):\n","    if args.loss_fn == 'ncl':\n","        return valid_ncl\n","    elif args.loss_fn == 'bcl':\n","        return valid_bcl\n","    else:\n","        return valid_normal\n","\n","\n","def valid_ncl(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats'):\n","    combiner = model['comb']\n","    model = model['model']\n","    network_num = 3\n","    model.eval()\n","    network_num = 3\n","    cnt_all = 0\n","    every_network_result = [0 for _ in range(network_num)]\n","\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","\n","\n","    end = time.time()\n","    bar = Bar(f'{mode}', max=len(valloader))\n","    \n","    classwise_correct = torch.zeros(num_class)\n","    classwise_num = torch.zeros(num_class)\n","    section_acc = torch.zeros(3)\n","    \n","    \n","    with torch.no_grad():\n","        for batch_idx, data_tuple in enumerate(valloader):\n","            image = data_tuple[0]\n","            label = data_tuple[1]\n","            indexs = data_tuple[2]\n","\n","            image, label = image.cuda(), label.cuda()\n","            image_list = [image for i in range(network_num)]\n","\n","            if args.dataset in ['cifar100', 'places']:\n","                feature = model((image_list,image_list), label=label, feature_flag=True)\n","                output_ce, output, output_MA = model(feature, classifier_flag=True)\n","            else:\n","                feature = model(image_list, label=label, feature_flag=True)\n","                output_ce = model(feature, classifier_flag=True)\n","\n","\n","            \n","            for j, logit in enumerate(output_ce):\n","                every_network_result[j] += torch.sum(torch.argmax(logit, dim=1).cpu() == label.cpu())\n","\n","            average_result = torch.mean(torch.stack(output_ce), dim=0)\n","            loss = criterion(average_result, label)\n","\n","            prec1, prec5 = accuracy(average_result.cpu(), label.cpu(), topk=(1,5))\n","            losses.update(loss.data.item(), image.size(0))\n","            top1.update(prec1.item(), image.size(0))\n","            top5.update(prec5.item(), image.size(0))\n","\n","            # classwise prediction\n","            pred_label = average_result.max(1)[1]\n","            pred_mask = (label == pred_label).float()\n","            for i in range(num_class):\n","                class_mask = (label == i).float()\n","                classwise_correct[i] += (class_mask * pred_mask).sum().detach().cpu()\n","                classwise_num[i] += class_mask.sum().detach().cpu()\n","                \n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","                        \n","            # plot progress\n","            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n","                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n","                        batch=batch_idx + 1,\n","                        size=len(valloader),\n","                        data=data_time.avg,\n","                        bt=batch_time.avg,\n","                        total=bar.elapsed_td,\n","                        eta=bar.eta_td,\n","                        loss=losses.avg,\n","                        top1=top1.avg,\n","                        top5=top5.avg,\n","                        )\n","            bar.next()\n","        bar.finish()\n","        \n","    # Major, Neutral, Minor\n","    classwise_acc = (classwise_correct / classwise_num)\n","    \n","    per_class_num = torch.tensor(per_class_num)\n","    many_pos = torch.where(per_class_num > 100)\n","    med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n","    few_pos = torch.where(per_class_num < 20)\n","    section_acc[0] = classwise_acc[many_pos].mean()\n","    section_acc[1] = classwise_acc[med_pos].mean()\n","    section_acc[2] = classwise_acc[few_pos].mean()\n","    \n","    return (losses.avg, top1.avg,  section_acc)\n","\n","def valid_normal(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","    \n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    bar = Bar(f'{mode}', max=len(valloader))\n","    \n","    classwise_correct = torch.zeros(num_class)\n","    classwise_num = torch.zeros(num_class)\n","    section_acc = torch.zeros(3)\n","    \n","    all_preds = np.zeros(len(valloader.dataset))\n","    with torch.no_grad():\n","        for batch_idx, data_tuple in enumerate(valloader):\n","            inputs = data_tuple[0].cuda(non_blocking=True)\n","            targets = data_tuple[1].cuda(non_blocking=True)\n","            indexs = data_tuple[2]\n","            \n","            # measure data loading time\n","            data_time.update(time.time() - end)\n","            \n","            # compute output\n","            outputs = model(inputs, None)\n","            loss = criterion(outputs, targets)\n","\n","            # measure accuracy and record loss\n","            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n","            losses.update(loss.item(), inputs.size(0))\n","            top1.update(prec1.item(), inputs.size(0))\n","            top5.update(prec5.item(), inputs.size(0))\n","            \n","            # classwise prediction\n","            pred_label = outputs.max(1)[1]\n","            all_preds[indexs] = pred_label.cpu().numpy()\n","                \n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","                        \n","            # plot progress\n","            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n","                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n","                        batch=batch_idx + 1,\n","                        size=len(valloader),\n","                        data=data_time.avg,\n","                        bt=batch_time.avg,\n","                        total=bar.elapsed_td,\n","                        eta=bar.eta_td,\n","                        loss=losses.avg,\n","                        top1=top1.avg,\n","                        top5=top5.avg,\n","                        )\n","            bar.next()\n","        bar.finish()\n","        # Major, Neutral, Minor\n","        \n","        all_targets = np.array(valloader.dataset.targets)\n","        pred_mask = (all_targets == all_preds).astype(float)\n","        for i in range(num_class):\n","            class_mask = np.where(all_targets == i)[0].reshape(-1)\n","            classwise_correct[i] += pred_mask[class_mask].sum()\n","            classwise_num[i] += len(class_mask)\n","            \n","        classwise_acc = (classwise_correct / classwise_num)\n","        \n","        per_class_num = torch.tensor(per_class_num)\n","        many_pos = torch.where(per_class_num > 100)\n","        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n","        few_pos = torch.where(per_class_num < 20)\n","        section_acc[0] = classwise_acc[many_pos].mean()\n","        section_acc[1] = classwise_acc[med_pos].mean()\n","        section_acc[2] = classwise_acc[few_pos].mean()\n","\n","    return (losses.avg, top1.avg,  section_acc)\n","\n","\n","def valid_bcl(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","    \n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    bar = Bar(f'{mode}', max=len(valloader))\n","    \n","    classwise_correct = torch.zeros(num_class)\n","    classwise_num = torch.zeros(num_class)\n","    section_acc = torch.zeros(3)\n","    \n","    all_preds = np.zeros(len(valloader.dataset))\n","    with torch.no_grad():\n","        for batch_idx, data_tuple in enumerate(valloader):\n","            inputs = data_tuple[0].cuda(non_blocking=True)\n","            targets = data_tuple[1].cuda(non_blocking=True)\n","            indexs = data_tuple[2]\n","            \n","            # measure data loading time\n","            data_time.update(time.time() - end)\n","            \n","            # compute output\n","            _, outputs, _ = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            # measure accuracy and record loss\n","            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n","            losses.update(loss.item(), inputs.size(0))\n","            top1.update(prec1.item(), inputs.size(0))\n","            top5.update(prec5.item(), inputs.size(0))\n","            \n","            # classwise prediction\n","            pred_label = outputs.max(1)[1]\n","            all_preds[indexs] = pred_label.cpu().numpy()\n","                \n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","                        \n","            # plot progress\n","            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n","                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n","                        batch=batch_idx + 1,\n","                        size=len(valloader),\n","                        data=data_time.avg,\n","                        bt=batch_time.avg,\n","                        total=bar.elapsed_td,\n","                        eta=bar.eta_td,\n","                        loss=losses.avg,\n","                        top1=top1.avg,\n","                        top5=top5.avg,\n","                        )\n","            bar.next()\n","        bar.finish()\n","        # Major, Neutral, Minor\n","        \n","        all_targets = np.array(valloader.dataset.targets)\n","        pred_mask = (all_targets == all_preds).astype(float)\n","        for i in range(num_class):\n","            class_mask = np.where(all_targets == i)[0].reshape(-1)\n","            classwise_correct[i] += pred_mask[class_mask].sum()\n","            classwise_num[i] += len(class_mask)\n","            \n","        classwise_acc = (classwise_correct / classwise_num)\n","        \n","        per_class_num = torch.tensor(per_class_num)\n","        many_pos = torch.where(per_class_num > 100)\n","        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n","        few_pos = torch.where(per_class_num < 20)\n","        section_acc[0] = classwise_acc[many_pos].mean()\n","        section_acc[1] = classwise_acc[med_pos].mean()\n","        section_acc[2] = classwise_acc[few_pos].mean()\n","\n","    return (losses.avg, top1.avg,  section_acc)\n"]},{"cell_type":"markdown","metadata":{},"source":["resnetbcl"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","from torch.nn import Parameter\n","\n","\n","def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","class NormedLinear(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(NormedLinear, self).__init__()\n","        self.weight = Parameter(torch.Tensor(in_features, out_features))\n","        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n","        self.apply(_weights_init)\n","\n","    def forward(self, x):\n","        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n","        return out\n","\n","class LambdaLayer(nn.Module):\n","\n","    def __init__(self, lambd):\n","        super(LambdaLayer, self).__init__()\n","        self.lambd = lambd\n","\n","    def forward(self, x):\n","        return self.lambd(x)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option='A'):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == 'A':\n","                \"\"\"\n","                For CIFAR10 ResNet paper uses option A.\n","                \"\"\"\n","                self.shortcut = LambdaLayer(lambda x:\n","                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n","            elif option == 'B':\n","                self.shortcut = nn.Sequential(\n","                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                     nn.BatchNorm2d(self.expansion * planes)\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet_s(nn.Module):\n","\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet_s, self).__init__()\n","        self.in_planes = 16\n","\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = F.avg_pool2d(out, out.size()[3])\n","        out = out.view(out.size(0), -1)\n","        return out\n","\n","class bcl_model(nn.Module):\n","    def __init__(self, num_classes=100, use_norm=False):\n","        super(bcl_model, self).__init__()\n","        self.encoder = ResNet_s(BasicBlock, [5,5,5], num_classes)\n","        dim_in = 64 #2048\n","        mid_dim = 512 #2048\n","        feat_dim = 128 #1024\n","        self.use_norm = use_norm\n","        self.head = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n","        \n","        if self.use_norm:\n","            self.fc = NormedLinear(dim_in, num_classes)\n","        else:\n","            self.fc = nn.Linear(dim_in, num_classes)\n","        self.head_fc = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n","\n","        self.apply(_weights_init)\n","\n","\n","    def forward(self, x):\n","        feat = self.encoder(x)\n","        feat_mlp = F.normalize(self.head(feat), dim=1)\n","        logits = self.fc(feat)\n","        if self.use_norm:\n","            centers_logits = F.normalize(self.head_fc(self.fc.weight.T), dim=1)\n","        else:\n","            centers_logits = F.normalize(self.head_fc(self.fc.weight), dim=1)\n","        return feat_mlp, logits, centers_logits\n"]},{"cell_type":"markdown","metadata":{},"source":["resnetncl"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","\n","import numpy as np\n","import cv2\n","import os\n","import copy\n","import math\n","from torch.nn.parameter import Parameter\n","\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            inplanes, planes, kernel_size=3, padding=1, bias=False, stride=stride\n","        )\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(\n","            planes, planes, kernel_size=3, padding=1, bias=False, stride=1\n","        )\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        # self.downsample = downsample\n","        if stride != 1 or self.expansion * planes != inplanes:\n","            self.downsample = nn.Sequential(\n","                nn.Conv2d(\n","                    inplanes,\n","                    self.expansion * planes,\n","                    kernel_size=1,\n","                    stride=stride,\n","                    bias=False,\n","                ),\n","                nn.BatchNorm2d(self.expansion * planes),\n","            )\n","        else:\n","            self.downsample = None\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class BottleNeck(nn.Module):\n","\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1):\n","        super(BottleNeck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu1 = nn.ReLU(True)\n","        self.conv2 = nn.Conv2d(\n","            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n","        )\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.relu2 = nn.ReLU(True)\n","        self.conv3 = nn.Conv2d(\n","            planes, planes * self.expansion, kernel_size=1, bias=False\n","        )\n","        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n","        if stride != 1 or self.expansion * planes != inplanes:\n","            self.downsample = nn.Sequential(\n","                nn.Conv2d(\n","                    inplanes,\n","                    self.expansion * planes,\n","                    kernel_size=1,\n","                    stride=stride,\n","                    bias=False,\n","                ),\n","                nn.BatchNorm2d(self.expansion * planes),\n","            )\n","        else:\n","            self.downsample = None\n","        self.relu = nn.ReLU(True)\n","\n","    def forward(self, x):\n","        out = self.relu1(self.bn1(self.conv1(x)))\n","\n","        out = self.relu2(self.bn2(self.conv2(out)))\n","\n","        out = self.bn3(self.conv3(out))\n","\n","        if self.downsample != None:\n","            residual = self.downsample(x)\n","        else:\n","            residual = x\n","        out = out + residual\n","        out = self.relu(out)\n","        return out\n","\n","##kaiming init missing!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","class ResNet(nn.Module):\n","    def __init__(\n","        self,\n","        args,\n","        block_type,\n","        num_blocks,\n","        last_layer_stride=2,\n","    ):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.block = block_type\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(True)\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.layer1 = self._make_layer(num_blocks[0], 64)\n","        self.layer2 = self._make_layer(\n","            num_blocks[1], 128, stride=2\n","        )\n","        self.layer3 = self._make_layer(\n","            num_blocks[2], 256, stride=2\n","        )\n","        self.layer4 = self._make_layer(\n","            num_blocks[3],\n","            512,\n","            stride=last_layer_stride,\n","        )\n","\n","    def load_model(self, pretrain):\n","        print(\"Loading Backbone pretrain model from {}......\".format(pretrain))\n","        model_dict = self.state_dict()\n","        pretrain_dict = torch.load(pretrain)\n","        pretrain_dict = pretrain_dict[\"state_dict\"] if \"state_dict\" in pretrain_dict else pretrain_dict\n","        from collections import OrderedDict\n","\n","        new_dict = OrderedDict()\n","        for k, v in pretrain_dict.items():\n","            if k.startswith(\"module\"):\n","                k = k[7:]\n","            if \"fc\" not in k and \"classifier\" not in k:\n","                k = k.replace(\"backbone.\", \"\")\n","                new_dict[k] = v\n","\n","        model_dict.update(new_dict)\n","        self.load_state_dict(model_dict)\n","        print(\"Backbone model has been loaded......\")\n","\n","    def _make_layer(self, num_block, planes, stride=1):\n","        strides = [stride] + [1] * (num_block - 1)\n","        layers = []\n","        for now_stride in strides:\n","            layers.append(\n","                self.block(\n","                    self.inplanes, planes, stride=now_stride\n","                )\n","            )\n","            self.inplanes = planes * self.block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, **kwargs):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.pool(out)\n","\n","        out = self.layer1(out)\n","        if 'layer' in kwargs and kwargs['layer'] == 'layer1':\n","            out = kwargs['coef']*out + (1-kwargs['coef'])*out[kwargs['index']]\n","        out = self.layer2(out)\n","        if 'layer' in kwargs and kwargs['layer'] == 'layer2':\n","            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n","        out = self.layer3(out)\n","        if 'layer' in kwargs and kwargs['layer'] == 'layer3':\n","            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n","        out = self.layer4(out)\n","        if 'layer' in kwargs and kwargs['layer'] == 'layer4':\n","            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n","        return out\n","\n","def res50(args,last_layer_stride=2):\n","    return ResNet(args,BottleNeck,[3, 4, 6, 3],last_layer_stride=last_layer_stride)\n","    \n","\n","def res152(args,last_layer_stride=2):\n","    return ResNet(args,BottleNeck,[3, 8, 36, 3],last_layer_stride=last_layer_stride)\n","    \n","\n","\n","\n","\n","def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","\n","class LambdaLayer(nn.Module):\n","    def __init__(self, lambd):\n","        super(LambdaLayer, self).__init__()\n","        self.lambd = lambd\n","\n","    def forward(self, x):\n","        return self.lambd(x)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option=\"A\"):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(\n","            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == \"A\":\n","                \"\"\"\n","                For CIFAR10 ResNet paper uses option A.\n","                \"\"\"\n","                self.shortcut = LambdaLayer(\n","                    lambda x: F.pad(\n","                        x[:, :, ::2, ::2],\n","                        (0, 0, 0, 0, planes // 4, planes // 4),\n","                        \"constant\",\n","                        0,\n","                    )\n","                )\n","            elif option == \"B\":\n","                self.shortcut = nn.Sequential(\n","                    nn.Conv2d(\n","                        in_planes,\n","                        self.expansion * planes,\n","                        kernel_size=1,\n","                        stride=stride,\n","                        bias=False,\n","                    ),\n","                    nn.BatchNorm2d(self.expansion * planes),\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet_Cifar(nn.Module):\n","    def __init__(self, block, num_blocks):\n","        super(ResNet_Cifar, self).__init__()\n","        self.in_planes = 16\n","\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","        self.apply(_weights_init)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def load_model(self, pretrain):\n","        print(\"Loading Backbone pretrain model from {}......\".format(pretrain))\n","        model_dict = self.state_dict()\n","        pretrain_dict = torch.load(pretrain)\n","        pretrain_dict = pretrain_dict[\"state_dict\"] if \"state_dict\" in pretrain_dict else pretrain_dict\n","        from collections import OrderedDict\n","\n","        new_dict = OrderedDict()\n","        for k, v in pretrain_dict.items():\n","            if k.startswith(\"module\"):\n","                k = k[7:]\n","            if \"last_linear\" not in k and \"classifier\" not in k and \"linear\" not in k and \"fd\" not in k:\n","                k = k.replace(\"backbone.\", \"\")\n","                k = k.replace(\"fr\", \"layer3.4\")\n","                new_dict[k] = v\n","        model_dict.update(new_dict)\n","        self.load_state_dict(model_dict)\n","        print(\"Backbone model has been loaded......\")\n","\n","    def forward(self, x, **kwargs):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        if 'layer' in kwargs and kwargs['layer'] == 'layer1':\n","            out = kwargs['coef']*out + (1-kwargs['coef'])*out[kwargs['index']]\n","        out = self.layer2(out)\n","        if 'layer' in kwargs and kwargs['layer'] == 'layer2':\n","            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n","        out = self.layer3(out)\n","        if 'layer' in kwargs and kwargs['layer'] == 'layer3':\n","            out = kwargs['coef']*out+(1-kwargs['coef'])*out[kwargs['index']]\n","        return out\n","\n","def res32_cifar(args,last_layer_stride):\n","    return ResNet_Cifar(BasicBlock, [5, 5, 5])\n","    \n","\n","\n","\n","def ncl_model(args, num_class_list):\n","    if args.dataset in ['cifar100', 'places']:\n","        model = multi_Network_MOCO(args, mode=\"train\", num_classes=args.num_class).cuda()\n","        comb = Combiner(args, num_class_list)\n","    else:\n","        model = multi_Network(args, mode=\"train\", num_classes=args.num_class).cuda()\n","        comb = Combiner(args, num_class_list)\n","    return {'comb': comb, 'model': model}\n","\n","class Combiner:\n","    def __init__(self, args, num_class_list=None):\n","        self.args = args\n","\n","        if self.args.dataset in ['cifar100', 'places']:\n","            self.type = 'multi_network_default_CON'\n","        else:\n","            self.type = 'multi_network_default'\n","        \n","        self.num_class_list = torch.FloatTensor(num_class_list)\n","        self.epoch_number = self.args.epochs\n","        self.initilize_all_parameters()\n","\n","    def initilize_all_parameters(self):\n","\n","        if self.args.dataset == 'cifar100':\n","            self.show_step = 100\n","            self.CON_ratio = 1.0    \n","            self.distributed = False\n","        elif self.args.dataset == 'places':\n","            self.show_step = 200\n","            self.CON_ratio = 1.0    \n","            self.distributed = True\n","        elif self.args.dataset == 'imgnet':\n","            self.show_step = 200\n","            self.CON_ratio = 0.0\n","            self.distributed = True\n","        elif self.args.dataset == 'inat':\n","            self.show_step = 500\n","            self.CON_ratio = 0.0\n","            self.distributed = True\n","\n","    def update(self, epoch):\n","        self.epoch = epoch\n","\n","\n","    def forward(self, model, criterion, image, label):\n","        return eval(\"self.{}\".format(self.type))(model, criterion, image, label)\n","\n","\n","    def multi_network_default(self, model, criterion, image, label):\n","\n","        for i in range(len(image)):\n","            image[i], label[i] = image[i].cuda(), label[i].cuda()\n","\n","\n","        feature = model(image, feature_flag=True, label=label)\n","        output = model(feature, classifier_flag=True)\n","\n","        loss = criterion(output, label)\n","\n","        average_result = torch.mean(torch.stack(output), dim=0)\n","        \n","        return loss\n","\n","    def multi_network_default_CON(self, model, criterion, image, label):\n","\n","        image_p = []\n","        image_k = []\n","        for i in range(len(image)):\n","            image_p.append(image[i][0].cuda())\n","            image_k.append(image[i][1].cuda())\n","            label[i] = label[i].cuda()\n","\n","        # shuffle BN\n","        if self.distributed:\n","            image_k, idx_unshuffle = shuffle_BN_DDP(image_k)\n","            pass\n","        else:\n","            image_k, idx_unshuffle = shuffle_BN(image_k)\n","\n","\n","        feature = model((image_p, image_k), feature_flag=True, label=label)\n","        output_ce, output_p, output_k = model(feature, classifier_flag=True)\n","\n","        # unshuffle\n","        if self.distributed:\n","            output_k = unshuffle_BN_DDP(output_k, idx_unshuffle)\n","        else:\n","            output_k = unshuffle_BN(output_k, idx_unshuffle)\n","\n","        loss_ce = criterion(output_ce, label, feature=feature, classifier=model.classifier)\n","\n","        average_result = torch.mean(torch.stack(output_ce), dim=0)\n","        \n","        # contrastive_loss\n","        loss_CON = 0\n","        for i, (q, k) in enumerate(zip(output_p, output_k)):\n","            q = F.normalize(q, dim=1)\n","            k = F.normalize(k, dim=1)\n","            # compute logits\n","            # Einstein sum is more intuitive\n","            # positive logits: Nx1\n","            l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n","            # negative logits: NxK\n","            l_neg = torch.einsum('nc,ck->nk', [q, model.MOCO[i].queue.clone().detach()])\n","\n","            # logits: Nx(1+K)\n","            logits = torch.cat([l_pos, l_neg], dim=1)\n","\n","            # apply temperature\n","            logits /= model.MOCO[i].T\n","\n","            # labels: positive key indicators\n","            labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n","\n","            # dequeue and enqueue\n","            if self.distributed:\n","                model.MOCO[i]._dequeue_and_enqueue_DDP(k)\n","            else:\n","                model.MOCO[i]._dequeue_and_enqueue(k)\n","\n","\n","            loss_CON += F.cross_entropy(logits, labels)\n","\n","        loss = loss_ce + loss_CON * self.CON_ratio\n","\n","        return loss\n","\n","\n","\n","class FCNorm(nn.Module):\n","    def __init__(self, num_features, num_classes):\n","        super(FCNorm, self).__init__()\n","        self.weight = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n","        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n","\n","    def forward(self, x):\n","        out = F.linear(F.normalize(x), F.normalize(self.weight))\n","        return out\n","\n","\n","class GAP(nn.Module):\n","    \"\"\"Global Average pooling\n","        Widely used in ResNet, Inception, DenseNet, etc.\n","     \"\"\"\n","\n","    def __init__(self):\n","        super(GAP, self).__init__()\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","    def forward(self, x):\n","        x = self.avgpool(x)\n","        #         x = x.view(x.shape[0], -1)\n","        return x\n","\n","class Identity(nn.Module):\n","    def __init__(self):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, x):\n","        return x\n","\n","\n","@torch.no_grad()\n","def concat_all_gather(tensor):\n","    \"\"\"\n","    Performs all_gather operation on the provided tensors.\n","    *** Warning ***: torch.distributed.all_gather has no gradient.\n","    \"\"\"\n","    #with torch.no_grad():\n","    tensors_gather = [torch.ones_like(tensor)\n","        for _ in range(torch.distributed.get_world_size())]\n","    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n","\n","    output = torch.cat(tensors_gather, dim=0)\n","    return output\n","\n","@torch.no_grad()\n","def shuffle_BN(image):\n","    #with torch.no_grad():\n","    batch_size = image[0].shape[0]\n","    idx_shuffle = torch.randperm(batch_size).cuda()\n","    for i in range(len(image)):\n","        image[i] = image[i][idx_shuffle]\n","    idx_unshuffle = torch.argsort(idx_shuffle)\n","    return image, idx_unshuffle\n","\n","@torch.no_grad()\n","def shuffle_BN_DDP(x):\n","    \"\"\"\n","    Batch shuffle, for making use of BatchNorm.\n","    *** Only support DistributedDataParallel (DDP) model. ***\n","    \"\"\"\n","    # gather from all gpus\n","\n","    #with torch.no_grad():\n","    shuffle_list = []\n","    idx_shuffle = 0\n","    for i in range(len(x)):\n","        batch_size_this = x[i].shape[0]\n","        x_gather = concat_all_gather(x[i])\n","        batch_size_all = x_gather.shape[0]\n","\n","        num_gpus = batch_size_all // batch_size_this\n","\n","        # random shuffle index\n","        if i == 0:\n","            idx_shuffle = torch.randperm(batch_size_all).cuda()\n","            # index for restoring\n","            idx_unshuffle = torch.argsort(idx_shuffle)\n","\n","        # broadcast to all gpus\n","        torch.distributed.broadcast(idx_shuffle, src=0)\n","\n","\n","\n","        # shuffled index for this gpu\n","        gpu_idx = torch.distributed.get_rank()\n","        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n","        shuffle_list.append(x_gather[idx_this])\n","\n","    return shuffle_list, idx_unshuffle\n","\n","@torch.no_grad()\n","def unshuffle_BN(x, idx_unshuffle):\n","    #with torch.no_grad():\n","    for i in range(len(x)):\n","        x[i] = x[i][idx_unshuffle]\n","    return x\n","\n","@torch.no_grad()\n","def unshuffle_BN_DDP(x, idx_unshuffle):\n","    \"\"\"\n","    Undo batch shuffle.\n","    *** Only support DistributedDataParallel (DDP) model. ***\n","    \"\"\"\n","    # gather from all gpus\n","   # with torch.no_grad():\n","    unshuffle_list = []\n","    for i in range(len(x)):\n","        batch_size_this = x[i].shape[0]\n","        x_gather = concat_all_gather(x[i])\n","        batch_size_all = x_gather.shape[0]\n","\n","        num_gpus = batch_size_all // batch_size_this\n","\n","        # restored index for this gpu\n","        gpu_idx = torch.distributed.get_rank()\n","        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n","        unshuffle_list.append(x_gather[idx_this])\n","\n","    return unshuffle_list\n","\n","class MoCo(nn.Module):\n","    \"\"\"\n","    Build a MoCo model with: a query encoder, a key encoder, and a queue\n","    https://arxiv.org/abs/1911.05722\n","    \"\"\"\n","    def __init__(self, dim=128, K=65536, m=0.999, T=0.07):\n","        \"\"\"\n","        dim: feature dimension (default: 128)\n","        K: queue size; number of negative keys (default: 65536)\n","        m: moco momentum of updating key encoder (default: 0.999)\n","        T: softmax temperature (default: 0.07)\n","        \"\"\"\n","        super(MoCo, self).__init__()\n","\n","        self.K = K\n","        self.m = m\n","        self.T = T\n","\n","        # create the queue\n","        self.register_buffer(\"queue\", torch.randn(dim, K))\n","        self.queue = nn.functional.normalize(self.queue, dim=0)\n","\n","        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n","\n","\n","\n","    @torch.no_grad()\n","    def _dequeue_and_enqueue_DDP(self, keys):\n","        # gather keys before updating queue\n","        keys = concat_all_gather(keys)\n","\n","        batch_size = keys.shape[0]\n","\n","        ptr = int(self.queue_ptr)\n","\n","        assert self.K % batch_size == 0  # for simplicity\n","\n","        # replace the keys at ptr (dequeue and enqueue)\n","        self.queue[:, ptr:ptr + batch_size] = keys.T\n","        ptr = (ptr + batch_size) % self.K  # move pointer\n","\n","        self.queue_ptr[0] = ptr\n","\n","    @torch.no_grad()\n","    def _dequeue_and_enqueue(self, keys, **kwargs):\n","\n","        batch_size = keys.shape[0]\n","\n","        ptr = int(self.queue_ptr)\n","\n","        assert self.K % batch_size == 0  # for simplicity\n","\n","        # replace the keys at ptr (dequeue and enqueue)\n","        self.queue[:, ptr:ptr + batch_size] = keys.T\n","\n","        ptr = (ptr + batch_size) % self.K  # move pointer\n","\n","        self.queue_ptr[0] = ptr\n","\n","class Cos_Classifier(nn.Module):\n","    \"\"\" plain cosine classifier \"\"\"\n","\n","    def __init__(self, num_classes=10, in_dim=640, scale=16, bias=False):\n","        super(Cos_Classifier, self).__init__()\n","        self.scale = scale\n","        self.weight = Parameter(torch.Tensor(num_classes, in_dim).cuda())\n","        self.bias = Parameter(torch.Tensor(num_classes).cuda(), requires_grad=bias)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        self.bias.data.fill_(0.)\n","        stdv = 1. / math.sqrt(self.weight.size(1))\n","        self.weight.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, x, **kwargs):\n","        ex = x / torch.norm(x.clone(), 2, 1, keepdim=True)\n","        ew = self.weight / torch.norm(self.weight, 2, 1, keepdim=True)\n","        out = torch.mm(ex, self.scale * ew.t()) + self.bias\n","        return out\n","\n","class multi_Network(nn.Module):\n","    def __init__(self, args, mode=\"train\", num_classes=1000):\n","        super(multi_Network, self).__init__()\n","        \n","        self.num_classes = num_classes\n","        self.args = args\n","        self.network_num = 3\n","        \n","        \n","        if self.args.dataset == 'cifar100':\n","            self.args.net_type = 'res32_cifar'\n","            self.args.cf = 'FC'\n","            self.args.cos_scale = 16\n","        elif self.args.dataset == 'imgnet':\n","            self.args.net_type = 'res50'\n","            self.args.cf = 'COS'\n","            self.args.cos_scale = 16\n","        elif self.args.dataset == 'inat':\n","            self.args.net_type = 'res50'\n","            self.args.cf = 'COS'\n","            self.args.cos_scale = 32\n","            \n","\n","        self.backbone = nn.ModuleList(\n","            eval(self.args.net_type)(\n","                self.args,\n","                last_layer_stride=2,\n","            ) for i in range(self.network_num))\n","\n","        self.module = nn.ModuleList(\n","            self._get_module()\n","            for i in range(self.network_num))\n","\n","        \n","        self.classifier = nn.ModuleList(\n","            self._get_multi_classifer(True, self.cf)\n","            for i in range(self.network_num))\n","\n","    def forward(self, input, **kwargs):\n","\n","        if \"feature_flag\" in kwargs:\n","            return self.extract_feature(input, **kwargs)\n","        elif \"classifier_flag\" in kwargs:\n","            return self.get_logits(input, **kwargs)\n","\n","        logits = []\n","        for i in range(self.network_num):\n","            x = (self.backbone[i])(input[i], **kwargs)\n","            x = (self.module[i])(x)\n","            x = x.view(x.shape[0], -1)\n","            self.feat.append(copy.deepcopy(x))\n","            x = (self.classifier[i])(x)\n","            logits.append(x)\n","\n","        return logits\n","\n","    def extract_feature(self, input, **kwargs):\n","\n","        feature = []\n","        for i in range(self.network_num):\n","            x = (self.backbone[i])(input[i])\n","            x = (self.module[i])(x)\n","            x = x.view(x.shape[0], -1)\n","            feature.append(x)\n","\n","        return feature\n","\n","    def get_logits(self, input, **kwargs):\n","\n","        logits = []\n","        for i in range(self.network_num):\n","            x = input[i]\n","            x = (self.classifier[i])(x)\n","            logits.append(x)\n","\n","        return logits\n","\n","    def extract_feature_maps(self, x):\n","        x = self.backbone(x)\n","        return x\n","\n","    def freeze_multi_backbone(self):\n","        print(\"Freezing backbone .......\")\n","        for p in self.backbone.parameters():\n","            p.requires_grad = False\n","\n","    def load_backbone_model(self, backbone_path=\"\"):\n","        self.backbone.load_model(backbone_path)\n","        print(\"Backbone model has been loaded...\")\n","\n","    def load_model(self, model_path, **kwargs):\n","        pretrain_dict = torch.load(\n","            model_path, map_location=\"cuda\"\n","        )\n","        pretrain_dict = pretrain_dict['state_dict'] if 'state_dict' in pretrain_dict else pretrain_dict\n","        model_dict = self.state_dict()\n","        from collections import OrderedDict\n","        new_dict = OrderedDict()\n","        for k, v in pretrain_dict.items():\n","            if 'backbone_only' in kwargs.keys() and 'classifier' in k:\n","                continue;\n","            if k.startswith(\"module\"):\n","                if k[7:] not in model_dict.keys():\n","                    print('not load:{}'.format(k))\n","                new_dict[k[7:]] = v\n","            else:\n","                new_dict[k] = v\n","        model_dict.update(new_dict)\n","        self.load_state_dict(model_dict)\n","        print(\"All model has been loaded...\")\n","\n","    def get_feature_length(self):\n","        if \"cifar\" in self.args.net_type:\n","            num_features = 64\n","        else:\n","            num_features = 2048\n","        return num_features\n","\n","    def _get_module(self):\n","        module = GAP()\n","        return module\n","\n","    def _get_multi_classifer(self, bias_flag, type):\n","\n","        num_features = self.get_feature_length()\n","        if type == \"FCNorm\":\n","            classifier = FCNorm(num_features, self.num_classes)\n","        elif type == \"FC\":\n","            classifier = nn.Linear(num_features, self.num_classes, bias=bias_flag)\n","        elif type == 'cos':\n","            classifier = Cos_Classifier(self.num_classes, num_features, scale=self.args.cos_scale, bias=bias_flag)\n","        else:\n","            raise NotImplementedError\n","\n","        return classifier\n","\n","class multi_Network_MOCO(nn.Module):\n","    def __init__(self, args, mode=\"train\", num_classes=1000):\n","        super(multi_Network_MOCO, self).__init__()\n","        \n","        self.args = args\n","        self.num_classes = num_classes\n","        self.network_num = 3\n","        \n","        if self.args.dataset == 'cifar100':\n","            self.args.net_type = 'res32_cifar'\n","            self.args.cf = 'FC'\n","            self.args.scf = 'mlp'\n","            self.args.cos_scale = 16\n","            self.args.moco_dim = 64\n","            self.args.mlp_dim = self.args.moco_dim\n","            self.args.moco_k = 1024\n","            self.args.moco_t = 0.2\n","        \n","        elif self.args.dataset == 'imgnet':\n","            self.args.net_type = 'res50'\n","            self.args.cf = 'COS'\n","            self.args.cos_scale = 16\n","\n","        elif self.args.dataset == 'inat':\n","            self.args.net_type = 'res50'\n","            self.args.cf = 'COS'\n","            self.args.cos_scale = 32\n","\n","        self.MOCO = nn.ModuleList(\n","            MoCo(dim=self.args.moco_dim, K=self.args.moco_k, T=self.args.moco_t)\n","            for i in range(self.network_num))\n","\n","\n","        self.backbone = nn.ModuleList(\n","            eval(self.args.net_type)(\n","                self.args,\n","                last_layer_stride=2,\n","            ) for i in range(self.network_num))\n","\n","\n","        self.module = nn.ModuleList(\n","            self._get_module()\n","            for i in range(self.network_num))\n","\n","        \n","        self.classifier = nn.ModuleList(\n","            self._get_multi_classifer(True, self.args.scf)\n","            for i in range(self.network_num))\n","        self.feat = []\n","\n","        self.backbone_MA = nn.ModuleList(\n","            eval(self.args.net_type)(\n","                self.args,\n","                last_layer_stride=2,\n","            ) for i in range(self.network_num))\n","\n","        for i in range(self.network_num):\n","            for param in self.backbone_MA[i].parameters():\n","                param.detach_()\n","\n","        self.module_MA = nn.ModuleList(\n","            self._get_module()\n","            for i in range(self.network_num))\n","        for i in range(self.network_num):\n","            for param in self.module_MA[i].parameters():\n","                param.detach_()\n","\n","        \n","        self.classifier_MA = nn.ModuleList(\n","            self._get_multi_classifer(True, self.args.scf)\n","            for i in range(self.network_num))\n","        for i in range(self.network_num):\n","            for param in self.classifier_MA[i].parameters():\n","                param.detach_()\n","        self.feat_MA = []\n","\n","        if self.args.cf == 'FC':\n","            self.classifier_ce = nn.ModuleList(\n","                nn.Linear(self.get_feature_length(), self.num_classes, True)\n","                for i in range(self.network_num))\n","        elif self.args.cf == 'cos':\n","            self.classifier_ce = nn.ModuleList(\n","                Cos_Classifier(self.num_classes, in_dim=self.get_feature_length(), scale=self.args.cos_scale, bias=True)\n","                for i in range(self.network_num))\n","\n","    def forward(self, input, **kwargs):\n","\n","\n","        if \"feature_flag\" in kwargs:\n","            return self.extract_feature(input, **kwargs)\n","        elif \"classifier_flag\" in kwargs:\n","            return self.get_logits(input, **kwargs)\n","\n","        logits = []\n","        logits_ce = []\n","        for i in range(self.network_num):\n","            x = (self.backbone[i])(input[i], **kwargs)\n","            x = (self.module[i])(x)\n","            feature = x.view(x.shape[0], -1)\n","            self.feat.append(copy.deepcopy(feature))\n","            \n","            output = (self.classifier[i])(feature)\n","            logits.append(output)\n","\n","            output_ce = (self.classifier_ce[i])(feature)\n","            logits_ce.append(output_ce)\n","\n","        logits_MA = []\n","        for i in range(self.network_num):\n","            x = (self.backbone_MA[i])(input[i], **kwargs)\n","            x = (self.module_MA[i])(x)\n","            x = x.view(x.shape[0], -1)\n","            self.feat_MA.append(copy.deepcopy(x))\n","            x = (self.classifier_MA[i])(x)\n","            logits_MA.append(x)\n","\n","        return logits_ce, logits, logits_MA\n","\n","    def extract_feature(self, input_all, **kwargs):\n","\n","        input, input_MA = input_all\n","\n","        feature = []\n","        for i in range(self.network_num):\n","            x = (self.backbone[i])(input[i], label=kwargs['label'][i])\n","            x = (self.module[i])(x)\n","            x = x.view(x.shape[0], -1)\n","            feature.append(x)\n","\n","        feature_MA = []\n","        for i in range(self.network_num):\n","            x = (self.backbone_MA[i])(input_MA[i], label=kwargs['label'][i])\n","            x = (self.module_MA[i])(x)\n","            x = x.view(x.shape[0], -1)\n","            feature_MA.append(x)\n","        return feature, feature_MA\n","\n","    def get_logits(self, input_all, **kwargs):\n","\n","        input, input_MA = input_all\n","        logits = []\n","        logits_ce = []\n","        for i in range(self.network_num):\n","            feature = input[i]\n","            \n","            output = (self.classifier[i])(feature)\n","            logits.append(output)\n","\n","            output_ce = (self.classifier_ce[i])(feature)\n","            logits_ce.append(output_ce)\n","\n","        logits_MA = []\n","        for i in range(self.network_num):\n","            x = input_MA[i]\n","            x = (self.classifier_MA[i])(x)\n","            logits_MA.append(x)\n","\n","        return logits_ce, logits, logits_MA\n","\n","    def extract_feature_maps(self, x):\n","        x = self.backbone(x)\n","        return x\n","\n","    def freeze_multi_backbone(self):\n","        print(\"Freezing backbone .......\")\n","        for p in self.backbone.parameters():\n","            p.requires_grad = False\n","\n","    def load_backbone_model(self, backbone_path=\"\"):\n","        self.backbone.load_model(backbone_path)\n","        print(\"Backbone model has been loaded...\")\n","\n","    def load_model(self, model_path, **kwargs):\n","        pretrain_dict = torch.load(\n","            model_path, map_location=\"cuda\"\n","        )\n","        pretrain_dict = pretrain_dict['state_dict'] if 'state_dict' in pretrain_dict else pretrain_dict\n","        model_dict = self.state_dict()\n","        from collections import OrderedDict\n","        new_dict = OrderedDict()\n","        for k, v in pretrain_dict.items():\n","            if 'backbone_only' in kwargs.keys() and 'classifier' in k:\n","                continue;\n","            if k.startswith(\"module\"):\n","                if k[7:] not in model_dict.keys():\n","                    print('not load:{}'.format(k))\n","                    continue\n","                new_dict[k[7:]] = v\n","            else:\n","                new_dict[k] = v\n","        model_dict.update(new_dict)\n","        self.load_state_dict(model_dict)\n","        print(\"All model has been loaded...\")\n","\n","    def get_feature_length(self):\n","        if \"cifar\" in self.args.net_type:\n","            num_features = 64\n","        else:\n","            num_features = 2048\n","        return num_features\n","\n","    def _get_module(self):\n","        module = GAP()\n","        return module\n","\n","    def _get_multi_classifer(self, bias_flag, type):\n","\n","        num_features = self.get_feature_length()\n","        if type == \"FCNorm\":\n","            classifier = FCNorm(num_features, self.args.mlp_dim)\n","        elif type == \"FC\":\n","            classifier = nn.Linear(num_features, self.args.mlp_dim, bias=bias_flag)\n","        elif type == \"mlp\":\n","            classifier = nn.Sequential(nn.Linear(num_features, num_features, bias=bias_flag), \\\n","                                       nn.ReLU(), \\\n","                                       nn.Linear(num_features, self.args.mlp_dim, bias=bias_flag))\n","        elif type == 'cos':\n","            classifier = Cos_Classifier(self.args.mlp_dim, num_features, scale=self.args.cos_scale, bias=bias_flag)\n","        else:\n","            raise NotImplementedError\n","\n","        return classifier\n"]},{"cell_type":"markdown","metadata":{},"source":["resnetride"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","from torch.nn import Parameter\n","\n","import random\n","\n","__all__ = ['resnet32_ride']\n","\n","def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","class NormedLinear(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(NormedLinear, self).__init__()\n","        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n","        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n","\n","    def forward(self, x):\n","        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n","        return out\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, in_planes, planes, stride=1):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        \n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            self.shortcut = nn.Sequential(\n","                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                     nn.BatchNorm2d(self.expansion * planes)\n","                )\n","            \n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","    \n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion *\n","                               planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","    \n","class ResNet_s(nn.Module):\n","    def __init__(self, block, num_blocks, num_experts, num_classes=10, \n","                 reduce_dimension=False, layer2_output_dim=None, \n","                 layer3_output_dim=None, use_norm=False, use_experts=None, s=30):\n","        super(ResNet_s, self).__init__()\n","        \n","        self.in_planes = 16\n","        self.num_experts = num_experts\n","        \n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.in_planes = self.next_in_planes\n","        \n","        if layer2_output_dim is None:\n","            if reduce_dimension:\n","                layer2_output_dim = 24\n","            else:\n","                layer2_output_dim = 32\n","                \n","        if layer3_output_dim is None:\n","            if reduce_dimension:\n","                layer3_output_dim = 48\n","            else:\n","                layer3_output_dim = 64\n","                \n","        self.layer2s = nn.ModuleList([self._make_layer(block, layer2_output_dim, num_blocks[1], stride=2) for _ in range(num_experts)])\n","        self.in_planes = self.next_in_planes\n","        self.layer3s = nn.ModuleList([self._make_layer(block, layer3_output_dim, num_blocks[2], stride=2) for _ in range(num_experts)])\n","        self.in_planes = self.next_in_planes\n","        \n","        if use_norm:\n","            self.linears = nn.ModuleList([NormedLinear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n","        else:\n","            self.linears = nn.ModuleList([nn.Linear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n","            s = 1\n","            \n","        if use_experts is None:\n","            self.use_experts = list(range(num_experts))\n","        elif use_experts == \"rand\":\n","            self.use_experts = None\n","        else:\n","            self.use_experts = [int(item) for item in use_experts.split(\",\")]\n","            \n","        self.s = s\n","        self.apply(_weights_init)\n","        \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        self.next_in_planes = self.in_planes\n","        for stride in strides:\n","            layers.append(block(self.next_in_planes, planes, stride))\n","            self.next_in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","    \n","    def _hook_before_iter(self):\n","        assert self.training, \"_hook_before_iter should be called at training time only, after train() is called\"\n","        count = 0\n","        for module in self.modules():\n","            if isinstance(module, nn.BatchNorm2d):\n","                if module.weight.requires_grad == False:\n","                    module.eval()\n","                    count += 1\n","                    \n","        if count > 0:\n","            print(\"Warning: detected at least one frozen BN, set them to eval state. Count:\", count)\n","            \n","    def _separate_part(self, x, ind):\n","        out = x\n","        out = (self.layer2s[ind])(out)\n","        out = (self.layer3s[ind])(out)\n","        self.feat_before_GAP.append(out)\n","        out = F.avg_pool2d(out, out.size()[3])\n","        out = out.view(out.size(0), -1)\n","        self.feat.append(out)\n","        out = (self.linears[ind])(out)\n","        out = out * self.s\n","        return out\n","    \n","    def forward(self, x, output_type = 'dict'):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        \n","        outs = []\n","        self.feat = []\n","        self.logits = outs\n","        self.feat_before_GAP = []\n","        \n","        if self.use_experts is None:\n","            use_experts = random.sample(range(self.num_experts), self.num_experts - 1)\n","        else:\n","            use_experts = self.use_experts\n","            \n","        for ind in use_experts:\n","            outs.append(self._separate_part(out, ind))\n","        final_out = torch.stack(outs, dim=1).mean(dim=1)\n","\n","        if output_type == 'dict':\n","            return {\"output\": final_out, \"logits\": torch.stack(outs, dim=1)}\n","        else:\n","            return final_out\n","        \n","def resnet32_ride(num_class, use_norm=True, num_experts=3):\n","    return ResNet_s(BasicBlock, [5,5,5], num_experts, num_classes=num_class, use_norm=use_norm, reduce_dimension=True)\n","\n","def test(net):\n","    import numpy as np\n","    total_params = 0\n","\n","    for x in filter(lambda p: p.requires_grad, net.parameters()):\n","        total_params += np.prod(x.data.numpy().shape)\n","    print(\"Total number of params\", total_params)\n","    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n","    \n","if __name__ == \"__main__\":\n","    for net_name in __all__:\n","        if net_name.startswith(\"resnet\"):\n","            print(net_name)\n","            test(globals()[net_name](2))\n","            print()"]},{"cell_type":"markdown","metadata":{},"source":["resnet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","from torch.nn import Parameter\n","\n","__all__ = ['resnet32', 'NormedLinear']\n","\n","def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","class NormedLinear(nn.Module):\n","\n","    def __init__(self, in_features, out_features):\n","        super(NormedLinear, self).__init__()\n","        self.weight = Parameter(torch.Tensor(in_features, out_features))\n","        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n","\n","    def forward(self, x):\n","        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n","        return out\n","\n","class LambdaLayer(nn.Module):\n","\n","    def __init__(self, lambd):\n","        super(LambdaLayer, self).__init__()\n","        self.lambd = lambd\n","\n","    def forward(self, x):\n","        return self.lambd(x)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option='A'):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == 'A':\n","                \"\"\"\n","                For CIFAR10 ResNet paper uses option A.\n","                \"\"\"\n","                self.shortcut = LambdaLayer(lambda x:\n","                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n","            elif option == 'B':\n","                self.shortcut = nn.Sequential(\n","                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                     nn.BatchNorm2d(self.expansion * planes)\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet_s(nn.Module):\n","\n","    def __init__(self, block, num_blocks, num_classes=10, use_norm=False):\n","        super(ResNet_s, self).__init__()\n","        self.in_planes = 16\n","\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","        if use_norm:\n","            self.linear = NormedLinear(64, num_classes)\n","        else:\n","            self.linear = nn.Linear(64, num_classes)\n","        self.apply(_weights_init)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, output_type='feat'):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = F.avg_pool2d(out, out.size()[3])\n","        out1 = out.view(out.size(0), -1)\n","        out = self.linear(out1)\n","        if output_type == 'feat':\n","            return out, out1\n","        else:\n","            return out\n","\n","def resnet32(num_class, use_norm):\n","    return ResNet_s(BasicBlock, [5,5,5], num_class, use_norm=use_norm)\n"]},{"cell_type":"markdown","metadata":{},"source":["net.py"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import shutil\n","#from models.resnet import *\n","#from models.resnet_ride import *\n","#from models.resnet_bcl import *\n","#from models.resnet_ncl import *\n","\n","import torch.nn as nn\n","import torchvision.models as models\n","\n","def get_model(args, num_class_list):\n","    if args.loss_fn in ['ride']:\n","        model = resnet32_ride(args.num_class, num_experts=args.num_experts).cuda()\n","        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n","    \n","    elif args.loss_fn in ['ncl']:\n","        model = ncl_model(args, num_class_list)\n","        print('    Total params: %.2fM' % (sum(p.numel() for p in model['model'].parameters())/1000000.0))\n","\n","    elif args.loss_fn in ['bcl']:\n","        model = bcl_model(args.num_class, use_norm=args.use_norm).cuda()\n","        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n","\n","    \n","    else:\n","        model = resnet32(args.num_class, use_norm= args.loss_fn == 'ldam_drw').cuda()\n","        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n","    \n","    \n","    torch.backends.cudnn.benchmark = True\n","    return model   \n","    \n","\n","\n","def load_model(args):\n","    if args.loss_fn == 'ride' and args.num_experts == 3 and args.ride_distill:\n","        print(\"---- ride teacher load ----\")\n","        filepath = os.path.join(args.out, 'checkpoint_teacher.pth.tar')\n","        if os.path.isfile(filepath):\n","            pass    \n","        else:\n","            shutil.copy2(os.path.join(args.out, 'checkpoint.pth.tar'), os.path.join(args.out, 'checkpoint_teacher.pth.tar'))\n","        checkpoint = torch.load(filepath)\n","        teacher = resnet32_ride(args.num_class, num_experts = 6).cuda()\n","        teacher.load_state_dict(checkpoint['state_dict'])\n","    else:\n","        teacher = None\n","    return teacher\n","    \n","        "]},{"cell_type":"markdown","metadata":{},"source":["config"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import argparse, torch, os, random\n","import numpy as np\n","\n","def parse_args(run_type = 'terminal'):\n","    parser = argparse.ArgumentParser(description='Python Training')\n","    \n","    # Optimization options\n","    parser.add_argument('--network', default='resnet32', help='Network: resnet32')\n","    parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs to run')\n","    parser.add_argument('--batch-size', default=128, type=int, metavar='N', help='train batchsize')\n","    parser.add_argument('--update-epoch', default=1, type=int, metavar='N', help='Update epoch')\n","    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float, metavar='LR', help='initial learning rate')\n","    parser.add_argument('--lr_decay', default=0.01, type=float, help='learnign rate decay')\n","    parser.add_argument('--momentum', default=0.9, type=float, help='SGD momentum')\n","    parser.add_argument('--wd', default=2e-4, type=float, help='weight decay factor for optimizer')\n","    parser.add_argument('--nesterov', action='store_true', help=\"Utilizing Nesterov\")\n","    parser.add_argument('--scheduler', default='warmup', type=str, help='LR scheduler')\n","    parser.add_argument('--warmup', default=5, type=int, help='Warmup epochs')\n","        \n","    parser.add_argument('--aug_prob', default=0.5, type=float, help='Augmentation Coin-tossing Probability')\n","    parser.add_argument('--cutout', action='store_true', help='Utilizing Cutout')\n","    parser.add_argument('--cmo', action='store_true', help='Utilizing CMO')\n","    parser.add_argument('--posthoc_la', action='store_true', help='Posthoc LA for state update')\n","    parser.add_argument('--cuda', action='store_true', help='Use CUDA')\n","    parser.add_argument('--aug_type', default='none')\n","    parser.add_argument('--sim_type', default='none')\n","    parser.add_argument('--max_d', type=int, default=30, help='max_d')\n","\n","    parser.add_argument('--num_test', default=10, type=int, help='Curriculum Test')\n","    parser.add_argument('--accept_rate', type=float, default=0.6, help='Increasing accept ratio')\n","    parser.add_argument('--verbose', action='store_true', help='Debug on/off')\n","    parser.add_argument('--use_norm', action='store_true', help='Utilize Normed Linear')\n","    \n","    # Checkpoints\n","    parser.add_argument('--out', default='./results/', help='Directory to output the result')\n","    parser.add_argument('--data_dir', default='~/dataset/')\n","    \n","    # Miscs\n","    parser.add_argument('--workers', type=int, default=4, help='# workers')\n","    parser.add_argument('--seed', type=str, default='None', help='manual seed')\n","    parser.add_argument('--gpu', default=None, type=str, help='id(s) for CUDA_VISIBLE_DEVICES')\n","    \n","    # Dataset options\n","    parser.add_argument('--dataset', default='cifar100', help='Dataset: cifar100')\n","    parser.add_argument('--num_max', type=int, default=500, help='Number of samples in the maximal class')\n","    parser.add_argument('--imb_ratio', type=int, default=100, help='Imbalance ratio for data')\n","    \n","    # Method options\n","    parser.add_argument('--loss_fn', type=str, default='ce', help='Loss function for training')\n","    parser.add_argument('--num_experts', type=int, default=3, help='Number of experts for RIDE')\n","    parser.add_argument('--ride_distill', action='store_true', help='Use RIDEWithDistill Loss')\n","    \n","    if run_type == 'terminal':\n","        args = parser.parse_args()\n","    elif run_type =='jupyter':\n","        args = parser.parse_args(args=[])\n","        \n","    args.out = f'{args.out}{args.dataset}/{args.loss_fn}@N_{args.num_max}_ir_{args.imb_ratio}/'\n","    \n","    if args.gpu:\n","        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n","    return args\n","\n","\n","def reproducibility(seed):\n","    if seed == 'None':\n","        return\n","    else:\n","        seed = int(seed)\n","        torch.manual_seed(seed)\n","        torch.backends.cudnn.deterministic = True\n","        np.random.seed(seed)\n","        random.seed(seed)\n","\n","def dataset_argument(args):\n","    if args.dataset == 'cifar100':\n","        args.num_class = 100\n","    else:\n","        args.num_class = 10\n","\n","    return args\n"]},{"cell_type":"markdown","metadata":{},"source":["logger"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import logging\n","from datetime import datetime\n","import os\n","import torch as t\n","\n","import pandas as pd\n","\n","class logger:\n","    def __init__(self, args):\n","            \n","        self.logger = logging.getLogger('Evaluation')\n","        self.logger.setLevel(logging.INFO)\n","        self.args = args\n","        \n","        formatter = logging.Formatter('%(message)s')\n","        \n","        strm_handler = logging.StreamHandler()\n","        strm_handler.setFormatter(formatter)\n","        \n","        now = datetime.now()\n","        time = f'{now.hour}:{now.minute}:{now.second}-{now.year}-{now.month}-{now.day}'\n","        os.makedirs(f'{args.out}',exist_ok=True)\n","        file_handler = logging.FileHandler(f'{args.out}/{time.replace(\":\", \"-\")}.txt')\n","\n","\n","        file_handler.setFormatter(formatter)\n","                        \n","        self.logger.addHandler(strm_handler)\n","        self.logger.addHandler(file_handler)\n","\n","        message = f'---{args.dataset}---'\n","        self(message, level=1)\n","        self.arg_logging(args)\n","\n","    def __call__(self,message, level):\n","        if level == 1:\n","            prefix = '--->' \n","        else:\n","            prefix = '  '*level + '>'\n","        \n","        self.logger.info(f'{prefix} {message}')\n","\n","\n","    def arg_logging(self, argument):\n","        self('Argument', level=1)\n","        arg_dict = vars(argument)\n","        for key in arg_dict.keys():\n","            if key == 'logger':\n","                pass\n","            else:\n","                self(f'{key:12s}: {arg_dict[key]}', level=2)\n","\n","    def map_save(self, map):\n","        map_df = pd.DataFrame(map)\n","        map_df.to_csv(f'{self.args.out}/curriculum.csv',encoding='utf-8')"]},{"cell_type":"markdown","metadata":{},"source":["plot"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch as t\n","import numpy as np\n","import os\n","import pandas as pd\n","\n","sns.set_palette(\"bright\")\n","sns.set_style(\"darkgrid\")\n","\n","def plot_score_epoch(curr_state, label, epoch, maps, out, name='heat'):\n","    label = t.tensor(label)\n","    \n","    num_samples_per_class = t.sum(t.nn.functional.one_hot(label, num_classes=len(t.unique(label))), dim=0)\n","    num_samples_sort = t.argsort(num_samples_per_class)\n","    \n","    for cidx in t.unique(label):\n","        pos = t.where(cidx == label)\n","        maps[epoch, cidx] = t.mean(curr_state[pos]).numpy()\n","\n","    # Transpose the matrix before plotting\n","    transposed_maps = np.transpose(maps)\n","\n","    sns.heatmap(transposed_maps, cmap='YlGnBu', vmin=0, vmax=10)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Class index')\n","\n","    # Flip the graph vertically before saving\n","    plt.gca().invert_yaxis()\n","\n","    os.makedirs(f'{out}/score_epoch_plot/', exist_ok=True)\n","    plt.savefig(f'{out}/score_epoch_plot/{name}.png')\n","\n","    plt.close()\n","\n","    return maps\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(torch.__version__)\n","print(f\"CUDA version: {torch.version.cuda}\")\n","torch.has_mps"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#import losses\n","\n","#from datasets.cifar100 import *\n","\n","#from train.train import *\n","#from train.validate import *\n","\n","#from models.net import *\n","\n","#from losses.loss import *\n","\n","#from utils.config import *\n","#from utils.plot import *\n","#from utils.common import make_imb_data, save_checkpoint, hms_string\n","\n","#from utils.logger import logger\n","\n","#args = parse_args()\n","\n","from argparse import Namespace\n","\n","# Replace the command below with your actual values\n","args=Namespace(network='resnet32', epochs=200, batch_size=128, update_epoch=1,\n","               lr=0.1, lr_decay=0.01, momentum=0.9, wd=0.0002, nesterov=False,\n","               scheduler='warmup', warmup=5, aug_prob=0.5, cutout=True, cmo=False,\n","               posthoc_la=False, cuda=True, aug_type='none', sim_type='none', max_d=30,\n","               num_test=10, accept_rate=0.6, verbose=True, use_norm=False,\n","               out='/kaggle/working/log3',\n","               data_dir='~/dataset/', workers=4, seed='None',\n","               gpu='0', dataset='cifar100', num_max=500, imb_ratio=100,\n","               loss_fn='ce', num_experts=3, ride_distill=False)\n","\n","reproducibility(args.seed)\n","args = dataset_argument(args)\n","args.logger = logger(args)\n","\n","best_acc = 0 # best test accuracy\n","curr_state_ac=[]\n","label_ac=[]\n","\n","def main():\n","    global best_acc,curr_state_ac,label_ac\n","\n","    try:\n","        assert args.num_max <= 50000. / args.num_class\n","    except AssertionError:\n","        args.num_max = int(50000 / args.num_class)\n","    \n","    print(f'==> Preparing imbalanced CIFAR-100')\n","    # N_SAMPLES_PER_CLASS = make_imb_data(args.num_max, args.num_class, args.imb_ratio)\n","    trainset, testset = get_cifar100(os.path.join(args.data_dir, 'cifar100/'), args)\n","    N_SAMPLES_PER_CLASS = trainset.img_num_list\n","        \n","    trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, drop_last= args.loss_fn == 'ncl', pin_memory=True, sampler=None)\n","    testloader = data.DataLoader(testset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True) \n","    \n","    if args.cmo:\n","        cls_num_list = N_SAMPLES_PER_CLASS\n","        cls_weight = 1.0 / (np.array(cls_num_list))\n","        cls_weight = cls_weight / np.sum(cls_weight) * len(cls_num_list)\n","        labels = trainloader.dataset.targets\n","        samples_weight = np.array([cls_weight[t] for t in labels])\n","        samples_weight = torch.from_numpy(samples_weight)\n","        samples_weight = samples_weight.double()\n","        print(\"samples_weight\", samples_weight)\n","        sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(labels), replacement=True)\n","        weighted_trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, sampler=sampler)\n","    else:\n","        weighted_trainloader = None\n","    \n","\n","    # Model\n","    print (\"==> creating {}\".format(args.network))\n","    model = get_model(args, N_SAMPLES_PER_CLASS)\n","    train_criterion = get_loss(args, N_SAMPLES_PER_CLASS)\n","    criterion = nn.CrossEntropyLoss() # For test, validation \n","    optimizer = get_optimizer(args, model)\n","    scheduler = get_scheduler(args,optimizer)\n","\n","    teacher = load_model(args)\n","\n","\n","    train = get_train_fn(args)\n","    validate = get_valid_fn(args)\n","    update_score = get_update_score_fn(args)\n","    \n","    start_time = time.time()\n","    \n","    test_accs = []\n","    for epoch in range(args.epochs):\n","        \n","        lr = adjust_learning_rate(optimizer, epoch, scheduler, args)\n","        if args.cuda:\n","            if epoch % args.update_epoch == 0:\n","                curr_state_ac, label_ac = update_score(trainloader, model, N_SAMPLES_PER_CLASS, posthoc_la = args.posthoc_la, num_test = args.num_test, accept_rate = args.accept_rate)\n","                print(curr_state_ac)\n","                \n","            if args.verbose:\n","                if epoch == 0:\n","                    maps = np.zeros((args.epochs,args.num_class))\n","                maps = plot_score_epoch(curr_state_ac,label_ac, epoch, maps, args.out)\n","        train_loss = train(args, trainloader, model, optimizer,train_criterion, epoch, weighted_trainloader, teacher) \n","\n","\n","        test_loss, test_acc, test_cls = validate(args, testloader, model, criterion, N_SAMPLES_PER_CLASS,  num_class=args.num_class, mode='test Valid')\n","\n","        if best_acc <= test_acc:\n","            best_acc = test_acc\n","            many_best = test_cls[0]\n","            med_best = test_cls[1]\n","            few_best = test_cls[2]\n","            # Save models\n","            save_checkpoint({\n","                'epoch': epoch + 1,\n","                'state_dict': model['model'].state_dict() if args.loss_fn == 'ncl' else model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, epoch + 1, args.out)\n","        test_accs.append(test_acc)\n","        \n","\n","        \n","        args.logger(f'Epoch: [{epoch+1} | {args.epochs}]', level=1)\n","        if args.cuda:\n","            args.logger(f'Max_state: {int(torch.max(curr_state_ac))}, min_state: {int(torch.min(curr_state_ac))}', level=2)\n","        args.logger(f'[Train]\\tLoss:\\t{train_loss:.4f}', level=2)\n","        args.logger(f'[Test ]\\tLoss:\\t{test_loss:.4f}\\tAcc:\\t{test_acc:.4f}', level=2)\n","        args.logger(f'[Stats]\\tMany:\\t{test_cls[0]:.4f}\\tMedium:\\t{test_cls[1]:.4f}\\tFew:\\t{test_cls[2]:.4f}', level=2)\n","        args.logger(f'[Best ]\\tAcc:\\t{np.max(test_accs):.4f}\\tMany:\\t{100*many_best:.4f}\\tMedium:\\t{100*med_best:.4f}\\tFew:\\t{100*few_best:.4f}', level=2)\n","        args.logger(f'[Param]\\tLR:\\t{lr:.8f}', level=2)\n","    \n","    end_time = time.time()\n","\n","    # Print the final results\n","    args.logger(f'Final performance...', level=1)\n","    args.logger(f'best bAcc (test):\\t{np.max(test_accs)}', level=2)\n","    args.logger(f'best statistics:\\tMany:\\t{many_best}\\tMed:\\t{med_best}\\tFew:\\t{few_best}', level=2)\n","    args.logger(f'Training Time: {hms_string(end_time - start_time)}', level=1)\n","\n","    \n","    if args.verbose:\n","        args.logger.map_save(maps)\n","\n","if __name__ == '__main__':\n","    main()\n","\n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Assuming variance_l1_norm is the calculated variance # If you have multiple variances, create a list\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(range(len(variance_list1)), variance_list1, color='blue', linestyle='-', linewidth=2)\n","plt.plot(range(len(variance_list)), variance_list, color='red', linestyle='-', linewidth=2)\n","plt.xlabel('Classes')\n","plt.ylabel('Variance of L1-norm')\n","plt.title('Variance of L1-norm Among Classes')\n","plt.xticks(range(len(variance_list1)), [f'Class_{i}' for i in range(len(variance_list1))])\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Data\n","categories = ['CE', 'CE_drw', 'Ldam_drw', 'BS', 'Ride']\n","vanilla = [38.49, 40.86, 42.48, 42.24, 48.6]\n","without_classwise = [41.38, 44.61, 46.55, 46.49, 48.92]\n","with_classwise = [42.27, 47.23, 47.52, 47.47, 49.53]\n","\n","# Setting the positions for the bars\n","x = np.arange(len(categories))  \n","width = 0.25  # the width of the bars\n","\n","# Creating the figure and the bars\n","fig, ax = plt.subplots()\n","bars1 = ax.bar(x - width, vanilla, width, label='Vanilla')\n","bars2 = ax.bar(x, without_classwise, width, label='CUDA Without Classwise')\n","bars3 = ax.bar(x + width, with_classwise, width, label='CUDA with classwise',color='green')\n","\n","# Adding labels, title, and custom x-axis tick labels\n","ax.set_xlabel('Categories')\n","ax.set_ylabel('Accuracy')\n","ax.set_title('Comparison of accuracy with and without classwise')\n","ax.set_ylim(min(min(vanilla), min(without_classwise), min(with_classwise)) - 1, max(max(vanilla), max(without_classwise), max(with_classwise)) + 1)\n","ax.set_xticks(x)\n","ax.set_xticklabels(categories)\n","ax.legend()\n","\n","# Display the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","# Data\n","categories = ['CUDA', 'AA(C)', 'AA(I)', 'AA(S)', 'Dada(C)', 'Dada(I)', 'FAA(C)', 'FAA(I)', 'RA']\n","values = [47.52, 47.2, 44.9, 44.67, 46.08, 45.05, 46.81, 44.92, 41.87]\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","\n","# Set y-limit\n","plt.ylim(40, 50)\n","\n","# Plot all categories\n","for i, category in enumerate(categories):\n","    if 'CUDA' in category:\n","        plt.bar(category, values[i], color='green')\n","    else:\n","        plt.bar(category, values[i], color='skyblue')\n","\n","plt.title('Augmentation Comparison')\n","plt.xlabel('Augmentation methods')\n","plt.ylabel('Accuracy')\n","plt.xticks(rotation=45, ha='right', fontsize=14)\n","\n","plt.tight_layout()\n","\n","# Show plot\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Data\n","categories = ['CE', 'CE_drw', 'Ldam', 'BS', 'Ride']\n","curriculum = [42.07, 47.2, 47.73, 46.49, 49.01]\n","without_curriculum = [41.4, 44.3, 46.56, 46.5, 48.72]\n","\n","# Setting the positions for the bars\n","x = np.arange(len(categories))  \n","width = 0.35  # the width of the bars\n","\n","# Creating the figure and the bars\n","fig, ax = plt.subplots()\n","bars1 = ax.bar(x - width/2, without_curriculum, width, label='Without Curriculum', color=\"pink\")\n","bars2 = ax.bar(x + width/2, curriculum, width, label='Cuda(with Curriculum)', color=\"green\")\n","# Adding labels, title, and custom x-axis tick labels\n","ax.set_xlabel('Categories')\n","ax.set_ylabel('Accuracy')\n","ax.set_title('Comparison of accuracy: Curriculum vs Without Curriculum')\n","ax.set_xticks(x)\n","ax.set_xticklabels(categories)\n","\n","ax.set_ylim(min(min(curriculum), min(without_curriculum)) - 1, max(max(curriculum), max(without_curriculum)) + 1)\n","\n","ax.legend()\n","\n","# Display the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Data\n","categories = ['100', '50', '10']\n","vanilla = [38.49, 42.92, 56.61]\n","cuda_without_cutout = [40.02, 45.36, 58.21]\n","cuda_with_cutout = [42.27, 46.91, 59.79]\n","\n","x = np.arange(len(categories))  # the label locations\n","width = 0.25  # the width of the bars\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","# Plotting the bars\n","bar1 = ax.bar(x - width, vanilla, width, label='Vanilla')\n","bar2 = ax.bar(x, cuda_without_cutout, width, label='Cuda(without cutout)')\n","bar3 = ax.bar(x + width, cuda_with_cutout, width, label='Cuda(with cutout)')\n","\n","# Adding labels, title, and legend\n","ax.set_xlabel('Imbalance Ratio', fontsize=14)\n","ax.set_ylabel('Accuracy', fontsize=14)\n","ax.set_title('Comparison of accuracy with and without cutout', fontsize=16)\n","ax.set_xticks(x)\n","ax.set_ylim(30, 65)\n","ax.set_xticklabels(categories, fontsize=12)\n","ax.legend(fontsize=12)\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["0.93 1.23 -1.46 6.37 5.68 3.93 \n"," "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2367101,"sourceId":3989074,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
