{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3989074,"sourceType":"datasetVersion","datasetId":2367101}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\n\nimport argparse, os, shutil, time, random, math\nimport numpy as np\n! pip3 install torch==2.1.2+cu118 torchvision==0.16.2+cpu torchaudio===2.1.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport numpy as np \nimport pandas as pd \nimport torch.backends.cudnn as cudnn\nimport torch.utils.data as data\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **1) Defining Loss Functions** \n##### The loss functions of model BCL,BS,Ride,CE,CE_drw are defined.","metadata":{}},{"cell_type":"markdown","source":"#### **Loss function:BCL**\n\n**We Implement a balanced contrastive loss, which balances class-specific logits and computes the loss based on the distances between features and class centers.**\n","metadata":{}},{"cell_type":"code","source":"\"\"\"\nAuthor: Yonglong Tian (yonglong@mit.edu)\nDate: May 07, 2020\n\"\"\"\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport math\nimport torch.nn.functional as F\nimport numpy as np\n\n\n\nclass BalSCL(nn.Module):\n    def __init__(self, cls_num_list=None, temperature=0.1):\n        super(BalSCL, self).__init__()\n        self.temperature = temperature\n        self.cls_num_list = cls_num_list\n\n    def forward(self, centers1, features, targets, ):\n\n        device = (torch.device('cuda')\n                  if features.is_cuda\n                  else torch.device('cpu'))\n        batch_size = features.shape[0]\n        targets = targets.contiguous().view(-1, 1)\n        targets_centers = torch.arange(len(self.cls_num_list), device=device).view(-1, 1)\n        targets = torch.cat([targets.repeat(2, 1), targets_centers], dim=0)\n        batch_cls_count = torch.eye(len(self.cls_num_list))[targets].sum(dim=0).squeeze()\n\n        mask = torch.eq(targets[:2 * batch_size], targets.T).float().to(device)\n        logits_mask = torch.scatter(\n            torch.ones_like(mask),\n            1,\n            torch.arange(batch_size * 2).view(-1, 1).to(device),\n            0\n        )\n        mask = mask * logits_mask\n        \n        # class-complement\n        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n        features = torch.cat([features, centers1], dim=0)\n        logits = features[:2 * batch_size].mm(features.T)\n        logits = torch.div(logits, self.temperature)\n\n        # For numerical stability\n        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n        logits = logits - logits_max.detach()\n\n        # class-averaging\n        exp_logits = torch.exp(logits) * logits_mask\n        per_ins_weight = torch.tensor([batch_cls_count[i] for i in targets], device=device).view(1, -1).expand(\n            2 * batch_size, 2 * batch_size + len(self.cls_num_list)) - mask\n        exp_logits_sum = exp_logits.div(per_ins_weight).sum(dim=1, keepdim=True)\n        \n        log_prob = logits - torch.log(exp_logits_sum)\n        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n\n        loss = - mean_log_prob_pos\n        loss = loss.view(2, batch_size).mean()\n        return loss\n\n\n\n\nclass LogitAdjust(nn.Module):\n\n    def __init__(self, cls_num_list, tau=1, weight=None):\n        super(LogitAdjust, self).__init__()\n        cls_num_list = torch.cuda.FloatTensor(cls_num_list)\n        cls_p_list = cls_num_list / cls_num_list.sum()\n        m_list = tau * torch.log(cls_p_list)\n        self.m_list = m_list.view(1, -1)\n        self.weight = weight\n\n    def forward(self, x, target):\n        x_m = x + self.m_list\n        return F.cross_entropy(x_m, target, weight=self.weight)\n\n\nclass BCLLoss(nn.Module):\n    def __init__(self, cls_num_list, tau=1, weight=None, temperature = 0.1, alpha=2.0, beta=0.6 ):\n        super(BCLLoss, self).__init__()\n        self.criterion_ce = LogitAdjust(cls_num_list).cuda()\n        self.criterion_scl = BalSCL(cls_num_list, temperature).cuda()\n        self.alpha = alpha\n        self.beta = beta\n        \n    def forward(self, centers,  logits, features, targets):\n        scl_loss = self.criterion_scl(centers, features, targets)\n        ce_loss = self.criterion_ce(logits, targets)\n\n        return self.alpha * ce_loss + self.beta * scl_loss\n\n\n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Loss function: BS**\n\n**We implements a variant of the softmax function, where the logits are adjusted by a log prior derived from a given probability distribution. The adjusted logits are then used to compute the cross-entropy loss.**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BS(nn.Module):\n    def __init__(self, dist):\n        super().__init__()\n        dist = torch.from_numpy(np.array(dist)).float().cuda()\n        self.prob = dist / sum(dist)\n        self.log_prior = torch.log(self.prob).unsqueeze(0)\n        \n    def forward(self, logits, targets, epoch=None, reduction='mean'):\n        adjusted_logits = logits + self.log_prior\n        return F.cross_entropy(adjusted_logits, targets, reduction = reduction)\n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Loss function: CE_drw**\n**This module provides a way to compute the cross-entropy loss with dynamic class reweighting, where the weights are adjusted based on the number of samples for each class and the current epoch.**","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass CE_DRW(nn.Module):\n    \n    def __init__(self, cls_num_list, reweight_epoch=160):\n        super(CE_DRW, self).__init__()\n        self.cls_num_list = cls_num_list\n        self.reweight_epoch= reweight_epoch\n        \n    def drw(self, epoch):\n        idx = epoch // self.reweight_epoch\n        betas = [0, 0.9999]\n        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n        self.weight = per_cls_weights\n\n    def forward(self, x, target, epoch, reduction='mean'):\n        self.drw(epoch)\n        return F.cross_entropy(x, target, weight=self.weight, reduction=reduction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Loss function: CE**\n\n**It computes the cross-entropy loss between the input logits and the target labels using PyTorch's F.cross_entropy function. It allows for specifying the weight for each class through the weight parameter.**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CE(nn.Module):\n    def __init__(self, weight=None):\n        super().__init__()\n        self.weight = weight\n    def forward(self, logits, targets, epoch=None, reduction='mean'):\n        return F.cross_entropy(logits, targets, weight = self.weight, reduction = reduction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Loss function: LDAM drw**\n\n**We calculate the large margin cosine distance, adjust the margins based on class frequencies, and apply a scaling factor to the adjusted logits before computing the cross-entropy loss.**","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass LDAM_DRW(nn.Module):\n    def __init__(self, cls_num_list, reweight_epoch, max_m=0.5, s=30):\n        super(LDAM_DRW, self).__init__()\n        self.cls_num_list = cls_num_list\n        self.reweight_epoch = reweight_epoch\n        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n        m_list = m_list * (max_m / np.max(m_list))\n        m_list = torch.cuda.FloatTensor(m_list)\n        self.m_list = m_list\n        assert s > 0\n        self.s = s\n      \n    def drw(self, epoch):\n        idx = epoch // self.reweight_epoch\n        betas = [0, 0.9999]\n        effective_num = 1.0 - np.power(betas[idx], self.cls_num_list)\n        per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(self.cls_num_list)\n        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n        self.weight = per_cls_weights\n\n\n    def forward(self, x, target, epoch=None, reduction='mean'):\n        self.drw(epoch)\n        index = torch.zeros_like(x, dtype=torch.uint8)\n        index.scatter_(1, target.data.view(-1, 1), 1)\n        \n        index_float = index.type(torch.cuda.FloatTensor)\n        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n        batch_m = batch_m.view((-1, 1))\n        x_m = x - batch_m\n    \n        output = torch.where(index, x_m, x)\n        return F.cross_entropy(self.s*output, target, weight=self.weight, reduction=reduction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Loss function: Ride**\n\n**We implement the Regularized Individual Diversity and Ensemble (RIDE) loss, a variant of cross-entropy loss with regularization terms to promote diversity among experts' predictions. It takes into account class imbalance and dynamic reweighting based on the provided class numbers. The loss is computed based on the output logits, target labels, and additional information**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nimport random\n\nclass RIDE(nn.Module):\n    def __init__(self, cls_num_list=None, base_diversity_temperature=1.0, max_m=0.5, s=30, reweight=True, reweight_epoch=-1, \n        base_loss_factor=1.0, additional_diversity_factor=-0.2, reweight_factor=0.05):\n        super().__init__()\n        self.base_loss = F.cross_entropy\n        self.base_loss_factor = base_loss_factor\n        if not reweight:\n            self.reweight_epoch = -1\n        else:\n            self.reweight_epoch = reweight_epoch\n\n        # LDAM is a variant of cross entropy and we handle it with self.m_list.\n        if cls_num_list is None:\n            # No cls_num_list is provided, then we cannot adjust cross entropy with LDAM.\n\n            self.m_list = None\n            self.per_cls_weights_enabled = None\n            self.per_cls_weights_enabled_diversity = None\n        else:\n            # We will use LDAM loss if we provide cls_num_list.\n\n            m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n            m_list = m_list * (max_m / np.max(m_list))\n            m_list = torch.tensor(m_list, dtype=torch.float, requires_grad=False)\n            self.m_list = m_list\n            self.s = s\n            assert s > 0\n            \n            if reweight_epoch != -1:\n                idx = 1 # condition could be put in order to set idx\n                betas = [0, 0.9999]\n                effective_num = 1.0 - np.power(betas[idx], cls_num_list)\n                per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n                per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(cls_num_list)\n                self.per_cls_weights_enabled = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False)\n            else:\n                self.per_cls_weights_enabled = None\n\n            cls_num_list = np.array(cls_num_list) / np.sum(cls_num_list)\n            C = len(cls_num_list)\n            per_cls_weights = C * cls_num_list * reweight_factor + 1 - reweight_factor\n\n            # Experimental normalization: This is for easier hyperparam tuning, the effect can be described in the learning rate so the math formulation keeps the same.\n            # At the same time, the 1 - max trick that was previously used is not required since weights are already adjusted.\n            per_cls_weights = per_cls_weights / np.max(per_cls_weights)\n\n            assert np.all(per_cls_weights > 0), \"reweight factor is too large: out of bounds\"\n            # save diversity per_cls_weights\n            self.per_cls_weights_enabled_diversity = torch.tensor(per_cls_weights, dtype=torch.float, requires_grad=False).cuda()\n\n        self.base_diversity_temperature = base_diversity_temperature\n        self.additional_diversity_factor = additional_diversity_factor\n\n    def to(self, device):\n        super().to(device)\n        if self.m_list is not None:\n            self.m_list = self.m_list.to(device)\n        \n        if self.per_cls_weights_enabled is not None:\n            self.per_cls_weights_enabled = self.per_cls_weights_enabled.to(device)\n\n        if self.per_cls_weights_enabled_diversity is not None:\n            self.per_cls_weights_enabled_diversity = self.per_cls_weights_enabled_diversity.to(device)\n\n        return self\n\n    def _hook_before_epoch(self, epoch):\n        if self.reweight_epoch != -1:\n            self.epoch = epoch\n\n            if epoch > self.reweight_epoch:\n                self.per_cls_weights_base = self.per_cls_weights_enabled\n                self.per_cls_weights_diversity = self.per_cls_weights_enabled_diversity\n            else:\n                self.per_cls_weights_base = None\n                self.per_cls_weights_diversity = None\n\n    def get_final_output(self, output_logits, target):\n        x = output_logits\n\n        index = torch.zeros_like(x, dtype=torch.uint8, device=x.device)\n        index.scatter_(1, target.data.view(-1, 1), 1)\n        \n        index_float = index.float()\n        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n        \n        batch_m = batch_m.view((-1, 1))\n        x_m = x - batch_m * self.s\n\n        final_output = torch.where(index, x_m, x)\n        return final_output\n\n    def forward(self, output_logits, target, extra_info=None, reduction='mean'):\n        if extra_info is None:\n            return self.base_loss(output_logits, target)\n\n        if reduction == 'none':\n            loss = torch.zeros_like(target).float()\n        else:\n            loss = 0\n\n\n        # Adding RIDE Individual Loss for each expert\n        for logits_item in extra_info['logits']:\n            ride_loss_logits = output_logits if self.additional_diversity_factor == 0 else logits_item\n            if self.m_list is None:\n                loss += self.base_loss_factor * self.base_loss(ride_loss_logits, target, reduction=reduction)\n            else:\n                final_output = self.get_final_output(ride_loss_logits, target)\n                loss += self.base_loss_factor * self.base_loss(final_output, target, weight=self.per_cls_weights_base, reduction=reduction)\n            \n            base_diversity_temperature = self.base_diversity_temperature\n\n            if self.per_cls_weights_diversity is not None:\n                diversity_temperature = base_diversity_temperature * self.per_cls_weights_diversity.view((1, -1))\n                temperature_mean = diversity_temperature.mean().item()\n            else:\n                diversity_temperature = base_diversity_temperature\n                temperature_mean = base_diversity_temperature\n            \n            output_dist = F.log_softmax(logits_item / diversity_temperature, dim=1)\n            with torch.no_grad():\n                # Using the mean takes only linear instead of quadratic time in computing and has only a slight difference so using the mean is preferred here\n                mean_output_dist = F.softmax(output_logits / diversity_temperature, dim=1)\n            \n            loss += self.additional_diversity_factor * temperature_mean * temperature_mean * F.kl_div(output_dist, mean_output_dist, reduction='batchmean')\n        \n        return loss\n\nclass RIDEWithDistill(nn.Module):\n    def __init__(self, cls_num_list=None, additional_distill_loss_factor=1.0, distill_temperature=1.5, ride_loss_factor=1.0, **kwargs):\n        super().__init__()\n        self.ride_loss = RIDE(cls_num_list=cls_num_list, **kwargs)\n        self.distill_temperature = distill_temperature\n\n        self.ride_loss_factor = ride_loss_factor\n        self.additional_distill_loss_factor = additional_distill_loss_factor\n\n    def to(self, device):\n        super().to(device)\n        self.ride_loss = self.ride_loss.to(device)\n        return self\n\n    def _hook_before_epoch(self, epoch):\n        self.ride_loss._hook_before_epoch(epoch)\n\n    def forward(self, student, target=None, teacher=None, extra_info=None):\n        output_logits = student\n        if extra_info is None:\n            return self.ride_loss(output_logits, target)\n\n        loss = 0\n        num_experts = len(extra_info['logits'])\n        for logits_item in extra_info['logits']:\n            loss += self.ride_loss_factor * self.ride_loss(output_logits, target, extra_info)\n            distill_temperature = self.distill_temperature\n\n            student_dist = F.log_softmax(student / distill_temperature, dim=1)\n            with torch.no_grad():\n                teacher_dist = F.softmax(teacher / distill_temperature, dim=1)\n            \n            distill_loss = F.kl_div(student_dist, teacher_dist, reduction='batchmean')\n            distill_loss = distill_temperature * distill_temperature * distill_loss\n            loss += self.additional_distill_loss_factor * distill_loss\n        return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Common utility functions**\n\n**A linear learning rate warm-up is used in the first 5 epochs to reach the initial learning rate. During training over 200 epochs, the learning rate is decayed at the 160th and 180th epochs by 0.01.**","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\n\nimport argparse, os, shutil, random, math\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\n!pip install progress\n# added on my own\nimport progress \n#end\n\nfrom progress.bar import Bar as Bar\n\ndef make_imb_data(max_num, class_num, gamma):\n    mu = np.power(1/gamma, 1/(class_num - 1))\n    class_num_list = []\n    for i in range(class_num):\n        if i == (class_num - 1):\n            class_num_list.append(int(max_num / gamma))\n        else:\n            class_num_list.append(int(max_num * np.power(mu, i)))\n    print(class_num_list)\n    return list(class_num_list)\n\ndef hms_string(sec_elapsed):\n    h = int(sec_elapsed / (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) / 60)\n    s = sec_elapsed % 60.\n    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n\ndef save_checkpoint(state, epoch, checkpoint='none', filename='checkpoint.pth.tar'):\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n    \n    if epoch % 100 == 0:\n        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_' + str(epoch) + '.pth.tar'))\n        \ndef linear_rampup(current, rampup_length=0):\n    if rampup_length == 0:\n        return 1.0\n    else:\n        current = np.clip(current / rampup_length, 0.0, 1.0)\n        return float(current)\n    \ndef adjust_learning_rate(optimizer, epoch, scheduler, args):\n    if scheduler == None:\n        if args.epochs == 200:\n            epoch = epoch + 1\n            if epoch <= args.warmup:\n                lr = args.lr * epoch / args.warmup\n            elif epoch > 180:\n                lr = args.lr * args.lr_decay ** 2\n            elif epoch > 160:\n                lr = args.lr * args.lr_decay\n            else:\n                lr = args.lr\n\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = lr\n            return lr\n\n        elif args.epochs == 400:\n            if args.loss_fn == 'bcl':\n                epoch = epoch + 1\n                if epoch <= args.warmup:\n                    lr = args.lr * epoch / args.warmup\n                elif epoch > 380:\n                    lr = args.lr * args.lr_decay ** 2\n                elif epoch > 360:\n                    lr = args.lr * args.lr_decay\n                else:\n                    lr = args.lr\n\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = lr\n                return lr\n            else:\n                epoch = epoch + 1\n                if epoch <= args.warmup:\n                    lr = args.lr * epoch / args.warmup\n                elif epoch > 360:\n                    lr = args.lr * args.lr_decay ** 2\n                elif epoch > 320:\n                    lr = args.lr * args.lr_decay\n                else:\n                    lr = args.lr\n\n                for param_group in optimizer.param_groups:\n                    param_group['lr'] = lr\n                return lr\n        else:\n            return args.lr\n    else:\n        scheduler.step()\n        return optimizer.param_groups[0]['lr']\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Fetch Loss function**\n\n **We use Stochastic Gradient Descent as our otpimizer.\nWe fetch the respective loss function based on the argument loss_fn which is passed by the user.**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom bisect import bisect_right\n\n\n\n#from utils.common import adjust_learning_rate\n\nfrom torch.optim import lr_scheduler\n\ndef get_optimizer(args, model):\n    _model = model\n    return optim.SGD(_model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd,\n                     nesterov=args.nesterov)\n\ndef get_scheduler(args, optimizer):\n    if args.scheduler == 'cosine':\n        return lr_scheduler.CosineAnnealingLR(optimizer, args.epochs, eta_min = 0)\n    elif args.scheduler == 'warmup':\n        return None\n\ndef get_loss(args, N_SAMPLES_PER_CLASS):\n    if args.loss_fn == 'ce':\n        train_criterion = CE()\n    elif args.loss_fn == 'ce_drw':\n        train_criterion = CE_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160)\n    elif args.loss_fn == 'bs':\n        train_criterion = BS(N_SAMPLES_PER_CLASS)\n    elif args.loss_fn == 'ldam_drw':\n        train_criterion = LDAM_DRW(cls_num_list=N_SAMPLES_PER_CLASS, reweight_epoch=160, max_m=0.5, s=30).cuda()\n    elif args.loss_fn == 'ride':\n        if args.num_experts == 3 and args.ride_distill:\n            train_criterion = RIDEWithDistill(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n        else:\n            train_criterion = RIDE(cls_num_list=N_SAMPLES_PER_CLASS, additional_diversity_factor=-0.45, reweight=True, reweight_epoch=160)\n        train_criterion = train_criterion.to(torch.device('cuda'))\n\n    elif args.loss_fn == 'bcl':\n        train_criterion = BCLLoss(N_SAMPLES_PER_CLASS)\n\n    else:\n        raise NotImplementedError\n        \n\n    return train_criterion\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **2)Defining Augmentation Policies**","metadata":{}},{"cell_type":"markdown","source":"#### **CUDA:Augmentation Strength**\n \n **Various functions are defined, each implementing a specific image augmentation operation using PIL. These include operations like flipping, mirroring, adjusting contrast, brightness, etc.The CUDA function takes an image and applies a sequence augmentation operations to it based on 'n' randomly selected operations from the list of available augmentation functions.'n' is LOL score which also controls the magnitude of the augmentation we apply on the image.**","metadata":{}},{"cell_type":"code","source":"import torch as t\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom torch.utils.data.dataset import Dataset\n\nimport random\nimport PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\nimport numpy as np\nimport torch\nfrom PIL import Image\n\ndef CUDA(img,m,n, rand=True, max_d=30):\n    _augment_list = augment_list()\n    ops = random.choices(_augment_list, k=n)\n    m = float(m) / max_d\n    for op, minval, maxval in ops:\n        val = (float(m)) * float(maxval - minval) + minval\n        img = op(img, val)\n    return img\n\ndef Flip(img, _):\n    return PIL.ImageOps.flip(img)\n\ndef Mirror(img, _):\n    return PIL.ImageOps.mirror(img)\n\ndef EdgeEnhance(img, _):\n    return img.filter(PIL.ImageFilter.EDGE_ENHANCE)\n\ndef Detail(img, _):\n    return img.filter(PIL.ImageFilter.DETAIL)\n\ndef Smooth(img, _):\n    return img.filter(PIL.ImageFilter.SMOOTH)\n    \ndef AutoContrast(img, _):\n    return PIL.ImageOps.autocontrast(img)\n\ndef Equalize(img, _):\n    return PIL.ImageOps.equalize(img)\n\ndef Invert(img, _):\n    return PIL.ImageOps.invert(img)\n\ndef GaussianBlur(img, v):\n    # assert 0 <= v <= 5\n    filter = PIL.ImageFilter.GaussianBlur(v)\n    return img.filter(filter)\n\ndef ResizeCrop(img, v):\n    # assert 1 <= v <= 2\n    width, height = img.size\n    enlarge = img.resize((int(width*v), int(height*v)), Image.ANTIALIAS)\n    left = int(width*v)//2 - width//2\n    right = int(width*v)//2 + width//2\n    top = int(height*v)//2 - height//2\n    bottom = int(height*v)//2 + height//2\n    return enlarge.crop((left, top, right, bottom))\n\ndef Rotate(img, v):  # [-30, 30]\n    # assert -30 <= v <= 30\n    if random.random() > 0.5:\n        v = -v\n    return img.rotate(v)\n\ndef Posterize(img, v):  # [4, 8]\n    v = int(v)\n    v = max(1, v)\n    return PIL.ImageOps.posterize(img, v)\n\ndef Solarize(img, v):  # [0, 256]\n    # assert 0 <= v <= 256\n    return PIL.ImageOps.solarize(img, v)\n\ndef SolarizeAdd(img, addition=0, threshold=128):\n    img_np = np.array(img).astype(int)\n    img_np = img_np + addition\n    img_np = np.clip(img_np, 0, 255)\n    img_np = img_np.astype(np.uint8)\n    img = Image.fromarray(img_np)\n    return PIL.ImageOps.solarize(img, threshold)\n\ndef Color(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Color(img).enhance(v)\n\ndef Contrast(img, v):  # [0.1,1.9]Æ’\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Contrast(img).enhance(v)\n\ndef Brightness(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Brightness(img).enhance(v)\n\ndef Sharpness(img, v):  # [0.1,1.9]\n    # assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n\ndef ShearX(img, v):  # [-0.3, 0.3]\n    # assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n\ndef ShearY(img, v):  # [-0.3, 0.3]\n    # assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n\ndef TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    # assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\ndef TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    # assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\ndef augment_list():  \n    l = [\n        (Flip, 0, 1),\n        (Mirror, 0, 1),\n        (EdgeEnhance, 0, 1),\n        (Detail, 0, 1),\n        (Smooth, 0, 1),\n        (AutoContrast, 0, 1),\n        (Equalize, 0, 1),\n        (Invert, 0, 1),\n        (GaussianBlur, 0, 2),\n        (ResizeCrop,1, 1.5),\n        (Rotate, 0, 30),\n        (Posterize, 0, 4),\n        (Solarize, 0, 256),\n        (SolarizeAdd, 0, 110),\n        (Color, 0.1, 1.9),\n        (Contrast, 0.1, 1.9),\n        (Brightness, 0.1, 1.9),\n        (Sharpness, 0.1, 1.9),\n        (ShearX, 0., 0.3),\n        (ShearY, 0., 0.3),\n        (TranslateXabs, 0., 100),\n        (TranslateYabs, 0., 100),\n    ]\n\n    \n\n    return l\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Augmentation technique:Autoaug**\n\n**We implement three classes Cifar10 policy,Imagenet policy and SVHN policy for image augmentation based on the AutoAugment technique.Each class contains a set of predefined sub-policies, and when called, randomly selects and applies one of these sub-policies to an input image.**\n","metadata":{}},{"cell_type":"code","source":"from PIL import Image, ImageEnhance, ImageOps\nimport numpy as np\nimport random\nimport torch\n\n\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n\nclass ImageNetPolicy(object):\n    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n        Example:\n        >>> policy = ImageNetPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     ImageNetPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment ImageNet Policy\"\n\n\nclass CIFAR10Policy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n        Example:\n        >>> policy = CIFAR10Policy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     CIFAR10Policy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n\n            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n\n            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n\n            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n\n            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment CIFAR10 Policy\"\n\n\nclass SVHNPolicy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on SVHN.\n        Example:\n        >>> policy = SVHNPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     SVHNPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.9, \"shearX\", 4, 0.2, \"invert\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.7, \"invert\", 5, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.6, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 3, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"equalize\", 1, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.8, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.4, \"invert\", 5, fillcolor),\n            SubPolicy(0.9, \"shearY\", 5, 0.2, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 6, 0.8, \"autocontrast\", 1, fillcolor),\n            SubPolicy(0.6, \"equalize\", 3, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.3, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 8, 0.7, \"invert\", 4, fillcolor),\n            SubPolicy(0.9, \"equalize\", 5, 0.6, \"translateY\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 4, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.3, \"contrast\", 3, 0.8, \"rotate\", 4, fillcolor),\n\n            SubPolicy(0.8, \"invert\", 5, 0.0, \"translateY\", 2, fillcolor),\n            SubPolicy(0.7, \"shearY\", 6, 0.4, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 0.8, \"rotate\", 4, fillcolor),\n            SubPolicy(0.3, \"shearY\", 7, 0.9, \"translateX\", 3, fillcolor),\n            SubPolicy(0.1, \"shearX\", 6, 0.6, \"invert\", 5, fillcolor),\n\n            SubPolicy(0.7, \"solarize\", 2, 0.6, \"translateY\", 7, fillcolor),\n            SubPolicy(0.8, \"shearY\", 4, 0.8, \"invert\", 8, fillcolor),\n            SubPolicy(0.7, \"shearX\", 9, 0.8, \"translateY\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 5, 0.7, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.7, \"shearX\", 2, 0.1, \"invert\", 5, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment SVHN Policy\"\n\n\nclass SubPolicy(object):\n    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n        ranges = {\n            \"shearX\": np.linspace(0, 0.3, 10),\n            \"shearY\": np.linspace(0, 0.3, 10),\n            \"translateX\": np.linspace(0, 150 / 331, 10),\n            \"translateY\": np.linspace(0, 150 / 331, 10),\n            \"rotate\": np.linspace(0, 30, 10),\n            \"color\": np.linspace(0.0, 0.9, 10),\n            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n            \"solarize\": np.linspace(256, 0, 10),\n            \"contrast\": np.linspace(0.0, 0.9, 10),\n            \"sharpness\": np.linspace(0.0, 0.9, 10),\n            \"brightness\": np.linspace(0.0, 0.9, 10),\n            \"autocontrast\": [0] * 10,\n            \"equalize\": [0] * 10,\n            \"invert\": [0] * 10\n        }\n\n        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n        def rotate_with_fill(img, magnitude):\n            rot = img.convert(\"RGBA\").rotate(magnitude)\n            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n\n        func = {\n            \"shearX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"shearY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"translateX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n                fillcolor=fillcolor),\n            \"translateY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n                fillcolor=fillcolor),\n            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n        }\n\n        self.p1 = p1\n        self.operation1 = func[operation1]\n        self.magnitude1 = ranges[operation1][magnitude_idx1]\n        self.p2 = p2\n        self.operation2 = func[operation2]\n        self.magnitude2 = ranges[operation2][magnitude_idx2]\n\n\n    def __call__(self, img):\n        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n        return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Augmentation technique:Randaug**\n\n**We implement the RandAugment policy, which randomly selects a set of augmentation operations from the predefined list and applies them to an image. The number of operations (n) and the magnitude (m) are configurable parameters.**","metadata":{}},{"cell_type":"code","source":"# code in this file is adpated from rpmcruz/autoaugment\n# https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\nimport random\n\nimport PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\nimport numpy as np\nimport torch\nfrom PIL import Image\n\n\ndef ShearX(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n\n\ndef ShearY(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n\n\ndef TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random.random() > 0.5:\n        v = -v\n    v = v * img.size[0]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random.random() > 0.5:\n        v = -v\n    v = v * img.size[1]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef Rotate(img, v):  # [-30, 30]\n    assert -30 <= v <= 30\n    if random.random() > 0.5:\n        v = -v\n    return img.rotate(v)\n\n\ndef AutoContrast(img, _):\n    return PIL.ImageOps.autocontrast(img)\n\n\ndef Invert(img, _):\n    return PIL.ImageOps.invert(img)\n\n\ndef Equalize(img, _):\n    return PIL.ImageOps.equalize(img)\n\n\ndef Flip(img, _):  # not from the paper\n    return PIL.ImageOps.mirror(img)\n\n\ndef Solarize(img, v):  # [0, 256]\n    assert 0 <= v <= 256\n    return PIL.ImageOps.solarize(img, v)\n\n\ndef SolarizeAdd(img, addition=0, threshold=128):\n    img_np = np.array(img).astype(int)\n    img_np = img_np + addition\n    img_np = np.clip(img_np, 0, 255)\n    img_np = img_np.astype(np.uint8)\n    img = Image.fromarray(img_np)\n    return PIL.ImageOps.solarize(img, threshold)\n\n\ndef Posterize(img, v):  # [4, 8]\n    v = int(v)\n    v = max(1, v)\n    return PIL.ImageOps.posterize(img, v)\n\n\ndef Contrast(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Contrast(img).enhance(v)\n\n\ndef Color(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Color(img).enhance(v)\n\n\ndef Brightness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Brightness(img).enhance(v)\n\n\ndef Sharpness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n\n\n\n\ndef CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n    # assert 0 <= v <= 20\n    if v < 0:\n        return img\n    w, h = img.size\n    x0 = np.random.uniform(w)\n    y0 = np.random.uniform(h)\n\n    x0 = int(max(0, x0 - v / 2.))\n    y0 = int(max(0, y0 - v / 2.))\n    x1 = min(w, x0 + v)\n    y1 = min(h, y0 + v)\n\n    xy = (x0, y0, x1, y1)\n    color = (125, 123, 114)\n    # color = (0, 0, 0)\n    img = img.copy()\n    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n    return img\n\n\ndef SamplePairing(imgs):  # [0, 0.4]\n    def f(img1, v):\n        i = np.random.choice(len(imgs))\n        img2 = PIL.Image.fromarray(imgs[i])\n        return PIL.Image.blend(img1, img2, v)\n\n    return f\n\n\ndef Identity(img, v):\n    return img\n\n\ndef augment_list():  # 16 oeprations and their ranges\n    # https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57\n    # l = [\n    #     (Identity, 0., 1.0),\n    #     (ShearX, 0., 0.3),  # 0\n    #     (ShearY, 0., 0.3),  # 1\n    #     (TranslateX, 0., 0.33),  # 2\n    #     (TranslateY, 0., 0.33),  # 3\n    #     (Rotate, 0, 30),  # 4\n    #     (AutoContrast, 0, 1),  # 5\n    #     (Invert, 0, 1),  # 6\n    #     (Equalize, 0, 1),  # 7\n    #     (Solarize, 0, 110),  # 8\n    #     (Posterize, 4, 8),  # 9\n    #     # (Contrast, 0.1, 1.9),  # 10\n    #     (Color, 0.1, 1.9),  # 11\n    #     (Brightness, 0.1, 1.9),  # 12\n    #     (Sharpness, 0.1, 1.9),  # 13\n    #     # (Cutout, 0, 0.2),  # 14\n    #     # (SamplePairing(imgs), 0, 0.4),  # 15\n    # ]\n\n    # https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505\n    l = [\n        (AutoContrast, 0, 1),\n        (Equalize, 0, 1),\n        (Invert, 0, 1),\n        (Rotate, 0, 30),\n        (Posterize, 0, 4),\n        (Solarize, 0, 256),\n        (SolarizeAdd, 0, 110),\n        (Color, 0.1, 1.9),\n        (Contrast, 0.1, 1.9),\n        (Brightness, 0.1, 1.9),\n        (Sharpness, 0.1, 1.9),\n        (ShearX, 0., 0.3),\n        (ShearY, 0., 0.3),\n        (CutoutAbs, 0, 40),\n        (TranslateXabs, 0., 100),\n        (TranslateYabs, 0., 100),\n    ]\n\n    return l\n\n\nclass Lighting(object):\n    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n\n    def __init__(self, alphastd, eigval, eigvec):\n        self.alphastd = alphastd\n        self.eigval = torch.Tensor(eigval)\n        self.eigvec = torch.Tensor(eigvec)\n\n    def __call__(self, img):\n        if self.alphastd == 0:\n            return img\n\n        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n        rgb = self.eigvec.type_as(img).clone() \\\n            .mul(alpha.view(1, 3).expand(3, 3)) \\\n            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n            .sum(1).squeeze()\n\n        return img.add(rgb.view(3, 1, 1).expand_as(img))\n\n\nclass CutoutDefault(object):\n    \"\"\"\n    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py\n    \"\"\"\n    def __init__(self, length):\n        self.length = length\n\n    def __call__(self, img):\n        h, w = img.size(1), img.size(2)\n        mask = np.ones((h, w), np.float32)\n        y = np.random.randint(h)\n        x = np.random.randint(w)\n\n        y1 = np.clip(y - self.length // 2, 0, h)\n        y2 = np.clip(y + self.length // 2, 0, h)\n        x1 = np.clip(x - self.length // 2, 0, w)\n        x2 = np.clip(x + self.length // 2, 0, w)\n\n        mask[y1: y2, x1: x2] = 0.\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img *= mask\n        return img\n\n\nclass RandAugment:\n    def __init__(self, n, m):\n        self.n = n\n        self.m = m      # [0, 30]\n        self.augment_list = augment_list()\n\n    def __call__(self, img):\n        ops = random.choices(self.augment_list, k=self.n)\n        for op, minval, maxval in ops:\n            val = (float(self.m) / 30) * float(maxval - minval) + minval\n            img = op(img, val)\n\n        return img\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Augmentation technique:Cutout**\n\n**We implement the \"Cutout\" augmentation operation, which randomly removes square patches from an image. This technique is used as a regularization method during training to improve the generalization.**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Transformations:Data preprocessing**\n\n**For CIFAR-100-LT, each side of the image is padded with 4 pixels, and a 32 Ã— 32 crop is randomly selected from the padded image or its horizontal flip.Then we normalize the image with following mean and standard deviation values sequentially: CIFAR-100-LT ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))**","metadata":{}},{"cell_type":"code","source":"from torchvision.transforms import transforms\nfrom PIL import ImageFilter\nimport random\n#from aug.cutout import *\n\ncifar10_mean = (0.4914, 0.4822, 0.4465)\ncifar10_std = (0.2023, 0.1994, 0.2010)\n\n\n\nclass GaussianBlur(object):\n    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n\n    def __init__(self, sigma=[.1, 2.]):\n        self.sigma = sigma\n\n    def __call__(self, x):\n        sigma = random.uniform(self.sigma[0], self.sigma[1])\n        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n        return x\n\n\n\ndef get_transform(loss_fn, cutout = False):\n    # Augmentations.\n    if loss_fn in ['ce', 'ldam_drw', 'bs', 'ce_drw', 'ride']:\n        train_before = [\n                transforms.RandomCrop(32, padding=4),\n                transforms.RandomHorizontalFlip(),\n            ]\n        \n        if cutout:\n            train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n\n        transform_train = [[transforms.Compose(train_before), transforms.Compose(train_after)]]\n\n    \n    elif loss_fn in ['bcl']:\n        regular_train_before = [\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),\n            ]\n\n        if cutout:\n            regular_train_after = [\n                transforms.ToTensor(),\n                Cutout(n_holes = 1, length = 16),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        else:\n            regular_train_after = [\n                transforms.ToTensor(),\n                transforms.Normalize(cifar10_mean, cifar10_std),\n                ]\n        \n        sim_cifar_before = [\n            transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n            ]\n        sim_cifar_after = [\n            transforms.ToTensor(),\n            transforms.Normalize(cifar10_mean, cifar10_std),\n            ]\n\n        transform_train = [\n            [transforms.Compose(regular_train_before), \n            transforms.Compose(regular_train_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)], \n            [transforms.Compose(sim_cifar_before), \n            transforms.Compose(sim_cifar_after)],\n            ]\n\n    transform_val = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(cifar10_mean, cifar10_std)\n    ])\n    \n    return transform_train, transform_val\n    \n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Creating Imbalanced Dataset**\n\n**CIFAR100_train extends the CIFAR100 dataset and allows for generating an imbalanced version of the dataset during training. It also provides functionality for applying various augmentation policies such as AutoAugment, RandAugment, etc.CIFAR100_val represents the CIFAR100 validation dataset. It allows for specifying indices to select a subset of data and applies transformations to the data during retrieval.**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport random\n\nimport torchvision\nimport torch\n\nfrom torch.utils.data import Dataset\n\nfrom torchvision.transforms import transforms\n\n\n\n    \ndef get_cifar100(root, args):\n    transform_train, transform_val = get_transform(args.loss_fn, cutout = args.cutout)\n\n    train_dataset = CIFAR100_train(root, args, imb_ratio = args.imb_ratio, train=True, transform = transform_train, aug_prob=args.aug_prob)\n    test_dataset = CIFAR100_val(root, transform=transform_val)\n    print (f\"#Train: {len(train_dataset)}, #Test: {len(test_dataset)}\")\n    return train_dataset, test_dataset\n    \nclass test_CIFAR100(Dataset):\n    def __init__(self, indices, state, cifar_dataset):\n        self.indices = indices\n        self.state = state\n        self.dataset = cifar_dataset\n\n    def __getitem__(self,idx):\n        data, label, _ = self.dataset.get_item(self.indices[idx], self.state[idx], train=False)\n        return data, label, self.indices[idx], self.state[idx]\n    \n    def __len__(self):\n        return len(self.indices)\n\nclass CIFAR100_train(torchvision.datasets.CIFAR100):\n    def __init__(self, root , args, aug_prob, imb_type='exp', imb_ratio=100, train=True, transform=None, target_transform=None, download=True):\n        super(CIFAR100_train,self).__init__(root, train=train, transform=transform, target_transform = target_transform, download= download)\n\n        np.random.seed(0)\n        self.args = args\n        self.cls_num = 100\n        self.img_num_list = self.get_img_num_per_cls(self.cls_num, imb_type, 1./imb_ratio)\n        self.transform_train = transform\n        self.gen_imbalanced_data(self.img_num_list)\n        \n\n        if 'autoaug_cifar' in args.aug_type:\n            print('autoaug_cifar')\n            self.aug_transform = transforms.Compose([CIFAR10Policy()])\n        elif 'autoaug_svhn' in args.aug_type:\n            print('autoaug_svhn')\n            self.aug_transform = transforms.Compose([SVHNPolicy()])\n        elif 'autoaug_imagenet' in args.aug_type:\n            print('autoaug_imagenet')\n            self.aug_transform = transforms.Compose([ImageNetPolicy()])\n        elif 'dada_cifar' in args.aug_type:\n            print('dada_cifar')\n            self.aug_transform = transforms.Compose([dada_cifar()])\n        elif 'dada_imagenet' in args.aug_type:\n            print('dada_imagenet')\n            self.aug_transform = transforms.Compose([dada_imagenet()])\n        elif 'faa_cifar' in args.aug_type:\n            print('faa_cifar')\n            self.aug_transform = transforms.Compose([faa_cifar()])\n        elif 'faa_imagenet' in args.aug_type:\n            print('faa_imagenet')\n            self.aug_transform = transforms.Compose([faa_imagenet()])\n        elif 'randaug' in args.aug_type:\n            print('randaug')\n            self.aug_transform = transforms.Compose([RandAugment(2, 14)])\n        elif 'none' in args.aug_type:\n            self.aug_transform = transforms.Compose([])\n        else:\n            raise NotImplementedError\n        \n\n\n\n        # max_mag = 10\n        # max_ops = 10\n        max_mag = 10\n        max_ops = 10\n        self.min_state = 0\n        self.max_state = max(max_mag, max_ops) + 1\n        \n        states = torch.arange(self.min_state, self.max_state)\n        if self.max_state == 1:\n            self.ops = torch.tensor([0])\n            self.mag = torch.tensor([0])\n            \n        elif max_mag > max_ops:\n            self.ops = (states * max_ops / max_mag).ceil().int()\n            self.mag = states.int()\n        else:\n            self.mag = (states * max_mag / max_ops).ceil().int()\n            self.ops = states.int()\n        \n        print(f\"Magnitude set = {self.mag}\")\n        print(f\"Operation set = {self.ops}\")\n\n        self.curr_state = torch.zeros(len(self.data))\n        self.score_tmp = torch.zeros((len(self.targets), self.max_state))\n        self.num_test = torch.zeros((len(self.targets), self.max_state))\n        self.aug_prob = aug_prob\n\n\n\n    def get_img_num_per_cls(self, cls_num, imb_type, imb_factor):\n        img_max = len(self.data) / cls_num\n        img_num_per_cls = []\n        if imb_type == 'exp':\n            for cls_idx in range(cls_num):\n                num = img_max * (imb_factor ** (cls_idx / (cls_num - 1.0)))\n                img_num_per_cls.append(int(num))\n        else:\n            img_num_per_cls.extend([int(img_max)] * cls_num)\n        return img_num_per_cls\n\n\n    def gen_imbalanced_data(self, img_num_per_cls):\n        new_data = []\n        new_targets = []\n        #changed from np.int64\n        targets_np = np.array(self.targets, dtype=int)\n        classes = np.unique(targets_np)\n        # np.random.shuffle(classes)\n\n        self.num_per_cls_dict = dict()\n        for the_class, the_img_num in zip(classes, img_num_per_cls):\n            self.num_per_cls_dict[the_class] = the_img_num\n            idx = np.where(targets_np == the_class)[0]\n            np.random.shuffle(idx)\n            selec_idx = idx[:the_img_num]\n            # print(selec_idx)\n            new_data.append(self.data[selec_idx, ...])\n            new_targets.extend([the_class, ] * the_img_num)\n        new_data = np.vstack(new_data)\n        self.data = new_data\n        self.targets = new_targets\n\n    def get_cls_num_list(self):\n        cls_num_list = []\n        for i in range(self.cls_num):\n            cls_num_list.append(self.num_per_cls_dict[i])\n        return cls_num_list\n\n    def sim_aug(self, img, state, type):\n        if type == 'cuda':\n            return  CUDA(img, self.mag[state], self.ops[state], max_d = self.args.max_d)\n        else:\n            return img\n        \n\n    \n    def get_item(self, index, state, train=True):\n        img, target = self.data[index], self.targets[index]\n        img = Image.fromarray(img)\n        \n        if train:\n            if len(self.transform_train) == 1:\n                img = self.transform_train[0][0](img)\n                img = self.aug_transform(img)\n                img = CUDA(img, self.mag[state], self.ops[state])\n                img = self.transform_train[0][1](img)\n                return img, target, index\n\n            elif len(self.transform_train) == 2:\n                img1 = self.transform_train[0][0](img)\n                img1 = self.aug_transform(img1)\n                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n                img1 = self.transform_train[0][1](img1)\n\n                img2 = self.transform_train[1][0](img)\n                img2 = self.sim_aug(img2, state, self.args.sim_type)\n                img2 = self.transform_train[1][1](img2)\n                \n                return (img1, img2), target, index\n                \n            elif len(self.transform_train) == 3:\n                img1 = self.transform_train[0][0](img)\n                img1 = self.aug_transform(img1)\n                img1 = CUDA(img1, self.mag[state], self.ops[state], max_d = self.args.max_d)\n                img1 = self.transform_train[0][1](img1)\n\n                img2 = self.transform_train[1][0](img)\n                img2 = self.sim_aug(img2, state, self.args.sim_type)\n                img2 = self.transform_train[1][1](img2)\n                \n                img3 = self.transform_train[2][0](img)\n                img3 = self.sim_aug(img3, state, self.args.sim_type)\n                img3 = self.transform_train[2][1](img3)\n                return (img1, img2, img3), target, index\n\n        else:\n            img = self.transform_train[0][0](img)\n            img = self.aug_transform(img)\n            img = CUDA(img, self.mag[state], self.ops[state], rand=False , max_d = self.args.max_d)\n            img = self.transform_train[0][1](img)\n            return img, target, index\n        \n    def __getitem__(self, index):\n        state = self.curr_state[index].int() if torch.rand(1) < self.aug_prob else 0\n        \n        img, target, index = self.get_item(index, state, train=True)\n        return img, target, index\n    \n    def update_scores(self, correct, index, state):\n        for s in np.unique(state):\n            pos = np.where(state == s)\n            score_result = np.bincount(index[pos], correct[pos], len(self.score_tmp))\n            num_test_result = np.bincount(index[pos], np.ones(len(index))[pos], len(self.score_tmp))\n            self.score_tmp[:,s] += score_result\n            self.num_test[:,s] += num_test_result\n            \n\n    def update(self):\n        # Increase\n        pos = torch.where((self.score_tmp == self.num_test) & (self.num_test != 0))\n        self.curr_state[pos] += 1\n        \n        # Decrease\n        pos = torch.where(self.score_tmp != self.num_test)\n        self.curr_state[pos] -= 1\n        \n        \n        self.curr_state = torch.clamp(self.curr_state, self.min_state, self.max_state-1)\n        self.score_tmp *= 0\n        self.num_test *= 0\n        \n    \nclass CIFAR100_val(torchvision.datasets.CIFAR100):\n    def __init__(self, root, transform=None, indexs=None,\n                 target_transform=None, download=True):\n        super(CIFAR100_val, self).__init__(root, train=False, transform=transform, target_transform=target_transform,download=download)\n        \n        if indexs is not None:\n            self.data = self.data[indexs]\n            self.targets = np.array(self.targets)[indexs]\n        self.data = [Image.fromarray(img) for img in self.data]\n        \n    def __getitem__(self, index):\n        img, target = self.data[index], self.targets[index]\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n        return img, target, index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Defining Accuracy**","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function, absolute_import\n\nimport errno\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\nfrom torch.autograd import Variable\n\n\n__all__ = ['accuracy', 'AverageMeter']\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].reshape(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\n       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **CMO:cutmix**\n\n**Cutmix function performs CutMix augmentation by blending two images together within a randomly generated bounding box, and it returns the modified background image along with the mixing ratio.**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ndef rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix(data_f, data_b):\n    lam = np.random.beta(1., 1.)\n    bbx1, bby1, bbx2, bby2 = rand_bbox(data_f.size(), lam)\n    data_b[:, :, bbx1:bbx2, bby1:bby2] = data_f[:, :, bbx1:bbx2, bby1:bby2]\n    lam = 1-((bbx2 - bbx1) * (bby2 - bby1) / (data_f.size()[2] * data_f.size()[3]))\n    \n    return data_b, torch.tensor(lam)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **3) Define Train function**","metadata":{}},{"cell_type":"markdown","source":"#### **Updating LOL Score and Training for Base Resnet**\n\n**The update_score_base function is implemented to update the scores and adjust the states of samples classwise within the dataset based on the model's performance for the models CE,CE_DRW and LDAM_DRW.\nIt randomly samples indices and their corresponding states from the dataset based on the number of test samples and the accept rate.It evaluates the model's performance on the sampled data and updates the scores within the dataset accordingly.It adjusts the states of samples within each class based on the accept rate and the ratio of correct predictions to the total number of trials.The commented out part represents the code to disable classwise scoring i.e to have Uniform score across all classes.** \n\n**The train_base function is used as a training loop for the model. It iterates over batches of data from the training loader.If CutMix augmentation is enabled and the epoch is within a specific range, it applies CutMix to the input data.Forward Pass computes the output predictions of the model given the input data.It computes the loss between the model predictions and the ground truth labels.**\n","metadata":{}},{"cell_type":"code","source":"\nfrom __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar\n\nimport copy, time\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\n\n\ndef update_score_base(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    curr_state = loader.dataset.curr_state\n    max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        n = num_test\n        pos, state = [], []\n        ''' \n        for s in range(max_state):\n            entire_pos = torch.arange(len(loader.dataset.targets))\n            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n            pos +=  _pos\n            state += [s] * len(_pos)\n        tmp_dataest = test_CIFAR100(pos,  state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataest, batch_size = 128,             \n                                                 shuffle=False, num_workers = 8)\n        \n        '''\n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            logit = model(data).cpu()\n\n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n\n    \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    \n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    '''\n    \n\n    all_indices = torch.arange(len(loader.dataset.targets))\n    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n\n    ratio = correct_sum_all_classes / trial_sum_all_classes\n    idx = loader.dataset.curr_state[0].int() + 1\n    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n\n    if condition:\n            loader.dataset.curr_state[all_indices] += 1\n    else:\n            loader.dataset.curr_state[all_indices] -= 1\n    '''\n        \n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n\n\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    \n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n\ndef train_base(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n    model.train()\n    \n    global labelfeats\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    bar = Bar('Training', max=len(trainloader))\n\n    \n        \n    \n    if args.cmo and 3 < epoch < (args.epochs - 3):\n        inverse_iter = iter(weighted_trainloader)\n    \n        \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo and 3 < epoch < (args.epochs - 3):\n            try:\n                data_tuple_f = next(inverse_iter)\n            except:\n                inverse_iter = iter(weighted_trainloader)\n                data_tuple_f = next(inverse_iter)\n\n            inputs_f = data_tuple_f[0]\n            targets_f = data_tuple_f[1]\n            inputs_f = inputs_f[:len(inputs_b)]\n            targets_f = targets_f[:len(targets_b)]\n            inputs_f = inputs_f.cuda(non_blocking=True)\n            targets_f = targets_f.cuda(non_blocking=True)\n\n        inputs_b = inputs_b.cuda(non_blocking=True)\n        targets_b = targets_b.cuda(non_blocking=True)\n        #for feature extraction\n        '''\n        if epoch==19:\n            targets_b1 = targets_b.to(labelfeats.device)\n            labelfeats = torch.cat((labelfeats, targets_b1), dim=0)\n            print(\"train_check\")\n        '''\n        \n        r = np.random.rand(1)\n        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n            inputs_b, lam = cutmix(inputs_f, inputs_b)\n            outputs = model(inputs_b,epoch)\n            loss = criterion(outputs, targets_b, epoch) * lam + criterion(outputs, targets_f, epoch) * (1.-lam)\n        else:\n            outputs = model(inputs_b,epoch)\n            loss = criterion(outputs, targets_b, epoch)\n        \n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Updating LOL Score and Training for ResnetBCL**","metadata":{}},{"cell_type":"code","source":"\n\nfrom __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar\n\nimport copy, time\nimport random\n\n#from datasets.cifar100 import test_CIFAR100\n\n\n\ndef update_score_bcl(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    # curr_state = loader.dataset.curr_state\n    # max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        \n        n = num_test\n        pos, state = [], []\n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n \n        \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n            _, logit, _ = model(data)\n            \n            if posthoc_la:\n                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))\n\n            correct = (logit.cpu().max(dim=1)[1] == label).int().detach().cpu()\n            loader.dataset.update_scores(correct,idx, state)\n\n\n            \n    \n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n        \n\n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n\n    \n    \n    # loader.dataset.update()\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n\n\n\ndef train_bcl(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    bar = Bar('Training', max=len(trainloader))\n        \n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n\n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo:\n            raise \"BCL not implemented for CMO...\"\n        else:\n            inputs_b = torch.cat([inputs_b[0], inputs_b[1], inputs_b[2]], dim=0).cuda()\n            batch_size = targets_b.shape[0]\n            targets_b = targets_b.cuda()\n            feat_mlp, logits, centers = model(inputs_b)\n            centers = centers[:args.num_class]\n            _, f2, f3 = torch.split(feat_mlp, [batch_size, batch_size, batch_size], dim=0)\n            features = torch.cat([f2.unsqueeze(1), f3.unsqueeze(1)], dim=1)\n            logits, _, __ = torch.split(logits, [batch_size, batch_size, batch_size], dim=0)\n            loss = criterion(centers, logits, features, targets_b)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        bar.next()\n    bar.finish()\n    return losses.avg\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Updating LOL Score and Training for Base ResnetRide**","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\n\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n#from aug.cutmix import *\n\n#from utils.accuracy import AverageMeter\n#from utils.common import Bar, adjust_learning_rate\n\nimport copy\n\n#from datasets.cifar100 import test_CIFAR100\nimport random\n\ndef update_score_ride(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):\n    model.eval()\n    \n    if posthoc_la:\n        dist = torch.tensor(n_samples_per_class)\n        prob = dist / dist.sum()\n    \n    curr_state = loader.dataset.curr_state\n    max_state = torch.max(curr_state).int() + 1\n    \n    with torch.no_grad():\n        n = num_test\n        pos, state = [], []\n            \n\n    \n    with torch.no_grad():\n        pos, state = [], []\n            \n        n = num_test\n        pos, state = [], []\n        \n        \n        for cidx in range(len(n_samples_per_class)):\n            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n            max_state = loader.dataset.curr_state[class_pos[0]].int() \n            for s in range(max_state+1):\n                _pos = random.choices(class_pos.tolist(), k = n * (s+1))\n                pos += _pos \n                state += [s] * len(_pos)\n        \n        \n        '''\n        \n        for s in range(max_state):\n            entire_pos = torch.arange(len(loader.dataset.targets))\n            _pos = random.choices(entire_pos.tolist(), k = n * (s+1)) \n            pos +=  _pos\n            state += [s] * len(_pos)\n        '''\n\n        \n        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)\n        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)\n        \n\n        for batch_idx, data_tuple in enumerate(tmp_loader):\n            data = data_tuple[0].cuda()\n            label = data_tuple[1]\n            idx = data_tuple[2]\n            state = data_tuple[3]\n\n\n            outputs = model(data, output_type='dict')\n            logit = outputs['logits'].cpu()\n\n            for cor_idx in range(logit.size(1)):\n                if cor_idx == 0:\n                    correct = (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n                else:\n                    correct += (logit[:,cor_idx].max(dim=1)[1] == label).int().detach().cpu()\n            \n            correct = torch.floor(correct/logit.size(1))\n            loader.dataset.update_scores(correct,idx, state)\n    '''\n    all_indices = torch.arange(len(loader.dataset.targets))\n    correct_sum_all_classes = torch.sum(loader.dataset.score_tmp, dim=0)\n    trial_sum_all_classes = torch.sum(loader.dataset.num_test, dim=0)\n\n    ratio = correct_sum_all_classes / trial_sum_all_classes\n    idx = loader.dataset.curr_state[0].int() + 1\n    condition = torch.sum((ratio[:idx] > accept_rate)) == idx\n\n    if condition:\n            loader.dataset.curr_state[all_indices] += 1\n    else:\n            loader.dataset.curr_state[all_indices] -= 1 \n    \n    '''\n    # loader.dataset.update()\n    correct_sum_per_class = torch.zeros(len(n_samples_per_class))\n    trial_sum_per_class = torch.zeros(len(n_samples_per_class))\n    for cidx in range(len(n_samples_per_class)):\n        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]\n        \n        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)\n        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)\n\n\n        ratio = correct_sum_row / trial_sum_row \n        idx = loader.dataset.curr_state[class_pos][0].int() + 1\n        condition = torch.sum((ratio[:idx] > accept_rate)) == idx \n        \n        if condition:\n            loader.dataset.curr_state[class_pos] += 1\n        else:\n            loader.dataset.curr_state[class_pos] -= 1\n    \n        \n\n    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)\n    loader.dataset.score_tmp *= 0\n    loader.dataset.num_test *= 0\n\n\n    model.train()\n    \n    # Debug\n    curr_state = loader.dataset.curr_state\n    label = loader.dataset.targets\n    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')\n\n    return curr_state, label\n\n\n\ndef ride_loss_wrap(criterion, student, teacher, target, extra_info):\n    if teacher == None:\n        return criterion(output_logits = student['output'], target = target, extra_info = extra_info)\n    else:\n        return criterion(student = student['output'], target = target, teacher = teacher, extra_info = extra_info)\n\ndef train_ride(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher):\n    \"\"\"\n    Training logic for an epoch\n    \n    :param epoch: Integer, current training epoch.\n    :return: A log that contains average loss and metric in this epoch.\n    \"\"\"\n    model.train()\n    \n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    end = time.time()\n    \n    if hasattr(criterion, \"_hook_before_epoch\"):\n        criterion._hook_before_epoch(epoch)\n        \n    bar = Bar('Training', max=len(trainloader))\n\n\n    if args.cmo and 3 < epoch < (args.epochs-3):\n        inverse_iter = iter(weighted_trainloader)\n\n    for batch_idx, data_tuple in enumerate(trainloader):\n        inputs_b = data_tuple[0]\n        targets_b = data_tuple[1]\n        indexs = data_tuple[2]\n        \n        # Measure data loading\n        data_time.update(time.time() - end)\n        batch_size = targets_b.size(0)\n        \n        if args.cmo and 3 < epoch < (args.epochs-3):\n            try:\n                data_tuple_f = next(inverse_iter)\n            except:\n                inverse_iter = iter(weighted_trainloader)\n                data_tuple_f = next(inverse_iter)\n                \n            inputs_f = data_tuple_f[0]\n            targets_f = data_tuple_f[1]\n            inputs_f = inputs_f[:len(inputs_b)]\n            targets_f = targets_f[:len(targets_b)]\n            inputs_f = inputs_f.cuda(non_blocking=True)\n            targets_f = targets_f.cuda(non_blocking=True)\n\n\n        inputs_b = inputs_b.cuda(non_blocking=True)\n        targets_b = targets_b.cuda(non_blocking=True)\n\n        r = np.random.rand(1)\n        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:\n            inputs_b, lam = cutmix(inputs_f, inputs_b)\n            outputs =  model(inputs_b)\n            extra_info = {}\n\n            if teacher == None:\n                teacher_outputs = None\n            else:\n                teacher_outputs = teacher(inputs_b)['output']\n            \n            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n                \n            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info) * lam + ride_loss_wrap(criterion, outputs, teacher_outputs, targets_f, extra_info) * (1.-lam)\n            \n            \n        else:\n            extra_info = {}\n            outputs = model(inputs_b)\n\n            \n            if teacher == None:\n                teacher_outputs = None\n            else:\n                teacher_outputs = teacher(inputs_b)['output']\n            \n            extra_info.update({\"logits\" : outputs['logits'].transpose(0,1)})\n            loss = ride_loss_wrap(criterion, outputs, teacher_outputs, targets_b, extra_info)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # record\n        losses.update(loss.item(), targets_b.size(0))\n        batch_time.update(time.time() - end)\n        end = time.time()\n        \n        # plot\n        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                      'Loss: {loss:.4f}'.format(\n                    batch=batch_idx + 1,\n                    size=len(trainloader),\n                    data=data_time.avg,\n                    bt=batch_time.avg,\n                    total=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg,\n                    )\n        \n        bar.next()\n    bar.finish()\n    return losses.avg\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Fetch train function**\n\n**We fetch the respective train function and update score funtion based on the argument loss_fn given on main cell.**","metadata":{}},{"cell_type":"code","source":"#from train.train_fn.base import train_base, update_score_base\n#from train.train_fn.ride import train_ride, update_score_ride\n#from train.train_fn.ncl import train_ncl, update_score_ncl\n#from train.train_fn.bcl import train_bcl, update_score_bcl\n\ndef get_train_fn(args):\n    if args.loss_fn == 'ride':\n        return train_ride\n    elif args.loss_fn == 'bcl':\n        return train_bcl\n    else:\n        return train_base\n\n        \n        \ndef get_update_score_fn(args):\n    if args.loss_fn == 'ride':\n        return update_score_ride\n    elif args.loss_fn == 'bcl':\n        return update_score_bcl\n    else:\n        return update_score_base\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Fetch validate function**\n\n**We fetch the respective validate function and update score funtion based on the argument loss_fn given on main cell.**","metadata":{}},{"cell_type":"code","source":"#from utils.accuracy import AverageMeter, accuracy\nfrom scipy import optimize\n#from utils.common import Bar\nimport torch\nimport numpy as np\nimport time\n\ndef get_valid_fn(args):\n    if args.loss_fn == 'bcl':\n        return valid_bcl\n    else:\n        return valid_normal\n\n\n\ndef valid_normal(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    \n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    all_preds = np.zeros(len(valloader.dataset))\n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            inputs = data_tuple[0].cuda(non_blocking=True)\n            targets = data_tuple[1].cuda(non_blocking=True)\n            indexs = data_tuple[2]\n            \n            # measure data loading time\n            data_time.update(time.time() - end)\n            \n            # compute output\n            outputs = model(inputs, \"train\")\n            loss = criterion(outputs, targets)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n            losses.update(loss.item(), inputs.size(0))\n            top1.update(prec1.item(), inputs.size(0))\n            top5.update(prec5.item(), inputs.size(0))\n            \n            # classwise prediction\n            pred_label = outputs.max(1)[1]\n            all_preds[indexs] = pred_label.cpu().numpy()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        # Major, Neutral, Minor\n        \n        all_targets = np.array(valloader.dataset.targets)\n        pred_mask = (all_targets == all_preds).astype(float)\n        for i in range(num_class):\n            class_mask = np.where(all_targets == i)[0].reshape(-1)\n            classwise_correct[i] += pred_mask[class_mask].sum()\n            classwise_num[i] += len(class_mask)\n            \n        classwise_acc = (classwise_correct / classwise_num)\n        \n        per_class_num = torch.tensor(per_class_num)\n        many_pos = torch.where(per_class_num > 100)\n        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n        few_pos = torch.where(per_class_num < 20)\n        section_acc[0] = classwise_acc[many_pos].mean()\n        section_acc[1] = classwise_acc[med_pos].mean()\n        section_acc[2] = classwise_acc[few_pos].mean()\n\n    return (losses.avg, top1.avg,  section_acc)\n\n\ndef valid_bcl(args, valloader, model, criterion, per_class_num, num_class=10, mode='Test Stats', trainloader = None):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    \n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    bar = Bar(f'{mode}', max=len(valloader))\n    \n    classwise_correct = torch.zeros(num_class)\n    classwise_num = torch.zeros(num_class)\n    section_acc = torch.zeros(3)\n    \n    all_preds = np.zeros(len(valloader.dataset))\n    with torch.no_grad():\n        for batch_idx, data_tuple in enumerate(valloader):\n            inputs = data_tuple[0].cuda(non_blocking=True)\n            targets = data_tuple[1].cuda(non_blocking=True)\n            indexs = data_tuple[2]\n            \n            # measure data loading time\n            data_time.update(time.time() - end)\n            \n            # compute output\n            _, outputs, _ = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # measure accuracy and record loss\n            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n            losses.update(loss.item(), inputs.size(0))\n            top1.update(prec1.item(), inputs.size(0))\n            top5.update(prec5.item(), inputs.size(0))\n            \n            # classwise prediction\n            pred_label = outputs.max(1)[1]\n            all_preds[indexs] = pred_label.cpu().numpy()\n                \n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n                        \n            # plot progress\n            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \\\n                          'Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n                        batch=batch_idx + 1,\n                        size=len(valloader),\n                        data=data_time.avg,\n                        bt=batch_time.avg,\n                        total=bar.elapsed_td,\n                        eta=bar.eta_td,\n                        loss=losses.avg,\n                        top1=top1.avg,\n                        top5=top5.avg,\n                        )\n            bar.next()\n        bar.finish()\n        # Major, Neutral, Minor\n        \n        all_targets = np.array(valloader.dataset.targets)\n        pred_mask = (all_targets == all_preds).astype(float)\n        for i in range(num_class):\n            class_mask = np.where(all_targets == i)[0].reshape(-1)\n            classwise_correct[i] += pred_mask[class_mask].sum()\n            classwise_num[i] += len(class_mask)\n            \n        classwise_acc = (classwise_correct / classwise_num)\n        \n        per_class_num = torch.tensor(per_class_num)\n        many_pos = torch.where(per_class_num > 100)\n        med_pos = torch.where((per_class_num <= 100) & (per_class_num >=20))\n        few_pos = torch.where(per_class_num < 20)\n        section_acc[0] = classwise_acc[many_pos].mean()\n        section_acc[1] = classwise_acc[med_pos].mean()\n        section_acc[2] = classwise_acc[few_pos].mean()\n\n    return (losses.avg, top1.avg,  section_acc)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **4) Defining Models**","metadata":{}},{"cell_type":"markdown","source":"#### **Model:Resnetbcl**","metadata":{}},{"cell_type":"markdown","source":"**The ResNet_s class defines a simplified ResNet architecture with basic blocks (BasicBlock).\nIt consists of three layers, each containing several residual blocks with different numbers of feature maps (16, 32, and 64) and strides (1 or 2).\nThe output feature maps are averaged globally using average pooling.\nThe output shape is flattened to be compatible with fully connected layers.\nHead Layers (head.**\n\n**The head module consists of two fully connected layers followed by batch normalization and ReLU activation.If use_norm is enabled, the output features are normalized using L2 normalization.**\n\n**The fc module is a linear layer mapping the output of the ResNet backbone to the number of classes (num_classes).If use_norm is enabled, the output is further normalized using L2 normalization.**\n\n\n**The head_fc module is similar to the head module but is used specifically for calculating the centers of the classes.It takes the transpose of the weights of the final fully connected layer and processes them through fully connected layers with batch normalization and ReLU activation.\nForward Method**\n\n**In the forward pass, the input data x is passed through the ResNet backbone to extract features.\nThese features are then processed through the head to obtain feature embeddings (feat_mlp) and through the output layer fc to obtain logits (logits).**\n","metadata":{}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n        self.apply(_weights_init)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass LambdaLayer(nn.Module):\n\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='A'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_s(nn.Module):\n\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet_s, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        return out\n\nclass bcl_model(nn.Module):\n    def __init__(self, num_classes=100, use_norm=False):\n        super(bcl_model, self).__init__()\n        self.encoder = ResNet_s(BasicBlock, [5,5,5], num_classes)\n        dim_in = 64 #2048\n        mid_dim = 512 #2048\n        feat_dim = 128 #1024\n        self.use_norm = use_norm\n        self.head = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n        \n        if self.use_norm:\n            self.fc = NormedLinear(dim_in, num_classes)\n        else:\n            self.fc = nn.Linear(dim_in, num_classes)\n        self.head_fc = nn.Sequential(nn.Linear(dim_in, mid_dim), nn.BatchNorm1d(mid_dim), nn.ReLU(inplace=True), nn.Linear(mid_dim, feat_dim))\n\n        self.apply(_weights_init)\n\n\n    def forward(self, x):\n        feat = self.encoder(x)\n        feat_mlp = F.normalize(self.head(feat), dim=1)\n        logits = self.fc(feat)\n        if self.use_norm:\n            centers_logits = F.normalize(self.head_fc(self.fc.weight.T), dim=1)\n        else:\n            centers_logits = F.normalize(self.head_fc(self.fc.weight), dim=1)\n        return feat_mlp, logits, centers_logits\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Model:Resnetride**\n\n\n**It consists of multiple layers of BasicBlock, organized into stages (layer1, layer2s, layer3s), with the number of blocks specified by num_blocks.\nThe number of experts (num_experts) determines how many parallel pathways are used through the network.\nEach expert processes the input independently through its own set of layers and linear transformation (linears).\nThe forward method computes the forward pass through the network, with the option to output either a dictionary containing the final output and logits or just the final output.\nThe model also supports freezing batch normalization layers (_hook_before_iter method) and handling frozen batch normalization layers during training.**","metadata":{}},{"cell_type":"code","source":"import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\nimport random\n\n__all__ = ['resnet32_ride']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_planes, planes, stride=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        \n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n            \n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n    \nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n    \nclass ResNet_s(nn.Module):\n    def __init__(self, block, num_blocks, num_experts, num_classes=10, \n                 reduce_dimension=False, layer2_output_dim=None, \n                 layer3_output_dim=None, use_norm=False, use_experts=None, s=30):\n        super(ResNet_s, self).__init__()\n        \n        self.in_planes = 16\n        self.num_experts = num_experts\n        \n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.in_planes = self.next_in_planes\n        \n        if layer2_output_dim is None:\n            if reduce_dimension:\n                layer2_output_dim = 24\n            else:\n                layer2_output_dim = 32\n                \n        if layer3_output_dim is None:\n            if reduce_dimension:\n                layer3_output_dim = 48\n            else:\n                layer3_output_dim = 64\n                \n        self.layer2s = nn.ModuleList([self._make_layer(block, layer2_output_dim, num_blocks[1], stride=2) for _ in range(num_experts)])\n        self.in_planes = self.next_in_planes\n        self.layer3s = nn.ModuleList([self._make_layer(block, layer3_output_dim, num_blocks[2], stride=2) for _ in range(num_experts)])\n        self.in_planes = self.next_in_planes\n        \n        if use_norm:\n            self.linears = nn.ModuleList([NormedLinear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n        else:\n            self.linears = nn.ModuleList([nn.Linear(layer3_output_dim, num_classes) for _ in range(num_experts)])\n            s = 1\n            \n        if use_experts is None:\n            self.use_experts = list(range(num_experts))\n        elif use_experts == \"rand\":\n            self.use_experts = None\n        else:\n            self.use_experts = [int(item) for item in use_experts.split(\",\")]\n            \n        self.s = s\n        self.apply(_weights_init)\n        \n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        self.next_in_planes = self.in_planes\n        for stride in strides:\n            layers.append(block(self.next_in_planes, planes, stride))\n            self.next_in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n    \n    def _hook_before_iter(self):\n        assert self.training, \"_hook_before_iter should be called at training time only, after train() is called\"\n        count = 0\n        for module in self.modules():\n            if isinstance(module, nn.BatchNorm2d):\n                if module.weight.requires_grad == False:\n                    module.eval()\n                    count += 1\n                    \n        if count > 0:\n            print(\"Warning: detected at least one frozen BN, set them to eval state. Count:\", count)\n            \n    def _separate_part(self, x, ind):\n        out = x\n        out = (self.layer2s[ind])(out)\n        out = (self.layer3s[ind])(out)\n        self.feat_before_GAP.append(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = out.view(out.size(0), -1)\n        self.feat.append(out)\n        out = (self.linears[ind])(out)\n        out = out * self.s\n        return out\n    \n    def forward(self, x, output_type = 'dict'):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        \n        outs = []\n        self.feat = []\n        self.logits = outs\n        self.feat_before_GAP = []\n        \n        if self.use_experts is None:\n            use_experts = random.sample(range(self.num_experts), self.num_experts - 1)\n        else:\n            use_experts = self.use_experts\n            \n        for ind in use_experts:\n            outs.append(self._separate_part(out, ind))\n        final_out = torch.stack(outs, dim=1).mean(dim=1)\n\n        if output_type == 'dict':\n            return {\"output\": final_out, \"logits\": torch.stack(outs, dim=1)}\n        else:\n            return final_out\n        \ndef resnet32_ride(num_class, use_norm=True, num_experts=3):\n    return ResNet_s(BasicBlock, [5,5,5], num_experts, num_classes=num_class, use_norm=use_norm, reduce_dimension=True)\n\ndef test(net):\n    import numpy as np\n    total_params = 0\n\n    for x in filter(lambda p: p.requires_grad, net.parameters()):\n        total_params += np.prod(x.data.numpy().shape)\n    print(\"Total number of params\", total_params)\n    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n    \nif __name__ == \"__main__\":\n    for net_name in __all__:\n        if net_name.startswith(\"resnet\"):\n            print(net_name)\n            test(globals()[net_name](2))\n            print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Model:Resnet**","metadata":{}},{"cell_type":"markdown","source":"**This class defines the ResNet architecture using the specified block type (BasicBlock) and number of blocks per layer.\nIt consists of a series of convolutional layers followed by several blocks (layer1, layer2, layer3), each containing multiple BasicBlock instances.\nThe output of the last layer is passed through average pooling and flattened before being fed into a linear layer (linear), which produces the final logits.\nIf use_norm is enabled, the output of the linear layer is passed through a NormedLinear layer.**","metadata":{}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.nn import Parameter\n\n__all__ = ['resnet32', 'NormedLinear']\n\ndef _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass NormedLinear(nn.Module):\n\n    def __init__(self, in_features, out_features):\n        super(NormedLinear, self).__init__()\n        self.weight = Parameter(torch.Tensor(in_features, out_features))\n        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n\n    def forward(self, x):\n        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n        return out\n\nclass LambdaLayer(nn.Module):\n\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='A'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                \"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet_s(nn.Module):\n\n    def __init__(self, block, num_blocks, num_classes=10, use_norm=False ):\n        super(ResNet_s, self).__init__()\n        self.in_planes = 16\n        self.feat= torch.empty(0)\n        \n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        if use_norm:\n            self.linear = NormedLinear(64, num_classes)\n        else:\n            self.linear = nn.Linear(64, num_classes)\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x, epoch=0):\n        global feats\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out1 = out.view(out.size(0), -1)\n        out = self.linear(out1)\n        \n        #code for feature extraction\n        '''\n        \n        if epoch==199:\n            outo = out1.to(self.feat.device)\n            self.feat = torch.cat((self.feat, outo), dim=0)\n            feats= self.feat\n            print(\"model_check\")\n        '''\n        return out        \n\n\n\ndef resnet32(num_class, use_norm ):\n    return ResNet_s(BasicBlock, [5,5,5], num_class, use_norm=use_norm )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Fetch Model**","metadata":{}},{"cell_type":"code","source":"import torch\nimport shutil\n#from models.resnet import *\n#from models.resnet_ride import *\n#from models.resnet_bcl import *\n#from models.resnet_ncl import *\n\nimport torch.nn as nn\nimport torchvision.models as models\n\ndef get_model(args, num_class_list ):\n    if args.loss_fn in ['ride']:\n        model = resnet32_ride(args.num_class, num_experts=args.num_experts).cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    \n\n    elif args.loss_fn in ['bcl']:\n        model = bcl_model(args.num_class, use_norm=args.use_norm).cuda()\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n\n    \n    else:\n        model = resnet32(args.num_class, use_norm= args.loss_fn == 'ldam_drw').cuda()\n        print(\"res_check\")\n        print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    \n    \n    torch.backends.cudnn.benchmark = True\n    return model   \n    \n\n\ndef load_model(args):\n    if args.loss_fn == 'ride' and args.num_experts == 3 and args.ride_distill:\n        print(\"---- ride teacher load ----\")\n        filepath = os.path.join(args.out, 'checkpoint_teacher.pth.tar')\n        if os.path.isfile(filepath):\n            pass    \n        else:\n            shutil.copy2(os.path.join(args.out, 'checkpoint.pth.tar'), os.path.join(args.out, 'checkpoint_teacher.pth.tar'))\n        checkpoint = torch.load(filepath)\n        teacher = resnet32_ride(args.num_class, num_experts = 6).cuda()\n        teacher.load_state_dict(checkpoint['state_dict'])\n    else:\n        teacher = None\n    return teacher\n    \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **5)Training the models**","metadata":{}},{"cell_type":"markdown","source":"#### **Optimization arguments**","metadata":{}},{"cell_type":"code","source":"import argparse, torch, os, random\nimport numpy as np\n\ndef parse_args(run_type = 'terminal'):\n    parser = argparse.ArgumentParser(description='Python Training')\n    \n    # Optimization options\n    parser.add_argument('--network', default='resnet32', help='Network: resnet32')\n    parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs to run')\n    parser.add_argument('--batch-size', default=128, type=int, metavar='N', help='train batchsize')\n    parser.add_argument('--update-epoch', default=1, type=int, metavar='N', help='Update epoch')\n    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float, metavar='LR', help='initial learning rate')\n    parser.add_argument('--lr_decay', default=0.01, type=float, help='learnign rate decay')\n    parser.add_argument('--momentum', default=0.9, type=float, help='SGD momentum')\n    parser.add_argument('--wd', default=2e-4, type=float, help='weight decay factor for optimizer')\n    parser.add_argument('--nesterov', action='store_true', help=\"Utilizing Nesterov\")\n    parser.add_argument('--scheduler', default='warmup', type=str, help='LR scheduler')\n    parser.add_argument('--warmup', default=5, type=int, help='Warmup epochs')\n        \n    parser.add_argument('--aug_prob', default=0.5, type=float, help='Augmentation Coin-tossing Probability')\n    parser.add_argument('--cutout', action='store_true', help='Utilizing Cutout')\n    parser.add_argument('--cmo', action='store_true', help='Utilizing CMO')\n    parser.add_argument('--posthoc_la', action='store_true', help='Posthoc LA for state update')\n    parser.add_argument('--cuda', action='store_true', help='Use CUDA')\n    parser.add_argument('--aug_type', default='none')\n    parser.add_argument('--sim_type', default='none')\n    parser.add_argument('--max_d', type=int, default=30, help='max_d')\n\n    parser.add_argument('--num_test', default=10, type=int, help='Curriculum Test')\n    parser.add_argument('--accept_rate', type=float, default=0.6, help='Increasing accept ratio')\n    parser.add_argument('--verbose', action='store_true', help='Debug on/off')\n    parser.add_argument('--use_norm', action='store_true', help='Utilize Normed Linear')\n    \n    # Checkpoints\n    parser.add_argument('--out', default='./results/', help='Directory to output the result')\n    parser.add_argument('--data_dir', default='~/dataset/')\n    \n    # Miscs\n    parser.add_argument('--workers', type=int, default=4, help='# workers')\n    parser.add_argument('--seed', type=str, default='None', help='manual seed')\n    parser.add_argument('--gpu', default=None, type=str, help='id(s) for CUDA_VISIBLE_DEVICES')\n    \n    # Dataset options\n    parser.add_argument('--dataset', default='cifar100', help='Dataset: cifar100')\n    parser.add_argument('--num_max', type=int, default=500, help='Number of samples in the maximal class')\n    parser.add_argument('--imb_ratio', type=int, default=100, help='Imbalance ratio for data')\n    \n    # Method options\n    parser.add_argument('--loss_fn', type=str, default='ce', help='Loss function for training')\n    parser.add_argument('--num_experts', type=int, default=3, help='Number of experts for RIDE')\n    parser.add_argument('--ride_distill', action='store_true', help='Use RIDEWithDistill Loss')\n    \n    if run_type == 'terminal':\n        args = parser.parse_args()\n    elif run_type =='jupyter':\n        args = parser.parse_args(args=[])\n        \n    args.out = f'{args.out}{args.dataset}/{args.loss_fn}@N_{args.num_max}_ir_{args.imb_ratio}/'\n    \n    if args.gpu:\n        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n    return args\n\n\ndef reproducibility(seed):\n    if seed == 'None':\n        return\n    else:\n        seed = int(seed)\n        torch.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        np.random.seed(seed)\n        random.seed(seed)\n\ndef dataset_argument(args):\n    if args.dataset == 'cifar100':\n        args.num_class = 100\n    else:\n        args.num_class = 10\n\n    return args\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Logger**","metadata":{}},{"cell_type":"code","source":"import logging\nfrom datetime import datetime\nimport os\nimport torch as t\n\nimport pandas as pd\n\nclass logger:\n    def __init__(self, args):\n            \n        self.logger = logging.getLogger('Evaluation')\n        self.logger.setLevel(logging.INFO)\n        self.args = args\n        \n        formatter = logging.Formatter('%(message)s')\n        \n        strm_handler = logging.StreamHandler()\n        strm_handler.setFormatter(formatter)\n        \n        now = datetime.now()\n        time = f'{now.hour}:{now.minute}:{now.second}-{now.year}-{now.month}-{now.day}'\n        os.makedirs(f'{args.out}',exist_ok=True)\n        file_handler = logging.FileHandler(f'{args.out}/{time.replace(\":\", \"-\")}.txt')\n\n\n        file_handler.setFormatter(formatter)\n                        \n        self.logger.addHandler(strm_handler)\n        self.logger.addHandler(file_handler)\n\n        message = f'---{args.dataset}---'\n        self(message, level=1)\n        self.arg_logging(args)\n\n    def __call__(self,message, level):\n        if level == 1:\n            prefix = '--->' \n        else:\n            prefix = '  '*level + '>'\n        \n        self.logger.info(f'{prefix} {message}')\n\n\n    def arg_logging(self, argument):\n        self('Argument', level=1)\n        arg_dict = vars(argument)\n        for key in arg_dict.keys():\n            if key == 'logger':\n                pass\n            else:\n                self(f'{key:12s}: {arg_dict[key]}', level=2)\n\n    def map_save(self, map):\n        map_df = pd.DataFrame(map)\n        map_df.to_csv(f'{self.args.out}/curriculum.csv',encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Plotting LOL score**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch as t\nimport numpy as np\nimport os\nimport pandas as pd\n\nsns.set_palette(\"bright\")\nsns.set_style(\"darkgrid\")\n\ndef plot_score_epoch(curr_state, label, epoch, maps, out, name='heat'):\n    label = t.tensor(label)\n    \n    num_samples_per_class = t.sum(t.nn.functional.one_hot(label, num_classes=len(t.unique(label))), dim=0)\n    num_samples_sort = t.argsort(num_samples_per_class)\n    \n    for cidx in t.unique(label):\n        pos = t.where(cidx == label)\n        maps[epoch, cidx] = t.mean(curr_state[pos]).numpy()\n\n    # Transpose the matrix before plotting\n    transposed_maps = np.transpose(maps)\n\n    sns.heatmap(transposed_maps, cmap='YlGnBu', vmin=0, vmax=10)\n    plt.xlabel('Epoch')\n    plt.ylabel('Class index')\n\n    # Flip the graph vertically before saving\n    plt.gca().invert_yaxis()\n\n    os.makedirs(f'{out}/score_epoch_plot/', exist_ok=True)\n    plt.savefig(f'{out}/score_epoch_plot/{name}.png')\n\n    plt.close()\n\n    return maps\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.__version__)\nprint(f\"CUDA version: {torch.version.cuda}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Passing arguments**\n\n**The provided code allows you to configure the ResNet variant and its training process by altering the arguments in the Namespace object \"args\". By running the code with different configurations, you can experiment with different settings and evaluate their impact on the model's performance.**","metadata":{}},{"cell_type":"code","source":"#import losses\n\n#from datasets.cifar100 import *\n\n#from train.train import *\n#from train.validate import *\n\n#from models.net import *\n\n#from losses.loss import *\n\n#from utils.config import *\n#from utils.plot import *\n#from utils.common import make_imb_data, save_checkpoint, hms_string\n\n#from utils.logger import logger\n\n#args = parse_args()\n\nfrom argparse import Namespace\n\n# Replace the command below with your actual values\nargs=Namespace(network='resnet32', epochs=200, batch_size=128, update_epoch=1,\n               lr=0.1, lr_decay=0.01, momentum=0.9, wd=0.0002, nesterov=False,\n               scheduler='warmup', warmup=5, aug_prob=0.5, cutout=False, cmo=False,\n               posthoc_la=False, cuda=False, aug_type='none', sim_type='none', max_d=30,\n               num_test=10, accept_rate=0.6, verbose=False, use_norm=False,\n               out='/kaggle/working/log3',\n               data_dir='~/dataset/', workers=4, seed='None',\n               gpu='0', dataset='cifar100', num_max=500, imb_ratio=100,\n               loss_fn='ce_drw', num_experts=3, ride_distill=False)\n\nreproducibility(args.seed)\nargs = dataset_argument(args)\nargs.logger = logger(args)\n\nbest_acc = 0 # best test accuracy\nlabelfeats=torch.empty(0)\ndef main():\n    global best_acc\n    global feats\n    global labelfeats\n    \n    try:\n        assert args.num_max <= 50000. / args.num_class\n    except AssertionError:\n        args.num_max = int(50000 / args.num_class)\n    \n    print(f'==> Preparing imbalanced CIFAR-100')\n    # N_SAMPLES_PER_CLASS = make_imb_data(args.num_max, args.num_class, args.imb_ratio)\n    trainset, testset = get_cifar100(os.path.join(args.data_dir, 'cifar100/'), args)\n    N_SAMPLES_PER_CLASS = trainset.img_num_list\n        \n    trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, drop_last= args.loss_fn == 'ncl', pin_memory=True, sampler=None)\n    testloader = data.DataLoader(testset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True) \n    \n    num_train_samples = len(trainset)\n    print(\"Number of samples in the training dataset:\", num_train_samples)\n\n    \n    if args.cmo:\n        cls_num_list = N_SAMPLES_PER_CLASS\n        cls_weight = 1.0 / (np.array(cls_num_list))\n        cls_weight = cls_weight / np.sum(cls_weight) * len(cls_num_list)\n        labels = trainloader.dataset.targets\n        samples_weight = np.array([cls_weight[t] for t in labels])\n        samples_weight = torch.from_numpy(samples_weight)\n        samples_weight = samples_weight.double()\n        print(\"samples_weight\", samples_weight)\n        sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(labels), replacement=True)\n        weighted_trainloader = data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, sampler=sampler)\n    else:\n        weighted_trainloader = None\n    \n\n    # Model\n    print (\"==> creating {}\".format(args.network))\n    model = get_model(args, N_SAMPLES_PER_CLASS)\n    train_criterion = get_loss(args, N_SAMPLES_PER_CLASS)\n    criterion = nn.CrossEntropyLoss() # For test, validation \n    optimizer = get_optimizer(args, model)\n    scheduler = get_scheduler(args,optimizer)\n\n    teacher = load_model(args)\n\n\n    train = get_train_fn(args)\n    validate = get_valid_fn(args)\n    update_score = get_update_score_fn(args)\n    \n    start_time = time.time()\n    \n    test_accs = []\n    for epoch in range(args.epochs):\n        lr = adjust_learning_rate(optimizer, epoch, scheduler, args)\n        if args.cuda:\n            if epoch % args.update_epoch == 0:\n                curr_state, label = update_score(trainloader, model, N_SAMPLES_PER_CLASS, posthoc_la = args.posthoc_la, num_test = args.num_test, accept_rate = args.accept_rate)\n\n                \n            if args.verbose:\n                if epoch == 0:\n                    maps = np.zeros((args.epochs,args.num_class))\n                maps = plot_score_epoch(curr_state,label, epoch, maps, args.out)\n        train_loss = train(args, trainloader, model, optimizer,train_criterion, epoch, weighted_trainloader, teacher) \n\n\n        test_loss, test_acc, test_cls = validate(args, testloader, model, criterion, N_SAMPLES_PER_CLASS,  num_class=args.num_class, mode='test Valid')\n\n        if best_acc <= test_acc:\n            best_acc = test_acc\n            many_best = test_cls[0]\n            med_best = test_cls[1]\n            few_best = test_cls[2]\n            # Save models\n            save_checkpoint({\n                'epoch': epoch + 1,\n                'state_dict': model['model'].state_dict() if args.loss_fn == 'ncl' else model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, epoch + 1, args.out)\n        test_accs.append(test_acc)\n      \n        \n        args.logger(f'Epoch: [{epoch+1} | {args.epochs}]', level=1)\n        if args.cuda:\n            args.logger(f'Max_state: {int(torch.max(curr_state))}, min_state: {int(torch.min(curr_state))}', level=2)\n        args.logger(f'[Train]\\tLoss:\\t{train_loss:.4f}', level=2)\n        args.logger(f'[Test ]\\tLoss:\\t{test_loss:.4f}\\tAcc:\\t{test_acc:.4f}', level=2)\n        args.logger(f'[Stats]\\tMany:\\t{test_cls[0]:.4f}\\tMedium:\\t{test_cls[1]:.4f}\\tFew:\\t{test_cls[2]:.4f}', level=2)\n        args.logger(f'[Best ]\\tAcc:\\t{np.max(test_accs):.4f}\\tMany:\\t{100*many_best:.4f}\\tMedium:\\t{100*med_best:.4f}\\tFew:\\t{100*few_best:.4f}', level=2)\n        args.logger(f'[Param]\\tLR:\\t{lr:.8f}', level=2)\n\n    \n    end_time = time.time()\n    \n    #\n    \n    max_memory_allocated = torch.cuda.max_memory_allocated() / (1024 ** 2)  # Convert to megabytes\n    print(f\"Max GPU Memory Allocated: {max_memory_allocated:.2f} MB\")\n    current_memory_allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # Convert to megabytes\n    print(f\"Current GPU Memory Allocated: {current_memory_allocated:.2f} MB\")\n    \n    lis=torch.empty(0)\n    lis = lis.to('cpu')\n    \n    print(feats.shape)\n    print(labelfeats.shape)\n\n    # Print the final results\n    args.logger(f'Final performance...', level=1)\n    args.logger(f'best bAcc (test):\\t{np.max(test_accs)}', level=2)\n    args.logger(f'best statistics:\\tMany:\\t{many_best}\\tMed:\\t{med_best}\\tFew:\\t{few_best}', level=2)\n    args.logger(f'Training Time: {hms_string(end_time - start_time)}', level=1)\n    \n\n\n    \n    if args.verbose:\n        args.logger.map_save(maps)\n\nif __name__ == '__main__':\n    main()\n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}